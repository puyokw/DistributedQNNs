{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:09.313929Z",
     "iopub.status.busy": "2023-12-10T08:47:09.313525Z",
     "iopub.status.idle": "2023-12-10T08:47:10.384511Z",
     "shell.execute_reply": "2023-12-10T08:47:10.384093Z"
    },
    "id": "UEv1RLJ01tYq"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import gradcheck\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:10.386846Z",
     "iopub.status.busy": "2023-12-10T08:47:10.386431Z",
     "iopub.status.idle": "2023-12-10T08:47:10.388538Z",
     "shell.execute_reply": "2023-12-10T08:47:10.388163Z"
    },
    "id": "UHp0vfRc1-T_",
    "outputId": "424a5495-7fcc-41d0-e082-e9cc75c019ec"
   },
   "outputs": [],
   "source": [
    "# !pip install torchquantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:10.389893Z",
     "iopub.status.busy": "2023-12-10T08:47:10.389687Z",
     "iopub.status.idle": "2023-12-10T08:47:11.038687Z",
     "shell.execute_reply": "2023-12-10T08:47:11.038182Z"
    },
    "id": "cDueIyyE1-5L"
   },
   "outputs": [],
   "source": [
    "import torchquantum as tq\n",
    "from torchquantum.measurement import expval_joint_analytical\n",
    "import warnings\n",
    "\n",
    "seed = 1001\n",
    "#random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:11.040810Z",
     "iopub.status.busy": "2023-12-10T08:47:11.040525Z",
     "iopub.status.idle": "2023-12-10T08:47:11.256879Z",
     "shell.execute_reply": "2023-12-10T08:47:11.256334Z"
    },
    "id": "UKTP2AJ-1tYs",
    "outputId": "a452f3ac-e509-49fe-f066-10a32eae2bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "semeion_data = torchvision.datasets.SEMEION(root='./data', download=True)\n",
    "dataset_name = 'semeion'\n",
    "data, label = semeion_data.data, semeion_data.labels\n",
    "data = data/255*math.pi/8 # pi/2\n",
    "n_qubits = 8\n",
    "n_class = len(np.unique(label))\n",
    "\n",
    "data = data.reshape(-1,data.shape[1]*data.shape[2])\n",
    "data = torch.from_numpy(data)\n",
    "label = torch.from_numpy(label)\n",
    "n_data, n_features = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:11.272596Z",
     "iopub.status.busy": "2023-12-10T08:47:11.272158Z",
     "iopub.status.idle": "2023-12-10T08:47:11.275171Z",
     "shell.execute_reply": "2023-12-10T08:47:11.274794Z"
    },
    "id": "YPw4rzwS1tYt"
   },
   "outputs": [],
   "source": [
    "class CoeffLayer(nn.Module):\n",
    "    def __init__(self, coeff):\n",
    "        super().__init__()\n",
    "        self.coeff = torch.nn.Parameter(coeff)\n",
    "    def forward(self, x):\n",
    "        ret = x * self.coeff\n",
    "        return ret\n",
    "\n",
    "class ConstCoeffLayer(nn.Module):\n",
    "    def __init__(self, coeff):\n",
    "        super().__init__()\n",
    "        self.coeff = coeff\n",
    "    def forward(self, x):\n",
    "        ret = x * self.coeff\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:11.276634Z",
     "iopub.status.busy": "2023-12-10T08:47:11.276434Z",
     "iopub.status.idle": "2023-12-10T08:47:11.281418Z",
     "shell.execute_reply": "2023-12-10T08:47:11.281043Z"
    },
    "id": "k4_zRBXbk55h"
   },
   "outputs": [],
   "source": [
    "# 16x16 =. 4x8x8\n",
    "class QNNsubModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # params is numpy array\n",
    "        super().__init__()\n",
    "        self.n_wires = n_qubits\n",
    "        self.encoder_gates_x = ([tq.functional.rx] * self.n_wires + [tq.functional.ry] * self.n_wires)*4\n",
    "        self.n_block = 5\n",
    "        self.n_depth_per_block = 20\n",
    "        params = np.random.rand( self.n_wires*self.n_depth_per_block*self.n_block*2)*math.pi\n",
    "        self.u_layers = tq.QuantumModuleList()\n",
    "        for j in range(self.n_depth_per_block*self.n_block):\n",
    "            for i in range(self.n_wires):\n",
    "                self.u_layers.append( tq.RX(has_params=True, trainable=True, init_params=params[i+(2*j)*self.n_wires]) )\n",
    "            for i in range(self.n_wires):\n",
    "                self.u_layers.append( tq.RY(has_params=True, trainable=True, init_params=params[i+(2*j+1)*self.n_wires]) )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, nx_features = x.shape\n",
    "        qdev = tq.QuantumDevice(\n",
    "            n_wires=self.n_wires, bsz = bsz, device=x.device, record_op=False\n",
    "        )\n",
    "        n_depth_per_block = self.n_depth_per_block\n",
    "        for d in range(self.n_block-1): # (2,4)\n",
    "            for k in range(n_depth_per_block):\n",
    "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
    "                    for i in range(self.n_wires):\n",
    "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
    "                for i in range(self.n_wires):\n",
    "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "            # data encoding\n",
    "            for j in range(2*d,2*d+2): # (0,2) (2,4)\n",
    "                for k in range(self.n_wires):\n",
    "                    self.encoder_gates_x[k+j*self.n_wires](qdev, wires=k, params=x[:, (k+j*self.n_wires)])\n",
    "            for i in range(self.n_wires):\n",
    "                qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "        for d in range(self.n_block-1,self.n_block): # (4,5)\n",
    "            for k in range(n_depth_per_block):\n",
    "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
    "                    for i in range(self.n_wires):\n",
    "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
    "                if k==n_depth_per_block-1:\n",
    "                    break\n",
    "                for i in range(self.n_wires):\n",
    "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "\n",
    "        obs_list = [ expval_joint_analytical(qdev, \"I\"*i+Pauli+\"I\"*(self.n_wires-1-i)) for Pauli in [\"X\",\"Z\"] for i in range(n_class//2)]\n",
    "        ret = torch.stack(obs_list, dim=1)\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:11.282831Z",
     "iopub.status.busy": "2023-12-10T08:47:11.282583Z",
     "iopub.status.idle": "2023-12-10T08:47:11.285842Z",
     "shell.execute_reply": "2023-12-10T08:47:11.285094Z"
    },
    "id": "n3w6djyB1tYv"
   },
   "outputs": [],
   "source": [
    "class QNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qnn1 = QNNsubModel()\n",
    "        self.qnn2 = QNNsubModel()\n",
    "        self.qnn3 = QNNsubModel()\n",
    "        self.qnn4 = QNNsubModel()\n",
    "    def forward(self, x):\n",
    "        in_x = [x[:,:64], x[:,64:128], x[:,128:192], x[:,192:256]]\n",
    "        ret1 = self.qnn1(in_x[0]) # 10\n",
    "        ret2 = self.qnn2(in_x[1]) # 10\n",
    "        ret3 = self.qnn3(in_x[2])\n",
    "        ret4 = self.qnn4(in_x[3])\n",
    "        ret = ret1 + ret2 + ret3 + ret4\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:11.287404Z",
     "iopub.status.busy": "2023-12-10T08:47:11.287152Z",
     "iopub.status.idle": "2023-12-10T08:47:11.290113Z",
     "shell.execute_reply": "2023-12-10T08:47:11.289743Z"
    },
    "id": "F-7DW09j1tYv"
   },
   "outputs": [],
   "source": [
    "def train(data, label, model, optimizer):\n",
    "    model.train(mode=True)\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(data)\n",
    "    loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
    "    acc = (pred.argmax(axis=1) == label).sum().item() / len(label)\n",
    "    # acc = accuracy_score(y_tr, pred.argmax(axis=1).cpu().detach().numpy() )\n",
    "    print(f\"train loss: {loss.item():.5f}, train acc: {acc:.3f}\", end=' ')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), acc\n",
    "\n",
    "def valid(data, label, model):\n",
    "    model.train(mode=False)\n",
    "    with torch.no_grad():\n",
    "        pred = model(data)\n",
    "        loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
    "    acc = (pred.argmax(axis=1) == label).sum().item() / len(label)\n",
    "    # acc = accuracy_score(y_te, pred.argmax(axis=1).cpu().detach().numpy() )\n",
    "    print(f\"valid loss: {loss.item():.5f} valid acc: {acc:.3f}\")\n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-12-10T08:47:11.291538Z",
     "iopub.status.busy": "2023-12-10T08:47:11.291305Z",
     "iopub.status.idle": "2023-12-10T10:38:21.459610Z",
     "shell.execute_reply": "2023-12-10T10:38:21.459158Z"
    },
    "id": "MarqNpSo1tYv",
    "outputId": "86cc0213-7f0b-4c6d-e743-658394539f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-0th: train loss: 2.30532, train acc: 0.101 valid loss: 2.18974 valid acc: 0.364\n",
      "0-1th: train loss: 2.18996, train acc: 0.335 valid loss: 2.06880 valid acc: 0.486\n",
      "0-2th: train loss: 2.06948, train acc: 0.490 valid loss: 1.98599 valid acc: 0.542\n",
      "0-3th: train loss: 1.98699, train acc: 0.533 valid loss: 1.93157 valid acc: 0.589\n",
      "0-4th: train loss: 1.93199, train acc: 0.577 valid loss: 1.89812 valid acc: 0.608\n",
      "0-5th: train loss: 1.89704, train acc: 0.604 valid loss: 1.87074 valid acc: 0.636\n",
      "0-6th: train loss: 1.86862, train acc: 0.633 valid loss: 1.84100 valid acc: 0.687\n",
      "0-7th: train loss: 1.83719, train acc: 0.681 valid loss: 1.82666 valid acc: 0.699\n",
      "0-8th: train loss: 1.81995, train acc: 0.699 valid loss: 1.80324 valid acc: 0.724\n",
      "0-9th: train loss: 1.79405, train acc: 0.720 valid loss: 1.78878 valid acc: 0.734\n",
      "0-10th: train loss: 1.77551, train acc: 0.735 valid loss: 1.77187 valid acc: 0.749\n",
      "0-11th: train loss: 1.75566, train acc: 0.758 valid loss: 1.74770 valid acc: 0.790\n",
      "0-12th: train loss: 1.73113, train acc: 0.794 valid loss: 1.74276 valid acc: 0.818\n",
      "0-13th: train loss: 1.72260, train acc: 0.814 valid loss: 1.73265 valid acc: 0.815\n",
      "0-14th: train loss: 1.70939, train acc: 0.824 valid loss: 1.70846 valid acc: 0.831\n",
      "0-15th: train loss: 1.68570, train acc: 0.844 valid loss: 1.69166 valid acc: 0.862\n",
      "0-16th: train loss: 1.66928, train acc: 0.868 valid loss: 1.67517 valid acc: 0.887\n",
      "0-17th: train loss: 1.65058, train acc: 0.895 valid loss: 1.66754 valid acc: 0.881\n",
      "0-18th: train loss: 1.64096, train acc: 0.907 valid loss: 1.64953 valid acc: 0.900\n",
      "0-19th: train loss: 1.62120, train acc: 0.924 valid loss: 1.63985 valid acc: 0.900\n",
      "0-20th: train loss: 1.60803, train acc: 0.930 valid loss: 1.63882 valid acc: 0.909\n",
      "0-21th: train loss: 1.60388, train acc: 0.934 valid loss: 1.62943 valid acc: 0.912\n",
      "0-22th: train loss: 1.59391, train acc: 0.940 valid loss: 1.61907 valid acc: 0.928\n",
      "0-23th: train loss: 1.58434, train acc: 0.946 valid loss: 1.61428 valid acc: 0.918\n",
      "0-24th: train loss: 1.58013, train acc: 0.944 valid loss: 1.61092 valid acc: 0.928\n",
      "0-25th: train loss: 1.57615, train acc: 0.946 valid loss: 1.60627 valid acc: 0.934\n",
      "0-26th: train loss: 1.56975, train acc: 0.950 valid loss: 1.60315 valid acc: 0.928\n",
      "0-27th: train loss: 1.56400, train acc: 0.957 valid loss: 1.60241 valid acc: 0.931\n",
      "0-28th: train loss: 1.56041, train acc: 0.963 valid loss: 1.60117 valid acc: 0.928\n",
      "0-29th: train loss: 1.55708, train acc: 0.964 valid loss: 1.59762 valid acc: 0.940\n",
      "0-30th: train loss: 1.55271, train acc: 0.964 valid loss: 1.59356 valid acc: 0.947\n",
      "0-31th: train loss: 1.54865, train acc: 0.965 valid loss: 1.59065 valid acc: 0.934\n",
      "0-32th: train loss: 1.54568, train acc: 0.965 valid loss: 1.58843 valid acc: 0.940\n",
      "0-33th: train loss: 1.54288, train acc: 0.968 valid loss: 1.58654 valid acc: 0.937\n",
      "0-34th: train loss: 1.53968, train acc: 0.969 valid loss: 1.58524 valid acc: 0.944\n",
      "0-35th: train loss: 1.53653, train acc: 0.970 valid loss: 1.58475 valid acc: 0.944\n",
      "0-36th: train loss: 1.53413, train acc: 0.972 valid loss: 1.58413 valid acc: 0.940\n",
      "0-37th: train loss: 1.53215, train acc: 0.973 valid loss: 1.58222 valid acc: 0.940\n",
      "0-38th: train loss: 1.52966, train acc: 0.973 valid loss: 1.57980 valid acc: 0.940\n",
      "0-39th: train loss: 1.52711, train acc: 0.975 valid loss: 1.57816 valid acc: 0.947\n",
      "0-40th: train loss: 1.52520, train acc: 0.976 valid loss: 1.57728 valid acc: 0.947\n",
      "0-41th: train loss: 1.52359, train acc: 0.977 valid loss: 1.57661 valid acc: 0.947\n",
      "0-42th: train loss: 1.52178, train acc: 0.978 valid loss: 1.57598 valid acc: 0.947\n",
      "0-43th: train loss: 1.51989, train acc: 0.980 valid loss: 1.57545 valid acc: 0.950\n",
      "0-44th: train loss: 1.51825, train acc: 0.980 valid loss: 1.57480 valid acc: 0.947\n",
      "0-45th: train loss: 1.51684, train acc: 0.983 valid loss: 1.57388 valid acc: 0.950\n",
      "0-46th: train loss: 1.51551, train acc: 0.983 valid loss: 1.57276 valid acc: 0.947\n",
      "0-47th: train loss: 1.51415, train acc: 0.984 valid loss: 1.57173 valid acc: 0.950\n",
      "0-48th: train loss: 1.51280, train acc: 0.984 valid loss: 1.57098 valid acc: 0.950\n",
      "0-49th: train loss: 1.51153, train acc: 0.984 valid loss: 1.57044 valid acc: 0.947\n",
      "0-50th: train loss: 1.51038, train acc: 0.984 valid loss: 1.56993 valid acc: 0.944\n",
      "0-51th: train loss: 1.50928, train acc: 0.987 valid loss: 1.56935 valid acc: 0.947\n",
      "0-52th: train loss: 1.50820, train acc: 0.987 valid loss: 1.56868 valid acc: 0.947\n",
      "0-53th: train loss: 1.50714, train acc: 0.987 valid loss: 1.56796 valid acc: 0.953\n",
      "0-54th: train loss: 1.50612, train acc: 0.987 valid loss: 1.56732 valid acc: 0.950\n",
      "0-55th: train loss: 1.50517, train acc: 0.988 valid loss: 1.56683 valid acc: 0.940\n",
      "0-56th: train loss: 1.50433, train acc: 0.988 valid loss: 1.56639 valid acc: 0.937\n",
      "0-57th: train loss: 1.50353, train acc: 0.988 valid loss: 1.56584 valid acc: 0.940\n",
      "0-58th: train loss: 1.50270, train acc: 0.989 valid loss: 1.56520 valid acc: 0.947\n",
      "0-59th: train loss: 1.50190, train acc: 0.989 valid loss: 1.56459 valid acc: 0.944\n",
      "0-60th: train loss: 1.50120, train acc: 0.989 valid loss: 1.56397 valid acc: 0.944\n",
      "0-61th: train loss: 1.50055, train acc: 0.989 valid loss: 1.56332 valid acc: 0.940\n",
      "0-62th: train loss: 1.49988, train acc: 0.989 valid loss: 1.56274 valid acc: 0.940\n",
      "0-63th: train loss: 1.49921, train acc: 0.990 valid loss: 1.56233 valid acc: 0.947\n",
      "0-64th: train loss: 1.49860, train acc: 0.990 valid loss: 1.56201 valid acc: 0.947\n",
      "0-65th: train loss: 1.49801, train acc: 0.990 valid loss: 1.56169 valid acc: 0.944\n",
      "0-66th: train loss: 1.49743, train acc: 0.990 valid loss: 1.56134 valid acc: 0.947\n",
      "0-67th: train loss: 1.49686, train acc: 0.990 valid loss: 1.56096 valid acc: 0.947\n",
      "0-68th: train loss: 1.49633, train acc: 0.991 valid loss: 1.56052 valid acc: 0.947\n",
      "0-69th: train loss: 1.49581, train acc: 0.991 valid loss: 1.56005 valid acc: 0.947\n",
      "0-70th: train loss: 1.49529, train acc: 0.991 valid loss: 1.55965 valid acc: 0.947\n",
      "0-71th: train loss: 1.49481, train acc: 0.991 valid loss: 1.55932 valid acc: 0.947\n",
      "0-72th: train loss: 1.49437, train acc: 0.991 valid loss: 1.55902 valid acc: 0.947\n",
      "0-73th: train loss: 1.49394, train acc: 0.991 valid loss: 1.55873 valid acc: 0.947\n",
      "0-74th: train loss: 1.49351, train acc: 0.992 valid loss: 1.55847 valid acc: 0.947\n",
      "0-75th: train loss: 1.49311, train acc: 0.992 valid loss: 1.55823 valid acc: 0.947\n",
      "0-76th: train loss: 1.49273, train acc: 0.992 valid loss: 1.55798 valid acc: 0.947\n",
      "0-77th: train loss: 1.49236, train acc: 0.992 valid loss: 1.55771 valid acc: 0.947\n",
      "0-78th: train loss: 1.49199, train acc: 0.992 valid loss: 1.55742 valid acc: 0.947\n",
      "0-79th: train loss: 1.49163, train acc: 0.992 valid loss: 1.55709 valid acc: 0.947\n",
      "0-80th: train loss: 1.49129, train acc: 0.992 valid loss: 1.55674 valid acc: 0.947\n",
      "0-81th: train loss: 1.49094, train acc: 0.992 valid loss: 1.55637 valid acc: 0.947\n",
      "0-82th: train loss: 1.49060, train acc: 0.992 valid loss: 1.55602 valid acc: 0.947\n",
      "0-83th: train loss: 1.49028, train acc: 0.992 valid loss: 1.55572 valid acc: 0.947\n",
      "0-84th: train loss: 1.48995, train acc: 0.993 valid loss: 1.55548 valid acc: 0.947\n",
      "0-85th: train loss: 1.48964, train acc: 0.993 valid loss: 1.55528 valid acc: 0.947\n",
      "0-86th: train loss: 1.48932, train acc: 0.993 valid loss: 1.55510 valid acc: 0.947\n",
      "0-87th: train loss: 1.48902, train acc: 0.993 valid loss: 1.55491 valid acc: 0.947\n",
      "0-88th: train loss: 1.48873, train acc: 0.994 valid loss: 1.55468 valid acc: 0.947\n",
      "0-89th: train loss: 1.48845, train acc: 0.994 valid loss: 1.55442 valid acc: 0.947\n",
      "0-90th: train loss: 1.48818, train acc: 0.994 valid loss: 1.55415 valid acc: 0.947\n",
      "0-91th: train loss: 1.48792, train acc: 0.994 valid loss: 1.55391 valid acc: 0.947\n",
      "0-92th: train loss: 1.48767, train acc: 0.994 valid loss: 1.55370 valid acc: 0.947\n",
      "0-93th: train loss: 1.48743, train acc: 0.994 valid loss: 1.55352 valid acc: 0.947\n",
      "0-94th: train loss: 1.48719, train acc: 0.994 valid loss: 1.55336 valid acc: 0.947\n",
      "0-95th: train loss: 1.48697, train acc: 0.994 valid loss: 1.55319 valid acc: 0.947\n",
      "0-96th: train loss: 1.48675, train acc: 0.994 valid loss: 1.55301 valid acc: 0.947\n",
      "0-97th: train loss: 1.48653, train acc: 0.994 valid loss: 1.55281 valid acc: 0.947\n",
      "0-98th: train loss: 1.48632, train acc: 0.994 valid loss: 1.55259 valid acc: 0.947\n",
      "0-99th: train loss: 1.48612, train acc: 0.994 valid loss: 1.55238 valid acc: 0.947\n",
      "0-100th: train loss: 1.48592, train acc: 0.994 valid loss: 1.55216 valid acc: 0.947\n",
      "0-101th: train loss: 1.48572, train acc: 0.994 valid loss: 1.55195 valid acc: 0.947\n",
      "0-102th: train loss: 1.48552, train acc: 0.994 valid loss: 1.55172 valid acc: 0.947\n",
      "0-103th: train loss: 1.48533, train acc: 0.995 valid loss: 1.55150 valid acc: 0.947\n",
      "0-104th: train loss: 1.48514, train acc: 0.995 valid loss: 1.55127 valid acc: 0.947\n",
      "0-105th: train loss: 1.48495, train acc: 0.995 valid loss: 1.55106 valid acc: 0.947\n",
      "0-106th: train loss: 1.48477, train acc: 0.995 valid loss: 1.55086 valid acc: 0.947\n",
      "0-107th: train loss: 1.48459, train acc: 0.995 valid loss: 1.55067 valid acc: 0.947\n",
      "0-108th: train loss: 1.48440, train acc: 0.995 valid loss: 1.55051 valid acc: 0.947\n",
      "0-109th: train loss: 1.48423, train acc: 0.995 valid loss: 1.55034 valid acc: 0.947\n",
      "0-110th: train loss: 1.48405, train acc: 0.995 valid loss: 1.55017 valid acc: 0.947\n",
      "0-111th: train loss: 1.48388, train acc: 0.995 valid loss: 1.54999 valid acc: 0.947\n",
      "0-112th: train loss: 1.48371, train acc: 0.995 valid loss: 1.54980 valid acc: 0.947\n",
      "0-113th: train loss: 1.48354, train acc: 0.995 valid loss: 1.54961 valid acc: 0.947\n",
      "0-114th: train loss: 1.48337, train acc: 0.995 valid loss: 1.54943 valid acc: 0.947\n",
      "0-115th: train loss: 1.48321, train acc: 0.995 valid loss: 1.54927 valid acc: 0.947\n",
      "0-116th: train loss: 1.48305, train acc: 0.995 valid loss: 1.54912 valid acc: 0.950\n",
      "0-117th: train loss: 1.48290, train acc: 0.995 valid loss: 1.54898 valid acc: 0.950\n",
      "0-118th: train loss: 1.48275, train acc: 0.995 valid loss: 1.54884 valid acc: 0.950\n",
      "0-119th: train loss: 1.48261, train acc: 0.995 valid loss: 1.54869 valid acc: 0.950\n",
      "0-120th: train loss: 1.48247, train acc: 0.995 valid loss: 1.54852 valid acc: 0.950\n",
      "0-121th: train loss: 1.48233, train acc: 0.995 valid loss: 1.54835 valid acc: 0.950\n",
      "0-122th: train loss: 1.48220, train acc: 0.995 valid loss: 1.54818 valid acc: 0.950\n",
      "0-123th: train loss: 1.48208, train acc: 0.995 valid loss: 1.54802 valid acc: 0.950\n",
      "0-124th: train loss: 1.48195, train acc: 0.995 valid loss: 1.54787 valid acc: 0.950\n",
      "0-125th: train loss: 1.48183, train acc: 0.995 valid loss: 1.54773 valid acc: 0.950\n",
      "0-126th: train loss: 1.48171, train acc: 0.995 valid loss: 1.54758 valid acc: 0.950\n",
      "0-127th: train loss: 1.48159, train acc: 0.995 valid loss: 1.54744 valid acc: 0.950\n",
      "0-128th: train loss: 1.48148, train acc: 0.995 valid loss: 1.54729 valid acc: 0.950\n",
      "0-129th: train loss: 1.48136, train acc: 0.995 valid loss: 1.54714 valid acc: 0.950\n",
      "0-130th: train loss: 1.48125, train acc: 0.995 valid loss: 1.54700 valid acc: 0.950\n",
      "0-131th: train loss: 1.48114, train acc: 0.995 valid loss: 1.54686 valid acc: 0.950\n",
      "0-132th: train loss: 1.48103, train acc: 0.995 valid loss: 1.54673 valid acc: 0.950\n",
      "0-133th: train loss: 1.48093, train acc: 0.995 valid loss: 1.54660 valid acc: 0.950\n",
      "0-134th: train loss: 1.48082, train acc: 0.995 valid loss: 1.54647 valid acc: 0.950\n",
      "0-135th: train loss: 1.48072, train acc: 0.995 valid loss: 1.54634 valid acc: 0.950\n",
      "0-136th: train loss: 1.48062, train acc: 0.995 valid loss: 1.54621 valid acc: 0.950\n",
      "0-137th: train loss: 1.48052, train acc: 0.995 valid loss: 1.54608 valid acc: 0.950\n",
      "0-138th: train loss: 1.48042, train acc: 0.995 valid loss: 1.54595 valid acc: 0.950\n",
      "0-139th: train loss: 1.48032, train acc: 0.995 valid loss: 1.54583 valid acc: 0.950\n",
      "0-140th: train loss: 1.48023, train acc: 0.995 valid loss: 1.54571 valid acc: 0.950\n",
      "0-141th: train loss: 1.48013, train acc: 0.995 valid loss: 1.54559 valid acc: 0.950\n",
      "0-142th: train loss: 1.48003, train acc: 0.995 valid loss: 1.54547 valid acc: 0.950\n",
      "0-143th: train loss: 1.47993, train acc: 0.995 valid loss: 1.54535 valid acc: 0.950\n",
      "0-144th: train loss: 1.47984, train acc: 0.995 valid loss: 1.54522 valid acc: 0.950\n",
      "0-145th: train loss: 1.47973, train acc: 0.995 valid loss: 1.54509 valid acc: 0.950\n",
      "0-146th: train loss: 1.47963, train acc: 0.995 valid loss: 1.54496 valid acc: 0.950\n",
      "0-147th: train loss: 1.47953, train acc: 0.995 valid loss: 1.54483 valid acc: 0.950\n",
      "0-148th: train loss: 1.47941, train acc: 0.995 valid loss: 1.54471 valid acc: 0.950\n",
      "0-149th: train loss: 1.47930, train acc: 0.996 valid loss: 1.54458 valid acc: 0.950\n",
      "0-150th: train loss: 1.47918, train acc: 0.997 valid loss: 1.54446 valid acc: 0.950\n",
      "0-151th: train loss: 1.47906, train acc: 0.997 valid loss: 1.54435 valid acc: 0.950\n",
      "0-152th: train loss: 1.47893, train acc: 0.997 valid loss: 1.54424 valid acc: 0.950\n",
      "0-153th: train loss: 1.47881, train acc: 0.997 valid loss: 1.54413 valid acc: 0.953\n",
      "0-154th: train loss: 1.47868, train acc: 0.997 valid loss: 1.54404 valid acc: 0.953\n",
      "0-155th: train loss: 1.47857, train acc: 0.997 valid loss: 1.54396 valid acc: 0.956\n",
      "0-156th: train loss: 1.47846, train acc: 0.997 valid loss: 1.54389 valid acc: 0.956\n",
      "0-157th: train loss: 1.47836, train acc: 0.997 valid loss: 1.54384 valid acc: 0.956\n",
      "0-158th: train loss: 1.47827, train acc: 0.997 valid loss: 1.54380 valid acc: 0.956\n",
      "0-159th: train loss: 1.47818, train acc: 0.997 valid loss: 1.54377 valid acc: 0.956\n",
      "0-160th: train loss: 1.47810, train acc: 0.997 valid loss: 1.54375 valid acc: 0.956\n",
      "0-161th: train loss: 1.47802, train acc: 0.997 valid loss: 1.54372 valid acc: 0.956\n",
      "0-162th: train loss: 1.47795, train acc: 0.997 valid loss: 1.54370 valid acc: 0.959\n",
      "0-163th: train loss: 1.47787, train acc: 0.997 valid loss: 1.54368 valid acc: 0.959\n",
      "0-164th: train loss: 1.47779, train acc: 0.997 valid loss: 1.54365 valid acc: 0.959\n",
      "0-165th: train loss: 1.47772, train acc: 0.997 valid loss: 1.54362 valid acc: 0.959\n",
      "0-166th: train loss: 1.47764, train acc: 0.997 valid loss: 1.54359 valid acc: 0.959\n",
      "0-167th: train loss: 1.47757, train acc: 0.997 valid loss: 1.54356 valid acc: 0.956\n",
      "0-168th: train loss: 1.47749, train acc: 0.997 valid loss: 1.54354 valid acc: 0.956\n",
      "0-169th: train loss: 1.47742, train acc: 0.997 valid loss: 1.54350 valid acc: 0.956\n",
      "0-170th: train loss: 1.47735, train acc: 0.997 valid loss: 1.54347 valid acc: 0.956\n",
      "0-171th: train loss: 1.47728, train acc: 0.997 valid loss: 1.54343 valid acc: 0.956\n",
      "0-172th: train loss: 1.47721, train acc: 0.997 valid loss: 1.54338 valid acc: 0.956\n",
      "0-173th: train loss: 1.47714, train acc: 0.997 valid loss: 1.54332 valid acc: 0.956\n",
      "0-174th: train loss: 1.47708, train acc: 0.997 valid loss: 1.54326 valid acc: 0.956\n",
      "0-175th: train loss: 1.47702, train acc: 0.997 valid loss: 1.54319 valid acc: 0.956\n",
      "0-176th: train loss: 1.47695, train acc: 0.997 valid loss: 1.54312 valid acc: 0.956\n",
      "0-177th: train loss: 1.47689, train acc: 0.997 valid loss: 1.54305 valid acc: 0.956\n",
      "0-178th: train loss: 1.47684, train acc: 0.997 valid loss: 1.54297 valid acc: 0.956\n",
      "0-179th: train loss: 1.47678, train acc: 0.997 valid loss: 1.54290 valid acc: 0.956\n",
      "0-180th: train loss: 1.47672, train acc: 0.997 valid loss: 1.54282 valid acc: 0.956\n",
      "0-181th: train loss: 1.47666, train acc: 0.997 valid loss: 1.54275 valid acc: 0.956\n",
      "0-182th: train loss: 1.47661, train acc: 0.997 valid loss: 1.54268 valid acc: 0.956\n",
      "0-183th: train loss: 1.47655, train acc: 0.997 valid loss: 1.54261 valid acc: 0.956\n",
      "0-184th: train loss: 1.47650, train acc: 0.997 valid loss: 1.54255 valid acc: 0.956\n",
      "0-185th: train loss: 1.47645, train acc: 0.997 valid loss: 1.54249 valid acc: 0.956\n",
      "0-186th: train loss: 1.47639, train acc: 0.997 valid loss: 1.54244 valid acc: 0.956\n",
      "0-187th: train loss: 1.47634, train acc: 0.997 valid loss: 1.54240 valid acc: 0.956\n",
      "0-188th: train loss: 1.47629, train acc: 0.997 valid loss: 1.54235 valid acc: 0.956\n",
      "0-189th: train loss: 1.47624, train acc: 0.997 valid loss: 1.54232 valid acc: 0.956\n",
      "0-190th: train loss: 1.47619, train acc: 0.997 valid loss: 1.54228 valid acc: 0.956\n",
      "0-191th: train loss: 1.47614, train acc: 0.997 valid loss: 1.54226 valid acc: 0.956\n",
      "0-192th: train loss: 1.47610, train acc: 0.997 valid loss: 1.54223 valid acc: 0.956\n",
      "0-193th: train loss: 1.47605, train acc: 0.997 valid loss: 1.54222 valid acc: 0.956\n",
      "0-194th: train loss: 1.47600, train acc: 0.997 valid loss: 1.54220 valid acc: 0.956\n",
      "0-195th: train loss: 1.47596, train acc: 0.997 valid loss: 1.54219 valid acc: 0.956\n",
      "0-196th: train loss: 1.47591, train acc: 0.997 valid loss: 1.54218 valid acc: 0.956\n",
      "0-197th: train loss: 1.47587, train acc: 0.997 valid loss: 1.54218 valid acc: 0.956\n",
      "0-198th: train loss: 1.47583, train acc: 0.997 valid loss: 1.54217 valid acc: 0.956\n",
      "0-199th: train loss: 1.47578, train acc: 0.997 valid loss: 1.54216 valid acc: 0.956\n",
      "0-200th: train loss: 1.47574, train acc: 0.997 valid loss: 1.54216 valid acc: 0.953\n",
      "0-201th: train loss: 1.47570, train acc: 0.997 valid loss: 1.54215 valid acc: 0.953\n",
      "0-202th: train loss: 1.47565, train acc: 0.997 valid loss: 1.54214 valid acc: 0.953\n",
      "0-203th: train loss: 1.47561, train acc: 0.997 valid loss: 1.54214 valid acc: 0.953\n",
      "0-204th: train loss: 1.47557, train acc: 0.997 valid loss: 1.54213 valid acc: 0.953\n",
      "0-205th: train loss: 1.47553, train acc: 0.997 valid loss: 1.54212 valid acc: 0.953\n",
      "0-206th: train loss: 1.47549, train acc: 0.997 valid loss: 1.54210 valid acc: 0.953\n",
      "0-207th: train loss: 1.47545, train acc: 0.997 valid loss: 1.54209 valid acc: 0.953\n",
      "0-208th: train loss: 1.47541, train acc: 0.997 valid loss: 1.54208 valid acc: 0.953\n",
      "0-209th: train loss: 1.47537, train acc: 0.997 valid loss: 1.54207 valid acc: 0.953\n",
      "0-210th: train loss: 1.47533, train acc: 0.997 valid loss: 1.54206 valid acc: 0.953\n",
      "0-211th: train loss: 1.47529, train acc: 0.997 valid loss: 1.54205 valid acc: 0.953\n",
      "0-212th: train loss: 1.47525, train acc: 0.997 valid loss: 1.54204 valid acc: 0.953\n",
      "0-213th: train loss: 1.47521, train acc: 0.997 valid loss: 1.54203 valid acc: 0.953\n",
      "0-214th: train loss: 1.47517, train acc: 0.997 valid loss: 1.54202 valid acc: 0.953\n",
      "0-215th: train loss: 1.47513, train acc: 0.997 valid loss: 1.54201 valid acc: 0.953\n",
      "0-216th: train loss: 1.47509, train acc: 0.997 valid loss: 1.54200 valid acc: 0.953\n",
      "0-217th: train loss: 1.47505, train acc: 0.997 valid loss: 1.54200 valid acc: 0.953\n",
      "0-218th: train loss: 1.47500, train acc: 0.997 valid loss: 1.54200 valid acc: 0.953\n",
      "0-219th: train loss: 1.47496, train acc: 0.997 valid loss: 1.54200 valid acc: 0.953\n",
      "0-220th: train loss: 1.47491, train acc: 0.997 valid loss: 1.54200 valid acc: 0.953\n",
      "0-221th: train loss: 1.47485, train acc: 0.998 valid loss: 1.54201 valid acc: 0.953\n",
      "0-222th: train loss: 1.47480, train acc: 0.998 valid loss: 1.54203 valid acc: 0.953\n",
      "0-223th: train loss: 1.47474, train acc: 0.998 valid loss: 1.54204 valid acc: 0.953\n",
      "0-224th: train loss: 1.47467, train acc: 0.998 valid loss: 1.54207 valid acc: 0.953\n",
      "0-225th: train loss: 1.47460, train acc: 0.998 valid loss: 1.54209 valid acc: 0.953\n",
      "0-226th: train loss: 1.47453, train acc: 0.998 valid loss: 1.54212 valid acc: 0.953\n",
      "0-227th: train loss: 1.47447, train acc: 0.998 valid loss: 1.54215 valid acc: 0.953\n",
      "0-228th: train loss: 1.47441, train acc: 0.998 valid loss: 1.54218 valid acc: 0.953\n",
      "0-229th: train loss: 1.47435, train acc: 0.998 valid loss: 1.54221 valid acc: 0.953\n",
      "0-230th: train loss: 1.47431, train acc: 0.998 valid loss: 1.54223 valid acc: 0.953\n",
      "0-231th: train loss: 1.47427, train acc: 0.998 valid loss: 1.54226 valid acc: 0.953\n",
      "0-232th: train loss: 1.47424, train acc: 0.998 valid loss: 1.54228 valid acc: 0.953\n",
      "0-233th: train loss: 1.47421, train acc: 0.998 valid loss: 1.54230 valid acc: 0.953\n",
      "0-234th: train loss: 1.47418, train acc: 0.998 valid loss: 1.54231 valid acc: 0.953\n",
      "0-235th: train loss: 1.47414, train acc: 0.998 valid loss: 1.54233 valid acc: 0.953\n",
      "0-236th: train loss: 1.47411, train acc: 0.998 valid loss: 1.54234 valid acc: 0.953\n",
      "0-237th: train loss: 1.47407, train acc: 0.998 valid loss: 1.54235 valid acc: 0.953\n",
      "0-238th: train loss: 1.47404, train acc: 0.998 valid loss: 1.54235 valid acc: 0.953\n",
      "0-239th: train loss: 1.47400, train acc: 0.998 valid loss: 1.54235 valid acc: 0.953\n",
      "0-240th: train loss: 1.47396, train acc: 0.998 valid loss: 1.54234 valid acc: 0.953\n",
      "0-241th: train loss: 1.47393, train acc: 0.998 valid loss: 1.54233 valid acc: 0.953\n",
      "0-242th: train loss: 1.47389, train acc: 0.998 valid loss: 1.54232 valid acc: 0.953\n",
      "0-243th: train loss: 1.47386, train acc: 0.998 valid loss: 1.54231 valid acc: 0.953\n",
      "0-244th: train loss: 1.47382, train acc: 0.998 valid loss: 1.54230 valid acc: 0.953\n",
      "0-245th: train loss: 1.47379, train acc: 0.998 valid loss: 1.54229 valid acc: 0.953\n",
      "0-246th: train loss: 1.47376, train acc: 0.998 valid loss: 1.54228 valid acc: 0.953\n",
      "0-247th: train loss: 1.47373, train acc: 0.998 valid loss: 1.54227 valid acc: 0.953\n",
      "0-248th: train loss: 1.47370, train acc: 0.998 valid loss: 1.54226 valid acc: 0.953\n",
      "0-249th: train loss: 1.47367, train acc: 0.998 valid loss: 1.54225 valid acc: 0.953\n",
      "0-250th: train loss: 1.47364, train acc: 0.998 valid loss: 1.54224 valid acc: 0.953\n",
      "0-251th: train loss: 1.47362, train acc: 0.998 valid loss: 1.54223 valid acc: 0.953\n",
      "0-252th: train loss: 1.47359, train acc: 0.998 valid loss: 1.54222 valid acc: 0.953\n",
      "0-253th: train loss: 1.47356, train acc: 0.998 valid loss: 1.54222 valid acc: 0.953\n",
      "0-254th: train loss: 1.47354, train acc: 0.998 valid loss: 1.54221 valid acc: 0.953\n",
      "0-255th: train loss: 1.47351, train acc: 0.998 valid loss: 1.54221 valid acc: 0.953\n",
      "0-256th: train loss: 1.47348, train acc: 0.998 valid loss: 1.54221 valid acc: 0.953\n",
      "0-257th: train loss: 1.47346, train acc: 0.998 valid loss: 1.54221 valid acc: 0.953\n",
      "0-258th: train loss: 1.47343, train acc: 0.998 valid loss: 1.54221 valid acc: 0.953\n",
      "0-259th: train loss: 1.47341, train acc: 0.998 valid loss: 1.54222 valid acc: 0.953\n",
      "0-260th: train loss: 1.47338, train acc: 0.998 valid loss: 1.54223 valid acc: 0.953\n",
      "0-261th: train loss: 1.47336, train acc: 0.998 valid loss: 1.54223 valid acc: 0.953\n",
      "0-262th: train loss: 1.47333, train acc: 0.998 valid loss: 1.54224 valid acc: 0.953\n",
      "0-263th: train loss: 1.47331, train acc: 0.998 valid loss: 1.54225 valid acc: 0.953\n",
      "0-264th: train loss: 1.47329, train acc: 0.998 valid loss: 1.54225 valid acc: 0.953\n",
      "0-265th: train loss: 1.47327, train acc: 0.998 valid loss: 1.54226 valid acc: 0.953\n",
      "0-266th: train loss: 1.47324, train acc: 0.998 valid loss: 1.54227 valid acc: 0.953\n",
      "0-267th: train loss: 1.47322, train acc: 0.998 valid loss: 1.54228 valid acc: 0.953\n",
      "0-268th: train loss: 1.47320, train acc: 0.998 valid loss: 1.54229 valid acc: 0.953\n",
      "0-269th: train loss: 1.47318, train acc: 0.998 valid loss: 1.54230 valid acc: 0.953\n",
      "0-270th: train loss: 1.47315, train acc: 0.998 valid loss: 1.54230 valid acc: 0.953\n",
      "0-271th: train loss: 1.47313, train acc: 0.998 valid loss: 1.54231 valid acc: 0.953\n",
      "0-272th: train loss: 1.47311, train acc: 0.998 valid loss: 1.54231 valid acc: 0.953\n",
      "0-273th: train loss: 1.47309, train acc: 0.998 valid loss: 1.54232 valid acc: 0.953\n",
      "0-274th: train loss: 1.47307, train acc: 0.998 valid loss: 1.54232 valid acc: 0.953\n",
      "0-275th: train loss: 1.47305, train acc: 0.998 valid loss: 1.54232 valid acc: 0.953\n",
      "0-276th: train loss: 1.47303, train acc: 0.998 valid loss: 1.54233 valid acc: 0.953\n",
      "0-277th: train loss: 1.47301, train acc: 0.998 valid loss: 1.54233 valid acc: 0.953\n",
      "0-278th: train loss: 1.47299, train acc: 0.998 valid loss: 1.54233 valid acc: 0.953\n",
      "0-279th: train loss: 1.47297, train acc: 0.998 valid loss: 1.54234 valid acc: 0.953\n",
      "0-280th: train loss: 1.47295, train acc: 0.998 valid loss: 1.54234 valid acc: 0.953\n",
      "0-281th: train loss: 1.47293, train acc: 0.998 valid loss: 1.54234 valid acc: 0.953\n",
      "0-282th: train loss: 1.47291, train acc: 0.998 valid loss: 1.54235 valid acc: 0.953\n",
      "0-283th: train loss: 1.47289, train acc: 0.998 valid loss: 1.54235 valid acc: 0.950\n",
      "0-284th: train loss: 1.47287, train acc: 0.998 valid loss: 1.54236 valid acc: 0.950\n",
      "0-285th: train loss: 1.47285, train acc: 0.998 valid loss: 1.54236 valid acc: 0.950\n",
      "0-286th: train loss: 1.47283, train acc: 0.998 valid loss: 1.54237 valid acc: 0.950\n",
      "0-287th: train loss: 1.47281, train acc: 0.998 valid loss: 1.54237 valid acc: 0.950\n",
      "0-288th: train loss: 1.47280, train acc: 0.998 valid loss: 1.54238 valid acc: 0.950\n",
      "0-289th: train loss: 1.47278, train acc: 0.998 valid loss: 1.54239 valid acc: 0.950\n",
      "0-290th: train loss: 1.47276, train acc: 0.998 valid loss: 1.54240 valid acc: 0.950\n",
      "0-291th: train loss: 1.47274, train acc: 0.998 valid loss: 1.54241 valid acc: 0.950\n",
      "0-292th: train loss: 1.47272, train acc: 0.998 valid loss: 1.54242 valid acc: 0.950\n",
      "0-293th: train loss: 1.47270, train acc: 0.998 valid loss: 1.54243 valid acc: 0.950\n",
      "0-294th: train loss: 1.47269, train acc: 0.998 valid loss: 1.54244 valid acc: 0.950\n",
      "0-295th: train loss: 1.47267, train acc: 0.998 valid loss: 1.54245 valid acc: 0.950\n",
      "0-296th: train loss: 1.47265, train acc: 0.998 valid loss: 1.54246 valid acc: 0.950\n",
      "0-297th: train loss: 1.47263, train acc: 0.998 valid loss: 1.54247 valid acc: 0.950\n",
      "0-298th: train loss: 1.47261, train acc: 0.998 valid loss: 1.54249 valid acc: 0.950\n",
      "0-299th: train loss: 1.47259, train acc: 0.998 valid loss: 1.54250 valid acc: 0.950\n",
      "1-0th: train loss: 2.30470, train acc: 0.097 valid loss: 2.18590 valid acc: 0.288\n",
      "1-1th: train loss: 2.18518, train acc: 0.281 valid loss: 2.12070 valid acc: 0.351\n",
      "1-2th: train loss: 2.10749, train acc: 0.372 valid loss: 2.03280 valid acc: 0.467\n",
      "1-3th: train loss: 2.00762, train acc: 0.505 valid loss: 1.98980 valid acc: 0.527\n",
      "1-4th: train loss: 1.96502, train acc: 0.545 valid loss: 1.93804 valid acc: 0.580\n",
      "1-5th: train loss: 1.91316, train acc: 0.622 valid loss: 1.90093 valid acc: 0.633\n",
      "1-6th: train loss: 1.87122, train acc: 0.673 valid loss: 1.87048 valid acc: 0.646\n",
      "1-7th: train loss: 1.83639, train acc: 0.695 valid loss: 1.84266 valid acc: 0.687\n",
      "1-8th: train loss: 1.79884, train acc: 0.738 valid loss: 1.82531 valid acc: 0.696\n",
      "1-9th: train loss: 1.77430, train acc: 0.779 valid loss: 1.81011 valid acc: 0.715\n",
      "1-10th: train loss: 1.75712, train acc: 0.792 valid loss: 1.78368 valid acc: 0.737\n",
      "1-11th: train loss: 1.72967, train acc: 0.814 valid loss: 1.76615 valid acc: 0.762\n",
      "1-12th: train loss: 1.71352, train acc: 0.817 valid loss: 1.75350 valid acc: 0.771\n",
      "1-13th: train loss: 1.70134, train acc: 0.826 valid loss: 1.74278 valid acc: 0.774\n",
      "1-14th: train loss: 1.68791, train acc: 0.836 valid loss: 1.73655 valid acc: 0.781\n",
      "1-15th: train loss: 1.67734, train acc: 0.845 valid loss: 1.73088 valid acc: 0.768\n",
      "1-16th: train loss: 1.66827, train acc: 0.855 valid loss: 1.72093 valid acc: 0.784\n",
      "1-17th: train loss: 1.65606, train acc: 0.866 valid loss: 1.70513 valid acc: 0.828\n",
      "1-18th: train loss: 1.63920, train acc: 0.896 valid loss: 1.69218 valid acc: 0.843\n",
      "1-19th: train loss: 1.62690, train acc: 0.918 valid loss: 1.68892 valid acc: 0.859\n",
      "1-20th: train loss: 1.62428, train acc: 0.918 valid loss: 1.67446 valid acc: 0.862\n",
      "1-21th: train loss: 1.60874, train acc: 0.927 valid loss: 1.66514 valid acc: 0.878\n",
      "1-22th: train loss: 1.59819, train acc: 0.933 valid loss: 1.66065 valid acc: 0.881\n",
      "1-23th: train loss: 1.59273, train acc: 0.936 valid loss: 1.65559 valid acc: 0.881\n",
      "1-24th: train loss: 1.58644, train acc: 0.936 valid loss: 1.65012 valid acc: 0.884\n",
      "1-25th: train loss: 1.57922, train acc: 0.945 valid loss: 1.64574 valid acc: 0.893\n",
      "1-26th: train loss: 1.57309, train acc: 0.951 valid loss: 1.64302 valid acc: 0.893\n",
      "1-27th: train loss: 1.56909, train acc: 0.959 valid loss: 1.64003 valid acc: 0.897\n",
      "1-28th: train loss: 1.56488, train acc: 0.959 valid loss: 1.63613 valid acc: 0.897\n",
      "1-29th: train loss: 1.55998, train acc: 0.967 valid loss: 1.63259 valid acc: 0.897\n",
      "1-30th: train loss: 1.55600, train acc: 0.969 valid loss: 1.62876 valid acc: 0.893\n",
      "1-31th: train loss: 1.55232, train acc: 0.968 valid loss: 1.62502 valid acc: 0.900\n",
      "1-32th: train loss: 1.54861, train acc: 0.970 valid loss: 1.62235 valid acc: 0.909\n",
      "1-33th: train loss: 1.54531, train acc: 0.972 valid loss: 1.62059 valid acc: 0.909\n",
      "1-34th: train loss: 1.54248, train acc: 0.973 valid loss: 1.61892 valid acc: 0.909\n",
      "1-35th: train loss: 1.53983, train acc: 0.974 valid loss: 1.61669 valid acc: 0.912\n",
      "1-36th: train loss: 1.53703, train acc: 0.974 valid loss: 1.61400 valid acc: 0.912\n",
      "1-37th: train loss: 1.53422, train acc: 0.976 valid loss: 1.61149 valid acc: 0.912\n",
      "1-38th: train loss: 1.53185, train acc: 0.977 valid loss: 1.60940 valid acc: 0.922\n",
      "1-39th: train loss: 1.52989, train acc: 0.977 valid loss: 1.60746 valid acc: 0.925\n",
      "1-40th: train loss: 1.52777, train acc: 0.979 valid loss: 1.60567 valid acc: 0.928\n",
      "1-41th: train loss: 1.52536, train acc: 0.980 valid loss: 1.60445 valid acc: 0.928\n",
      "1-42th: train loss: 1.52323, train acc: 0.982 valid loss: 1.60368 valid acc: 0.925\n",
      "1-43th: train loss: 1.52163, train acc: 0.984 valid loss: 1.60253 valid acc: 0.925\n",
      "1-44th: train loss: 1.52013, train acc: 0.984 valid loss: 1.60059 valid acc: 0.925\n",
      "1-45th: train loss: 1.51835, train acc: 0.984 valid loss: 1.59843 valid acc: 0.931\n",
      "1-46th: train loss: 1.51657, train acc: 0.987 valid loss: 1.59687 valid acc: 0.934\n",
      "1-47th: train loss: 1.51513, train acc: 0.987 valid loss: 1.59596 valid acc: 0.931\n",
      "1-48th: train loss: 1.51390, train acc: 0.987 valid loss: 1.59530 valid acc: 0.928\n",
      "1-49th: train loss: 1.51254, train acc: 0.987 valid loss: 1.59479 valid acc: 0.931\n",
      "1-50th: train loss: 1.51111, train acc: 0.987 valid loss: 1.59440 valid acc: 0.937\n",
      "1-51th: train loss: 1.50985, train acc: 0.989 valid loss: 1.59380 valid acc: 0.931\n",
      "1-52th: train loss: 1.50876, train acc: 0.989 valid loss: 1.59270 valid acc: 0.934\n",
      "1-53th: train loss: 1.50765, train acc: 0.989 valid loss: 1.59130 valid acc: 0.937\n",
      "1-54th: train loss: 1.50653, train acc: 0.991 valid loss: 1.59007 valid acc: 0.937\n",
      "1-55th: train loss: 1.50550, train acc: 0.992 valid loss: 1.58921 valid acc: 0.931\n",
      "1-56th: train loss: 1.50456, train acc: 0.992 valid loss: 1.58864 valid acc: 0.931\n",
      "1-57th: train loss: 1.50362, train acc: 0.992 valid loss: 1.58826 valid acc: 0.928\n",
      "1-58th: train loss: 1.50270, train acc: 0.992 valid loss: 1.58792 valid acc: 0.928\n",
      "1-59th: train loss: 1.50185, train acc: 0.992 valid loss: 1.58742 valid acc: 0.925\n",
      "1-60th: train loss: 1.50104, train acc: 0.992 valid loss: 1.58665 valid acc: 0.925\n",
      "1-61th: train loss: 1.50024, train acc: 0.992 valid loss: 1.58572 valid acc: 0.928\n",
      "1-62th: train loss: 1.49947, train acc: 0.992 valid loss: 1.58485 valid acc: 0.931\n",
      "1-63th: train loss: 1.49874, train acc: 0.993 valid loss: 1.58413 valid acc: 0.931\n",
      "1-64th: train loss: 1.49806, train acc: 0.994 valid loss: 1.58354 valid acc: 0.931\n",
      "1-65th: train loss: 1.49739, train acc: 0.994 valid loss: 1.58301 valid acc: 0.931\n",
      "1-66th: train loss: 1.49674, train acc: 0.994 valid loss: 1.58245 valid acc: 0.928\n",
      "1-67th: train loss: 1.49611, train acc: 0.994 valid loss: 1.58180 valid acc: 0.928\n",
      "1-68th: train loss: 1.49550, train acc: 0.995 valid loss: 1.58106 valid acc: 0.931\n",
      "1-69th: train loss: 1.49492, train acc: 0.995 valid loss: 1.58031 valid acc: 0.931\n",
      "1-70th: train loss: 1.49437, train acc: 0.995 valid loss: 1.57963 valid acc: 0.931\n",
      "1-71th: train loss: 1.49384, train acc: 0.995 valid loss: 1.57906 valid acc: 0.931\n",
      "1-72th: train loss: 1.49331, train acc: 0.995 valid loss: 1.57860 valid acc: 0.934\n",
      "1-73th: train loss: 1.49280, train acc: 0.995 valid loss: 1.57821 valid acc: 0.934\n",
      "1-74th: train loss: 1.49232, train acc: 0.995 valid loss: 1.57779 valid acc: 0.934\n",
      "1-75th: train loss: 1.49187, train acc: 0.995 valid loss: 1.57731 valid acc: 0.934\n",
      "1-76th: train loss: 1.49142, train acc: 0.995 valid loss: 1.57680 valid acc: 0.937\n",
      "1-77th: train loss: 1.49098, train acc: 0.995 valid loss: 1.57634 valid acc: 0.937\n",
      "1-78th: train loss: 1.49056, train acc: 0.996 valid loss: 1.57597 valid acc: 0.937\n",
      "1-79th: train loss: 1.49016, train acc: 0.996 valid loss: 1.57568 valid acc: 0.937\n",
      "1-80th: train loss: 1.48977, train acc: 0.996 valid loss: 1.57544 valid acc: 0.937\n",
      "1-81th: train loss: 1.48939, train acc: 0.996 valid loss: 1.57517 valid acc: 0.940\n",
      "1-82th: train loss: 1.48903, train acc: 0.996 valid loss: 1.57484 valid acc: 0.937\n",
      "1-83th: train loss: 1.48868, train acc: 0.996 valid loss: 1.57443 valid acc: 0.937\n",
      "1-84th: train loss: 1.48834, train acc: 0.996 valid loss: 1.57399 valid acc: 0.937\n",
      "1-85th: train loss: 1.48802, train acc: 0.996 valid loss: 1.57360 valid acc: 0.937\n",
      "1-86th: train loss: 1.48771, train acc: 0.996 valid loss: 1.57328 valid acc: 0.937\n",
      "1-87th: train loss: 1.48741, train acc: 0.996 valid loss: 1.57305 valid acc: 0.934\n",
      "1-88th: train loss: 1.48712, train acc: 0.996 valid loss: 1.57287 valid acc: 0.934\n",
      "1-89th: train loss: 1.48683, train acc: 0.996 valid loss: 1.57268 valid acc: 0.934\n",
      "1-90th: train loss: 1.48656, train acc: 0.996 valid loss: 1.57244 valid acc: 0.937\n",
      "1-91th: train loss: 1.48630, train acc: 0.996 valid loss: 1.57213 valid acc: 0.937\n",
      "1-92th: train loss: 1.48604, train acc: 0.996 valid loss: 1.57175 valid acc: 0.937\n",
      "1-93th: train loss: 1.48579, train acc: 0.996 valid loss: 1.57136 valid acc: 0.937\n",
      "1-94th: train loss: 1.48555, train acc: 0.996 valid loss: 1.57100 valid acc: 0.937\n",
      "1-95th: train loss: 1.48531, train acc: 0.996 valid loss: 1.57069 valid acc: 0.937\n",
      "1-96th: train loss: 1.48508, train acc: 0.996 valid loss: 1.57042 valid acc: 0.937\n",
      "1-97th: train loss: 1.48486, train acc: 0.996 valid loss: 1.57018 valid acc: 0.940\n",
      "1-98th: train loss: 1.48464, train acc: 0.996 valid loss: 1.56994 valid acc: 0.940\n",
      "1-99th: train loss: 1.48443, train acc: 0.997 valid loss: 1.56968 valid acc: 0.940\n",
      "1-100th: train loss: 1.48422, train acc: 0.997 valid loss: 1.56941 valid acc: 0.940\n",
      "1-101th: train loss: 1.48402, train acc: 0.997 valid loss: 1.56914 valid acc: 0.940\n",
      "1-102th: train loss: 1.48382, train acc: 0.997 valid loss: 1.56887 valid acc: 0.940\n",
      "1-103th: train loss: 1.48362, train acc: 0.997 valid loss: 1.56861 valid acc: 0.940\n",
      "1-104th: train loss: 1.48343, train acc: 0.997 valid loss: 1.56837 valid acc: 0.940\n",
      "1-105th: train loss: 1.48324, train acc: 0.997 valid loss: 1.56814 valid acc: 0.940\n",
      "1-106th: train loss: 1.48306, train acc: 0.997 valid loss: 1.56792 valid acc: 0.940\n",
      "1-107th: train loss: 1.48288, train acc: 0.997 valid loss: 1.56770 valid acc: 0.940\n",
      "1-108th: train loss: 1.48271, train acc: 0.997 valid loss: 1.56749 valid acc: 0.940\n",
      "1-109th: train loss: 1.48254, train acc: 0.997 valid loss: 1.56728 valid acc: 0.940\n",
      "1-110th: train loss: 1.48237, train acc: 0.997 valid loss: 1.56708 valid acc: 0.940\n",
      "1-111th: train loss: 1.48221, train acc: 0.997 valid loss: 1.56689 valid acc: 0.940\n",
      "1-112th: train loss: 1.48205, train acc: 0.997 valid loss: 1.56670 valid acc: 0.940\n",
      "1-113th: train loss: 1.48190, train acc: 0.997 valid loss: 1.56652 valid acc: 0.940\n",
      "1-114th: train loss: 1.48175, train acc: 0.997 valid loss: 1.56633 valid acc: 0.940\n",
      "1-115th: train loss: 1.48160, train acc: 0.997 valid loss: 1.56615 valid acc: 0.944\n",
      "1-116th: train loss: 1.48146, train acc: 0.997 valid loss: 1.56597 valid acc: 0.944\n",
      "1-117th: train loss: 1.48132, train acc: 0.997 valid loss: 1.56580 valid acc: 0.944\n",
      "1-118th: train loss: 1.48119, train acc: 0.997 valid loss: 1.56565 valid acc: 0.944\n",
      "1-119th: train loss: 1.48105, train acc: 0.997 valid loss: 1.56550 valid acc: 0.944\n",
      "1-120th: train loss: 1.48092, train acc: 0.997 valid loss: 1.56535 valid acc: 0.944\n",
      "1-121th: train loss: 1.48079, train acc: 0.997 valid loss: 1.56521 valid acc: 0.944\n",
      "1-122th: train loss: 1.48067, train acc: 0.997 valid loss: 1.56506 valid acc: 0.944\n",
      "1-123th: train loss: 1.48054, train acc: 0.997 valid loss: 1.56490 valid acc: 0.944\n",
      "1-124th: train loss: 1.48042, train acc: 0.997 valid loss: 1.56475 valid acc: 0.944\n",
      "1-125th: train loss: 1.48031, train acc: 0.997 valid loss: 1.56461 valid acc: 0.944\n",
      "1-126th: train loss: 1.48019, train acc: 0.997 valid loss: 1.56447 valid acc: 0.944\n",
      "1-127th: train loss: 1.48007, train acc: 0.997 valid loss: 1.56434 valid acc: 0.944\n",
      "1-128th: train loss: 1.47996, train acc: 0.997 valid loss: 1.56422 valid acc: 0.944\n",
      "1-129th: train loss: 1.47985, train acc: 0.997 valid loss: 1.56410 valid acc: 0.944\n",
      "1-130th: train loss: 1.47974, train acc: 0.997 valid loss: 1.56398 valid acc: 0.944\n",
      "1-131th: train loss: 1.47964, train acc: 0.997 valid loss: 1.56387 valid acc: 0.944\n",
      "1-132th: train loss: 1.47953, train acc: 0.997 valid loss: 1.56375 valid acc: 0.944\n",
      "1-133th: train loss: 1.47943, train acc: 0.997 valid loss: 1.56364 valid acc: 0.944\n",
      "1-134th: train loss: 1.47933, train acc: 0.997 valid loss: 1.56353 valid acc: 0.944\n",
      "1-135th: train loss: 1.47923, train acc: 0.997 valid loss: 1.56343 valid acc: 0.944\n",
      "1-136th: train loss: 1.47913, train acc: 0.997 valid loss: 1.56332 valid acc: 0.944\n",
      "1-137th: train loss: 1.47903, train acc: 0.997 valid loss: 1.56322 valid acc: 0.944\n",
      "1-138th: train loss: 1.47894, train acc: 0.997 valid loss: 1.56312 valid acc: 0.940\n",
      "1-139th: train loss: 1.47884, train acc: 0.997 valid loss: 1.56301 valid acc: 0.940\n",
      "1-140th: train loss: 1.47874, train acc: 0.997 valid loss: 1.56291 valid acc: 0.944\n",
      "1-141th: train loss: 1.47865, train acc: 0.997 valid loss: 1.56281 valid acc: 0.944\n",
      "1-142th: train loss: 1.47855, train acc: 0.997 valid loss: 1.56272 valid acc: 0.944\n",
      "1-143th: train loss: 1.47846, train acc: 0.997 valid loss: 1.56263 valid acc: 0.944\n",
      "1-144th: train loss: 1.47836, train acc: 0.997 valid loss: 1.56255 valid acc: 0.944\n",
      "1-145th: train loss: 1.47826, train acc: 0.997 valid loss: 1.56248 valid acc: 0.944\n",
      "1-146th: train loss: 1.47817, train acc: 0.997 valid loss: 1.56240 valid acc: 0.944\n",
      "1-147th: train loss: 1.47806, train acc: 0.997 valid loss: 1.56233 valid acc: 0.944\n",
      "1-148th: train loss: 1.47796, train acc: 0.997 valid loss: 1.56227 valid acc: 0.944\n",
      "1-149th: train loss: 1.47785, train acc: 0.997 valid loss: 1.56221 valid acc: 0.944\n",
      "1-150th: train loss: 1.47775, train acc: 0.997 valid loss: 1.56215 valid acc: 0.947\n",
      "1-151th: train loss: 1.47763, train acc: 0.998 valid loss: 1.56211 valid acc: 0.947\n",
      "1-152th: train loss: 1.47752, train acc: 0.998 valid loss: 1.56207 valid acc: 0.947\n",
      "1-153th: train loss: 1.47741, train acc: 0.998 valid loss: 1.56203 valid acc: 0.947\n",
      "1-154th: train loss: 1.47730, train acc: 0.998 valid loss: 1.56200 valid acc: 0.944\n",
      "1-155th: train loss: 1.47720, train acc: 0.998 valid loss: 1.56196 valid acc: 0.944\n",
      "1-156th: train loss: 1.47709, train acc: 0.998 valid loss: 1.56193 valid acc: 0.944\n",
      "1-157th: train loss: 1.47698, train acc: 0.998 valid loss: 1.56191 valid acc: 0.944\n",
      "1-158th: train loss: 1.47688, train acc: 0.998 valid loss: 1.56188 valid acc: 0.947\n",
      "1-159th: train loss: 1.47677, train acc: 0.998 valid loss: 1.56186 valid acc: 0.947\n",
      "1-160th: train loss: 1.47665, train acc: 0.998 valid loss: 1.56184 valid acc: 0.947\n",
      "1-161th: train loss: 1.47653, train acc: 0.999 valid loss: 1.56183 valid acc: 0.947\n",
      "1-162th: train loss: 1.47640, train acc: 0.999 valid loss: 1.56181 valid acc: 0.947\n",
      "1-163th: train loss: 1.47627, train acc: 0.999 valid loss: 1.56179 valid acc: 0.947\n",
      "1-164th: train loss: 1.47615, train acc: 0.999 valid loss: 1.56176 valid acc: 0.947\n",
      "1-165th: train loss: 1.47603, train acc: 0.999 valid loss: 1.56173 valid acc: 0.944\n",
      "1-166th: train loss: 1.47592, train acc: 0.999 valid loss: 1.56170 valid acc: 0.944\n",
      "1-167th: train loss: 1.47582, train acc: 0.999 valid loss: 1.56167 valid acc: 0.944\n",
      "1-168th: train loss: 1.47573, train acc: 0.999 valid loss: 1.56164 valid acc: 0.944\n",
      "1-169th: train loss: 1.47565, train acc: 0.999 valid loss: 1.56161 valid acc: 0.944\n",
      "1-170th: train loss: 1.47557, train acc: 0.999 valid loss: 1.56158 valid acc: 0.944\n",
      "1-171th: train loss: 1.47550, train acc: 0.999 valid loss: 1.56155 valid acc: 0.944\n",
      "1-172th: train loss: 1.47543, train acc: 0.999 valid loss: 1.56150 valid acc: 0.944\n",
      "1-173th: train loss: 1.47536, train acc: 0.999 valid loss: 1.56144 valid acc: 0.944\n",
      "1-174th: train loss: 1.47529, train acc: 0.999 valid loss: 1.56136 valid acc: 0.944\n",
      "1-175th: train loss: 1.47522, train acc: 0.999 valid loss: 1.56127 valid acc: 0.944\n",
      "1-176th: train loss: 1.47515, train acc: 0.999 valid loss: 1.56118 valid acc: 0.944\n",
      "1-177th: train loss: 1.47508, train acc: 0.999 valid loss: 1.56108 valid acc: 0.944\n",
      "1-178th: train loss: 1.47501, train acc: 0.999 valid loss: 1.56097 valid acc: 0.944\n",
      "1-179th: train loss: 1.47494, train acc: 0.999 valid loss: 1.56085 valid acc: 0.944\n",
      "1-180th: train loss: 1.47487, train acc: 0.999 valid loss: 1.56073 valid acc: 0.944\n",
      "1-181th: train loss: 1.47481, train acc: 0.999 valid loss: 1.56059 valid acc: 0.944\n",
      "1-182th: train loss: 1.47474, train acc: 0.999 valid loss: 1.56043 valid acc: 0.944\n",
      "1-183th: train loss: 1.47468, train acc: 0.999 valid loss: 1.56028 valid acc: 0.944\n",
      "1-184th: train loss: 1.47462, train acc: 0.999 valid loss: 1.56012 valid acc: 0.947\n",
      "1-185th: train loss: 1.47457, train acc: 0.999 valid loss: 1.55996 valid acc: 0.947\n",
      "1-186th: train loss: 1.47451, train acc: 0.999 valid loss: 1.55980 valid acc: 0.947\n",
      "1-187th: train loss: 1.47446, train acc: 0.999 valid loss: 1.55964 valid acc: 0.947\n",
      "1-188th: train loss: 1.47440, train acc: 0.999 valid loss: 1.55949 valid acc: 0.947\n",
      "1-189th: train loss: 1.47435, train acc: 0.999 valid loss: 1.55934 valid acc: 0.950\n",
      "1-190th: train loss: 1.47430, train acc: 0.999 valid loss: 1.55919 valid acc: 0.950\n",
      "1-191th: train loss: 1.47425, train acc: 0.999 valid loss: 1.55904 valid acc: 0.950\n",
      "1-192th: train loss: 1.47420, train acc: 0.999 valid loss: 1.55889 valid acc: 0.950\n",
      "1-193th: train loss: 1.47415, train acc: 0.999 valid loss: 1.55876 valid acc: 0.950\n",
      "1-194th: train loss: 1.47411, train acc: 0.999 valid loss: 1.55862 valid acc: 0.950\n",
      "1-195th: train loss: 1.47406, train acc: 0.999 valid loss: 1.55850 valid acc: 0.950\n",
      "1-196th: train loss: 1.47401, train acc: 0.999 valid loss: 1.55838 valid acc: 0.950\n",
      "1-197th: train loss: 1.47397, train acc: 0.999 valid loss: 1.55826 valid acc: 0.950\n",
      "1-198th: train loss: 1.47392, train acc: 0.999 valid loss: 1.55815 valid acc: 0.950\n",
      "1-199th: train loss: 1.47388, train acc: 0.999 valid loss: 1.55804 valid acc: 0.950\n",
      "1-200th: train loss: 1.47384, train acc: 0.999 valid loss: 1.55793 valid acc: 0.950\n",
      "1-201th: train loss: 1.47379, train acc: 0.999 valid loss: 1.55782 valid acc: 0.950\n",
      "1-202th: train loss: 1.47375, train acc: 0.999 valid loss: 1.55772 valid acc: 0.950\n",
      "1-203th: train loss: 1.47371, train acc: 0.999 valid loss: 1.55762 valid acc: 0.950\n",
      "1-204th: train loss: 1.47367, train acc: 0.999 valid loss: 1.55753 valid acc: 0.950\n",
      "1-205th: train loss: 1.47363, train acc: 0.999 valid loss: 1.55743 valid acc: 0.950\n",
      "1-206th: train loss: 1.47359, train acc: 0.999 valid loss: 1.55734 valid acc: 0.950\n",
      "1-207th: train loss: 1.47355, train acc: 0.999 valid loss: 1.55725 valid acc: 0.950\n",
      "1-208th: train loss: 1.47351, train acc: 0.999 valid loss: 1.55716 valid acc: 0.950\n",
      "1-209th: train loss: 1.47347, train acc: 0.999 valid loss: 1.55706 valid acc: 0.950\n",
      "1-210th: train loss: 1.47344, train acc: 0.999 valid loss: 1.55697 valid acc: 0.950\n",
      "1-211th: train loss: 1.47340, train acc: 0.999 valid loss: 1.55688 valid acc: 0.950\n",
      "1-212th: train loss: 1.47336, train acc: 0.999 valid loss: 1.55679 valid acc: 0.950\n",
      "1-213th: train loss: 1.47333, train acc: 0.999 valid loss: 1.55669 valid acc: 0.950\n",
      "1-214th: train loss: 1.47329, train acc: 0.999 valid loss: 1.55660 valid acc: 0.950\n",
      "1-215th: train loss: 1.47326, train acc: 0.999 valid loss: 1.55651 valid acc: 0.950\n",
      "1-216th: train loss: 1.47322, train acc: 0.999 valid loss: 1.55641 valid acc: 0.950\n",
      "1-217th: train loss: 1.47319, train acc: 0.999 valid loss: 1.55632 valid acc: 0.950\n",
      "1-218th: train loss: 1.47315, train acc: 0.999 valid loss: 1.55622 valid acc: 0.950\n",
      "1-219th: train loss: 1.47312, train acc: 0.999 valid loss: 1.55613 valid acc: 0.950\n",
      "1-220th: train loss: 1.47309, train acc: 0.999 valid loss: 1.55603 valid acc: 0.950\n",
      "1-221th: train loss: 1.47305, train acc: 0.999 valid loss: 1.55594 valid acc: 0.950\n",
      "1-222th: train loss: 1.47302, train acc: 0.999 valid loss: 1.55584 valid acc: 0.950\n",
      "1-223th: train loss: 1.47299, train acc: 0.999 valid loss: 1.55575 valid acc: 0.950\n",
      "1-224th: train loss: 1.47296, train acc: 0.999 valid loss: 1.55565 valid acc: 0.950\n",
      "1-225th: train loss: 1.47292, train acc: 0.999 valid loss: 1.55555 valid acc: 0.950\n",
      "1-226th: train loss: 1.47289, train acc: 0.999 valid loss: 1.55546 valid acc: 0.950\n",
      "1-227th: train loss: 1.47286, train acc: 0.999 valid loss: 1.55536 valid acc: 0.950\n",
      "1-228th: train loss: 1.47283, train acc: 0.999 valid loss: 1.55526 valid acc: 0.950\n",
      "1-229th: train loss: 1.47280, train acc: 0.999 valid loss: 1.55517 valid acc: 0.950\n",
      "1-230th: train loss: 1.47277, train acc: 0.999 valid loss: 1.55507 valid acc: 0.950\n",
      "1-231th: train loss: 1.47274, train acc: 0.999 valid loss: 1.55497 valid acc: 0.950\n",
      "1-232th: train loss: 1.47271, train acc: 0.999 valid loss: 1.55488 valid acc: 0.950\n",
      "1-233th: train loss: 1.47268, train acc: 0.999 valid loss: 1.55478 valid acc: 0.950\n",
      "1-234th: train loss: 1.47266, train acc: 0.999 valid loss: 1.55468 valid acc: 0.950\n",
      "1-235th: train loss: 1.47263, train acc: 0.999 valid loss: 1.55459 valid acc: 0.950\n",
      "1-236th: train loss: 1.47260, train acc: 0.999 valid loss: 1.55450 valid acc: 0.950\n",
      "1-237th: train loss: 1.47257, train acc: 0.999 valid loss: 1.55440 valid acc: 0.950\n",
      "1-238th: train loss: 1.47254, train acc: 0.999 valid loss: 1.55431 valid acc: 0.950\n",
      "1-239th: train loss: 1.47252, train acc: 0.999 valid loss: 1.55422 valid acc: 0.950\n",
      "1-240th: train loss: 1.47249, train acc: 0.999 valid loss: 1.55412 valid acc: 0.950\n",
      "1-241th: train loss: 1.47246, train acc: 0.999 valid loss: 1.55403 valid acc: 0.950\n",
      "1-242th: train loss: 1.47244, train acc: 0.999 valid loss: 1.55394 valid acc: 0.950\n",
      "1-243th: train loss: 1.47241, train acc: 0.999 valid loss: 1.55385 valid acc: 0.950\n",
      "1-244th: train loss: 1.47239, train acc: 0.999 valid loss: 1.55376 valid acc: 0.950\n",
      "1-245th: train loss: 1.47236, train acc: 0.999 valid loss: 1.55367 valid acc: 0.950\n",
      "1-246th: train loss: 1.47233, train acc: 0.999 valid loss: 1.55358 valid acc: 0.950\n",
      "1-247th: train loss: 1.47231, train acc: 0.999 valid loss: 1.55349 valid acc: 0.950\n",
      "1-248th: train loss: 1.47228, train acc: 0.999 valid loss: 1.55341 valid acc: 0.950\n",
      "1-249th: train loss: 1.47226, train acc: 0.999 valid loss: 1.55332 valid acc: 0.950\n",
      "1-250th: train loss: 1.47224, train acc: 0.999 valid loss: 1.55323 valid acc: 0.950\n",
      "1-251th: train loss: 1.47221, train acc: 0.999 valid loss: 1.55315 valid acc: 0.950\n",
      "1-252th: train loss: 1.47219, train acc: 0.999 valid loss: 1.55306 valid acc: 0.950\n",
      "1-253th: train loss: 1.47216, train acc: 0.999 valid loss: 1.55297 valid acc: 0.950\n",
      "1-254th: train loss: 1.47214, train acc: 0.999 valid loss: 1.55289 valid acc: 0.950\n",
      "1-255th: train loss: 1.47212, train acc: 0.999 valid loss: 1.55281 valid acc: 0.950\n",
      "1-256th: train loss: 1.47209, train acc: 0.999 valid loss: 1.55272 valid acc: 0.950\n",
      "1-257th: train loss: 1.47207, train acc: 0.999 valid loss: 1.55264 valid acc: 0.947\n",
      "1-258th: train loss: 1.47205, train acc: 0.999 valid loss: 1.55255 valid acc: 0.947\n",
      "1-259th: train loss: 1.47202, train acc: 0.999 valid loss: 1.55247 valid acc: 0.947\n",
      "1-260th: train loss: 1.47200, train acc: 0.999 valid loss: 1.55239 valid acc: 0.947\n",
      "1-261th: train loss: 1.47198, train acc: 0.999 valid loss: 1.55231 valid acc: 0.947\n",
      "1-262th: train loss: 1.47196, train acc: 0.999 valid loss: 1.55223 valid acc: 0.947\n",
      "1-263th: train loss: 1.47194, train acc: 0.999 valid loss: 1.55215 valid acc: 0.947\n",
      "1-264th: train loss: 1.47191, train acc: 0.999 valid loss: 1.55207 valid acc: 0.947\n",
      "1-265th: train loss: 1.47189, train acc: 0.999 valid loss: 1.55199 valid acc: 0.947\n",
      "1-266th: train loss: 1.47187, train acc: 0.999 valid loss: 1.55191 valid acc: 0.947\n",
      "1-267th: train loss: 1.47185, train acc: 0.999 valid loss: 1.55183 valid acc: 0.947\n",
      "1-268th: train loss: 1.47183, train acc: 0.999 valid loss: 1.55175 valid acc: 0.947\n",
      "1-269th: train loss: 1.47181, train acc: 0.999 valid loss: 1.55168 valid acc: 0.947\n",
      "1-270th: train loss: 1.47179, train acc: 0.999 valid loss: 1.55160 valid acc: 0.947\n",
      "1-271th: train loss: 1.47177, train acc: 0.999 valid loss: 1.55152 valid acc: 0.947\n",
      "1-272th: train loss: 1.47175, train acc: 0.999 valid loss: 1.55145 valid acc: 0.947\n",
      "1-273th: train loss: 1.47173, train acc: 0.999 valid loss: 1.55138 valid acc: 0.947\n",
      "1-274th: train loss: 1.47171, train acc: 0.999 valid loss: 1.55130 valid acc: 0.947\n",
      "1-275th: train loss: 1.47169, train acc: 0.999 valid loss: 1.55123 valid acc: 0.947\n",
      "1-276th: train loss: 1.47167, train acc: 0.999 valid loss: 1.55116 valid acc: 0.947\n",
      "1-277th: train loss: 1.47165, train acc: 0.999 valid loss: 1.55109 valid acc: 0.947\n",
      "1-278th: train loss: 1.47163, train acc: 0.999 valid loss: 1.55102 valid acc: 0.947\n",
      "1-279th: train loss: 1.47161, train acc: 0.999 valid loss: 1.55095 valid acc: 0.947\n",
      "1-280th: train loss: 1.47159, train acc: 0.999 valid loss: 1.55088 valid acc: 0.947\n",
      "1-281th: train loss: 1.47157, train acc: 0.999 valid loss: 1.55081 valid acc: 0.947\n",
      "1-282th: train loss: 1.47155, train acc: 0.999 valid loss: 1.55074 valid acc: 0.947\n",
      "1-283th: train loss: 1.47154, train acc: 0.999 valid loss: 1.55067 valid acc: 0.947\n",
      "1-284th: train loss: 1.47152, train acc: 0.999 valid loss: 1.55061 valid acc: 0.950\n",
      "1-285th: train loss: 1.47150, train acc: 0.999 valid loss: 1.55054 valid acc: 0.950\n",
      "1-286th: train loss: 1.47148, train acc: 0.999 valid loss: 1.55048 valid acc: 0.950\n",
      "1-287th: train loss: 1.47146, train acc: 0.999 valid loss: 1.55041 valid acc: 0.950\n",
      "1-288th: train loss: 1.47145, train acc: 0.999 valid loss: 1.55035 valid acc: 0.950\n",
      "1-289th: train loss: 1.47143, train acc: 0.999 valid loss: 1.55029 valid acc: 0.950\n",
      "1-290th: train loss: 1.47141, train acc: 0.999 valid loss: 1.55022 valid acc: 0.950\n",
      "1-291th: train loss: 1.47139, train acc: 0.999 valid loss: 1.55016 valid acc: 0.950\n",
      "1-292th: train loss: 1.47138, train acc: 0.999 valid loss: 1.55010 valid acc: 0.950\n",
      "1-293th: train loss: 1.47136, train acc: 0.999 valid loss: 1.55004 valid acc: 0.950\n",
      "1-294th: train loss: 1.47134, train acc: 0.999 valid loss: 1.54998 valid acc: 0.950\n",
      "1-295th: train loss: 1.47132, train acc: 0.999 valid loss: 1.54992 valid acc: 0.950\n",
      "1-296th: train loss: 1.47131, train acc: 0.999 valid loss: 1.54986 valid acc: 0.950\n",
      "1-297th: train loss: 1.47129, train acc: 0.999 valid loss: 1.54981 valid acc: 0.950\n",
      "1-298th: train loss: 1.47127, train acc: 0.999 valid loss: 1.54975 valid acc: 0.950\n",
      "1-299th: train loss: 1.47126, train acc: 0.999 valid loss: 1.54969 valid acc: 0.950\n",
      "2-0th: train loss: 2.32420, train acc: 0.058 valid loss: 2.22232 valid acc: 0.266\n",
      "2-1th: train loss: 2.21728, train acc: 0.271 valid loss: 2.12966 valid acc: 0.373\n",
      "2-2th: train loss: 2.12360, train acc: 0.378 valid loss: 2.04574 valid acc: 0.473\n",
      "2-3th: train loss: 2.03914, train acc: 0.485 valid loss: 1.97862 valid acc: 0.571\n",
      "2-4th: train loss: 1.97380, train acc: 0.557 valid loss: 1.94827 valid acc: 0.580\n",
      "2-5th: train loss: 1.93868, train acc: 0.579 valid loss: 1.91575 valid acc: 0.586\n",
      "2-6th: train loss: 1.90407, train acc: 0.599 valid loss: 1.88189 valid acc: 0.621\n",
      "2-7th: train loss: 1.86904, train acc: 0.633 valid loss: 1.85600 valid acc: 0.649\n",
      "2-8th: train loss: 1.84073, train acc: 0.674 valid loss: 1.84323 valid acc: 0.655\n",
      "2-9th: train loss: 1.83272, train acc: 0.674 valid loss: 1.82477 valid acc: 0.687\n",
      "2-10th: train loss: 1.81388, train acc: 0.686 valid loss: 1.80892 valid acc: 0.693\n",
      "2-11th: train loss: 1.79302, train acc: 0.703 valid loss: 1.80515 valid acc: 0.702\n",
      "2-12th: train loss: 1.78620, train acc: 0.710 valid loss: 1.80005 valid acc: 0.708\n",
      "2-13th: train loss: 1.77990, train acc: 0.711 valid loss: 1.78464 valid acc: 0.721\n",
      "2-14th: train loss: 1.76445, train acc: 0.732 valid loss: 1.76360 valid acc: 0.762\n",
      "2-15th: train loss: 1.74431, train acc: 0.779 valid loss: 1.75382 valid acc: 0.777\n",
      "2-16th: train loss: 1.73504, train acc: 0.796 valid loss: 1.74391 valid acc: 0.777\n",
      "2-17th: train loss: 1.72258, train acc: 0.810 valid loss: 1.73252 valid acc: 0.790\n",
      "2-18th: train loss: 1.70726, train acc: 0.821 valid loss: 1.72226 valid acc: 0.793\n",
      "2-19th: train loss: 1.69334, train acc: 0.826 valid loss: 1.71146 valid acc: 0.815\n",
      "2-20th: train loss: 1.68026, train acc: 0.838 valid loss: 1.70587 valid acc: 0.828\n",
      "2-21th: train loss: 1.67321, train acc: 0.844 valid loss: 1.70294 valid acc: 0.831\n",
      "2-22th: train loss: 1.66899, train acc: 0.849 valid loss: 1.69639 valid acc: 0.831\n",
      "2-23th: train loss: 1.66075, train acc: 0.853 valid loss: 1.69144 valid acc: 0.843\n",
      "2-24th: train loss: 1.65359, train acc: 0.859 valid loss: 1.69121 valid acc: 0.834\n",
      "2-25th: train loss: 1.65117, train acc: 0.859 valid loss: 1.68808 valid acc: 0.834\n",
      "2-26th: train loss: 1.64712, train acc: 0.865 valid loss: 1.68190 valid acc: 0.834\n",
      "2-27th: train loss: 1.64093, train acc: 0.867 valid loss: 1.67820 valid acc: 0.834\n",
      "2-28th: train loss: 1.63669, train acc: 0.868 valid loss: 1.67473 valid acc: 0.837\n",
      "2-29th: train loss: 1.63197, train acc: 0.872 valid loss: 1.66766 valid acc: 0.853\n",
      "2-30th: train loss: 1.62356, train acc: 0.887 valid loss: 1.65668 valid acc: 0.875\n",
      "2-31th: train loss: 1.61127, train acc: 0.904 valid loss: 1.64607 valid acc: 0.909\n",
      "2-32th: train loss: 1.59979, train acc: 0.934 valid loss: 1.64212 valid acc: 0.915\n",
      "2-33th: train loss: 1.59578, train acc: 0.940 valid loss: 1.62610 valid acc: 0.922\n",
      "2-34th: train loss: 1.58030, train acc: 0.951 valid loss: 1.61699 valid acc: 0.931\n",
      "2-35th: train loss: 1.57161, train acc: 0.950 valid loss: 1.61235 valid acc: 0.925\n",
      "2-36th: train loss: 1.56690, train acc: 0.950 valid loss: 1.60632 valid acc: 0.931\n",
      "2-37th: train loss: 1.56024, train acc: 0.955 valid loss: 1.60096 valid acc: 0.947\n",
      "2-38th: train loss: 1.55446, train acc: 0.965 valid loss: 1.59834 valid acc: 0.944\n",
      "2-39th: train loss: 1.55137, train acc: 0.966 valid loss: 1.59573 valid acc: 0.947\n",
      "2-40th: train loss: 1.54842, train acc: 0.968 valid loss: 1.59202 valid acc: 0.950\n",
      "2-41th: train loss: 1.54475, train acc: 0.969 valid loss: 1.58909 valid acc: 0.956\n",
      "2-42th: train loss: 1.54186, train acc: 0.972 valid loss: 1.58714 valid acc: 0.953\n",
      "2-43th: train loss: 1.53953, train acc: 0.973 valid loss: 1.58611 valid acc: 0.947\n",
      "2-44th: train loss: 1.53739, train acc: 0.975 valid loss: 1.58531 valid acc: 0.947\n",
      "2-45th: train loss: 1.53520, train acc: 0.977 valid loss: 1.58356 valid acc: 0.950\n",
      "2-46th: train loss: 1.53262, train acc: 0.976 valid loss: 1.58163 valid acc: 0.950\n",
      "2-47th: train loss: 1.53037, train acc: 0.976 valid loss: 1.58007 valid acc: 0.956\n",
      "2-48th: train loss: 1.52864, train acc: 0.976 valid loss: 1.57812 valid acc: 0.953\n",
      "2-49th: train loss: 1.52656, train acc: 0.977 valid loss: 1.57600 valid acc: 0.950\n",
      "2-50th: train loss: 1.52417, train acc: 0.978 valid loss: 1.57471 valid acc: 0.950\n",
      "2-51th: train loss: 1.52226, train acc: 0.979 valid loss: 1.57422 valid acc: 0.953\n",
      "2-52th: train loss: 1.52082, train acc: 0.980 valid loss: 1.57361 valid acc: 0.953\n",
      "2-53th: train loss: 1.51921, train acc: 0.980 valid loss: 1.57265 valid acc: 0.953\n",
      "2-54th: train loss: 1.51743, train acc: 0.980 valid loss: 1.57189 valid acc: 0.953\n",
      "2-55th: train loss: 1.51601, train acc: 0.981 valid loss: 1.57138 valid acc: 0.950\n",
      "2-56th: train loss: 1.51491, train acc: 0.983 valid loss: 1.57066 valid acc: 0.950\n",
      "2-57th: train loss: 1.51370, train acc: 0.983 valid loss: 1.56974 valid acc: 0.950\n",
      "2-58th: train loss: 1.51234, train acc: 0.983 valid loss: 1.56907 valid acc: 0.950\n",
      "2-59th: train loss: 1.51115, train acc: 0.983 valid loss: 1.56876 valid acc: 0.950\n",
      "2-60th: train loss: 1.51022, train acc: 0.982 valid loss: 1.56847 valid acc: 0.956\n",
      "2-61th: train loss: 1.50926, train acc: 0.984 valid loss: 1.56802 valid acc: 0.953\n",
      "2-62th: train loss: 1.50818, train acc: 0.984 valid loss: 1.56763 valid acc: 0.947\n",
      "2-63th: train loss: 1.50718, train acc: 0.986 valid loss: 1.56738 valid acc: 0.947\n",
      "2-64th: train loss: 1.50636, train acc: 0.986 valid loss: 1.56705 valid acc: 0.950\n",
      "2-65th: train loss: 1.50558, train acc: 0.988 valid loss: 1.56647 valid acc: 0.950\n",
      "2-66th: train loss: 1.50471, train acc: 0.988 valid loss: 1.56578 valid acc: 0.950\n",
      "2-67th: train loss: 1.50385, train acc: 0.988 valid loss: 1.56520 valid acc: 0.953\n",
      "2-68th: train loss: 1.50310, train acc: 0.988 valid loss: 1.56473 valid acc: 0.953\n",
      "2-69th: train loss: 1.50240, train acc: 0.988 valid loss: 1.56426 valid acc: 0.953\n",
      "2-70th: train loss: 1.50167, train acc: 0.989 valid loss: 1.56379 valid acc: 0.950\n",
      "2-71th: train loss: 1.50092, train acc: 0.990 valid loss: 1.56339 valid acc: 0.950\n",
      "2-72th: train loss: 1.50023, train acc: 0.990 valid loss: 1.56300 valid acc: 0.950\n",
      "2-73th: train loss: 1.49962, train acc: 0.990 valid loss: 1.56253 valid acc: 0.950\n",
      "2-74th: train loss: 1.49901, train acc: 0.990 valid loss: 1.56196 valid acc: 0.950\n",
      "2-75th: train loss: 1.49839, train acc: 0.990 valid loss: 1.56140 valid acc: 0.947\n",
      "2-76th: train loss: 1.49781, train acc: 0.991 valid loss: 1.56091 valid acc: 0.947\n",
      "2-77th: train loss: 1.49728, train acc: 0.991 valid loss: 1.56048 valid acc: 0.947\n",
      "2-78th: train loss: 1.49676, train acc: 0.991 valid loss: 1.56008 valid acc: 0.947\n",
      "2-79th: train loss: 1.49625, train acc: 0.991 valid loss: 1.55972 valid acc: 0.947\n",
      "2-80th: train loss: 1.49576, train acc: 0.991 valid loss: 1.55937 valid acc: 0.947\n",
      "2-81th: train loss: 1.49528, train acc: 0.991 valid loss: 1.55901 valid acc: 0.947\n",
      "2-82th: train loss: 1.49483, train acc: 0.992 valid loss: 1.55863 valid acc: 0.947\n",
      "2-83th: train loss: 1.49440, train acc: 0.992 valid loss: 1.55825 valid acc: 0.947\n",
      "2-84th: train loss: 1.49397, train acc: 0.992 valid loss: 1.55788 valid acc: 0.947\n",
      "2-85th: train loss: 1.49355, train acc: 0.992 valid loss: 1.55754 valid acc: 0.947\n",
      "2-86th: train loss: 1.49315, train acc: 0.992 valid loss: 1.55722 valid acc: 0.947\n",
      "2-87th: train loss: 1.49276, train acc: 0.992 valid loss: 1.55691 valid acc: 0.947\n",
      "2-88th: train loss: 1.49237, train acc: 0.992 valid loss: 1.55659 valid acc: 0.947\n",
      "2-89th: train loss: 1.49199, train acc: 0.992 valid loss: 1.55624 valid acc: 0.947\n",
      "2-90th: train loss: 1.49162, train acc: 0.993 valid loss: 1.55588 valid acc: 0.947\n",
      "2-91th: train loss: 1.49125, train acc: 0.993 valid loss: 1.55553 valid acc: 0.947\n",
      "2-92th: train loss: 1.49089, train acc: 0.993 valid loss: 1.55520 valid acc: 0.947\n",
      "2-93th: train loss: 1.49053, train acc: 0.994 valid loss: 1.55488 valid acc: 0.947\n",
      "2-94th: train loss: 1.49017, train acc: 0.994 valid loss: 1.55457 valid acc: 0.947\n",
      "2-95th: train loss: 1.48982, train acc: 0.994 valid loss: 1.55427 valid acc: 0.947\n",
      "2-96th: train loss: 1.48947, train acc: 0.995 valid loss: 1.55396 valid acc: 0.947\n",
      "2-97th: train loss: 1.48913, train acc: 0.995 valid loss: 1.55363 valid acc: 0.947\n",
      "2-98th: train loss: 1.48879, train acc: 0.995 valid loss: 1.55332 valid acc: 0.947\n",
      "2-99th: train loss: 1.48846, train acc: 0.995 valid loss: 1.55303 valid acc: 0.947\n",
      "2-100th: train loss: 1.48813, train acc: 0.995 valid loss: 1.55277 valid acc: 0.947\n",
      "2-101th: train loss: 1.48780, train acc: 0.995 valid loss: 1.55252 valid acc: 0.947\n",
      "2-102th: train loss: 1.48746, train acc: 0.995 valid loss: 1.55227 valid acc: 0.947\n",
      "2-103th: train loss: 1.48712, train acc: 0.996 valid loss: 1.55203 valid acc: 0.947\n",
      "2-104th: train loss: 1.48677, train acc: 0.996 valid loss: 1.55178 valid acc: 0.947\n",
      "2-105th: train loss: 1.48642, train acc: 0.996 valid loss: 1.55154 valid acc: 0.950\n",
      "2-106th: train loss: 1.48606, train acc: 0.997 valid loss: 1.55133 valid acc: 0.950\n",
      "2-107th: train loss: 1.48571, train acc: 0.998 valid loss: 1.55116 valid acc: 0.956\n",
      "2-108th: train loss: 1.48538, train acc: 0.998 valid loss: 1.55104 valid acc: 0.956\n",
      "2-109th: train loss: 1.48506, train acc: 0.998 valid loss: 1.55095 valid acc: 0.956\n",
      "2-110th: train loss: 1.48477, train acc: 0.998 valid loss: 1.55085 valid acc: 0.956\n",
      "2-111th: train loss: 1.48451, train acc: 0.998 valid loss: 1.55071 valid acc: 0.956\n",
      "2-112th: train loss: 1.48427, train acc: 0.998 valid loss: 1.55053 valid acc: 0.956\n",
      "2-113th: train loss: 1.48404, train acc: 0.998 valid loss: 1.55030 valid acc: 0.956\n",
      "2-114th: train loss: 1.48382, train acc: 0.998 valid loss: 1.55005 valid acc: 0.953\n",
      "2-115th: train loss: 1.48361, train acc: 0.998 valid loss: 1.54982 valid acc: 0.953\n",
      "2-116th: train loss: 1.48340, train acc: 0.998 valid loss: 1.54960 valid acc: 0.953\n",
      "2-117th: train loss: 1.48318, train acc: 0.998 valid loss: 1.54940 valid acc: 0.953\n",
      "2-118th: train loss: 1.48297, train acc: 0.998 valid loss: 1.54920 valid acc: 0.953\n",
      "2-119th: train loss: 1.48276, train acc: 0.998 valid loss: 1.54899 valid acc: 0.953\n",
      "2-120th: train loss: 1.48256, train acc: 0.998 valid loss: 1.54875 valid acc: 0.953\n",
      "2-121th: train loss: 1.48236, train acc: 0.998 valid loss: 1.54847 valid acc: 0.953\n",
      "2-122th: train loss: 1.48217, train acc: 0.998 valid loss: 1.54818 valid acc: 0.953\n",
      "2-123th: train loss: 1.48199, train acc: 0.998 valid loss: 1.54787 valid acc: 0.953\n",
      "2-124th: train loss: 1.48181, train acc: 0.998 valid loss: 1.54758 valid acc: 0.953\n",
      "2-125th: train loss: 1.48164, train acc: 0.998 valid loss: 1.54729 valid acc: 0.953\n",
      "2-126th: train loss: 1.48148, train acc: 0.998 valid loss: 1.54703 valid acc: 0.953\n",
      "2-127th: train loss: 1.48132, train acc: 0.998 valid loss: 1.54677 valid acc: 0.953\n",
      "2-128th: train loss: 1.48116, train acc: 0.998 valid loss: 1.54653 valid acc: 0.953\n",
      "2-129th: train loss: 1.48101, train acc: 0.998 valid loss: 1.54629 valid acc: 0.953\n",
      "2-130th: train loss: 1.48087, train acc: 0.998 valid loss: 1.54605 valid acc: 0.953\n",
      "2-131th: train loss: 1.48072, train acc: 0.998 valid loss: 1.54582 valid acc: 0.950\n",
      "2-132th: train loss: 1.48058, train acc: 0.998 valid loss: 1.54560 valid acc: 0.950\n",
      "2-133th: train loss: 1.48044, train acc: 0.998 valid loss: 1.54539 valid acc: 0.950\n",
      "2-134th: train loss: 1.48030, train acc: 0.998 valid loss: 1.54519 valid acc: 0.950\n",
      "2-135th: train loss: 1.48017, train acc: 0.998 valid loss: 1.54499 valid acc: 0.953\n",
      "2-136th: train loss: 1.48003, train acc: 0.998 valid loss: 1.54480 valid acc: 0.953\n",
      "2-137th: train loss: 1.47991, train acc: 0.998 valid loss: 1.54462 valid acc: 0.953\n",
      "2-138th: train loss: 1.47978, train acc: 0.998 valid loss: 1.54443 valid acc: 0.953\n",
      "2-139th: train loss: 1.47966, train acc: 0.998 valid loss: 1.54425 valid acc: 0.953\n",
      "2-140th: train loss: 1.47954, train acc: 0.998 valid loss: 1.54406 valid acc: 0.953\n",
      "2-141th: train loss: 1.47942, train acc: 0.998 valid loss: 1.54388 valid acc: 0.953\n",
      "2-142th: train loss: 1.47931, train acc: 0.998 valid loss: 1.54370 valid acc: 0.953\n",
      "2-143th: train loss: 1.47919, train acc: 0.998 valid loss: 1.54353 valid acc: 0.953\n",
      "2-144th: train loss: 1.47908, train acc: 0.998 valid loss: 1.54336 valid acc: 0.953\n",
      "2-145th: train loss: 1.47897, train acc: 0.998 valid loss: 1.54319 valid acc: 0.953\n",
      "2-146th: train loss: 1.47886, train acc: 0.998 valid loss: 1.54302 valid acc: 0.953\n",
      "2-147th: train loss: 1.47875, train acc: 0.998 valid loss: 1.54286 valid acc: 0.953\n",
      "2-148th: train loss: 1.47864, train acc: 0.998 valid loss: 1.54269 valid acc: 0.953\n",
      "2-149th: train loss: 1.47854, train acc: 0.998 valid loss: 1.54252 valid acc: 0.953\n",
      "2-150th: train loss: 1.47843, train acc: 0.998 valid loss: 1.54234 valid acc: 0.953\n",
      "2-151th: train loss: 1.47832, train acc: 0.998 valid loss: 1.54217 valid acc: 0.953\n",
      "2-152th: train loss: 1.47822, train acc: 0.998 valid loss: 1.54200 valid acc: 0.953\n",
      "2-153th: train loss: 1.47811, train acc: 0.998 valid loss: 1.54185 valid acc: 0.953\n",
      "2-154th: train loss: 1.47801, train acc: 0.998 valid loss: 1.54169 valid acc: 0.953\n",
      "2-155th: train loss: 1.47790, train acc: 0.999 valid loss: 1.54155 valid acc: 0.956\n",
      "2-156th: train loss: 1.47780, train acc: 0.999 valid loss: 1.54142 valid acc: 0.956\n",
      "2-157th: train loss: 1.47769, train acc: 0.999 valid loss: 1.54129 valid acc: 0.956\n",
      "2-158th: train loss: 1.47759, train acc: 0.999 valid loss: 1.54116 valid acc: 0.956\n",
      "2-159th: train loss: 1.47749, train acc: 0.999 valid loss: 1.54104 valid acc: 0.956\n",
      "2-160th: train loss: 1.47739, train acc: 0.999 valid loss: 1.54092 valid acc: 0.956\n",
      "2-161th: train loss: 1.47730, train acc: 0.999 valid loss: 1.54080 valid acc: 0.956\n",
      "2-162th: train loss: 1.47721, train acc: 0.999 valid loss: 1.54069 valid acc: 0.956\n",
      "2-163th: train loss: 1.47712, train acc: 0.999 valid loss: 1.54058 valid acc: 0.956\n",
      "2-164th: train loss: 1.47703, train acc: 0.999 valid loss: 1.54047 valid acc: 0.956\n",
      "2-165th: train loss: 1.47695, train acc: 0.999 valid loss: 1.54036 valid acc: 0.956\n",
      "2-166th: train loss: 1.47686, train acc: 0.999 valid loss: 1.54025 valid acc: 0.956\n",
      "2-167th: train loss: 1.47678, train acc: 0.999 valid loss: 1.54014 valid acc: 0.956\n",
      "2-168th: train loss: 1.47670, train acc: 0.999 valid loss: 1.54003 valid acc: 0.956\n",
      "2-169th: train loss: 1.47662, train acc: 0.999 valid loss: 1.53991 valid acc: 0.956\n",
      "2-170th: train loss: 1.47655, train acc: 0.999 valid loss: 1.53979 valid acc: 0.956\n",
      "2-171th: train loss: 1.47647, train acc: 0.999 valid loss: 1.53968 valid acc: 0.959\n",
      "2-172th: train loss: 1.47640, train acc: 0.999 valid loss: 1.53956 valid acc: 0.959\n",
      "2-173th: train loss: 1.47632, train acc: 0.999 valid loss: 1.53944 valid acc: 0.959\n",
      "2-174th: train loss: 1.47625, train acc: 0.999 valid loss: 1.53932 valid acc: 0.959\n",
      "2-175th: train loss: 1.47618, train acc: 0.999 valid loss: 1.53920 valid acc: 0.959\n",
      "2-176th: train loss: 1.47611, train acc: 0.999 valid loss: 1.53908 valid acc: 0.959\n",
      "2-177th: train loss: 1.47604, train acc: 0.999 valid loss: 1.53895 valid acc: 0.959\n",
      "2-178th: train loss: 1.47597, train acc: 0.999 valid loss: 1.53883 valid acc: 0.959\n",
      "2-179th: train loss: 1.47591, train acc: 0.999 valid loss: 1.53871 valid acc: 0.959\n",
      "2-180th: train loss: 1.47584, train acc: 0.999 valid loss: 1.53859 valid acc: 0.962\n",
      "2-181th: train loss: 1.47578, train acc: 0.999 valid loss: 1.53847 valid acc: 0.962\n",
      "2-182th: train loss: 1.47572, train acc: 0.999 valid loss: 1.53836 valid acc: 0.962\n",
      "2-183th: train loss: 1.47566, train acc: 0.999 valid loss: 1.53824 valid acc: 0.962\n",
      "2-184th: train loss: 1.47559, train acc: 0.999 valid loss: 1.53814 valid acc: 0.966\n",
      "2-185th: train loss: 1.47554, train acc: 0.999 valid loss: 1.53803 valid acc: 0.966\n",
      "2-186th: train loss: 1.47548, train acc: 0.999 valid loss: 1.53793 valid acc: 0.966\n",
      "2-187th: train loss: 1.47542, train acc: 0.999 valid loss: 1.53782 valid acc: 0.966\n",
      "2-188th: train loss: 1.47536, train acc: 0.999 valid loss: 1.53772 valid acc: 0.966\n",
      "2-189th: train loss: 1.47531, train acc: 0.999 valid loss: 1.53763 valid acc: 0.966\n",
      "2-190th: train loss: 1.47525, train acc: 0.999 valid loss: 1.53753 valid acc: 0.966\n",
      "2-191th: train loss: 1.47520, train acc: 0.999 valid loss: 1.53744 valid acc: 0.966\n",
      "2-192th: train loss: 1.47514, train acc: 0.999 valid loss: 1.53735 valid acc: 0.966\n",
      "2-193th: train loss: 1.47509, train acc: 0.999 valid loss: 1.53726 valid acc: 0.966\n",
      "2-194th: train loss: 1.47504, train acc: 0.999 valid loss: 1.53717 valid acc: 0.966\n",
      "2-195th: train loss: 1.47499, train acc: 0.999 valid loss: 1.53708 valid acc: 0.966\n",
      "2-196th: train loss: 1.47494, train acc: 0.999 valid loss: 1.53699 valid acc: 0.966\n",
      "2-197th: train loss: 1.47488, train acc: 0.999 valid loss: 1.53691 valid acc: 0.966\n",
      "2-198th: train loss: 1.47484, train acc: 0.999 valid loss: 1.53682 valid acc: 0.966\n",
      "2-199th: train loss: 1.47479, train acc: 0.999 valid loss: 1.53673 valid acc: 0.966\n",
      "2-200th: train loss: 1.47474, train acc: 0.999 valid loss: 1.53664 valid acc: 0.966\n",
      "2-201th: train loss: 1.47469, train acc: 0.999 valid loss: 1.53656 valid acc: 0.966\n",
      "2-202th: train loss: 1.47464, train acc: 0.999 valid loss: 1.53647 valid acc: 0.966\n",
      "2-203th: train loss: 1.47460, train acc: 0.999 valid loss: 1.53638 valid acc: 0.966\n",
      "2-204th: train loss: 1.47455, train acc: 0.999 valid loss: 1.53630 valid acc: 0.966\n",
      "2-205th: train loss: 1.47451, train acc: 0.999 valid loss: 1.53621 valid acc: 0.966\n",
      "2-206th: train loss: 1.47446, train acc: 0.999 valid loss: 1.53612 valid acc: 0.966\n",
      "2-207th: train loss: 1.47442, train acc: 0.999 valid loss: 1.53603 valid acc: 0.966\n",
      "2-208th: train loss: 1.47438, train acc: 0.999 valid loss: 1.53595 valid acc: 0.966\n",
      "2-209th: train loss: 1.47433, train acc: 0.999 valid loss: 1.53586 valid acc: 0.966\n",
      "2-210th: train loss: 1.47429, train acc: 0.999 valid loss: 1.53578 valid acc: 0.966\n",
      "2-211th: train loss: 1.47425, train acc: 0.999 valid loss: 1.53569 valid acc: 0.966\n",
      "2-212th: train loss: 1.47421, train acc: 0.999 valid loss: 1.53561 valid acc: 0.966\n",
      "2-213th: train loss: 1.47417, train acc: 0.999 valid loss: 1.53552 valid acc: 0.966\n",
      "2-214th: train loss: 1.47413, train acc: 0.999 valid loss: 1.53544 valid acc: 0.966\n",
      "2-215th: train loss: 1.47409, train acc: 0.999 valid loss: 1.53535 valid acc: 0.966\n",
      "2-216th: train loss: 1.47405, train acc: 0.999 valid loss: 1.53527 valid acc: 0.969\n",
      "2-217th: train loss: 1.47401, train acc: 0.999 valid loss: 1.53518 valid acc: 0.969\n",
      "2-218th: train loss: 1.47397, train acc: 0.999 valid loss: 1.53510 valid acc: 0.969\n",
      "2-219th: train loss: 1.47393, train acc: 0.999 valid loss: 1.53501 valid acc: 0.969\n",
      "2-220th: train loss: 1.47390, train acc: 0.999 valid loss: 1.53493 valid acc: 0.969\n",
      "2-221th: train loss: 1.47386, train acc: 0.999 valid loss: 1.53485 valid acc: 0.969\n",
      "2-222th: train loss: 1.47382, train acc: 0.999 valid loss: 1.53476 valid acc: 0.969\n",
      "2-223th: train loss: 1.47379, train acc: 0.999 valid loss: 1.53468 valid acc: 0.969\n",
      "2-224th: train loss: 1.47375, train acc: 0.999 valid loss: 1.53459 valid acc: 0.969\n",
      "2-225th: train loss: 1.47371, train acc: 0.999 valid loss: 1.53451 valid acc: 0.969\n",
      "2-226th: train loss: 1.47368, train acc: 0.999 valid loss: 1.53443 valid acc: 0.969\n",
      "2-227th: train loss: 1.47365, train acc: 0.999 valid loss: 1.53434 valid acc: 0.969\n",
      "2-228th: train loss: 1.47361, train acc: 0.999 valid loss: 1.53426 valid acc: 0.969\n",
      "2-229th: train loss: 1.47358, train acc: 0.999 valid loss: 1.53418 valid acc: 0.969\n",
      "2-230th: train loss: 1.47354, train acc: 0.999 valid loss: 1.53410 valid acc: 0.969\n",
      "2-231th: train loss: 1.47351, train acc: 0.999 valid loss: 1.53402 valid acc: 0.969\n",
      "2-232th: train loss: 1.47348, train acc: 0.999 valid loss: 1.53393 valid acc: 0.969\n",
      "2-233th: train loss: 1.47345, train acc: 0.999 valid loss: 1.53385 valid acc: 0.969\n",
      "2-234th: train loss: 1.47341, train acc: 0.999 valid loss: 1.53377 valid acc: 0.969\n",
      "2-235th: train loss: 1.47338, train acc: 0.999 valid loss: 1.53369 valid acc: 0.969\n",
      "2-236th: train loss: 1.47335, train acc: 0.999 valid loss: 1.53361 valid acc: 0.969\n",
      "2-237th: train loss: 1.47332, train acc: 0.999 valid loss: 1.53353 valid acc: 0.969\n",
      "2-238th: train loss: 1.47329, train acc: 0.999 valid loss: 1.53345 valid acc: 0.969\n",
      "2-239th: train loss: 1.47326, train acc: 0.999 valid loss: 1.53337 valid acc: 0.969\n",
      "2-240th: train loss: 1.47323, train acc: 0.999 valid loss: 1.53329 valid acc: 0.969\n",
      "2-241th: train loss: 1.47320, train acc: 0.999 valid loss: 1.53321 valid acc: 0.969\n",
      "2-242th: train loss: 1.47317, train acc: 0.999 valid loss: 1.53313 valid acc: 0.969\n",
      "2-243th: train loss: 1.47314, train acc: 0.999 valid loss: 1.53305 valid acc: 0.969\n",
      "2-244th: train loss: 1.47311, train acc: 0.999 valid loss: 1.53297 valid acc: 0.969\n",
      "2-245th: train loss: 1.47309, train acc: 0.999 valid loss: 1.53289 valid acc: 0.969\n",
      "2-246th: train loss: 1.47306, train acc: 0.999 valid loss: 1.53281 valid acc: 0.969\n",
      "2-247th: train loss: 1.47303, train acc: 0.999 valid loss: 1.53273 valid acc: 0.969\n",
      "2-248th: train loss: 1.47300, train acc: 0.999 valid loss: 1.53265 valid acc: 0.969\n",
      "2-249th: train loss: 1.47298, train acc: 0.999 valid loss: 1.53257 valid acc: 0.969\n",
      "2-250th: train loss: 1.47295, train acc: 0.999 valid loss: 1.53249 valid acc: 0.969\n",
      "2-251th: train loss: 1.47292, train acc: 0.999 valid loss: 1.53241 valid acc: 0.969\n",
      "2-252th: train loss: 1.47290, train acc: 0.999 valid loss: 1.53233 valid acc: 0.969\n",
      "2-253th: train loss: 1.47287, train acc: 0.999 valid loss: 1.53225 valid acc: 0.969\n",
      "2-254th: train loss: 1.47284, train acc: 0.999 valid loss: 1.53217 valid acc: 0.969\n",
      "2-255th: train loss: 1.47282, train acc: 0.999 valid loss: 1.53209 valid acc: 0.969\n",
      "2-256th: train loss: 1.47279, train acc: 0.999 valid loss: 1.53201 valid acc: 0.969\n",
      "2-257th: train loss: 1.47277, train acc: 0.999 valid loss: 1.53193 valid acc: 0.969\n",
      "2-258th: train loss: 1.47274, train acc: 0.999 valid loss: 1.53185 valid acc: 0.969\n",
      "2-259th: train loss: 1.47272, train acc: 0.999 valid loss: 1.53177 valid acc: 0.969\n",
      "2-260th: train loss: 1.47269, train acc: 0.999 valid loss: 1.53169 valid acc: 0.969\n",
      "2-261th: train loss: 1.47267, train acc: 0.999 valid loss: 1.53162 valid acc: 0.969\n",
      "2-262th: train loss: 1.47265, train acc: 0.999 valid loss: 1.53154 valid acc: 0.969\n",
      "2-263th: train loss: 1.47262, train acc: 0.999 valid loss: 1.53146 valid acc: 0.969\n",
      "2-264th: train loss: 1.47260, train acc: 0.999 valid loss: 1.53138 valid acc: 0.969\n",
      "2-265th: train loss: 1.47258, train acc: 0.999 valid loss: 1.53130 valid acc: 0.969\n",
      "2-266th: train loss: 1.47255, train acc: 0.999 valid loss: 1.53122 valid acc: 0.969\n",
      "2-267th: train loss: 1.47253, train acc: 0.999 valid loss: 1.53115 valid acc: 0.969\n",
      "2-268th: train loss: 1.47251, train acc: 0.999 valid loss: 1.53107 valid acc: 0.969\n",
      "2-269th: train loss: 1.47249, train acc: 0.999 valid loss: 1.53099 valid acc: 0.969\n",
      "2-270th: train loss: 1.47246, train acc: 0.999 valid loss: 1.53091 valid acc: 0.969\n",
      "2-271th: train loss: 1.47244, train acc: 0.999 valid loss: 1.53083 valid acc: 0.966\n",
      "2-272th: train loss: 1.47242, train acc: 0.999 valid loss: 1.53076 valid acc: 0.966\n",
      "2-273th: train loss: 1.47240, train acc: 0.999 valid loss: 1.53068 valid acc: 0.969\n",
      "2-274th: train loss: 1.47238, train acc: 0.999 valid loss: 1.53060 valid acc: 0.969\n",
      "2-275th: train loss: 1.47236, train acc: 0.999 valid loss: 1.53053 valid acc: 0.969\n",
      "2-276th: train loss: 1.47233, train acc: 0.999 valid loss: 1.53045 valid acc: 0.969\n",
      "2-277th: train loss: 1.47231, train acc: 0.999 valid loss: 1.53037 valid acc: 0.966\n",
      "2-278th: train loss: 1.47229, train acc: 0.999 valid loss: 1.53030 valid acc: 0.966\n",
      "2-279th: train loss: 1.47227, train acc: 0.999 valid loss: 1.53022 valid acc: 0.966\n",
      "2-280th: train loss: 1.47225, train acc: 0.999 valid loss: 1.53014 valid acc: 0.966\n",
      "2-281th: train loss: 1.47223, train acc: 0.999 valid loss: 1.53007 valid acc: 0.966\n",
      "2-282th: train loss: 1.47221, train acc: 0.999 valid loss: 1.52999 valid acc: 0.966\n",
      "2-283th: train loss: 1.47219, train acc: 0.999 valid loss: 1.52991 valid acc: 0.966\n",
      "2-284th: train loss: 1.47217, train acc: 0.999 valid loss: 1.52984 valid acc: 0.966\n",
      "2-285th: train loss: 1.47215, train acc: 0.999 valid loss: 1.52976 valid acc: 0.966\n",
      "2-286th: train loss: 1.47213, train acc: 0.999 valid loss: 1.52969 valid acc: 0.966\n",
      "2-287th: train loss: 1.47212, train acc: 0.999 valid loss: 1.52961 valid acc: 0.966\n",
      "2-288th: train loss: 1.47210, train acc: 0.999 valid loss: 1.52954 valid acc: 0.966\n",
      "2-289th: train loss: 1.47208, train acc: 0.999 valid loss: 1.52946 valid acc: 0.966\n",
      "2-290th: train loss: 1.47206, train acc: 0.999 valid loss: 1.52939 valid acc: 0.966\n",
      "2-291th: train loss: 1.47204, train acc: 0.999 valid loss: 1.52932 valid acc: 0.966\n",
      "2-292th: train loss: 1.47202, train acc: 0.999 valid loss: 1.52924 valid acc: 0.969\n",
      "2-293th: train loss: 1.47201, train acc: 0.999 valid loss: 1.52917 valid acc: 0.969\n",
      "2-294th: train loss: 1.47199, train acc: 0.999 valid loss: 1.52910 valid acc: 0.969\n",
      "2-295th: train loss: 1.47197, train acc: 0.999 valid loss: 1.52902 valid acc: 0.969\n",
      "2-296th: train loss: 1.47195, train acc: 0.999 valid loss: 1.52895 valid acc: 0.969\n",
      "2-297th: train loss: 1.47193, train acc: 0.999 valid loss: 1.52888 valid acc: 0.969\n",
      "2-298th: train loss: 1.47192, train acc: 0.999 valid loss: 1.52881 valid acc: 0.969\n",
      "2-299th: train loss: 1.47190, train acc: 0.999 valid loss: 1.52874 valid acc: 0.969\n",
      "3-0th: train loss: 2.30642, train acc: 0.122 valid loss: 2.22614 valid acc: 0.211\n",
      "3-1th: train loss: 2.21135, train acc: 0.243 valid loss: 2.13923 valid acc: 0.371\n",
      "3-2th: train loss: 2.12300, train acc: 0.373 valid loss: 2.07805 valid acc: 0.434\n",
      "3-3th: train loss: 2.06459, train acc: 0.436 valid loss: 2.01599 valid acc: 0.522\n",
      "3-4th: train loss: 2.00260, train acc: 0.501 valid loss: 1.96588 valid acc: 0.563\n",
      "3-5th: train loss: 1.94850, train acc: 0.587 valid loss: 1.93723 valid acc: 0.613\n",
      "3-6th: train loss: 1.91493, train acc: 0.624 valid loss: 1.90213 valid acc: 0.654\n",
      "3-7th: train loss: 1.87339, train acc: 0.672 valid loss: 1.87922 valid acc: 0.667\n",
      "3-8th: train loss: 1.84494, train acc: 0.696 valid loss: 1.86108 valid acc: 0.673\n",
      "3-9th: train loss: 1.82557, train acc: 0.707 valid loss: 1.84566 valid acc: 0.676\n",
      "3-10th: train loss: 1.80964, train acc: 0.715 valid loss: 1.83025 valid acc: 0.679\n",
      "3-11th: train loss: 1.79174, train acc: 0.729 valid loss: 1.81418 valid acc: 0.711\n",
      "3-12th: train loss: 1.77327, train acc: 0.744 valid loss: 1.79917 valid acc: 0.730\n",
      "3-13th: train loss: 1.75681, train acc: 0.777 valid loss: 1.78725 valid acc: 0.755\n",
      "3-14th: train loss: 1.74167, train acc: 0.805 valid loss: 1.77605 valid acc: 0.774\n",
      "3-15th: train loss: 1.72846, train acc: 0.818 valid loss: 1.74769 valid acc: 0.805\n",
      "3-16th: train loss: 1.70033, train acc: 0.848 valid loss: 1.72114 valid acc: 0.830\n",
      "3-17th: train loss: 1.67446, train acc: 0.873 valid loss: 1.69818 valid acc: 0.871\n",
      "3-18th: train loss: 1.64990, train acc: 0.904 valid loss: 1.68974 valid acc: 0.865\n",
      "3-19th: train loss: 1.63828, train acc: 0.919 valid loss: 1.67161 valid acc: 0.874\n",
      "3-20th: train loss: 1.61967, train acc: 0.933 valid loss: 1.65500 valid acc: 0.881\n",
      "3-21th: train loss: 1.60341, train acc: 0.939 valid loss: 1.64810 valid acc: 0.881\n",
      "3-22th: train loss: 1.59568, train acc: 0.942 valid loss: 1.64421 valid acc: 0.887\n",
      "3-23th: train loss: 1.59135, train acc: 0.942 valid loss: 1.63842 valid acc: 0.899\n",
      "3-24th: train loss: 1.58640, train acc: 0.945 valid loss: 1.63037 valid acc: 0.906\n",
      "3-25th: train loss: 1.57976, train acc: 0.949 valid loss: 1.62304 valid acc: 0.909\n",
      "3-26th: train loss: 1.57330, train acc: 0.957 valid loss: 1.61891 valid acc: 0.909\n",
      "3-27th: train loss: 1.56868, train acc: 0.961 valid loss: 1.61717 valid acc: 0.909\n",
      "3-28th: train loss: 1.56520, train acc: 0.963 valid loss: 1.61550 valid acc: 0.912\n",
      "3-29th: train loss: 1.56140, train acc: 0.965 valid loss: 1.61331 valid acc: 0.921\n",
      "3-30th: train loss: 1.55740, train acc: 0.968 valid loss: 1.61110 valid acc: 0.928\n",
      "3-31th: train loss: 1.55388, train acc: 0.969 valid loss: 1.60862 valid acc: 0.931\n",
      "3-32th: train loss: 1.55050, train acc: 0.969 valid loss: 1.60541 valid acc: 0.928\n",
      "3-33th: train loss: 1.54669, train acc: 0.970 valid loss: 1.60207 valid acc: 0.925\n",
      "3-34th: train loss: 1.54295, train acc: 0.971 valid loss: 1.59944 valid acc: 0.928\n",
      "3-35th: train loss: 1.54011, train acc: 0.973 valid loss: 1.59741 valid acc: 0.931\n",
      "3-36th: train loss: 1.53798, train acc: 0.973 valid loss: 1.59536 valid acc: 0.931\n",
      "3-37th: train loss: 1.53578, train acc: 0.974 valid loss: 1.59324 valid acc: 0.931\n",
      "3-38th: train loss: 1.53321, train acc: 0.975 valid loss: 1.59153 valid acc: 0.928\n",
      "3-39th: train loss: 1.53056, train acc: 0.976 valid loss: 1.59071 valid acc: 0.921\n",
      "3-40th: train loss: 1.52827, train acc: 0.978 valid loss: 1.59068 valid acc: 0.925\n",
      "3-41th: train loss: 1.52650, train acc: 0.979 valid loss: 1.59074 valid acc: 0.921\n",
      "3-42th: train loss: 1.52501, train acc: 0.981 valid loss: 1.59004 valid acc: 0.921\n",
      "3-43th: train loss: 1.52342, train acc: 0.981 valid loss: 1.58841 valid acc: 0.928\n",
      "3-44th: train loss: 1.52164, train acc: 0.982 valid loss: 1.58644 valid acc: 0.928\n",
      "3-45th: train loss: 1.51994, train acc: 0.983 valid loss: 1.58467 valid acc: 0.931\n",
      "3-46th: train loss: 1.51847, train acc: 0.984 valid loss: 1.58328 valid acc: 0.931\n",
      "3-47th: train loss: 1.51713, train acc: 0.984 valid loss: 1.58228 valid acc: 0.931\n",
      "3-48th: train loss: 1.51583, train acc: 0.984 valid loss: 1.58170 valid acc: 0.931\n",
      "3-49th: train loss: 1.51459, train acc: 0.984 valid loss: 1.58140 valid acc: 0.928\n",
      "3-50th: train loss: 1.51343, train acc: 0.984 valid loss: 1.58109 valid acc: 0.928\n",
      "3-51th: train loss: 1.51229, train acc: 0.984 valid loss: 1.58059 valid acc: 0.928\n",
      "3-52th: train loss: 1.51117, train acc: 0.985 valid loss: 1.57988 valid acc: 0.928\n",
      "3-53th: train loss: 1.51011, train acc: 0.986 valid loss: 1.57908 valid acc: 0.931\n",
      "3-54th: train loss: 1.50914, train acc: 0.986 valid loss: 1.57829 valid acc: 0.934\n",
      "3-55th: train loss: 1.50826, train acc: 0.986 valid loss: 1.57754 valid acc: 0.937\n",
      "3-56th: train loss: 1.50744, train acc: 0.986 valid loss: 1.57681 valid acc: 0.937\n",
      "3-57th: train loss: 1.50663, train acc: 0.986 valid loss: 1.57608 valid acc: 0.937\n",
      "3-58th: train loss: 1.50580, train acc: 0.986 valid loss: 1.57539 valid acc: 0.937\n",
      "3-59th: train loss: 1.50500, train acc: 0.987 valid loss: 1.57481 valid acc: 0.937\n",
      "3-60th: train loss: 1.50427, train acc: 0.987 valid loss: 1.57434 valid acc: 0.937\n",
      "3-61th: train loss: 1.50359, train acc: 0.987 valid loss: 1.57397 valid acc: 0.934\n",
      "3-62th: train loss: 1.50295, train acc: 0.987 valid loss: 1.57364 valid acc: 0.934\n",
      "3-63th: train loss: 1.50229, train acc: 0.987 valid loss: 1.57333 valid acc: 0.934\n",
      "3-64th: train loss: 1.50162, train acc: 0.987 valid loss: 1.57301 valid acc: 0.934\n",
      "3-65th: train loss: 1.50097, train acc: 0.987 valid loss: 1.57270 valid acc: 0.934\n",
      "3-66th: train loss: 1.50034, train acc: 0.987 valid loss: 1.57243 valid acc: 0.934\n",
      "3-67th: train loss: 1.49975, train acc: 0.987 valid loss: 1.57221 valid acc: 0.934\n",
      "3-68th: train loss: 1.49918, train acc: 0.988 valid loss: 1.57206 valid acc: 0.934\n",
      "3-69th: train loss: 1.49861, train acc: 0.991 valid loss: 1.57197 valid acc: 0.937\n",
      "3-70th: train loss: 1.49803, train acc: 0.991 valid loss: 1.57193 valid acc: 0.937\n",
      "3-71th: train loss: 1.49746, train acc: 0.992 valid loss: 1.57188 valid acc: 0.937\n",
      "3-72th: train loss: 1.49691, train acc: 0.992 valid loss: 1.57177 valid acc: 0.937\n",
      "3-73th: train loss: 1.49638, train acc: 0.992 valid loss: 1.57158 valid acc: 0.937\n",
      "3-74th: train loss: 1.49587, train acc: 0.993 valid loss: 1.57133 valid acc: 0.937\n",
      "3-75th: train loss: 1.49536, train acc: 0.993 valid loss: 1.57108 valid acc: 0.937\n",
      "3-76th: train loss: 1.49486, train acc: 0.994 valid loss: 1.57088 valid acc: 0.940\n",
      "3-77th: train loss: 1.49436, train acc: 0.995 valid loss: 1.57076 valid acc: 0.943\n",
      "3-78th: train loss: 1.49389, train acc: 0.995 valid loss: 1.57072 valid acc: 0.943\n",
      "3-79th: train loss: 1.49343, train acc: 0.995 valid loss: 1.57070 valid acc: 0.943\n",
      "3-80th: train loss: 1.49298, train acc: 0.995 valid loss: 1.57066 valid acc: 0.943\n",
      "3-81th: train loss: 1.49255, train acc: 0.995 valid loss: 1.57054 valid acc: 0.943\n",
      "3-82th: train loss: 1.49214, train acc: 0.995 valid loss: 1.57034 valid acc: 0.943\n",
      "3-83th: train loss: 1.49174, train acc: 0.995 valid loss: 1.57007 valid acc: 0.943\n",
      "3-84th: train loss: 1.49135, train acc: 0.995 valid loss: 1.56977 valid acc: 0.940\n",
      "3-85th: train loss: 1.49098, train acc: 0.995 valid loss: 1.56948 valid acc: 0.940\n",
      "3-86th: train loss: 1.49062, train acc: 0.995 valid loss: 1.56921 valid acc: 0.940\n",
      "3-87th: train loss: 1.49027, train acc: 0.995 valid loss: 1.56898 valid acc: 0.940\n",
      "3-88th: train loss: 1.48994, train acc: 0.995 valid loss: 1.56878 valid acc: 0.940\n",
      "3-89th: train loss: 1.48961, train acc: 0.995 valid loss: 1.56863 valid acc: 0.937\n",
      "3-90th: train loss: 1.48929, train acc: 0.995 valid loss: 1.56852 valid acc: 0.937\n",
      "3-91th: train loss: 1.48897, train acc: 0.996 valid loss: 1.56845 valid acc: 0.937\n",
      "3-92th: train loss: 1.48867, train acc: 0.996 valid loss: 1.56840 valid acc: 0.937\n",
      "3-93th: train loss: 1.48836, train acc: 0.996 valid loss: 1.56836 valid acc: 0.937\n",
      "3-94th: train loss: 1.48807, train acc: 0.996 valid loss: 1.56829 valid acc: 0.934\n",
      "3-95th: train loss: 1.48777, train acc: 0.996 valid loss: 1.56818 valid acc: 0.934\n",
      "3-96th: train loss: 1.48749, train acc: 0.996 valid loss: 1.56805 valid acc: 0.934\n",
      "3-97th: train loss: 1.48720, train acc: 0.996 valid loss: 1.56789 valid acc: 0.934\n",
      "3-98th: train loss: 1.48692, train acc: 0.996 valid loss: 1.56775 valid acc: 0.934\n",
      "3-99th: train loss: 1.48664, train acc: 0.996 valid loss: 1.56763 valid acc: 0.934\n",
      "3-100th: train loss: 1.48637, train acc: 0.996 valid loss: 1.56753 valid acc: 0.934\n",
      "3-101th: train loss: 1.48609, train acc: 0.997 valid loss: 1.56745 valid acc: 0.934\n",
      "3-102th: train loss: 1.48582, train acc: 0.997 valid loss: 1.56737 valid acc: 0.934\n",
      "3-103th: train loss: 1.48555, train acc: 0.997 valid loss: 1.56727 valid acc: 0.934\n",
      "3-104th: train loss: 1.48527, train acc: 0.997 valid loss: 1.56716 valid acc: 0.934\n",
      "3-105th: train loss: 1.48500, train acc: 0.997 valid loss: 1.56702 valid acc: 0.934\n",
      "3-106th: train loss: 1.48472, train acc: 0.997 valid loss: 1.56689 valid acc: 0.934\n",
      "3-107th: train loss: 1.48445, train acc: 0.998 valid loss: 1.56675 valid acc: 0.934\n",
      "3-108th: train loss: 1.48418, train acc: 0.998 valid loss: 1.56662 valid acc: 0.934\n",
      "3-109th: train loss: 1.48392, train acc: 0.998 valid loss: 1.56650 valid acc: 0.934\n",
      "3-110th: train loss: 1.48367, train acc: 0.998 valid loss: 1.56638 valid acc: 0.934\n",
      "3-111th: train loss: 1.48344, train acc: 0.998 valid loss: 1.56626 valid acc: 0.934\n",
      "3-112th: train loss: 1.48322, train acc: 0.998 valid loss: 1.56614 valid acc: 0.934\n",
      "3-113th: train loss: 1.48301, train acc: 0.998 valid loss: 1.56602 valid acc: 0.934\n",
      "3-114th: train loss: 1.48282, train acc: 0.998 valid loss: 1.56591 valid acc: 0.934\n",
      "3-115th: train loss: 1.48263, train acc: 0.998 valid loss: 1.56580 valid acc: 0.934\n",
      "3-116th: train loss: 1.48244, train acc: 0.998 valid loss: 1.56569 valid acc: 0.934\n",
      "3-117th: train loss: 1.48226, train acc: 0.998 valid loss: 1.56558 valid acc: 0.937\n",
      "3-118th: train loss: 1.48209, train acc: 0.998 valid loss: 1.56547 valid acc: 0.937\n",
      "3-119th: train loss: 1.48191, train acc: 0.998 valid loss: 1.56534 valid acc: 0.937\n",
      "3-120th: train loss: 1.48174, train acc: 0.998 valid loss: 1.56521 valid acc: 0.937\n",
      "3-121th: train loss: 1.48158, train acc: 0.998 valid loss: 1.56506 valid acc: 0.940\n",
      "3-122th: train loss: 1.48142, train acc: 0.998 valid loss: 1.56490 valid acc: 0.940\n",
      "3-123th: train loss: 1.48126, train acc: 0.998 valid loss: 1.56473 valid acc: 0.940\n",
      "3-124th: train loss: 1.48110, train acc: 0.998 valid loss: 1.56455 valid acc: 0.940\n",
      "3-125th: train loss: 1.48095, train acc: 0.998 valid loss: 1.56435 valid acc: 0.940\n",
      "3-126th: train loss: 1.48081, train acc: 0.998 valid loss: 1.56415 valid acc: 0.943\n",
      "3-127th: train loss: 1.48067, train acc: 0.998 valid loss: 1.56393 valid acc: 0.943\n",
      "3-128th: train loss: 1.48053, train acc: 0.998 valid loss: 1.56372 valid acc: 0.943\n",
      "3-129th: train loss: 1.48039, train acc: 0.998 valid loss: 1.56352 valid acc: 0.943\n",
      "3-130th: train loss: 1.48026, train acc: 0.998 valid loss: 1.56332 valid acc: 0.943\n",
      "3-131th: train loss: 1.48013, train acc: 0.998 valid loss: 1.56313 valid acc: 0.943\n",
      "3-132th: train loss: 1.48001, train acc: 0.998 valid loss: 1.56294 valid acc: 0.943\n",
      "3-133th: train loss: 1.47988, train acc: 0.998 valid loss: 1.56276 valid acc: 0.943\n",
      "3-134th: train loss: 1.47976, train acc: 0.998 valid loss: 1.56257 valid acc: 0.943\n",
      "3-135th: train loss: 1.47964, train acc: 0.998 valid loss: 1.56239 valid acc: 0.943\n",
      "3-136th: train loss: 1.47953, train acc: 0.998 valid loss: 1.56221 valid acc: 0.943\n",
      "3-137th: train loss: 1.47941, train acc: 0.998 valid loss: 1.56204 valid acc: 0.943\n",
      "3-138th: train loss: 1.47930, train acc: 0.998 valid loss: 1.56187 valid acc: 0.943\n",
      "3-139th: train loss: 1.47919, train acc: 0.998 valid loss: 1.56172 valid acc: 0.943\n",
      "3-140th: train loss: 1.47909, train acc: 0.998 valid loss: 1.56157 valid acc: 0.943\n",
      "3-141th: train loss: 1.47898, train acc: 0.998 valid loss: 1.56142 valid acc: 0.943\n",
      "3-142th: train loss: 1.47888, train acc: 0.998 valid loss: 1.56129 valid acc: 0.943\n",
      "3-143th: train loss: 1.47878, train acc: 0.998 valid loss: 1.56116 valid acc: 0.943\n",
      "3-144th: train loss: 1.47868, train acc: 0.998 valid loss: 1.56104 valid acc: 0.943\n",
      "3-145th: train loss: 1.47859, train acc: 0.998 valid loss: 1.56093 valid acc: 0.943\n",
      "3-146th: train loss: 1.47849, train acc: 0.998 valid loss: 1.56081 valid acc: 0.943\n",
      "3-147th: train loss: 1.47840, train acc: 0.998 valid loss: 1.56070 valid acc: 0.940\n",
      "3-148th: train loss: 1.47831, train acc: 0.998 valid loss: 1.56059 valid acc: 0.940\n",
      "3-149th: train loss: 1.47822, train acc: 0.998 valid loss: 1.56047 valid acc: 0.940\n",
      "3-150th: train loss: 1.47813, train acc: 0.998 valid loss: 1.56036 valid acc: 0.940\n",
      "3-151th: train loss: 1.47804, train acc: 0.998 valid loss: 1.56025 valid acc: 0.940\n",
      "3-152th: train loss: 1.47796, train acc: 0.998 valid loss: 1.56014 valid acc: 0.940\n",
      "3-153th: train loss: 1.47787, train acc: 0.998 valid loss: 1.56003 valid acc: 0.940\n",
      "3-154th: train loss: 1.47779, train acc: 0.998 valid loss: 1.55993 valid acc: 0.940\n",
      "3-155th: train loss: 1.47771, train acc: 0.998 valid loss: 1.55983 valid acc: 0.940\n",
      "3-156th: train loss: 1.47763, train acc: 0.998 valid loss: 1.55973 valid acc: 0.937\n",
      "3-157th: train loss: 1.47755, train acc: 0.998 valid loss: 1.55963 valid acc: 0.937\n",
      "3-158th: train loss: 1.47747, train acc: 0.998 valid loss: 1.55953 valid acc: 0.937\n",
      "3-159th: train loss: 1.47740, train acc: 0.998 valid loss: 1.55943 valid acc: 0.937\n",
      "3-160th: train loss: 1.47732, train acc: 0.998 valid loss: 1.55934 valid acc: 0.937\n",
      "3-161th: train loss: 1.47725, train acc: 0.998 valid loss: 1.55924 valid acc: 0.937\n",
      "3-162th: train loss: 1.47718, train acc: 0.998 valid loss: 1.55915 valid acc: 0.937\n",
      "3-163th: train loss: 1.47711, train acc: 0.998 valid loss: 1.55906 valid acc: 0.937\n",
      "3-164th: train loss: 1.47704, train acc: 0.998 valid loss: 1.55896 valid acc: 0.937\n",
      "3-165th: train loss: 1.47697, train acc: 0.998 valid loss: 1.55887 valid acc: 0.937\n",
      "3-166th: train loss: 1.47690, train acc: 0.998 valid loss: 1.55878 valid acc: 0.937\n",
      "3-167th: train loss: 1.47683, train acc: 0.998 valid loss: 1.55869 valid acc: 0.937\n",
      "3-168th: train loss: 1.47676, train acc: 0.998 valid loss: 1.55860 valid acc: 0.937\n",
      "3-169th: train loss: 1.47670, train acc: 0.998 valid loss: 1.55851 valid acc: 0.937\n",
      "3-170th: train loss: 1.47663, train acc: 0.998 valid loss: 1.55842 valid acc: 0.937\n",
      "3-171th: train loss: 1.47657, train acc: 0.998 valid loss: 1.55833 valid acc: 0.937\n",
      "3-172th: train loss: 1.47651, train acc: 0.998 valid loss: 1.55824 valid acc: 0.937\n",
      "3-173th: train loss: 1.47644, train acc: 0.998 valid loss: 1.55816 valid acc: 0.937\n",
      "3-174th: train loss: 1.47638, train acc: 0.998 valid loss: 1.55808 valid acc: 0.934\n",
      "3-175th: train loss: 1.47632, train acc: 0.998 valid loss: 1.55799 valid acc: 0.937\n",
      "3-176th: train loss: 1.47626, train acc: 0.998 valid loss: 1.55791 valid acc: 0.937\n",
      "3-177th: train loss: 1.47621, train acc: 0.998 valid loss: 1.55783 valid acc: 0.937\n",
      "3-178th: train loss: 1.47615, train acc: 0.998 valid loss: 1.55775 valid acc: 0.937\n",
      "3-179th: train loss: 1.47609, train acc: 0.998 valid loss: 1.55768 valid acc: 0.937\n",
      "3-180th: train loss: 1.47603, train acc: 0.998 valid loss: 1.55760 valid acc: 0.937\n",
      "3-181th: train loss: 1.47598, train acc: 0.998 valid loss: 1.55752 valid acc: 0.937\n",
      "3-182th: train loss: 1.47592, train acc: 0.998 valid loss: 1.55745 valid acc: 0.937\n",
      "3-183th: train loss: 1.47587, train acc: 0.998 valid loss: 1.55738 valid acc: 0.937\n",
      "3-184th: train loss: 1.47582, train acc: 0.998 valid loss: 1.55731 valid acc: 0.937\n",
      "3-185th: train loss: 1.47576, train acc: 0.998 valid loss: 1.55724 valid acc: 0.937\n",
      "3-186th: train loss: 1.47571, train acc: 0.998 valid loss: 1.55717 valid acc: 0.937\n",
      "3-187th: train loss: 1.47566, train acc: 0.998 valid loss: 1.55710 valid acc: 0.937\n",
      "3-188th: train loss: 1.47561, train acc: 0.998 valid loss: 1.55703 valid acc: 0.937\n",
      "3-189th: train loss: 1.47556, train acc: 0.998 valid loss: 1.55697 valid acc: 0.937\n",
      "3-190th: train loss: 1.47551, train acc: 0.998 valid loss: 1.55690 valid acc: 0.937\n",
      "3-191th: train loss: 1.47546, train acc: 0.998 valid loss: 1.55683 valid acc: 0.937\n",
      "3-192th: train loss: 1.47541, train acc: 0.998 valid loss: 1.55677 valid acc: 0.937\n",
      "3-193th: train loss: 1.47536, train acc: 0.998 valid loss: 1.55670 valid acc: 0.937\n",
      "3-194th: train loss: 1.47532, train acc: 0.998 valid loss: 1.55664 valid acc: 0.937\n",
      "3-195th: train loss: 1.47527, train acc: 0.998 valid loss: 1.55657 valid acc: 0.937\n",
      "3-196th: train loss: 1.47522, train acc: 0.998 valid loss: 1.55651 valid acc: 0.937\n",
      "3-197th: train loss: 1.47518, train acc: 0.998 valid loss: 1.55644 valid acc: 0.937\n",
      "3-198th: train loss: 1.47513, train acc: 0.998 valid loss: 1.55638 valid acc: 0.937\n",
      "3-199th: train loss: 1.47509, train acc: 0.998 valid loss: 1.55631 valid acc: 0.937\n",
      "3-200th: train loss: 1.47504, train acc: 0.998 valid loss: 1.55625 valid acc: 0.937\n",
      "3-201th: train loss: 1.47500, train acc: 0.998 valid loss: 1.55619 valid acc: 0.937\n",
      "3-202th: train loss: 1.47496, train acc: 0.998 valid loss: 1.55612 valid acc: 0.937\n",
      "3-203th: train loss: 1.47491, train acc: 0.998 valid loss: 1.55606 valid acc: 0.937\n",
      "3-204th: train loss: 1.47487, train acc: 0.998 valid loss: 1.55600 valid acc: 0.937\n",
      "3-205th: train loss: 1.47483, train acc: 0.998 valid loss: 1.55594 valid acc: 0.937\n",
      "3-206th: train loss: 1.47479, train acc: 0.998 valid loss: 1.55588 valid acc: 0.937\n",
      "3-207th: train loss: 1.47475, train acc: 0.998 valid loss: 1.55582 valid acc: 0.937\n",
      "3-208th: train loss: 1.47471, train acc: 0.998 valid loss: 1.55576 valid acc: 0.937\n",
      "3-209th: train loss: 1.47467, train acc: 0.998 valid loss: 1.55570 valid acc: 0.937\n",
      "3-210th: train loss: 1.47463, train acc: 0.998 valid loss: 1.55564 valid acc: 0.937\n",
      "3-211th: train loss: 1.47459, train acc: 0.998 valid loss: 1.55558 valid acc: 0.937\n",
      "3-212th: train loss: 1.47455, train acc: 0.998 valid loss: 1.55553 valid acc: 0.937\n",
      "3-213th: train loss: 1.47451, train acc: 0.998 valid loss: 1.55547 valid acc: 0.940\n",
      "3-214th: train loss: 1.47447, train acc: 0.998 valid loss: 1.55541 valid acc: 0.940\n",
      "3-215th: train loss: 1.47444, train acc: 0.998 valid loss: 1.55536 valid acc: 0.940\n",
      "3-216th: train loss: 1.47440, train acc: 0.998 valid loss: 1.55530 valid acc: 0.940\n",
      "3-217th: train loss: 1.47436, train acc: 0.998 valid loss: 1.55524 valid acc: 0.940\n",
      "3-218th: train loss: 1.47433, train acc: 0.998 valid loss: 1.55519 valid acc: 0.940\n",
      "3-219th: train loss: 1.47429, train acc: 0.998 valid loss: 1.55513 valid acc: 0.940\n",
      "3-220th: train loss: 1.47425, train acc: 0.998 valid loss: 1.55507 valid acc: 0.940\n",
      "3-221th: train loss: 1.47422, train acc: 0.998 valid loss: 1.55502 valid acc: 0.940\n",
      "3-222th: train loss: 1.47418, train acc: 0.998 valid loss: 1.55496 valid acc: 0.940\n",
      "3-223th: train loss: 1.47415, train acc: 0.998 valid loss: 1.55491 valid acc: 0.940\n",
      "3-224th: train loss: 1.47412, train acc: 0.998 valid loss: 1.55485 valid acc: 0.940\n",
      "3-225th: train loss: 1.47408, train acc: 0.998 valid loss: 1.55480 valid acc: 0.940\n",
      "3-226th: train loss: 1.47405, train acc: 0.998 valid loss: 1.55474 valid acc: 0.940\n",
      "3-227th: train loss: 1.47401, train acc: 0.998 valid loss: 1.55469 valid acc: 0.940\n",
      "3-228th: train loss: 1.47398, train acc: 0.998 valid loss: 1.55463 valid acc: 0.943\n",
      "3-229th: train loss: 1.47395, train acc: 0.998 valid loss: 1.55458 valid acc: 0.943\n",
      "3-230th: train loss: 1.47392, train acc: 0.998 valid loss: 1.55452 valid acc: 0.943\n",
      "3-231th: train loss: 1.47389, train acc: 0.998 valid loss: 1.55447 valid acc: 0.943\n",
      "3-232th: train loss: 1.47385, train acc: 0.998 valid loss: 1.55441 valid acc: 0.943\n",
      "3-233th: train loss: 1.47382, train acc: 0.998 valid loss: 1.55436 valid acc: 0.943\n",
      "3-234th: train loss: 1.47379, train acc: 0.998 valid loss: 1.55431 valid acc: 0.943\n",
      "3-235th: train loss: 1.47376, train acc: 0.998 valid loss: 1.55425 valid acc: 0.943\n",
      "3-236th: train loss: 1.47373, train acc: 0.998 valid loss: 1.55420 valid acc: 0.943\n",
      "3-237th: train loss: 1.47370, train acc: 0.998 valid loss: 1.55414 valid acc: 0.943\n",
      "3-238th: train loss: 1.47367, train acc: 0.998 valid loss: 1.55409 valid acc: 0.943\n",
      "3-239th: train loss: 1.47364, train acc: 0.998 valid loss: 1.55404 valid acc: 0.943\n",
      "3-240th: train loss: 1.47361, train acc: 0.998 valid loss: 1.55399 valid acc: 0.943\n",
      "3-241th: train loss: 1.47359, train acc: 0.998 valid loss: 1.55393 valid acc: 0.943\n",
      "3-242th: train loss: 1.47356, train acc: 0.998 valid loss: 1.55388 valid acc: 0.943\n",
      "3-243th: train loss: 1.47353, train acc: 0.998 valid loss: 1.55383 valid acc: 0.943\n",
      "3-244th: train loss: 1.47350, train acc: 0.998 valid loss: 1.55378 valid acc: 0.943\n",
      "3-245th: train loss: 1.47347, train acc: 0.998 valid loss: 1.55373 valid acc: 0.943\n",
      "3-246th: train loss: 1.47345, train acc: 0.998 valid loss: 1.55367 valid acc: 0.943\n",
      "3-247th: train loss: 1.47342, train acc: 0.998 valid loss: 1.55362 valid acc: 0.943\n",
      "3-248th: train loss: 1.47339, train acc: 0.998 valid loss: 1.55357 valid acc: 0.943\n",
      "3-249th: train loss: 1.47337, train acc: 0.998 valid loss: 1.55352 valid acc: 0.943\n",
      "3-250th: train loss: 1.47334, train acc: 0.998 valid loss: 1.55347 valid acc: 0.943\n",
      "3-251th: train loss: 1.47331, train acc: 0.998 valid loss: 1.55342 valid acc: 0.943\n",
      "3-252th: train loss: 1.47329, train acc: 0.998 valid loss: 1.55337 valid acc: 0.943\n",
      "3-253th: train loss: 1.47326, train acc: 0.998 valid loss: 1.55332 valid acc: 0.943\n",
      "3-254th: train loss: 1.47324, train acc: 0.998 valid loss: 1.55327 valid acc: 0.943\n",
      "3-255th: train loss: 1.47321, train acc: 0.998 valid loss: 1.55322 valid acc: 0.943\n",
      "3-256th: train loss: 1.47319, train acc: 0.998 valid loss: 1.55317 valid acc: 0.943\n",
      "3-257th: train loss: 1.47316, train acc: 0.998 valid loss: 1.55312 valid acc: 0.943\n",
      "3-258th: train loss: 1.47314, train acc: 0.998 valid loss: 1.55307 valid acc: 0.943\n",
      "3-259th: train loss: 1.47311, train acc: 0.998 valid loss: 1.55302 valid acc: 0.943\n",
      "3-260th: train loss: 1.47309, train acc: 0.998 valid loss: 1.55297 valid acc: 0.943\n",
      "3-261th: train loss: 1.47307, train acc: 0.998 valid loss: 1.55292 valid acc: 0.943\n",
      "3-262th: train loss: 1.47304, train acc: 0.998 valid loss: 1.55287 valid acc: 0.943\n",
      "3-263th: train loss: 1.47302, train acc: 0.998 valid loss: 1.55283 valid acc: 0.943\n",
      "3-264th: train loss: 1.47300, train acc: 0.998 valid loss: 1.55278 valid acc: 0.943\n",
      "3-265th: train loss: 1.47297, train acc: 0.998 valid loss: 1.55273 valid acc: 0.943\n",
      "3-266th: train loss: 1.47295, train acc: 0.998 valid loss: 1.55268 valid acc: 0.943\n",
      "3-267th: train loss: 1.47293, train acc: 0.998 valid loss: 1.55264 valid acc: 0.943\n",
      "3-268th: train loss: 1.47291, train acc: 0.998 valid loss: 1.55259 valid acc: 0.943\n",
      "3-269th: train loss: 1.47288, train acc: 0.998 valid loss: 1.55254 valid acc: 0.943\n",
      "3-270th: train loss: 1.47286, train acc: 0.998 valid loss: 1.55249 valid acc: 0.943\n",
      "3-271th: train loss: 1.47284, train acc: 0.998 valid loss: 1.55245 valid acc: 0.943\n",
      "3-272th: train loss: 1.47282, train acc: 0.998 valid loss: 1.55240 valid acc: 0.943\n",
      "3-273th: train loss: 1.47280, train acc: 0.998 valid loss: 1.55236 valid acc: 0.943\n",
      "3-274th: train loss: 1.47278, train acc: 0.998 valid loss: 1.55231 valid acc: 0.943\n",
      "3-275th: train loss: 1.47276, train acc: 0.998 valid loss: 1.55227 valid acc: 0.943\n",
      "3-276th: train loss: 1.47274, train acc: 0.998 valid loss: 1.55222 valid acc: 0.943\n",
      "3-277th: train loss: 1.47272, train acc: 0.998 valid loss: 1.55217 valid acc: 0.943\n",
      "3-278th: train loss: 1.47270, train acc: 0.998 valid loss: 1.55213 valid acc: 0.943\n",
      "3-279th: train loss: 1.47268, train acc: 0.998 valid loss: 1.55209 valid acc: 0.943\n",
      "3-280th: train loss: 1.47266, train acc: 0.998 valid loss: 1.55204 valid acc: 0.943\n",
      "3-281th: train loss: 1.47264, train acc: 0.998 valid loss: 1.55200 valid acc: 0.943\n",
      "3-282th: train loss: 1.47262, train acc: 0.998 valid loss: 1.55195 valid acc: 0.943\n",
      "3-283th: train loss: 1.47260, train acc: 0.998 valid loss: 1.55191 valid acc: 0.943\n",
      "3-284th: train loss: 1.47258, train acc: 0.998 valid loss: 1.55187 valid acc: 0.943\n",
      "3-285th: train loss: 1.47256, train acc: 0.998 valid loss: 1.55182 valid acc: 0.943\n",
      "3-286th: train loss: 1.47254, train acc: 0.998 valid loss: 1.55178 valid acc: 0.943\n",
      "3-287th: train loss: 1.47252, train acc: 0.998 valid loss: 1.55174 valid acc: 0.943\n",
      "3-288th: train loss: 1.47250, train acc: 0.998 valid loss: 1.55170 valid acc: 0.943\n",
      "3-289th: train loss: 1.47249, train acc: 0.998 valid loss: 1.55165 valid acc: 0.943\n",
      "3-290th: train loss: 1.47247, train acc: 0.998 valid loss: 1.55161 valid acc: 0.943\n",
      "3-291th: train loss: 1.47245, train acc: 0.998 valid loss: 1.55157 valid acc: 0.940\n",
      "3-292th: train loss: 1.47243, train acc: 0.998 valid loss: 1.55153 valid acc: 0.940\n",
      "3-293th: train loss: 1.47242, train acc: 0.998 valid loss: 1.55149 valid acc: 0.940\n",
      "3-294th: train loss: 1.47240, train acc: 0.998 valid loss: 1.55145 valid acc: 0.940\n",
      "3-295th: train loss: 1.47238, train acc: 0.998 valid loss: 1.55141 valid acc: 0.940\n",
      "3-296th: train loss: 1.47236, train acc: 0.998 valid loss: 1.55137 valid acc: 0.940\n",
      "3-297th: train loss: 1.47235, train acc: 0.998 valid loss: 1.55133 valid acc: 0.940\n",
      "3-298th: train loss: 1.47233, train acc: 0.998 valid loss: 1.55129 valid acc: 0.940\n",
      "3-299th: train loss: 1.47231, train acc: 0.998 valid loss: 1.55125 valid acc: 0.940\n",
      "4-0th: train loss: 2.31395, train acc: 0.096 valid loss: 2.22650 valid acc: 0.233\n",
      "4-1th: train loss: 2.21777, train acc: 0.230 valid loss: 2.13734 valid acc: 0.352\n",
      "4-2th: train loss: 2.11452, train acc: 0.380 valid loss: 2.07955 valid acc: 0.421\n",
      "4-3th: train loss: 2.04565, train acc: 0.443 valid loss: 2.01123 valid acc: 0.506\n",
      "4-4th: train loss: 1.97525, train acc: 0.565 valid loss: 1.94081 valid acc: 0.651\n",
      "4-5th: train loss: 1.90118, train acc: 0.691 valid loss: 1.89435 valid acc: 0.682\n",
      "4-6th: train loss: 1.85142, train acc: 0.733 valid loss: 1.84808 valid acc: 0.720\n",
      "4-7th: train loss: 1.80284, train acc: 0.773 valid loss: 1.80709 valid acc: 0.758\n",
      "4-8th: train loss: 1.75964, train acc: 0.798 valid loss: 1.77733 valid acc: 0.783\n",
      "4-9th: train loss: 1.72916, train acc: 0.832 valid loss: 1.75521 valid acc: 0.818\n",
      "4-10th: train loss: 1.70577, train acc: 0.855 valid loss: 1.73631 valid acc: 0.833\n",
      "4-11th: train loss: 1.68455, train acc: 0.871 valid loss: 1.72045 valid acc: 0.855\n",
      "4-12th: train loss: 1.66578, train acc: 0.885 valid loss: 1.70816 valid acc: 0.871\n",
      "4-13th: train loss: 1.65013, train acc: 0.900 valid loss: 1.69717 valid acc: 0.877\n",
      "4-14th: train loss: 1.63627, train acc: 0.904 valid loss: 1.68740 valid acc: 0.881\n",
      "4-15th: train loss: 1.62456, train acc: 0.914 valid loss: 1.67945 valid acc: 0.884\n",
      "4-16th: train loss: 1.61505, train acc: 0.925 valid loss: 1.67240 valid acc: 0.877\n",
      "4-17th: train loss: 1.60607, train acc: 0.930 valid loss: 1.66573 valid acc: 0.884\n",
      "4-18th: train loss: 1.59706, train acc: 0.937 valid loss: 1.66022 valid acc: 0.893\n",
      "4-19th: train loss: 1.58919, train acc: 0.940 valid loss: 1.65600 valid acc: 0.896\n",
      "4-20th: train loss: 1.58289, train acc: 0.947 valid loss: 1.65216 valid acc: 0.890\n",
      "4-21th: train loss: 1.57749, train acc: 0.951 valid loss: 1.64745 valid acc: 0.890\n",
      "4-22th: train loss: 1.57181, train acc: 0.957 valid loss: 1.64215 valid acc: 0.896\n",
      "4-23th: train loss: 1.56587, train acc: 0.958 valid loss: 1.63793 valid acc: 0.896\n",
      "4-24th: train loss: 1.56098, train acc: 0.965 valid loss: 1.63519 valid acc: 0.896\n",
      "4-25th: train loss: 1.55722, train acc: 0.965 valid loss: 1.63282 valid acc: 0.899\n",
      "4-26th: train loss: 1.55346, train acc: 0.967 valid loss: 1.63029 valid acc: 0.903\n",
      "4-27th: train loss: 1.54938, train acc: 0.969 valid loss: 1.62792 valid acc: 0.903\n",
      "4-28th: train loss: 1.54555, train acc: 0.972 valid loss: 1.62584 valid acc: 0.899\n",
      "4-29th: train loss: 1.54233, train acc: 0.973 valid loss: 1.62360 valid acc: 0.906\n",
      "4-30th: train loss: 1.53942, train acc: 0.975 valid loss: 1.62094 valid acc: 0.906\n",
      "4-31th: train loss: 1.53651, train acc: 0.975 valid loss: 1.61830 valid acc: 0.903\n",
      "4-32th: train loss: 1.53375, train acc: 0.976 valid loss: 1.61607 valid acc: 0.899\n",
      "4-33th: train loss: 1.53120, train acc: 0.979 valid loss: 1.61422 valid acc: 0.903\n",
      "4-34th: train loss: 1.52876, train acc: 0.980 valid loss: 1.61263 valid acc: 0.906\n",
      "4-35th: train loss: 1.52643, train acc: 0.980 valid loss: 1.61123 valid acc: 0.906\n",
      "4-36th: train loss: 1.52434, train acc: 0.981 valid loss: 1.60979 valid acc: 0.906\n",
      "4-37th: train loss: 1.52246, train acc: 0.983 valid loss: 1.60804 valid acc: 0.909\n",
      "4-38th: train loss: 1.52062, train acc: 0.983 valid loss: 1.60599 valid acc: 0.906\n",
      "4-39th: train loss: 1.51880, train acc: 0.984 valid loss: 1.60393 valid acc: 0.906\n",
      "4-40th: train loss: 1.51710, train acc: 0.984 valid loss: 1.60215 valid acc: 0.903\n",
      "4-41th: train loss: 1.51553, train acc: 0.984 valid loss: 1.60077 valid acc: 0.906\n",
      "4-42th: train loss: 1.51410, train acc: 0.984 valid loss: 1.59973 valid acc: 0.906\n",
      "4-43th: train loss: 1.51277, train acc: 0.986 valid loss: 1.59879 valid acc: 0.906\n",
      "4-44th: train loss: 1.51148, train acc: 0.986 valid loss: 1.59779 valid acc: 0.909\n",
      "4-45th: train loss: 1.51020, train acc: 0.986 valid loss: 1.59670 valid acc: 0.909\n",
      "4-46th: train loss: 1.50899, train acc: 0.987 valid loss: 1.59561 valid acc: 0.909\n",
      "4-47th: train loss: 1.50790, train acc: 0.987 valid loss: 1.59461 valid acc: 0.912\n",
      "4-48th: train loss: 1.50689, train acc: 0.987 valid loss: 1.59372 valid acc: 0.912\n",
      "4-49th: train loss: 1.50590, train acc: 0.987 valid loss: 1.59298 valid acc: 0.912\n",
      "4-50th: train loss: 1.50492, train acc: 0.987 valid loss: 1.59237 valid acc: 0.915\n",
      "4-51th: train loss: 1.50401, train acc: 0.988 valid loss: 1.59176 valid acc: 0.921\n",
      "4-52th: train loss: 1.50314, train acc: 0.988 valid loss: 1.59108 valid acc: 0.925\n",
      "4-53th: train loss: 1.50229, train acc: 0.988 valid loss: 1.59034 valid acc: 0.925\n",
      "4-54th: train loss: 1.50146, train acc: 0.989 valid loss: 1.58964 valid acc: 0.925\n",
      "4-55th: train loss: 1.50069, train acc: 0.990 valid loss: 1.58905 valid acc: 0.928\n",
      "4-56th: train loss: 1.49995, train acc: 0.990 valid loss: 1.58857 valid acc: 0.928\n",
      "4-57th: train loss: 1.49923, train acc: 0.990 valid loss: 1.58820 valid acc: 0.928\n",
      "4-58th: train loss: 1.49852, train acc: 0.991 valid loss: 1.58788 valid acc: 0.931\n",
      "4-59th: train loss: 1.49784, train acc: 0.991 valid loss: 1.58756 valid acc: 0.934\n",
      "4-60th: train loss: 1.49720, train acc: 0.991 valid loss: 1.58715 valid acc: 0.934\n",
      "4-61th: train loss: 1.49658, train acc: 0.991 valid loss: 1.58665 valid acc: 0.928\n",
      "4-62th: train loss: 1.49598, train acc: 0.991 valid loss: 1.58610 valid acc: 0.925\n",
      "4-63th: train loss: 1.49540, train acc: 0.991 valid loss: 1.58558 valid acc: 0.925\n",
      "4-64th: train loss: 1.49484, train acc: 0.991 valid loss: 1.58512 valid acc: 0.928\n",
      "4-65th: train loss: 1.49429, train acc: 0.992 valid loss: 1.58473 valid acc: 0.931\n",
      "4-66th: train loss: 1.49376, train acc: 0.992 valid loss: 1.58438 valid acc: 0.931\n",
      "4-67th: train loss: 1.49325, train acc: 0.993 valid loss: 1.58401 valid acc: 0.931\n",
      "4-68th: train loss: 1.49275, train acc: 0.993 valid loss: 1.58360 valid acc: 0.931\n",
      "4-69th: train loss: 1.49227, train acc: 0.993 valid loss: 1.58316 valid acc: 0.931\n",
      "4-70th: train loss: 1.49180, train acc: 0.993 valid loss: 1.58270 valid acc: 0.931\n",
      "4-71th: train loss: 1.49134, train acc: 0.994 valid loss: 1.58228 valid acc: 0.931\n",
      "4-72th: train loss: 1.49089, train acc: 0.994 valid loss: 1.58193 valid acc: 0.934\n",
      "4-73th: train loss: 1.49045, train acc: 0.994 valid loss: 1.58163 valid acc: 0.934\n",
      "4-74th: train loss: 1.49003, train acc: 0.995 valid loss: 1.58136 valid acc: 0.934\n",
      "4-75th: train loss: 1.48961, train acc: 0.995 valid loss: 1.58110 valid acc: 0.934\n",
      "4-76th: train loss: 1.48921, train acc: 0.995 valid loss: 1.58080 valid acc: 0.934\n",
      "4-77th: train loss: 1.48882, train acc: 0.995 valid loss: 1.58047 valid acc: 0.934\n",
      "4-78th: train loss: 1.48844, train acc: 0.995 valid loss: 1.58011 valid acc: 0.934\n",
      "4-79th: train loss: 1.48807, train acc: 0.995 valid loss: 1.57975 valid acc: 0.934\n",
      "4-80th: train loss: 1.48772, train acc: 0.995 valid loss: 1.57941 valid acc: 0.934\n",
      "4-81th: train loss: 1.48737, train acc: 0.995 valid loss: 1.57910 valid acc: 0.937\n",
      "4-82th: train loss: 1.48704, train acc: 0.996 valid loss: 1.57881 valid acc: 0.937\n",
      "4-83th: train loss: 1.48672, train acc: 0.996 valid loss: 1.57855 valid acc: 0.937\n",
      "4-84th: train loss: 1.48640, train acc: 0.996 valid loss: 1.57829 valid acc: 0.937\n",
      "4-85th: train loss: 1.48610, train acc: 0.996 valid loss: 1.57801 valid acc: 0.934\n",
      "4-86th: train loss: 1.48580, train acc: 0.996 valid loss: 1.57771 valid acc: 0.934\n",
      "4-87th: train loss: 1.48552, train acc: 0.996 valid loss: 1.57739 valid acc: 0.934\n",
      "4-88th: train loss: 1.48524, train acc: 0.997 valid loss: 1.57705 valid acc: 0.934\n",
      "4-89th: train loss: 1.48497, train acc: 0.997 valid loss: 1.57671 valid acc: 0.934\n",
      "4-90th: train loss: 1.48470, train acc: 0.997 valid loss: 1.57637 valid acc: 0.934\n",
      "4-91th: train loss: 1.48445, train acc: 0.997 valid loss: 1.57604 valid acc: 0.934\n",
      "4-92th: train loss: 1.48420, train acc: 0.997 valid loss: 1.57572 valid acc: 0.934\n",
      "4-93th: train loss: 1.48396, train acc: 0.997 valid loss: 1.57542 valid acc: 0.934\n",
      "4-94th: train loss: 1.48373, train acc: 0.997 valid loss: 1.57513 valid acc: 0.934\n",
      "4-95th: train loss: 1.48350, train acc: 0.997 valid loss: 1.57485 valid acc: 0.934\n",
      "4-96th: train loss: 1.48328, train acc: 0.997 valid loss: 1.57459 valid acc: 0.934\n",
      "4-97th: train loss: 1.48306, train acc: 0.997 valid loss: 1.57433 valid acc: 0.934\n",
      "4-98th: train loss: 1.48285, train acc: 0.997 valid loss: 1.57407 valid acc: 0.934\n",
      "4-99th: train loss: 1.48265, train acc: 0.997 valid loss: 1.57382 valid acc: 0.934\n",
      "4-100th: train loss: 1.48245, train acc: 0.997 valid loss: 1.57359 valid acc: 0.934\n",
      "4-101th: train loss: 1.48226, train acc: 0.997 valid loss: 1.57336 valid acc: 0.934\n",
      "4-102th: train loss: 1.48208, train acc: 0.997 valid loss: 1.57315 valid acc: 0.934\n",
      "4-103th: train loss: 1.48190, train acc: 0.997 valid loss: 1.57294 valid acc: 0.934\n",
      "4-104th: train loss: 1.48173, train acc: 0.997 valid loss: 1.57274 valid acc: 0.931\n",
      "4-105th: train loss: 1.48156, train acc: 0.997 valid loss: 1.57255 valid acc: 0.934\n",
      "4-106th: train loss: 1.48140, train acc: 0.997 valid loss: 1.57235 valid acc: 0.934\n",
      "4-107th: train loss: 1.48124, train acc: 0.997 valid loss: 1.57217 valid acc: 0.934\n",
      "4-108th: train loss: 1.48108, train acc: 0.997 valid loss: 1.57199 valid acc: 0.934\n",
      "4-109th: train loss: 1.48093, train acc: 0.997 valid loss: 1.57182 valid acc: 0.937\n",
      "4-110th: train loss: 1.48078, train acc: 0.997 valid loss: 1.57166 valid acc: 0.937\n",
      "4-111th: train loss: 1.48064, train acc: 0.997 valid loss: 1.57150 valid acc: 0.937\n",
      "4-112th: train loss: 1.48050, train acc: 0.997 valid loss: 1.57135 valid acc: 0.937\n",
      "4-113th: train loss: 1.48036, train acc: 0.997 valid loss: 1.57120 valid acc: 0.937\n",
      "4-114th: train loss: 1.48022, train acc: 0.997 valid loss: 1.57104 valid acc: 0.937\n",
      "4-115th: train loss: 1.48009, train acc: 0.997 valid loss: 1.57089 valid acc: 0.937\n",
      "4-116th: train loss: 1.47996, train acc: 0.997 valid loss: 1.57074 valid acc: 0.937\n",
      "4-117th: train loss: 1.47984, train acc: 0.997 valid loss: 1.57058 valid acc: 0.937\n",
      "4-118th: train loss: 1.47972, train acc: 0.997 valid loss: 1.57042 valid acc: 0.937\n",
      "4-119th: train loss: 1.47959, train acc: 0.997 valid loss: 1.57027 valid acc: 0.937\n",
      "4-120th: train loss: 1.47948, train acc: 0.997 valid loss: 1.57011 valid acc: 0.937\n",
      "4-121th: train loss: 1.47936, train acc: 0.997 valid loss: 1.56996 valid acc: 0.937\n",
      "4-122th: train loss: 1.47925, train acc: 0.997 valid loss: 1.56980 valid acc: 0.937\n",
      "4-123th: train loss: 1.47913, train acc: 0.997 valid loss: 1.56966 valid acc: 0.937\n",
      "4-124th: train loss: 1.47902, train acc: 0.997 valid loss: 1.56952 valid acc: 0.937\n",
      "4-125th: train loss: 1.47891, train acc: 0.997 valid loss: 1.56938 valid acc: 0.937\n",
      "4-126th: train loss: 1.47880, train acc: 0.997 valid loss: 1.56925 valid acc: 0.937\n",
      "4-127th: train loss: 1.47869, train acc: 0.997 valid loss: 1.56912 valid acc: 0.937\n",
      "4-128th: train loss: 1.47859, train acc: 0.997 valid loss: 1.56898 valid acc: 0.937\n",
      "4-129th: train loss: 1.47848, train acc: 0.997 valid loss: 1.56885 valid acc: 0.937\n",
      "4-130th: train loss: 1.47837, train acc: 0.998 valid loss: 1.56873 valid acc: 0.940\n",
      "4-131th: train loss: 1.47827, train acc: 0.998 valid loss: 1.56861 valid acc: 0.940\n",
      "4-132th: train loss: 1.47816, train acc: 0.998 valid loss: 1.56850 valid acc: 0.940\n",
      "4-133th: train loss: 1.47805, train acc: 0.998 valid loss: 1.56839 valid acc: 0.940\n",
      "4-134th: train loss: 1.47794, train acc: 0.998 valid loss: 1.56829 valid acc: 0.940\n",
      "4-135th: train loss: 1.47783, train acc: 0.998 valid loss: 1.56820 valid acc: 0.940\n",
      "4-136th: train loss: 1.47772, train acc: 0.998 valid loss: 1.56812 valid acc: 0.940\n",
      "4-137th: train loss: 1.47762, train acc: 0.998 valid loss: 1.56804 valid acc: 0.940\n",
      "4-138th: train loss: 1.47751, train acc: 0.998 valid loss: 1.56796 valid acc: 0.943\n",
      "4-139th: train loss: 1.47741, train acc: 0.998 valid loss: 1.56790 valid acc: 0.943\n",
      "4-140th: train loss: 1.47731, train acc: 0.998 valid loss: 1.56783 valid acc: 0.943\n",
      "4-141th: train loss: 1.47722, train acc: 0.998 valid loss: 1.56778 valid acc: 0.943\n",
      "4-142th: train loss: 1.47713, train acc: 0.998 valid loss: 1.56772 valid acc: 0.943\n",
      "4-143th: train loss: 1.47704, train acc: 0.998 valid loss: 1.56768 valid acc: 0.943\n",
      "4-144th: train loss: 1.47695, train acc: 0.998 valid loss: 1.56763 valid acc: 0.943\n",
      "4-145th: train loss: 1.47686, train acc: 0.998 valid loss: 1.56760 valid acc: 0.943\n",
      "4-146th: train loss: 1.47677, train acc: 0.998 valid loss: 1.56757 valid acc: 0.943\n",
      "4-147th: train loss: 1.47668, train acc: 0.998 valid loss: 1.56756 valid acc: 0.943\n",
      "4-148th: train loss: 1.47658, train acc: 0.998 valid loss: 1.56756 valid acc: 0.947\n",
      "4-149th: train loss: 1.47649, train acc: 0.998 valid loss: 1.56757 valid acc: 0.947\n",
      "4-150th: train loss: 1.47638, train acc: 0.998 valid loss: 1.56760 valid acc: 0.947\n",
      "4-151th: train loss: 1.47628, train acc: 0.998 valid loss: 1.56764 valid acc: 0.947\n",
      "4-152th: train loss: 1.47617, train acc: 0.998 valid loss: 1.56770 valid acc: 0.947\n",
      "4-153th: train loss: 1.47607, train acc: 0.998 valid loss: 1.56777 valid acc: 0.950\n",
      "4-154th: train loss: 1.47597, train acc: 0.998 valid loss: 1.56784 valid acc: 0.950\n",
      "4-155th: train loss: 1.47588, train acc: 0.998 valid loss: 1.56791 valid acc: 0.950\n",
      "4-156th: train loss: 1.47580, train acc: 0.998 valid loss: 1.56797 valid acc: 0.947\n",
      "4-157th: train loss: 1.47572, train acc: 0.998 valid loss: 1.56801 valid acc: 0.947\n",
      "4-158th: train loss: 1.47565, train acc: 0.998 valid loss: 1.56802 valid acc: 0.947\n",
      "4-159th: train loss: 1.47557, train acc: 0.998 valid loss: 1.56802 valid acc: 0.947\n",
      "4-160th: train loss: 1.47550, train acc: 0.998 valid loss: 1.56799 valid acc: 0.947\n",
      "4-161th: train loss: 1.47542, train acc: 0.998 valid loss: 1.56794 valid acc: 0.947\n",
      "4-162th: train loss: 1.47534, train acc: 0.998 valid loss: 1.56788 valid acc: 0.947\n",
      "4-163th: train loss: 1.47526, train acc: 0.998 valid loss: 1.56783 valid acc: 0.947\n",
      "4-164th: train loss: 1.47518, train acc: 0.998 valid loss: 1.56779 valid acc: 0.947\n",
      "4-165th: train loss: 1.47509, train acc: 0.999 valid loss: 1.56776 valid acc: 0.947\n",
      "4-166th: train loss: 1.47501, train acc: 0.999 valid loss: 1.56775 valid acc: 0.947\n",
      "4-167th: train loss: 1.47492, train acc: 0.999 valid loss: 1.56777 valid acc: 0.947\n",
      "4-168th: train loss: 1.47483, train acc: 0.999 valid loss: 1.56779 valid acc: 0.947\n",
      "4-169th: train loss: 1.47475, train acc: 0.999 valid loss: 1.56781 valid acc: 0.943\n",
      "4-170th: train loss: 1.47467, train acc: 0.999 valid loss: 1.56782 valid acc: 0.943\n",
      "4-171th: train loss: 1.47460, train acc: 0.999 valid loss: 1.56783 valid acc: 0.940\n",
      "4-172th: train loss: 1.47453, train acc: 0.999 valid loss: 1.56782 valid acc: 0.940\n",
      "4-173th: train loss: 1.47447, train acc: 0.999 valid loss: 1.56780 valid acc: 0.940\n",
      "4-174th: train loss: 1.47440, train acc: 0.999 valid loss: 1.56777 valid acc: 0.940\n",
      "4-175th: train loss: 1.47435, train acc: 0.999 valid loss: 1.56772 valid acc: 0.940\n",
      "4-176th: train loss: 1.47429, train acc: 0.999 valid loss: 1.56767 valid acc: 0.940\n",
      "4-177th: train loss: 1.47423, train acc: 0.999 valid loss: 1.56760 valid acc: 0.940\n",
      "4-178th: train loss: 1.47417, train acc: 0.999 valid loss: 1.56752 valid acc: 0.940\n",
      "4-179th: train loss: 1.47411, train acc: 0.999 valid loss: 1.56742 valid acc: 0.943\n",
      "4-180th: train loss: 1.47406, train acc: 0.999 valid loss: 1.56731 valid acc: 0.943\n",
      "4-181th: train loss: 1.47400, train acc: 0.999 valid loss: 1.56719 valid acc: 0.943\n",
      "4-182th: train loss: 1.47395, train acc: 0.999 valid loss: 1.56707 valid acc: 0.940\n",
      "4-183th: train loss: 1.47389, train acc: 0.999 valid loss: 1.56696 valid acc: 0.940\n",
      "4-184th: train loss: 1.47384, train acc: 0.999 valid loss: 1.56685 valid acc: 0.940\n",
      "4-185th: train loss: 1.47379, train acc: 0.999 valid loss: 1.56674 valid acc: 0.940\n",
      "4-186th: train loss: 1.47374, train acc: 0.999 valid loss: 1.56665 valid acc: 0.940\n",
      "4-187th: train loss: 1.47369, train acc: 0.999 valid loss: 1.56657 valid acc: 0.940\n",
      "4-188th: train loss: 1.47365, train acc: 0.999 valid loss: 1.56650 valid acc: 0.940\n",
      "4-189th: train loss: 1.47360, train acc: 0.999 valid loss: 1.56645 valid acc: 0.940\n",
      "4-190th: train loss: 1.47356, train acc: 0.999 valid loss: 1.56640 valid acc: 0.940\n",
      "4-191th: train loss: 1.47351, train acc: 0.999 valid loss: 1.56636 valid acc: 0.940\n",
      "4-192th: train loss: 1.47347, train acc: 0.999 valid loss: 1.56632 valid acc: 0.940\n",
      "4-193th: train loss: 1.47343, train acc: 0.999 valid loss: 1.56629 valid acc: 0.940\n",
      "4-194th: train loss: 1.47338, train acc: 0.999 valid loss: 1.56625 valid acc: 0.940\n",
      "4-195th: train loss: 1.47334, train acc: 0.999 valid loss: 1.56622 valid acc: 0.940\n",
      "4-196th: train loss: 1.47330, train acc: 0.999 valid loss: 1.56619 valid acc: 0.943\n",
      "4-197th: train loss: 1.47326, train acc: 0.999 valid loss: 1.56617 valid acc: 0.943\n",
      "4-198th: train loss: 1.47322, train acc: 0.999 valid loss: 1.56614 valid acc: 0.943\n",
      "4-199th: train loss: 1.47319, train acc: 0.999 valid loss: 1.56612 valid acc: 0.940\n",
      "4-200th: train loss: 1.47315, train acc: 0.999 valid loss: 1.56610 valid acc: 0.940\n",
      "4-201th: train loss: 1.47311, train acc: 0.999 valid loss: 1.56608 valid acc: 0.940\n",
      "4-202th: train loss: 1.47308, train acc: 0.999 valid loss: 1.56605 valid acc: 0.940\n",
      "4-203th: train loss: 1.47304, train acc: 0.999 valid loss: 1.56602 valid acc: 0.940\n",
      "4-204th: train loss: 1.47301, train acc: 0.999 valid loss: 1.56599 valid acc: 0.940\n",
      "4-205th: train loss: 1.47297, train acc: 0.999 valid loss: 1.56596 valid acc: 0.940\n",
      "4-206th: train loss: 1.47294, train acc: 0.999 valid loss: 1.56593 valid acc: 0.940\n",
      "4-207th: train loss: 1.47291, train acc: 0.999 valid loss: 1.56590 valid acc: 0.940\n",
      "4-208th: train loss: 1.47287, train acc: 0.999 valid loss: 1.56588 valid acc: 0.940\n",
      "4-209th: train loss: 1.47284, train acc: 0.999 valid loss: 1.56586 valid acc: 0.940\n",
      "4-210th: train loss: 1.47281, train acc: 0.999 valid loss: 1.56584 valid acc: 0.940\n",
      "4-211th: train loss: 1.47278, train acc: 0.999 valid loss: 1.56582 valid acc: 0.940\n",
      "4-212th: train loss: 1.47275, train acc: 0.999 valid loss: 1.56581 valid acc: 0.940\n",
      "4-213th: train loss: 1.47272, train acc: 0.999 valid loss: 1.56579 valid acc: 0.940\n",
      "4-214th: train loss: 1.47269, train acc: 0.999 valid loss: 1.56578 valid acc: 0.940\n",
      "4-215th: train loss: 1.47266, train acc: 0.999 valid loss: 1.56576 valid acc: 0.940\n",
      "4-216th: train loss: 1.47263, train acc: 0.999 valid loss: 1.56575 valid acc: 0.940\n",
      "4-217th: train loss: 1.47260, train acc: 0.999 valid loss: 1.56573 valid acc: 0.937\n",
      "4-218th: train loss: 1.47257, train acc: 0.999 valid loss: 1.56572 valid acc: 0.937\n",
      "4-219th: train loss: 1.47254, train acc: 0.999 valid loss: 1.56571 valid acc: 0.937\n",
      "4-220th: train loss: 1.47252, train acc: 0.999 valid loss: 1.56570 valid acc: 0.937\n",
      "4-221th: train loss: 1.47249, train acc: 0.999 valid loss: 1.56569 valid acc: 0.934\n",
      "4-222th: train loss: 1.47246, train acc: 0.999 valid loss: 1.56568 valid acc: 0.937\n",
      "4-223th: train loss: 1.47244, train acc: 0.999 valid loss: 1.56568 valid acc: 0.937\n",
      "4-224th: train loss: 1.47241, train acc: 0.999 valid loss: 1.56567 valid acc: 0.937\n",
      "4-225th: train loss: 1.47238, train acc: 0.999 valid loss: 1.56567 valid acc: 0.937\n",
      "4-226th: train loss: 1.47236, train acc: 0.999 valid loss: 1.56566 valid acc: 0.937\n",
      "4-227th: train loss: 1.47233, train acc: 0.999 valid loss: 1.56566 valid acc: 0.937\n",
      "4-228th: train loss: 1.47231, train acc: 0.999 valid loss: 1.56566 valid acc: 0.937\n",
      "4-229th: train loss: 1.47228, train acc: 0.999 valid loss: 1.56566 valid acc: 0.937\n",
      "4-230th: train loss: 1.47226, train acc: 0.999 valid loss: 1.56567 valid acc: 0.937\n",
      "4-231th: train loss: 1.47224, train acc: 0.999 valid loss: 1.56568 valid acc: 0.937\n",
      "4-232th: train loss: 1.47221, train acc: 0.999 valid loss: 1.56568 valid acc: 0.937\n",
      "4-233th: train loss: 1.47219, train acc: 0.999 valid loss: 1.56569 valid acc: 0.937\n",
      "4-234th: train loss: 1.47217, train acc: 0.999 valid loss: 1.56571 valid acc: 0.937\n",
      "4-235th: train loss: 1.47214, train acc: 0.999 valid loss: 1.56572 valid acc: 0.937\n",
      "4-236th: train loss: 1.47212, train acc: 0.999 valid loss: 1.56573 valid acc: 0.937\n",
      "4-237th: train loss: 1.47210, train acc: 0.999 valid loss: 1.56574 valid acc: 0.937\n",
      "4-238th: train loss: 1.47208, train acc: 0.999 valid loss: 1.56575 valid acc: 0.937\n",
      "4-239th: train loss: 1.47205, train acc: 0.999 valid loss: 1.56576 valid acc: 0.937\n",
      "4-240th: train loss: 1.47203, train acc: 0.999 valid loss: 1.56578 valid acc: 0.937\n",
      "4-241th: train loss: 1.47201, train acc: 0.999 valid loss: 1.56579 valid acc: 0.937\n",
      "4-242th: train loss: 1.47199, train acc: 0.999 valid loss: 1.56580 valid acc: 0.937\n",
      "4-243th: train loss: 1.47197, train acc: 0.999 valid loss: 1.56581 valid acc: 0.937\n",
      "4-244th: train loss: 1.47195, train acc: 0.999 valid loss: 1.56582 valid acc: 0.937\n",
      "4-245th: train loss: 1.47193, train acc: 0.999 valid loss: 1.56584 valid acc: 0.937\n",
      "4-246th: train loss: 1.47191, train acc: 0.999 valid loss: 1.56585 valid acc: 0.934\n",
      "4-247th: train loss: 1.47189, train acc: 0.999 valid loss: 1.56586 valid acc: 0.934\n",
      "4-248th: train loss: 1.47187, train acc: 0.999 valid loss: 1.56588 valid acc: 0.934\n",
      "4-249th: train loss: 1.47185, train acc: 0.999 valid loss: 1.56589 valid acc: 0.934\n",
      "4-250th: train loss: 1.47183, train acc: 0.999 valid loss: 1.56591 valid acc: 0.934\n",
      "4-251th: train loss: 1.47181, train acc: 0.999 valid loss: 1.56592 valid acc: 0.934\n",
      "4-252th: train loss: 1.47179, train acc: 0.999 valid loss: 1.56594 valid acc: 0.934\n",
      "4-253th: train loss: 1.47177, train acc: 0.999 valid loss: 1.56596 valid acc: 0.931\n",
      "4-254th: train loss: 1.47175, train acc: 0.999 valid loss: 1.56599 valid acc: 0.931\n",
      "4-255th: train loss: 1.47173, train acc: 0.999 valid loss: 1.56601 valid acc: 0.931\n",
      "4-256th: train loss: 1.47171, train acc: 0.999 valid loss: 1.56603 valid acc: 0.934\n",
      "4-257th: train loss: 1.47170, train acc: 0.999 valid loss: 1.56606 valid acc: 0.934\n",
      "4-258th: train loss: 1.47168, train acc: 0.999 valid loss: 1.56608 valid acc: 0.934\n",
      "4-259th: train loss: 1.47166, train acc: 0.999 valid loss: 1.56611 valid acc: 0.934\n",
      "4-260th: train loss: 1.47164, train acc: 0.999 valid loss: 1.56613 valid acc: 0.931\n",
      "4-261th: train loss: 1.47163, train acc: 0.999 valid loss: 1.56616 valid acc: 0.931\n",
      "4-262th: train loss: 1.47161, train acc: 0.999 valid loss: 1.56619 valid acc: 0.931\n",
      "4-263th: train loss: 1.47159, train acc: 0.999 valid loss: 1.56622 valid acc: 0.931\n",
      "4-264th: train loss: 1.47157, train acc: 0.999 valid loss: 1.56624 valid acc: 0.931\n",
      "4-265th: train loss: 1.47156, train acc: 0.999 valid loss: 1.56627 valid acc: 0.931\n",
      "4-266th: train loss: 1.47154, train acc: 0.999 valid loss: 1.56630 valid acc: 0.931\n",
      "4-267th: train loss: 1.47152, train acc: 0.999 valid loss: 1.56633 valid acc: 0.931\n",
      "4-268th: train loss: 1.47151, train acc: 0.999 valid loss: 1.56636 valid acc: 0.931\n",
      "4-269th: train loss: 1.47149, train acc: 0.999 valid loss: 1.56639 valid acc: 0.931\n",
      "4-270th: train loss: 1.47148, train acc: 0.999 valid loss: 1.56642 valid acc: 0.931\n",
      "4-271th: train loss: 1.47146, train acc: 0.999 valid loss: 1.56645 valid acc: 0.931\n",
      "4-272th: train loss: 1.47144, train acc: 0.999 valid loss: 1.56647 valid acc: 0.931\n",
      "4-273th: train loss: 1.47143, train acc: 0.999 valid loss: 1.56650 valid acc: 0.931\n",
      "4-274th: train loss: 1.47141, train acc: 0.999 valid loss: 1.56653 valid acc: 0.931\n",
      "4-275th: train loss: 1.47140, train acc: 0.999 valid loss: 1.56656 valid acc: 0.931\n",
      "4-276th: train loss: 1.47138, train acc: 0.999 valid loss: 1.56660 valid acc: 0.928\n",
      "4-277th: train loss: 1.47137, train acc: 0.999 valid loss: 1.56663 valid acc: 0.928\n",
      "4-278th: train loss: 1.47135, train acc: 0.999 valid loss: 1.56666 valid acc: 0.928\n",
      "4-279th: train loss: 1.47134, train acc: 0.999 valid loss: 1.56669 valid acc: 0.928\n",
      "4-280th: train loss: 1.47132, train acc: 0.999 valid loss: 1.56672 valid acc: 0.928\n",
      "4-281th: train loss: 1.47131, train acc: 0.999 valid loss: 1.56675 valid acc: 0.931\n",
      "4-282th: train loss: 1.47129, train acc: 0.999 valid loss: 1.56679 valid acc: 0.931\n",
      "4-283th: train loss: 1.47128, train acc: 0.999 valid loss: 1.56682 valid acc: 0.931\n",
      "4-284th: train loss: 1.47126, train acc: 0.999 valid loss: 1.56685 valid acc: 0.931\n",
      "4-285th: train loss: 1.47125, train acc: 0.999 valid loss: 1.56689 valid acc: 0.931\n",
      "4-286th: train loss: 1.47124, train acc: 0.999 valid loss: 1.56692 valid acc: 0.931\n",
      "4-287th: train loss: 1.47122, train acc: 0.999 valid loss: 1.56696 valid acc: 0.931\n",
      "4-288th: train loss: 1.47121, train acc: 0.999 valid loss: 1.56699 valid acc: 0.931\n",
      "4-289th: train loss: 1.47119, train acc: 0.999 valid loss: 1.56702 valid acc: 0.931\n",
      "4-290th: train loss: 1.47118, train acc: 0.999 valid loss: 1.56706 valid acc: 0.931\n",
      "4-291th: train loss: 1.47117, train acc: 0.999 valid loss: 1.56709 valid acc: 0.931\n",
      "4-292th: train loss: 1.47115, train acc: 0.999 valid loss: 1.56713 valid acc: 0.931\n",
      "4-293th: train loss: 1.47114, train acc: 0.999 valid loss: 1.56716 valid acc: 0.931\n",
      "4-294th: train loss: 1.47113, train acc: 0.999 valid loss: 1.56720 valid acc: 0.931\n",
      "4-295th: train loss: 1.47111, train acc: 0.999 valid loss: 1.56723 valid acc: 0.931\n",
      "4-296th: train loss: 1.47110, train acc: 0.999 valid loss: 1.56727 valid acc: 0.931\n",
      "4-297th: train loss: 1.47109, train acc: 0.999 valid loss: 1.56730 valid acc: 0.931\n",
      "4-298th: train loss: 1.47108, train acc: 0.999 valid loss: 1.56734 valid acc: 0.931\n",
      "4-299th: train loss: 1.47106, train acc: 0.999 valid loss: 1.56737 valid acc: 0.931\n"
     ]
    }
   ],
   "source": [
    "all_all_tr_loss = []\n",
    "all_all_valid_loss = []\n",
    "all_all_tr_acc = []\n",
    "all_all_valid_acc = []\n",
    "\n",
    "max_epochs = 300\n",
    "lr = 0.005\n",
    "n_fold = 5\n",
    "skf = StratifiedKFold(n_splits=n_fold)\n",
    "for i_fold, (tr, te) in enumerate(skf.split(data, label)):\n",
    "    data_tr, data_te, label_tr, label_te = data[tr].to(device), data[te].to(device), label[tr].to(device), label[te].to(device)\n",
    "    model = torch.nn.Sequential(\n",
    "        QNNModel(),\n",
    "        ConstCoeffLayer(10),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=5e-5)\n",
    "    all_tr_loss = []\n",
    "    all_valid_loss = []\n",
    "    all_tr_acc = []\n",
    "    all_valid_acc = []\n",
    "    for i_epoch in range(max_epochs):\n",
    "        print(f\"{i_fold}-{i_epoch}th:\", end=\" \")\n",
    "        loss_tr, acc_tr = train(data_tr, label_tr, model, optimizer)\n",
    "        loss_valid, acc_valid = valid(data_te, label_te, model)\n",
    "        all_tr_loss.append(loss_tr)\n",
    "        all_valid_loss.append(loss_valid)\n",
    "        all_tr_acc.append(acc_tr)\n",
    "        all_valid_acc.append(acc_valid)\n",
    "        ###\n",
    "    all_all_tr_loss.append(all_tr_loss)\n",
    "    all_all_valid_loss.append(all_valid_loss)\n",
    "    all_all_tr_acc.append(all_tr_acc)\n",
    "    all_all_valid_acc.append(all_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T10:38:21.461467Z",
     "iopub.status.busy": "2023-12-10T10:38:21.461264Z",
     "iopub.status.idle": "2023-12-10T10:38:21.464687Z",
     "shell.execute_reply": "2023-12-10T10:38:21.464311Z"
    },
    "id": "H9RZHvE3k55h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.9976452119309263, test acc: 0.9498432601880877, train loss: 1.4725923538208008, valid loss: 1.5424981117248535\n",
      "train acc: 0.9992150706436421, test acc: 0.9498432601880877, train loss: 1.4712580442428589, valid loss: 1.549694538116455\n",
      "train acc: 0.9992150706436421, test acc: 0.9686520376175548, train loss: 1.471899151802063, valid loss: 1.5287351608276367\n",
      "train acc: 0.9984313725490196, test acc: 0.940251572327044, train loss: 1.4723131656646729, valid loss: 1.5512453317642212\n",
      "train acc: 0.9992156862745099, test acc: 0.9308176100628931, train loss: 1.4710627794265747, valid loss: 1.5673707723617554\n",
      "0.998744482408348 0.9478815480767334\n",
      "0.0006279128959370133 0.012557900899928075\n",
      "1.4718250989913941 1.5479087829589844\n",
      "0.0005890764086812488 0.012569754649676237\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "valid_acc = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "for i in range(len(all_all_tr_acc)):\n",
    "    train_acc.append(all_all_tr_acc[i][-1])\n",
    "    valid_acc.append(all_all_valid_acc[i][-1])\n",
    "    train_loss.append(all_all_tr_loss[i][-1])\n",
    "    valid_loss.append(all_all_valid_loss[i][-1])\n",
    "    print(f\"train acc: {train_acc[-1]}, test acc: {valid_acc[-1]}, train loss: {train_loss[-1]}, valid loss: {valid_loss[-1]}\")\n",
    "\n",
    "print( np.mean(train_acc), np.mean(valid_acc) )\n",
    "print( np.std(train_acc), np.std(valid_acc) )\n",
    "print( np.mean(train_loss), np.mean(valid_loss))\n",
    "print( np.std(train_loss), np.std(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T10:38:21.466111Z",
     "iopub.status.busy": "2023-12-10T10:38:21.465908Z",
     "iopub.status.idle": "2023-12-10T10:38:21.468658Z",
     "shell.execute_reply": "2023-12-10T10:38:21.468178Z"
    },
    "id": "DFnNQRLu1tYw"
   },
   "outputs": [],
   "source": [
    "nu0 = model[0].qnn1.n_depth_per_block\n",
    "c0 = int(model[1].coeff)\n",
    "prefix_name = dataset_name+\"_\"+\"4qnn\"+str(nu0)+\"_c\"+str(c0)+\"_\"+str(n_qubits)+\"qubits_\"\n",
    "if False:\n",
    "    pd.DataFrame(all_all_tr_acc).to_csv(prefix_name+\"_tr_acc.csv\", index=False)\n",
    "    pd.DataFrame(all_all_valid_acc).to_csv(prefix_name+\"_valid_acc.csv\", index=False)\n",
    "    pd.DataFrame(all_all_tr_loss).to_csv(prefix_name+\"_tr_loss.csv\", index=False)\n",
    "    pd.DataFrame(all_all_valid_loss).to_csv(prefix_name+\"_valid_loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yz0oPaAQk55i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
