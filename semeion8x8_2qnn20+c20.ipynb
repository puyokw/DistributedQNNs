{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:22.779683Z",
          "iopub.status.busy": "2023-12-06T08:56:22.779592Z",
          "iopub.status.idle": "2023-12-06T08:56:24.578226Z",
          "shell.execute_reply": "2023-12-06T08:56:24.577785Z"
        },
        "id": "UEv1RLJ01tYq"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import gradcheck\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:24.581862Z",
          "iopub.status.busy": "2023-12-06T08:56:24.581643Z",
          "iopub.status.idle": "2023-12-06T08:56:24.583627Z",
          "shell.execute_reply": "2023-12-06T08:56:24.583278Z"
        },
        "id": "UHp0vfRc1-T_",
        "outputId": "76192af5-b067-4fea-c5cc-62ea50f68a26"
      },
      "outputs": [],
      "source": [
        "# !pip install torchquantum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:24.587213Z",
          "iopub.status.busy": "2023-12-06T08:56:24.586935Z",
          "iopub.status.idle": "2023-12-06T08:56:26.010716Z",
          "shell.execute_reply": "2023-12-06T08:56:26.010330Z"
        },
        "id": "cDueIyyE1-5L"
      },
      "outputs": [],
      "source": [
        "import torchquantum as tq\n",
        "from torchquantum.measurement import expval_joint_analytical\n",
        "import warnings\n",
        "\n",
        "seed = 1001\n",
        "#random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "warnings.simplefilter('ignore', UserWarning)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# NZ_INPUT_ANGLE = 2\n",
        "# device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.013653Z",
          "iopub.status.busy": "2023-12-06T08:56:26.013313Z",
          "iopub.status.idle": "2023-12-06T08:56:26.386525Z",
          "shell.execute_reply": "2023-12-06T08:56:26.385940Z"
        },
        "id": "UKTP2AJ-1tYs",
        "outputId": "79239391-978d-4889-f734-e1152ae9f68b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://archive.ics.uci.edu/ml/machine-learning-databases/semeion/semeion.data to ./data/semeion.data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2889702it [00:01, 2624923.72it/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "semeion_data = torchvision.datasets.SEMEION(root='./data', download=True)\n",
        "dataset_name = 'semeion'\n",
        "data, label = semeion_data.data, semeion_data.labels\n",
        "data = data/255*math.pi*0.25 # pi/2\n",
        "n_qubits = 8\n",
        "n_class = len(np.unique(label))\n",
        "\n",
        "data = torch.nn.AvgPool2d( (2,2), stride=(2,2) )( torch.from_numpy(data) ) # # (1593, 16, 16) => (1593, 8, 8)\n",
        "data = data.reshape(-1,data.shape[1]*data.shape[2]) # (1593, 8, 8) => (1593, 64)\n",
        "label = torch.from_numpy(label)\n",
        "n_data, n_features = data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.419345Z",
          "iopub.status.busy": "2023-12-06T08:56:26.419160Z",
          "iopub.status.idle": "2023-12-06T08:56:26.421654Z",
          "shell.execute_reply": "2023-12-06T08:56:26.421277Z"
        },
        "id": "YPw4rzwS1tYt"
      },
      "outputs": [],
      "source": [
        "class CoeffLayer(nn.Module):\n",
        "    def __init__(self, coeff):\n",
        "        super().__init__()\n",
        "        self.coeff = torch.nn.Parameter(coeff)\n",
        "    def forward(self, x):\n",
        "        ret = x * self.coeff\n",
        "        return ret\n",
        "\n",
        "class ConstCoeffLayer(nn.Module):\n",
        "    def __init__(self, coeff):\n",
        "        super().__init__()\n",
        "        self.coeff = coeff\n",
        "    def forward(self, x):\n",
        "        ret = x * self.coeff\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.423671Z",
          "iopub.status.busy": "2023-12-06T08:56:26.423478Z",
          "iopub.status.idle": "2023-12-06T08:56:26.431021Z",
          "shell.execute_reply": "2023-12-06T08:56:26.430568Z"
        },
        "id": "k4_zRBXbk55h"
      },
      "outputs": [],
      "source": [
        "class QNNsubModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        # params is numpy array\n",
        "        super().__init__()\n",
        "        self.n_wires = n_qubits\n",
        "        self.encoder_gates_x = ([tq.functional.rx] * self.n_wires + [tq.functional.ry] * self.n_wires)*2\n",
        "        self.n_block = 3\n",
        "        self.n_depth_per_block = 20\n",
        "        params = np.random.rand( self.n_wires*self.n_depth_per_block*self.n_block*2)*math.pi\n",
        "        self.u_layers = tq.QuantumModuleList()\n",
        "        for j in range(self.n_depth_per_block*self.n_block):\n",
        "            for i in range(self.n_wires):\n",
        "                self.u_layers.append( tq.RX(has_params=True, trainable=True, init_params=params[i+(2*j)*self.n_wires]) )\n",
        "            for i in range(self.n_wires):\n",
        "                self.u_layers.append( tq.RY(has_params=True, trainable=True, init_params=params[i+(2*j+1)*self.n_wires]) )\n",
        "\n",
        "    def forward(self, x):\n",
        "        bsz, nx_features = x.shape\n",
        "        qdev = tq.QuantumDevice(\n",
        "            n_wires=self.n_wires, bsz = bsz, device=x.device, record_op=False\n",
        "        )\n",
        "        n_depth_per_block = self.n_depth_per_block\n",
        "        for d in range(self.n_block-1): # (2,4)\n",
        "            for k in range(n_depth_per_block):\n",
        "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
        "                    for i in range(self.n_wires):\n",
        "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
        "                for i in range(self.n_wires):\n",
        "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "            # data encoding\n",
        "            for j in range(2*d,2*d+2): # (0,2) (2,4)\n",
        "                for k in range(self.n_wires):\n",
        "                    self.encoder_gates_x[k+j*self.n_wires](qdev, wires=k, params=x[:, (k+j*self.n_wires)])\n",
        "            for i in range(self.n_wires):\n",
        "                qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "        for d in range(self.n_block-1,self.n_block): # (4,5)\n",
        "            for k in range(n_depth_per_block):\n",
        "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
        "                    for i in range(self.n_wires):\n",
        "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
        "                if k==n_depth_per_block-1:\n",
        "                    break\n",
        "                for i in range(self.n_wires):\n",
        "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "\n",
        "        obs_list = [ expval_joint_analytical(qdev, \"I\"*i+Pauli+\"I\"*(self.n_wires-1-i)) for Pauli in [\"X\",\"Z\"] for i in range(n_class//2)]\n",
        "        ret = torch.stack(obs_list, dim=1)\n",
        "        return ret\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.432949Z",
          "iopub.status.busy": "2023-12-06T08:56:26.432774Z",
          "iopub.status.idle": "2023-12-06T08:56:26.435667Z",
          "shell.execute_reply": "2023-12-06T08:56:26.435280Z"
        },
        "id": "n3w6djyB1tYv"
      },
      "outputs": [],
      "source": [
        "class QNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.qnn1 = QNNsubModel()\n",
        "        self.qnn2 = QNNsubModel()\n",
        "    def forward(self, x):\n",
        "        in_x = [x[:,:32], x[:,32:]]\n",
        "        ret1 = self.qnn1(in_x[0]) # 10\n",
        "        ret2 = self.qnn2(in_x[1]) # 10\n",
        "        ret = ret1 + ret2\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.442298Z",
          "iopub.status.busy": "2023-12-06T08:56:26.442097Z",
          "iopub.status.idle": "2023-12-06T08:56:26.445630Z",
          "shell.execute_reply": "2023-12-06T08:56:26.445212Z"
        },
        "id": "F-7DW09j1tYv"
      },
      "outputs": [],
      "source": [
        "def train(data, label, model, optimizer):\n",
        "    model.train(mode=True)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
        "    acc = (pred.argmax(axis=1) == label).sum().item() / len(label)\n",
        "    # acc = accuracy_score(y_tr, pred.argmax(axis=1).cpu().detach().numpy() )\n",
        "    print(f\"train loss: {loss.item():.5f}, train acc: {acc:.3f}\", end=' ')\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item(), acc\n",
        "\n",
        "def valid(data, label, model):\n",
        "    model.train(mode=False)\n",
        "    with torch.no_grad():\n",
        "        pred = model(data)\n",
        "        loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
        "    acc = (pred.argmax(axis=1) == label).sum().item() / len(label)\n",
        "    # acc = accuracy_score(y_te, pred.argmax(axis=1).cpu().detach().numpy() )\n",
        "    print(f\"valid loss: {loss.item():.5f} valid acc: {acc:.3f}\")\n",
        "    return loss.item(), acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.447501Z",
          "iopub.status.busy": "2023-12-06T08:56:26.447318Z",
          "iopub.status.idle": "2023-12-06T22:43:15.347017Z",
          "shell.execute_reply": "2023-12-06T22:43:15.346447Z"
        },
        "id": "MarqNpSo1tYv",
        "outputId": "2300ba01-717a-40dc-ac29-7070f017f0aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0-0th: train loss: 2.34716, train acc: 0.055 valid loss: 2.28400 valid acc: 0.141\n",
            "0-1th: train loss: 2.27822, train acc: 0.173 valid loss: 2.22011 valid acc: 0.229\n",
            "0-2th: train loss: 2.21824, train acc: 0.241 valid loss: 2.18260 valid acc: 0.266\n",
            "0-3th: train loss: 2.17849, train acc: 0.277 valid loss: 2.13755 valid acc: 0.342\n",
            "0-4th: train loss: 2.13461, train acc: 0.345 valid loss: 2.09467 valid acc: 0.382\n",
            "0-5th: train loss: 2.09500, train acc: 0.391 valid loss: 2.06706 valid acc: 0.417\n",
            "0-6th: train loss: 2.06721, train acc: 0.414 valid loss: 2.04301 valid acc: 0.442\n",
            "0-7th: train loss: 2.04115, train acc: 0.439 valid loss: 2.01555 valid acc: 0.476\n",
            "0-8th: train loss: 2.01183, train acc: 0.473 valid loss: 1.98402 valid acc: 0.508\n",
            "0-9th: train loss: 1.97715, train acc: 0.511 valid loss: 1.95584 valid acc: 0.530\n",
            "0-10th: train loss: 1.94429, train acc: 0.551 valid loss: 1.93954 valid acc: 0.558\n",
            "0-11th: train loss: 1.92620, train acc: 0.573 valid loss: 1.92526 valid acc: 0.574\n",
            "0-12th: train loss: 1.91047, train acc: 0.589 valid loss: 1.90511 valid acc: 0.586\n",
            "0-13th: train loss: 1.88849, train acc: 0.611 valid loss: 1.88374 valid acc: 0.636\n",
            "0-14th: train loss: 1.86580, train acc: 0.637 valid loss: 1.86694 valid acc: 0.655\n",
            "0-15th: train loss: 1.84708, train acc: 0.660 valid loss: 1.85621 valid acc: 0.658\n",
            "0-16th: train loss: 1.83348, train acc: 0.673 valid loss: 1.84750 valid acc: 0.665\n",
            "0-17th: train loss: 1.82240, train acc: 0.685 valid loss: 1.83732 valid acc: 0.671\n",
            "0-18th: train loss: 1.81050, train acc: 0.695 valid loss: 1.82593 valid acc: 0.680\n",
            "0-19th: train loss: 1.79747, train acc: 0.706 valid loss: 1.81559 valid acc: 0.693\n",
            "0-20th: train loss: 1.78561, train acc: 0.724 valid loss: 1.80616 valid acc: 0.693\n",
            "0-21th: train loss: 1.77511, train acc: 0.729 valid loss: 1.79457 valid acc: 0.708\n",
            "0-22th: train loss: 1.76343, train acc: 0.737 valid loss: 1.77854 valid acc: 0.730\n",
            "0-23th: train loss: 1.74870, train acc: 0.757 valid loss: 1.76072 valid acc: 0.752\n",
            "0-24th: train loss: 1.73217, train acc: 0.779 valid loss: 1.74815 valid acc: 0.771\n",
            "0-25th: train loss: 1.71992, train acc: 0.802 valid loss: 1.74350 valid acc: 0.777\n",
            "0-26th: train loss: 1.71472, train acc: 0.806 valid loss: 1.73840 valid acc: 0.777\n",
            "0-27th: train loss: 1.70947, train acc: 0.813 valid loss: 1.72961 valid acc: 0.784\n",
            "0-28th: train loss: 1.70120, train acc: 0.817 valid loss: 1.72163 valid acc: 0.793\n",
            "0-29th: train loss: 1.69314, train acc: 0.823 valid loss: 1.71600 valid acc: 0.796\n",
            "0-30th: train loss: 1.68695, train acc: 0.826 valid loss: 1.71164 valid acc: 0.796\n",
            "0-31th: train loss: 1.68213, train acc: 0.828 valid loss: 1.70768 valid acc: 0.799\n",
            "0-32th: train loss: 1.67797, train acc: 0.831 valid loss: 1.70349 valid acc: 0.799\n",
            "0-33th: train loss: 1.67372, train acc: 0.834 valid loss: 1.69839 valid acc: 0.806\n",
            "0-34th: train loss: 1.66860, train acc: 0.836 valid loss: 1.69181 valid acc: 0.806\n",
            "0-35th: train loss: 1.66204, train acc: 0.849 valid loss: 1.68323 valid acc: 0.812\n",
            "0-36th: train loss: 1.65374, train acc: 0.858 valid loss: 1.67134 valid acc: 0.837\n",
            "0-37th: train loss: 1.64327, train acc: 0.874 valid loss: 1.65498 valid acc: 0.856\n",
            "0-38th: train loss: 1.63003, train acc: 0.891 valid loss: 1.63908 valid acc: 0.887\n",
            "0-39th: train loss: 1.61632, train acc: 0.911 valid loss: 1.63349 valid acc: 0.893\n",
            "0-40th: train loss: 1.60872, train acc: 0.920 valid loss: 1.63211 valid acc: 0.887\n",
            "0-41th: train loss: 1.60273, train acc: 0.928 valid loss: 1.62660 valid acc: 0.890\n",
            "0-42th: train loss: 1.59260, train acc: 0.936 valid loss: 1.62067 valid acc: 0.897\n",
            "0-43th: train loss: 1.58277, train acc: 0.938 valid loss: 1.61698 valid acc: 0.900\n",
            "0-44th: train loss: 1.57637, train acc: 0.942 valid loss: 1.61498 valid acc: 0.900\n",
            "0-45th: train loss: 1.57242, train acc: 0.948 valid loss: 1.61396 valid acc: 0.906\n",
            "0-46th: train loss: 1.56970, train acc: 0.952 valid loss: 1.61330 valid acc: 0.906\n",
            "0-47th: train loss: 1.56746, train acc: 0.954 valid loss: 1.61220 valid acc: 0.912\n",
            "0-48th: train loss: 1.56495, train acc: 0.954 valid loss: 1.61004 valid acc: 0.906\n",
            "0-49th: train loss: 1.56168, train acc: 0.958 valid loss: 1.60692 valid acc: 0.906\n",
            "0-50th: train loss: 1.55793, train acc: 0.960 valid loss: 1.60347 valid acc: 0.915\n",
            "0-51th: train loss: 1.55444, train acc: 0.964 valid loss: 1.60026 valid acc: 0.918\n",
            "0-52th: train loss: 1.55168, train acc: 0.967 valid loss: 1.59735 valid acc: 0.915\n",
            "0-53th: train loss: 1.54937, train acc: 0.968 valid loss: 1.59454 valid acc: 0.915\n",
            "0-54th: train loss: 1.54694, train acc: 0.970 valid loss: 1.59187 valid acc: 0.918\n",
            "0-55th: train loss: 1.54419, train acc: 0.972 valid loss: 1.58962 valid acc: 0.918\n",
            "0-56th: train loss: 1.54142, train acc: 0.974 valid loss: 1.58795 valid acc: 0.918\n",
            "0-57th: train loss: 1.53895, train acc: 0.976 valid loss: 1.58670 valid acc: 0.922\n",
            "0-58th: train loss: 1.53684, train acc: 0.976 valid loss: 1.58559 valid acc: 0.925\n",
            "0-59th: train loss: 1.53495, train acc: 0.976 valid loss: 1.58452 valid acc: 0.925\n",
            "0-60th: train loss: 1.53319, train acc: 0.978 valid loss: 1.58349 valid acc: 0.928\n",
            "0-61th: train loss: 1.53155, train acc: 0.978 valid loss: 1.58250 valid acc: 0.925\n",
            "0-62th: train loss: 1.53001, train acc: 0.979 valid loss: 1.58150 valid acc: 0.918\n",
            "0-63th: train loss: 1.52854, train acc: 0.980 valid loss: 1.58039 valid acc: 0.922\n",
            "0-64th: train loss: 1.52708, train acc: 0.980 valid loss: 1.57919 valid acc: 0.922\n",
            "0-65th: train loss: 1.52567, train acc: 0.980 valid loss: 1.57799 valid acc: 0.928\n",
            "0-66th: train loss: 1.52437, train acc: 0.980 valid loss: 1.57689 valid acc: 0.928\n",
            "0-67th: train loss: 1.52323, train acc: 0.981 valid loss: 1.57594 valid acc: 0.928\n",
            "0-68th: train loss: 1.52219, train acc: 0.981 valid loss: 1.57514 valid acc: 0.931\n",
            "0-69th: train loss: 1.52117, train acc: 0.981 valid loss: 1.57453 valid acc: 0.928\n",
            "0-70th: train loss: 1.52012, train acc: 0.982 valid loss: 1.57412 valid acc: 0.931\n",
            "0-71th: train loss: 1.51909, train acc: 0.983 valid loss: 1.57391 valid acc: 0.928\n",
            "0-72th: train loss: 1.51815, train acc: 0.983 valid loss: 1.57379 valid acc: 0.931\n",
            "0-73th: train loss: 1.51731, train acc: 0.984 valid loss: 1.57359 valid acc: 0.931\n",
            "0-74th: train loss: 1.51653, train acc: 0.984 valid loss: 1.57318 valid acc: 0.931\n",
            "0-75th: train loss: 1.51574, train acc: 0.984 valid loss: 1.57252 valid acc: 0.931\n",
            "0-76th: train loss: 1.51492, train acc: 0.984 valid loss: 1.57170 valid acc: 0.931\n",
            "0-77th: train loss: 1.51412, train acc: 0.984 valid loss: 1.57088 valid acc: 0.931\n",
            "0-78th: train loss: 1.51337, train acc: 0.984 valid loss: 1.57017 valid acc: 0.931\n",
            "0-79th: train loss: 1.51270, train acc: 0.985 valid loss: 1.56963 valid acc: 0.931\n",
            "0-80th: train loss: 1.51206, train acc: 0.985 valid loss: 1.56925 valid acc: 0.931\n",
            "0-81th: train loss: 1.51143, train acc: 0.985 valid loss: 1.56900 valid acc: 0.928\n",
            "0-82th: train loss: 1.51079, train acc: 0.985 valid loss: 1.56883 valid acc: 0.928\n",
            "0-83th: train loss: 1.51018, train acc: 0.986 valid loss: 1.56870 valid acc: 0.928\n",
            "0-84th: train loss: 1.50959, train acc: 0.986 valid loss: 1.56855 valid acc: 0.928\n",
            "0-85th: train loss: 1.50903, train acc: 0.986 valid loss: 1.56834 valid acc: 0.928\n",
            "0-86th: train loss: 1.50850, train acc: 0.986 valid loss: 1.56806 valid acc: 0.928\n",
            "0-87th: train loss: 1.50799, train acc: 0.986 valid loss: 1.56771 valid acc: 0.928\n",
            "0-88th: train loss: 1.50748, train acc: 0.986 valid loss: 1.56734 valid acc: 0.928\n",
            "0-89th: train loss: 1.50700, train acc: 0.986 valid loss: 1.56696 valid acc: 0.928\n",
            "0-90th: train loss: 1.50652, train acc: 0.987 valid loss: 1.56660 valid acc: 0.928\n",
            "0-91th: train loss: 1.50606, train acc: 0.987 valid loss: 1.56627 valid acc: 0.928\n",
            "0-92th: train loss: 1.50561, train acc: 0.987 valid loss: 1.56595 valid acc: 0.928\n",
            "0-93th: train loss: 1.50518, train acc: 0.987 valid loss: 1.56565 valid acc: 0.928\n",
            "0-94th: train loss: 1.50476, train acc: 0.988 valid loss: 1.56535 valid acc: 0.931\n",
            "0-95th: train loss: 1.50434, train acc: 0.988 valid loss: 1.56504 valid acc: 0.931\n",
            "0-96th: train loss: 1.50393, train acc: 0.988 valid loss: 1.56474 valid acc: 0.931\n",
            "0-97th: train loss: 1.50352, train acc: 0.989 valid loss: 1.56443 valid acc: 0.931\n",
            "0-98th: train loss: 1.50312, train acc: 0.989 valid loss: 1.56413 valid acc: 0.931\n",
            "0-99th: train loss: 1.50274, train acc: 0.989 valid loss: 1.56383 valid acc: 0.934\n",
            "0-100th: train loss: 1.50236, train acc: 0.989 valid loss: 1.56353 valid acc: 0.937\n",
            "0-101th: train loss: 1.50199, train acc: 0.989 valid loss: 1.56324 valid acc: 0.937\n",
            "0-102th: train loss: 1.50162, train acc: 0.989 valid loss: 1.56294 valid acc: 0.940\n",
            "0-103th: train loss: 1.50126, train acc: 0.989 valid loss: 1.56265 valid acc: 0.940\n",
            "0-104th: train loss: 1.50090, train acc: 0.990 valid loss: 1.56237 valid acc: 0.940\n",
            "0-105th: train loss: 1.50055, train acc: 0.991 valid loss: 1.56211 valid acc: 0.940\n",
            "0-106th: train loss: 1.50021, train acc: 0.991 valid loss: 1.56185 valid acc: 0.940\n",
            "0-107th: train loss: 1.49987, train acc: 0.991 valid loss: 1.56162 valid acc: 0.940\n",
            "0-108th: train loss: 1.49954, train acc: 0.991 valid loss: 1.56140 valid acc: 0.940\n",
            "0-109th: train loss: 1.49921, train acc: 0.991 valid loss: 1.56119 valid acc: 0.940\n",
            "0-110th: train loss: 1.49888, train acc: 0.991 valid loss: 1.56101 valid acc: 0.940\n",
            "0-111th: train loss: 1.49856, train acc: 0.991 valid loss: 1.56083 valid acc: 0.940\n",
            "0-112th: train loss: 1.49824, train acc: 0.991 valid loss: 1.56067 valid acc: 0.940\n",
            "0-113th: train loss: 1.49793, train acc: 0.992 valid loss: 1.56051 valid acc: 0.937\n",
            "0-114th: train loss: 1.49763, train acc: 0.992 valid loss: 1.56036 valid acc: 0.937\n",
            "0-115th: train loss: 1.49733, train acc: 0.992 valid loss: 1.56021 valid acc: 0.940\n",
            "0-116th: train loss: 1.49703, train acc: 0.993 valid loss: 1.56006 valid acc: 0.940\n",
            "0-117th: train loss: 1.49674, train acc: 0.993 valid loss: 1.55990 valid acc: 0.940\n",
            "0-118th: train loss: 1.49646, train acc: 0.993 valid loss: 1.55973 valid acc: 0.940\n",
            "0-119th: train loss: 1.49618, train acc: 0.993 valid loss: 1.55956 valid acc: 0.940\n",
            "0-120th: train loss: 1.49591, train acc: 0.993 valid loss: 1.55938 valid acc: 0.940\n",
            "0-121th: train loss: 1.49564, train acc: 0.993 valid loss: 1.55921 valid acc: 0.940\n",
            "0-122th: train loss: 1.49538, train acc: 0.993 valid loss: 1.55904 valid acc: 0.940\n",
            "0-123th: train loss: 1.49513, train acc: 0.993 valid loss: 1.55888 valid acc: 0.940\n",
            "0-124th: train loss: 1.49488, train acc: 0.993 valid loss: 1.55873 valid acc: 0.940\n",
            "0-125th: train loss: 1.49464, train acc: 0.994 valid loss: 1.55858 valid acc: 0.940\n",
            "0-126th: train loss: 1.49440, train acc: 0.994 valid loss: 1.55843 valid acc: 0.937\n",
            "0-127th: train loss: 1.49417, train acc: 0.994 valid loss: 1.55828 valid acc: 0.937\n",
            "0-128th: train loss: 1.49394, train acc: 0.994 valid loss: 1.55811 valid acc: 0.937\n",
            "0-129th: train loss: 1.49372, train acc: 0.994 valid loss: 1.55794 valid acc: 0.937\n",
            "0-130th: train loss: 1.49350, train acc: 0.994 valid loss: 1.55775 valid acc: 0.937\n",
            "0-131th: train loss: 1.49328, train acc: 0.994 valid loss: 1.55755 valid acc: 0.937\n",
            "0-132th: train loss: 1.49307, train acc: 0.994 valid loss: 1.55736 valid acc: 0.937\n",
            "0-133th: train loss: 1.49286, train acc: 0.994 valid loss: 1.55717 valid acc: 0.937\n",
            "0-134th: train loss: 1.49265, train acc: 0.994 valid loss: 1.55700 valid acc: 0.937\n",
            "0-135th: train loss: 1.49245, train acc: 0.994 valid loss: 1.55683 valid acc: 0.937\n",
            "0-136th: train loss: 1.49225, train acc: 0.994 valid loss: 1.55668 valid acc: 0.937\n",
            "0-137th: train loss: 1.49206, train acc: 0.995 valid loss: 1.55654 valid acc: 0.937\n",
            "0-138th: train loss: 1.49186, train acc: 0.995 valid loss: 1.55641 valid acc: 0.937\n",
            "0-139th: train loss: 1.49168, train acc: 0.995 valid loss: 1.55627 valid acc: 0.937\n",
            "0-140th: train loss: 1.49149, train acc: 0.995 valid loss: 1.55613 valid acc: 0.937\n",
            "0-141th: train loss: 1.49131, train acc: 0.995 valid loss: 1.55598 valid acc: 0.937\n",
            "0-142th: train loss: 1.49113, train acc: 0.995 valid loss: 1.55584 valid acc: 0.937\n",
            "0-143th: train loss: 1.49095, train acc: 0.995 valid loss: 1.55569 valid acc: 0.937\n",
            "0-144th: train loss: 1.49077, train acc: 0.995 valid loss: 1.55554 valid acc: 0.937\n",
            "0-145th: train loss: 1.49060, train acc: 0.995 valid loss: 1.55540 valid acc: 0.940\n",
            "0-146th: train loss: 1.49043, train acc: 0.995 valid loss: 1.55526 valid acc: 0.937\n",
            "0-147th: train loss: 1.49026, train acc: 0.995 valid loss: 1.55513 valid acc: 0.937\n",
            "0-148th: train loss: 1.49009, train acc: 0.995 valid loss: 1.55501 valid acc: 0.937\n",
            "0-149th: train loss: 1.48993, train acc: 0.995 valid loss: 1.55488 valid acc: 0.937\n",
            "0-150th: train loss: 1.48976, train acc: 0.995 valid loss: 1.55476 valid acc: 0.937\n",
            "0-151th: train loss: 1.48960, train acc: 0.995 valid loss: 1.55464 valid acc: 0.937\n",
            "0-152th: train loss: 1.48944, train acc: 0.995 valid loss: 1.55452 valid acc: 0.937\n",
            "0-153th: train loss: 1.48928, train acc: 0.995 valid loss: 1.55440 valid acc: 0.937\n",
            "0-154th: train loss: 1.48912, train acc: 0.995 valid loss: 1.55429 valid acc: 0.937\n",
            "0-155th: train loss: 1.48896, train acc: 0.995 valid loss: 1.55417 valid acc: 0.937\n",
            "0-156th: train loss: 1.48880, train acc: 0.995 valid loss: 1.55406 valid acc: 0.937\n",
            "0-157th: train loss: 1.48865, train acc: 0.995 valid loss: 1.55395 valid acc: 0.937\n",
            "0-158th: train loss: 1.48850, train acc: 0.995 valid loss: 1.55385 valid acc: 0.937\n",
            "0-159th: train loss: 1.48834, train acc: 0.996 valid loss: 1.55374 valid acc: 0.937\n",
            "0-160th: train loss: 1.48819, train acc: 0.997 valid loss: 1.55362 valid acc: 0.937\n",
            "0-161th: train loss: 1.48804, train acc: 0.997 valid loss: 1.55351 valid acc: 0.937\n",
            "0-162th: train loss: 1.48790, train acc: 0.997 valid loss: 1.55339 valid acc: 0.937\n",
            "0-163th: train loss: 1.48776, train acc: 0.997 valid loss: 1.55327 valid acc: 0.934\n",
            "0-164th: train loss: 1.48762, train acc: 0.997 valid loss: 1.55315 valid acc: 0.934\n",
            "0-165th: train loss: 1.48748, train acc: 0.997 valid loss: 1.55303 valid acc: 0.934\n",
            "0-166th: train loss: 1.48735, train acc: 0.997 valid loss: 1.55291 valid acc: 0.934\n",
            "0-167th: train loss: 1.48721, train acc: 0.997 valid loss: 1.55278 valid acc: 0.934\n",
            "0-168th: train loss: 1.48708, train acc: 0.997 valid loss: 1.55265 valid acc: 0.934\n",
            "0-169th: train loss: 1.48695, train acc: 0.997 valid loss: 1.55251 valid acc: 0.934\n",
            "0-170th: train loss: 1.48683, train acc: 0.997 valid loss: 1.55238 valid acc: 0.934\n",
            "0-171th: train loss: 1.48670, train acc: 0.997 valid loss: 1.55224 valid acc: 0.934\n",
            "0-172th: train loss: 1.48658, train acc: 0.997 valid loss: 1.55210 valid acc: 0.934\n",
            "0-173th: train loss: 1.48645, train acc: 0.997 valid loss: 1.55197 valid acc: 0.934\n",
            "0-174th: train loss: 1.48633, train acc: 0.997 valid loss: 1.55184 valid acc: 0.934\n",
            "0-175th: train loss: 1.48621, train acc: 0.997 valid loss: 1.55172 valid acc: 0.934\n",
            "0-176th: train loss: 1.48609, train acc: 0.997 valid loss: 1.55160 valid acc: 0.934\n",
            "0-177th: train loss: 1.48597, train acc: 0.997 valid loss: 1.55149 valid acc: 0.934\n",
            "0-178th: train loss: 1.48585, train acc: 0.997 valid loss: 1.55138 valid acc: 0.934\n",
            "0-179th: train loss: 1.48573, train acc: 0.998 valid loss: 1.55128 valid acc: 0.934\n",
            "0-180th: train loss: 1.48561, train acc: 0.998 valid loss: 1.55118 valid acc: 0.934\n",
            "0-181th: train loss: 1.48549, train acc: 0.998 valid loss: 1.55109 valid acc: 0.934\n",
            "0-182th: train loss: 1.48538, train acc: 0.998 valid loss: 1.55099 valid acc: 0.934\n",
            "0-183th: train loss: 1.48526, train acc: 0.998 valid loss: 1.55091 valid acc: 0.934\n",
            "0-184th: train loss: 1.48515, train acc: 0.998 valid loss: 1.55082 valid acc: 0.937\n",
            "0-185th: train loss: 1.48504, train acc: 0.998 valid loss: 1.55073 valid acc: 0.937\n",
            "0-186th: train loss: 1.48494, train acc: 0.998 valid loss: 1.55065 valid acc: 0.937\n",
            "0-187th: train loss: 1.48483, train acc: 0.998 valid loss: 1.55056 valid acc: 0.937\n",
            "0-188th: train loss: 1.48473, train acc: 0.998 valid loss: 1.55048 valid acc: 0.937\n",
            "0-189th: train loss: 1.48463, train acc: 0.998 valid loss: 1.55039 valid acc: 0.937\n",
            "0-190th: train loss: 1.48454, train acc: 0.998 valid loss: 1.55030 valid acc: 0.937\n",
            "0-191th: train loss: 1.48444, train acc: 0.998 valid loss: 1.55022 valid acc: 0.937\n",
            "0-192th: train loss: 1.48435, train acc: 0.998 valid loss: 1.55013 valid acc: 0.937\n",
            "0-193th: train loss: 1.48426, train acc: 0.998 valid loss: 1.55004 valid acc: 0.937\n",
            "0-194th: train loss: 1.48417, train acc: 0.998 valid loss: 1.54996 valid acc: 0.937\n",
            "0-195th: train loss: 1.48408, train acc: 0.998 valid loss: 1.54987 valid acc: 0.937\n",
            "0-196th: train loss: 1.48399, train acc: 0.998 valid loss: 1.54979 valid acc: 0.937\n",
            "0-197th: train loss: 1.48390, train acc: 0.998 valid loss: 1.54971 valid acc: 0.937\n",
            "0-198th: train loss: 1.48382, train acc: 0.998 valid loss: 1.54963 valid acc: 0.937\n",
            "0-199th: train loss: 1.48373, train acc: 0.998 valid loss: 1.54955 valid acc: 0.937\n",
            "0-200th: train loss: 1.48365, train acc: 0.998 valid loss: 1.54947 valid acc: 0.937\n",
            "0-201th: train loss: 1.48357, train acc: 0.998 valid loss: 1.54939 valid acc: 0.937\n",
            "0-202th: train loss: 1.48349, train acc: 0.998 valid loss: 1.54931 valid acc: 0.937\n",
            "0-203th: train loss: 1.48341, train acc: 0.998 valid loss: 1.54923 valid acc: 0.937\n",
            "0-204th: train loss: 1.48333, train acc: 0.998 valid loss: 1.54915 valid acc: 0.940\n",
            "0-205th: train loss: 1.48325, train acc: 0.998 valid loss: 1.54907 valid acc: 0.940\n",
            "0-206th: train loss: 1.48317, train acc: 0.998 valid loss: 1.54899 valid acc: 0.944\n",
            "0-207th: train loss: 1.48310, train acc: 0.998 valid loss: 1.54890 valid acc: 0.944\n",
            "0-208th: train loss: 1.48302, train acc: 0.998 valid loss: 1.54882 valid acc: 0.944\n",
            "0-209th: train loss: 1.48295, train acc: 0.998 valid loss: 1.54873 valid acc: 0.944\n",
            "0-210th: train loss: 1.48288, train acc: 0.998 valid loss: 1.54864 valid acc: 0.944\n",
            "0-211th: train loss: 1.48281, train acc: 0.998 valid loss: 1.54855 valid acc: 0.944\n",
            "0-212th: train loss: 1.48273, train acc: 0.998 valid loss: 1.54845 valid acc: 0.944\n",
            "0-213th: train loss: 1.48266, train acc: 0.998 valid loss: 1.54836 valid acc: 0.944\n",
            "0-214th: train loss: 1.48259, train acc: 0.998 valid loss: 1.54827 valid acc: 0.944\n",
            "0-215th: train loss: 1.48253, train acc: 0.998 valid loss: 1.54817 valid acc: 0.944\n",
            "0-216th: train loss: 1.48246, train acc: 0.998 valid loss: 1.54808 valid acc: 0.944\n",
            "0-217th: train loss: 1.48239, train acc: 0.998 valid loss: 1.54798 valid acc: 0.944\n",
            "0-218th: train loss: 1.48232, train acc: 0.998 valid loss: 1.54789 valid acc: 0.944\n",
            "0-219th: train loss: 1.48226, train acc: 0.998 valid loss: 1.54780 valid acc: 0.944\n",
            "0-220th: train loss: 1.48219, train acc: 0.998 valid loss: 1.54771 valid acc: 0.944\n",
            "0-221th: train loss: 1.48213, train acc: 0.998 valid loss: 1.54762 valid acc: 0.944\n",
            "0-222th: train loss: 1.48207, train acc: 0.998 valid loss: 1.54753 valid acc: 0.944\n",
            "0-223th: train loss: 1.48200, train acc: 0.998 valid loss: 1.54744 valid acc: 0.944\n",
            "0-224th: train loss: 1.48194, train acc: 0.998 valid loss: 1.54735 valid acc: 0.944\n",
            "0-225th: train loss: 1.48188, train acc: 0.998 valid loss: 1.54727 valid acc: 0.944\n",
            "0-226th: train loss: 1.48182, train acc: 0.998 valid loss: 1.54719 valid acc: 0.944\n",
            "0-227th: train loss: 1.48176, train acc: 0.998 valid loss: 1.54710 valid acc: 0.944\n",
            "0-228th: train loss: 1.48170, train acc: 0.998 valid loss: 1.54702 valid acc: 0.944\n",
            "0-229th: train loss: 1.48164, train acc: 0.998 valid loss: 1.54694 valid acc: 0.944\n",
            "0-230th: train loss: 1.48158, train acc: 0.998 valid loss: 1.54685 valid acc: 0.944\n",
            "0-231th: train loss: 1.48152, train acc: 0.998 valid loss: 1.54677 valid acc: 0.944\n",
            "0-232th: train loss: 1.48146, train acc: 0.998 valid loss: 1.54669 valid acc: 0.944\n",
            "0-233th: train loss: 1.48141, train acc: 0.998 valid loss: 1.54661 valid acc: 0.944\n",
            "0-234th: train loss: 1.48135, train acc: 0.998 valid loss: 1.54653 valid acc: 0.944\n",
            "0-235th: train loss: 1.48130, train acc: 0.998 valid loss: 1.54644 valid acc: 0.944\n",
            "0-236th: train loss: 1.48124, train acc: 0.998 valid loss: 1.54636 valid acc: 0.940\n",
            "0-237th: train loss: 1.48118, train acc: 0.998 valid loss: 1.54628 valid acc: 0.940\n",
            "0-238th: train loss: 1.48113, train acc: 0.998 valid loss: 1.54620 valid acc: 0.940\n",
            "0-239th: train loss: 1.48108, train acc: 0.998 valid loss: 1.54612 valid acc: 0.940\n",
            "0-240th: train loss: 1.48102, train acc: 0.998 valid loss: 1.54604 valid acc: 0.940\n",
            "0-241th: train loss: 1.48097, train acc: 0.998 valid loss: 1.54596 valid acc: 0.940\n",
            "0-242th: train loss: 1.48092, train acc: 0.998 valid loss: 1.54588 valid acc: 0.940\n",
            "0-243th: train loss: 1.48086, train acc: 0.998 valid loss: 1.54580 valid acc: 0.940\n",
            "0-244th: train loss: 1.48081, train acc: 0.998 valid loss: 1.54572 valid acc: 0.940\n",
            "0-245th: train loss: 1.48076, train acc: 0.998 valid loss: 1.54564 valid acc: 0.940\n",
            "0-246th: train loss: 1.48071, train acc: 0.998 valid loss: 1.54557 valid acc: 0.940\n",
            "0-247th: train loss: 1.48066, train acc: 0.998 valid loss: 1.54549 valid acc: 0.940\n",
            "0-248th: train loss: 1.48061, train acc: 0.998 valid loss: 1.54542 valid acc: 0.940\n",
            "0-249th: train loss: 1.48056, train acc: 0.998 valid loss: 1.54534 valid acc: 0.940\n",
            "0-250th: train loss: 1.48051, train acc: 0.998 valid loss: 1.54527 valid acc: 0.944\n",
            "0-251th: train loss: 1.48046, train acc: 0.998 valid loss: 1.54519 valid acc: 0.944\n",
            "0-252th: train loss: 1.48041, train acc: 0.998 valid loss: 1.54512 valid acc: 0.944\n",
            "0-253th: train loss: 1.48037, train acc: 0.998 valid loss: 1.54505 valid acc: 0.944\n",
            "0-254th: train loss: 1.48032, train acc: 0.998 valid loss: 1.54498 valid acc: 0.944\n",
            "0-255th: train loss: 1.48027, train acc: 0.998 valid loss: 1.54490 valid acc: 0.944\n",
            "0-256th: train loss: 1.48022, train acc: 0.998 valid loss: 1.54483 valid acc: 0.944\n",
            "0-257th: train loss: 1.48018, train acc: 0.998 valid loss: 1.54476 valid acc: 0.940\n",
            "0-258th: train loss: 1.48013, train acc: 0.998 valid loss: 1.54469 valid acc: 0.940\n",
            "0-259th: train loss: 1.48009, train acc: 0.998 valid loss: 1.54462 valid acc: 0.940\n",
            "0-260th: train loss: 1.48004, train acc: 0.998 valid loss: 1.54455 valid acc: 0.940\n",
            "0-261th: train loss: 1.47999, train acc: 0.998 valid loss: 1.54448 valid acc: 0.940\n",
            "0-262th: train loss: 1.47995, train acc: 0.998 valid loss: 1.54441 valid acc: 0.940\n",
            "0-263th: train loss: 1.47991, train acc: 0.998 valid loss: 1.54435 valid acc: 0.940\n",
            "0-264th: train loss: 1.47986, train acc: 0.998 valid loss: 1.54428 valid acc: 0.940\n",
            "0-265th: train loss: 1.47982, train acc: 0.998 valid loss: 1.54421 valid acc: 0.940\n",
            "0-266th: train loss: 1.47977, train acc: 0.998 valid loss: 1.54414 valid acc: 0.940\n",
            "0-267th: train loss: 1.47973, train acc: 0.998 valid loss: 1.54408 valid acc: 0.940\n",
            "0-268th: train loss: 1.47969, train acc: 0.998 valid loss: 1.54401 valid acc: 0.940\n",
            "0-269th: train loss: 1.47965, train acc: 0.998 valid loss: 1.54395 valid acc: 0.940\n",
            "0-270th: train loss: 1.47960, train acc: 0.998 valid loss: 1.54388 valid acc: 0.940\n",
            "0-271th: train loss: 1.47956, train acc: 0.998 valid loss: 1.54382 valid acc: 0.940\n",
            "0-272th: train loss: 1.47952, train acc: 0.998 valid loss: 1.54375 valid acc: 0.940\n",
            "0-273th: train loss: 1.47948, train acc: 0.998 valid loss: 1.54369 valid acc: 0.940\n",
            "0-274th: train loss: 1.47944, train acc: 0.998 valid loss: 1.54362 valid acc: 0.940\n",
            "0-275th: train loss: 1.47940, train acc: 0.998 valid loss: 1.54356 valid acc: 0.940\n",
            "0-276th: train loss: 1.47936, train acc: 0.998 valid loss: 1.54350 valid acc: 0.940\n",
            "0-277th: train loss: 1.47932, train acc: 0.998 valid loss: 1.54344 valid acc: 0.940\n",
            "0-278th: train loss: 1.47928, train acc: 0.998 valid loss: 1.54338 valid acc: 0.940\n",
            "0-279th: train loss: 1.47924, train acc: 0.998 valid loss: 1.54331 valid acc: 0.940\n",
            "0-280th: train loss: 1.47920, train acc: 0.998 valid loss: 1.54325 valid acc: 0.940\n",
            "0-281th: train loss: 1.47916, train acc: 0.998 valid loss: 1.54319 valid acc: 0.940\n",
            "0-282th: train loss: 1.47912, train acc: 0.998 valid loss: 1.54313 valid acc: 0.940\n",
            "0-283th: train loss: 1.47908, train acc: 0.998 valid loss: 1.54307 valid acc: 0.940\n",
            "0-284th: train loss: 1.47904, train acc: 0.998 valid loss: 1.54301 valid acc: 0.940\n",
            "0-285th: train loss: 1.47900, train acc: 0.998 valid loss: 1.54295 valid acc: 0.940\n",
            "0-286th: train loss: 1.47897, train acc: 0.998 valid loss: 1.54289 valid acc: 0.940\n",
            "0-287th: train loss: 1.47893, train acc: 0.998 valid loss: 1.54284 valid acc: 0.940\n",
            "0-288th: train loss: 1.47889, train acc: 0.998 valid loss: 1.54278 valid acc: 0.944\n",
            "0-289th: train loss: 1.47885, train acc: 0.998 valid loss: 1.54272 valid acc: 0.944\n",
            "0-290th: train loss: 1.47882, train acc: 0.998 valid loss: 1.54266 valid acc: 0.944\n",
            "0-291th: train loss: 1.47878, train acc: 0.998 valid loss: 1.54261 valid acc: 0.944\n",
            "0-292th: train loss: 1.47874, train acc: 0.998 valid loss: 1.54255 valid acc: 0.944\n",
            "0-293th: train loss: 1.47871, train acc: 0.998 valid loss: 1.54249 valid acc: 0.944\n",
            "0-294th: train loss: 1.47867, train acc: 0.998 valid loss: 1.54244 valid acc: 0.944\n",
            "0-295th: train loss: 1.47864, train acc: 0.998 valid loss: 1.54238 valid acc: 0.944\n",
            "0-296th: train loss: 1.47860, train acc: 0.998 valid loss: 1.54233 valid acc: 0.944\n",
            "0-297th: train loss: 1.47857, train acc: 0.998 valid loss: 1.54227 valid acc: 0.944\n",
            "0-298th: train loss: 1.47853, train acc: 0.998 valid loss: 1.54222 valid acc: 0.944\n",
            "0-299th: train loss: 1.47850, train acc: 0.998 valid loss: 1.54216 valid acc: 0.944\n",
            "1-0th: train loss: 2.30104, train acc: 0.133 valid loss: 2.22248 valid acc: 0.248\n",
            "1-1th: train loss: 2.21877, train acc: 0.243 valid loss: 2.15975 valid acc: 0.304\n",
            "1-2th: train loss: 2.15344, train acc: 0.314 valid loss: 2.11404 valid acc: 0.367\n",
            "1-3th: train loss: 2.10128, train acc: 0.363 valid loss: 2.07072 valid acc: 0.411\n",
            "1-4th: train loss: 2.04921, train acc: 0.434 valid loss: 2.02174 valid acc: 0.448\n",
            "1-5th: train loss: 1.99231, train acc: 0.501 valid loss: 1.98701 valid acc: 0.483\n",
            "1-6th: train loss: 1.95463, train acc: 0.536 valid loss: 1.95800 valid acc: 0.524\n",
            "1-7th: train loss: 1.92519, train acc: 0.568 valid loss: 1.92479 valid acc: 0.552\n",
            "1-8th: train loss: 1.89250, train acc: 0.604 valid loss: 1.89168 valid acc: 0.614\n",
            "1-9th: train loss: 1.86208, train acc: 0.640 valid loss: 1.86586 valid acc: 0.633\n",
            "1-10th: train loss: 1.83888, train acc: 0.666 valid loss: 1.84596 valid acc: 0.658\n",
            "1-11th: train loss: 1.81922, train acc: 0.691 valid loss: 1.82666 valid acc: 0.687\n",
            "1-12th: train loss: 1.79800, train acc: 0.719 valid loss: 1.80862 valid acc: 0.708\n",
            "1-13th: train loss: 1.77705, train acc: 0.748 valid loss: 1.79370 valid acc: 0.721\n",
            "1-14th: train loss: 1.75955, train acc: 0.759 valid loss: 1.77784 valid acc: 0.755\n",
            "1-15th: train loss: 1.74213, train acc: 0.772 valid loss: 1.75920 valid acc: 0.768\n",
            "1-16th: train loss: 1.72311, train acc: 0.798 valid loss: 1.73960 valid acc: 0.806\n",
            "1-17th: train loss: 1.70396, train acc: 0.831 valid loss: 1.72302 valid acc: 0.828\n",
            "1-18th: train loss: 1.68882, train acc: 0.851 valid loss: 1.71276 valid acc: 0.831\n",
            "1-19th: train loss: 1.67919, train acc: 0.859 valid loss: 1.70310 valid acc: 0.824\n",
            "1-20th: train loss: 1.66829, train acc: 0.868 valid loss: 1.69248 valid acc: 0.840\n",
            "1-21th: train loss: 1.65551, train acc: 0.878 valid loss: 1.68483 valid acc: 0.853\n",
            "1-22th: train loss: 1.64540, train acc: 0.886 valid loss: 1.68071 valid acc: 0.850\n",
            "1-23th: train loss: 1.63872, train acc: 0.889 valid loss: 1.67749 valid acc: 0.856\n",
            "1-24th: train loss: 1.63316, train acc: 0.892 valid loss: 1.67319 valid acc: 0.850\n",
            "1-25th: train loss: 1.62706, train acc: 0.896 valid loss: 1.66748 valid acc: 0.853\n",
            "1-26th: train loss: 1.62026, train acc: 0.900 valid loss: 1.66109 valid acc: 0.862\n",
            "1-27th: train loss: 1.61348, train acc: 0.910 valid loss: 1.65519 valid acc: 0.868\n",
            "1-28th: train loss: 1.60757, train acc: 0.915 valid loss: 1.65056 valid acc: 0.875\n",
            "1-29th: train loss: 1.60289, train acc: 0.921 valid loss: 1.64687 valid acc: 0.868\n",
            "1-30th: train loss: 1.59894, train acc: 0.920 valid loss: 1.64314 valid acc: 0.871\n",
            "1-31th: train loss: 1.59482, train acc: 0.919 valid loss: 1.63910 valid acc: 0.875\n",
            "1-32th: train loss: 1.59024, train acc: 0.922 valid loss: 1.63536 valid acc: 0.881\n",
            "1-33th: train loss: 1.58575, train acc: 0.926 valid loss: 1.63250 valid acc: 0.884\n",
            "1-34th: train loss: 1.58190, train acc: 0.929 valid loss: 1.63049 valid acc: 0.887\n",
            "1-35th: train loss: 1.57871, train acc: 0.930 valid loss: 1.62877 valid acc: 0.887\n",
            "1-36th: train loss: 1.57580, train acc: 0.932 valid loss: 1.62686 valid acc: 0.893\n",
            "1-37th: train loss: 1.57282, train acc: 0.933 valid loss: 1.62464 valid acc: 0.893\n",
            "1-38th: train loss: 1.56970, train acc: 0.936 valid loss: 1.62239 valid acc: 0.890\n",
            "1-39th: train loss: 1.56663, train acc: 0.941 valid loss: 1.62039 valid acc: 0.887\n",
            "1-40th: train loss: 1.56386, train acc: 0.945 valid loss: 1.61866 valid acc: 0.893\n",
            "1-41th: train loss: 1.56140, train acc: 0.947 valid loss: 1.61695 valid acc: 0.893\n",
            "1-42th: train loss: 1.55903, train acc: 0.951 valid loss: 1.61508 valid acc: 0.893\n",
            "1-43th: train loss: 1.55660, train acc: 0.952 valid loss: 1.61309 valid acc: 0.903\n",
            "1-44th: train loss: 1.55414, train acc: 0.957 valid loss: 1.61117 valid acc: 0.897\n",
            "1-45th: train loss: 1.55182, train acc: 0.958 valid loss: 1.60946 valid acc: 0.900\n",
            "1-46th: train loss: 1.54977, train acc: 0.961 valid loss: 1.60790 valid acc: 0.906\n",
            "1-47th: train loss: 1.54792, train acc: 0.963 valid loss: 1.60635 valid acc: 0.906\n",
            "1-48th: train loss: 1.54616, train acc: 0.964 valid loss: 1.60471 valid acc: 0.906\n",
            "1-49th: train loss: 1.54438, train acc: 0.965 valid loss: 1.60304 valid acc: 0.912\n",
            "1-50th: train loss: 1.54261, train acc: 0.967 valid loss: 1.60144 valid acc: 0.915\n",
            "1-51th: train loss: 1.54095, train acc: 0.968 valid loss: 1.59993 valid acc: 0.915\n",
            "1-52th: train loss: 1.53938, train acc: 0.968 valid loss: 1.59845 valid acc: 0.915\n",
            "1-53th: train loss: 1.53786, train acc: 0.968 valid loss: 1.59694 valid acc: 0.918\n",
            "1-54th: train loss: 1.53636, train acc: 0.969 valid loss: 1.59542 valid acc: 0.915\n",
            "1-55th: train loss: 1.53487, train acc: 0.970 valid loss: 1.59393 valid acc: 0.915\n",
            "1-56th: train loss: 1.53343, train acc: 0.970 valid loss: 1.59254 valid acc: 0.922\n",
            "1-57th: train loss: 1.53207, train acc: 0.970 valid loss: 1.59125 valid acc: 0.918\n",
            "1-58th: train loss: 1.53077, train acc: 0.971 valid loss: 1.59005 valid acc: 0.918\n",
            "1-59th: train loss: 1.52952, train acc: 0.971 valid loss: 1.58892 valid acc: 0.925\n",
            "1-60th: train loss: 1.52829, train acc: 0.972 valid loss: 1.58787 valid acc: 0.925\n",
            "1-61th: train loss: 1.52710, train acc: 0.974 valid loss: 1.58687 valid acc: 0.922\n",
            "1-62th: train loss: 1.52595, train acc: 0.975 valid loss: 1.58590 valid acc: 0.922\n",
            "1-63th: train loss: 1.52485, train acc: 0.976 valid loss: 1.58494 valid acc: 0.922\n",
            "1-64th: train loss: 1.52377, train acc: 0.976 valid loss: 1.58402 valid acc: 0.922\n",
            "1-65th: train loss: 1.52272, train acc: 0.977 valid loss: 1.58316 valid acc: 0.922\n",
            "1-66th: train loss: 1.52170, train acc: 0.978 valid loss: 1.58237 valid acc: 0.918\n",
            "1-67th: train loss: 1.52070, train acc: 0.979 valid loss: 1.58163 valid acc: 0.925\n",
            "1-68th: train loss: 1.51974, train acc: 0.980 valid loss: 1.58093 valid acc: 0.928\n",
            "1-69th: train loss: 1.51881, train acc: 0.981 valid loss: 1.58023 valid acc: 0.925\n",
            "1-70th: train loss: 1.51793, train acc: 0.983 valid loss: 1.57951 valid acc: 0.934\n",
            "1-71th: train loss: 1.51707, train acc: 0.983 valid loss: 1.57874 valid acc: 0.937\n",
            "1-72th: train loss: 1.51624, train acc: 0.983 valid loss: 1.57793 valid acc: 0.937\n",
            "1-73th: train loss: 1.51543, train acc: 0.983 valid loss: 1.57711 valid acc: 0.937\n",
            "1-74th: train loss: 1.51466, train acc: 0.983 valid loss: 1.57630 valid acc: 0.940\n",
            "1-75th: train loss: 1.51391, train acc: 0.983 valid loss: 1.57553 valid acc: 0.944\n",
            "1-76th: train loss: 1.51319, train acc: 0.984 valid loss: 1.57479 valid acc: 0.944\n",
            "1-77th: train loss: 1.51249, train acc: 0.984 valid loss: 1.57409 valid acc: 0.940\n",
            "1-78th: train loss: 1.51181, train acc: 0.984 valid loss: 1.57343 valid acc: 0.940\n",
            "1-79th: train loss: 1.51115, train acc: 0.984 valid loss: 1.57281 valid acc: 0.940\n",
            "1-80th: train loss: 1.51051, train acc: 0.984 valid loss: 1.57220 valid acc: 0.944\n",
            "1-81th: train loss: 1.50988, train acc: 0.984 valid loss: 1.57162 valid acc: 0.947\n",
            "1-82th: train loss: 1.50928, train acc: 0.984 valid loss: 1.57104 valid acc: 0.950\n",
            "1-83th: train loss: 1.50868, train acc: 0.984 valid loss: 1.57048 valid acc: 0.950\n",
            "1-84th: train loss: 1.50810, train acc: 0.985 valid loss: 1.56994 valid acc: 0.950\n",
            "1-85th: train loss: 1.50753, train acc: 0.985 valid loss: 1.56943 valid acc: 0.950\n",
            "1-86th: train loss: 1.50699, train acc: 0.986 valid loss: 1.56896 valid acc: 0.950\n",
            "1-87th: train loss: 1.50646, train acc: 0.986 valid loss: 1.56851 valid acc: 0.950\n",
            "1-88th: train loss: 1.50594, train acc: 0.987 valid loss: 1.56810 valid acc: 0.950\n",
            "1-89th: train loss: 1.50545, train acc: 0.987 valid loss: 1.56770 valid acc: 0.953\n",
            "1-90th: train loss: 1.50496, train acc: 0.987 valid loss: 1.56731 valid acc: 0.950\n",
            "1-91th: train loss: 1.50450, train acc: 0.987 valid loss: 1.56692 valid acc: 0.950\n",
            "1-92th: train loss: 1.50405, train acc: 0.987 valid loss: 1.56652 valid acc: 0.950\n",
            "1-93th: train loss: 1.50360, train acc: 0.987 valid loss: 1.56611 valid acc: 0.950\n",
            "1-94th: train loss: 1.50317, train acc: 0.987 valid loss: 1.56570 valid acc: 0.950\n",
            "1-95th: train loss: 1.50275, train acc: 0.987 valid loss: 1.56530 valid acc: 0.950\n",
            "1-96th: train loss: 1.50234, train acc: 0.987 valid loss: 1.56491 valid acc: 0.950\n",
            "1-97th: train loss: 1.50193, train acc: 0.987 valid loss: 1.56454 valid acc: 0.950\n",
            "1-98th: train loss: 1.50153, train acc: 0.987 valid loss: 1.56419 valid acc: 0.950\n",
            "1-99th: train loss: 1.50114, train acc: 0.987 valid loss: 1.56385 valid acc: 0.950\n",
            "1-100th: train loss: 1.50076, train acc: 0.988 valid loss: 1.56351 valid acc: 0.950\n",
            "1-101th: train loss: 1.50038, train acc: 0.989 valid loss: 1.56318 valid acc: 0.950\n",
            "1-102th: train loss: 1.50001, train acc: 0.989 valid loss: 1.56285 valid acc: 0.950\n",
            "1-103th: train loss: 1.49964, train acc: 0.989 valid loss: 1.56253 valid acc: 0.950\n",
            "1-104th: train loss: 1.49928, train acc: 0.989 valid loss: 1.56221 valid acc: 0.950\n",
            "1-105th: train loss: 1.49892, train acc: 0.989 valid loss: 1.56191 valid acc: 0.950\n",
            "1-106th: train loss: 1.49858, train acc: 0.990 valid loss: 1.56163 valid acc: 0.950\n",
            "1-107th: train loss: 1.49824, train acc: 0.991 valid loss: 1.56137 valid acc: 0.950\n",
            "1-108th: train loss: 1.49790, train acc: 0.991 valid loss: 1.56113 valid acc: 0.950\n",
            "1-109th: train loss: 1.49757, train acc: 0.991 valid loss: 1.56091 valid acc: 0.950\n",
            "1-110th: train loss: 1.49725, train acc: 0.991 valid loss: 1.56071 valid acc: 0.950\n",
            "1-111th: train loss: 1.49694, train acc: 0.991 valid loss: 1.56051 valid acc: 0.950\n",
            "1-112th: train loss: 1.49663, train acc: 0.991 valid loss: 1.56032 valid acc: 0.950\n",
            "1-113th: train loss: 1.49632, train acc: 0.992 valid loss: 1.56014 valid acc: 0.950\n",
            "1-114th: train loss: 1.49603, train acc: 0.992 valid loss: 1.55996 valid acc: 0.950\n",
            "1-115th: train loss: 1.49573, train acc: 0.992 valid loss: 1.55979 valid acc: 0.950\n",
            "1-116th: train loss: 1.49545, train acc: 0.993 valid loss: 1.55962 valid acc: 0.950\n",
            "1-117th: train loss: 1.49517, train acc: 0.993 valid loss: 1.55946 valid acc: 0.950\n",
            "1-118th: train loss: 1.49489, train acc: 0.993 valid loss: 1.55931 valid acc: 0.950\n",
            "1-119th: train loss: 1.49462, train acc: 0.993 valid loss: 1.55917 valid acc: 0.950\n",
            "1-120th: train loss: 1.49436, train acc: 0.993 valid loss: 1.55903 valid acc: 0.950\n",
            "1-121th: train loss: 1.49410, train acc: 0.993 valid loss: 1.55889 valid acc: 0.950\n",
            "1-122th: train loss: 1.49384, train acc: 0.993 valid loss: 1.55876 valid acc: 0.950\n",
            "1-123th: train loss: 1.49359, train acc: 0.993 valid loss: 1.55863 valid acc: 0.950\n",
            "1-124th: train loss: 1.49334, train acc: 0.993 valid loss: 1.55850 valid acc: 0.953\n",
            "1-125th: train loss: 1.49310, train acc: 0.993 valid loss: 1.55837 valid acc: 0.953\n",
            "1-126th: train loss: 1.49286, train acc: 0.993 valid loss: 1.55824 valid acc: 0.953\n",
            "1-127th: train loss: 1.49263, train acc: 0.993 valid loss: 1.55812 valid acc: 0.953\n",
            "1-128th: train loss: 1.49240, train acc: 0.994 valid loss: 1.55800 valid acc: 0.950\n",
            "1-129th: train loss: 1.49217, train acc: 0.994 valid loss: 1.55788 valid acc: 0.950\n",
            "1-130th: train loss: 1.49196, train acc: 0.994 valid loss: 1.55775 valid acc: 0.950\n",
            "1-131th: train loss: 1.49174, train acc: 0.995 valid loss: 1.55763 valid acc: 0.953\n",
            "1-132th: train loss: 1.49153, train acc: 0.995 valid loss: 1.55749 valid acc: 0.953\n",
            "1-133th: train loss: 1.49133, train acc: 0.995 valid loss: 1.55736 valid acc: 0.953\n",
            "1-134th: train loss: 1.49113, train acc: 0.995 valid loss: 1.55721 valid acc: 0.953\n",
            "1-135th: train loss: 1.49093, train acc: 0.995 valid loss: 1.55707 valid acc: 0.953\n",
            "1-136th: train loss: 1.49074, train acc: 0.995 valid loss: 1.55693 valid acc: 0.953\n",
            "1-137th: train loss: 1.49055, train acc: 0.995 valid loss: 1.55678 valid acc: 0.953\n",
            "1-138th: train loss: 1.49036, train acc: 0.995 valid loss: 1.55663 valid acc: 0.953\n",
            "1-139th: train loss: 1.49018, train acc: 0.995 valid loss: 1.55648 valid acc: 0.953\n",
            "1-140th: train loss: 1.49000, train acc: 0.995 valid loss: 1.55633 valid acc: 0.953\n",
            "1-141th: train loss: 1.48982, train acc: 0.995 valid loss: 1.55617 valid acc: 0.953\n",
            "1-142th: train loss: 1.48964, train acc: 0.995 valid loss: 1.55601 valid acc: 0.953\n",
            "1-143th: train loss: 1.48947, train acc: 0.995 valid loss: 1.55585 valid acc: 0.953\n",
            "1-144th: train loss: 1.48929, train acc: 0.995 valid loss: 1.55569 valid acc: 0.953\n",
            "1-145th: train loss: 1.48912, train acc: 0.995 valid loss: 1.55552 valid acc: 0.953\n",
            "1-146th: train loss: 1.48895, train acc: 0.995 valid loss: 1.55536 valid acc: 0.953\n",
            "1-147th: train loss: 1.48878, train acc: 0.995 valid loss: 1.55520 valid acc: 0.953\n",
            "1-148th: train loss: 1.48861, train acc: 0.995 valid loss: 1.55503 valid acc: 0.950\n",
            "1-149th: train loss: 1.48845, train acc: 0.995 valid loss: 1.55487 valid acc: 0.950\n",
            "1-150th: train loss: 1.48828, train acc: 0.995 valid loss: 1.55472 valid acc: 0.950\n",
            "1-151th: train loss: 1.48811, train acc: 0.995 valid loss: 1.55456 valid acc: 0.950\n",
            "1-152th: train loss: 1.48795, train acc: 0.996 valid loss: 1.55441 valid acc: 0.950\n",
            "1-153th: train loss: 1.48779, train acc: 0.996 valid loss: 1.55427 valid acc: 0.950\n",
            "1-154th: train loss: 1.48763, train acc: 0.996 valid loss: 1.55414 valid acc: 0.950\n",
            "1-155th: train loss: 1.48747, train acc: 0.996 valid loss: 1.55402 valid acc: 0.953\n",
            "1-156th: train loss: 1.48732, train acc: 0.996 valid loss: 1.55391 valid acc: 0.953\n",
            "1-157th: train loss: 1.48718, train acc: 0.996 valid loss: 1.55382 valid acc: 0.953\n",
            "1-158th: train loss: 1.48703, train acc: 0.996 valid loss: 1.55373 valid acc: 0.953\n",
            "1-159th: train loss: 1.48689, train acc: 0.996 valid loss: 1.55364 valid acc: 0.953\n",
            "1-160th: train loss: 1.48676, train acc: 0.996 valid loss: 1.55357 valid acc: 0.953\n",
            "1-161th: train loss: 1.48662, train acc: 0.996 valid loss: 1.55350 valid acc: 0.953\n",
            "1-162th: train loss: 1.48649, train acc: 0.996 valid loss: 1.55343 valid acc: 0.953\n",
            "1-163th: train loss: 1.48636, train acc: 0.996 valid loss: 1.55337 valid acc: 0.953\n",
            "1-164th: train loss: 1.48622, train acc: 0.996 valid loss: 1.55331 valid acc: 0.953\n",
            "1-165th: train loss: 1.48609, train acc: 0.996 valid loss: 1.55326 valid acc: 0.953\n",
            "1-166th: train loss: 1.48596, train acc: 0.996 valid loss: 1.55321 valid acc: 0.953\n",
            "1-167th: train loss: 1.48583, train acc: 0.996 valid loss: 1.55316 valid acc: 0.953\n",
            "1-168th: train loss: 1.48570, train acc: 0.996 valid loss: 1.55312 valid acc: 0.953\n",
            "1-169th: train loss: 1.48557, train acc: 0.996 valid loss: 1.55307 valid acc: 0.953\n",
            "1-170th: train loss: 1.48544, train acc: 0.996 valid loss: 1.55303 valid acc: 0.953\n",
            "1-171th: train loss: 1.48531, train acc: 0.996 valid loss: 1.55299 valid acc: 0.953\n",
            "1-172th: train loss: 1.48518, train acc: 0.997 valid loss: 1.55295 valid acc: 0.953\n",
            "1-173th: train loss: 1.48505, train acc: 0.997 valid loss: 1.55292 valid acc: 0.953\n",
            "1-174th: train loss: 1.48492, train acc: 0.997 valid loss: 1.55289 valid acc: 0.953\n",
            "1-175th: train loss: 1.48480, train acc: 0.997 valid loss: 1.55287 valid acc: 0.953\n",
            "1-176th: train loss: 1.48467, train acc: 0.997 valid loss: 1.55284 valid acc: 0.953\n",
            "1-177th: train loss: 1.48455, train acc: 0.997 valid loss: 1.55282 valid acc: 0.953\n",
            "1-178th: train loss: 1.48443, train acc: 0.997 valid loss: 1.55279 valid acc: 0.953\n",
            "1-179th: train loss: 1.48431, train acc: 0.997 valid loss: 1.55277 valid acc: 0.953\n",
            "1-180th: train loss: 1.48420, train acc: 0.997 valid loss: 1.55274 valid acc: 0.953\n",
            "1-181th: train loss: 1.48409, train acc: 0.997 valid loss: 1.55271 valid acc: 0.953\n",
            "1-182th: train loss: 1.48399, train acc: 0.997 valid loss: 1.55268 valid acc: 0.953\n",
            "1-183th: train loss: 1.48388, train acc: 0.997 valid loss: 1.55264 valid acc: 0.953\n",
            "1-184th: train loss: 1.48378, train acc: 0.997 valid loss: 1.55260 valid acc: 0.953\n",
            "1-185th: train loss: 1.48368, train acc: 0.997 valid loss: 1.55255 valid acc: 0.953\n",
            "1-186th: train loss: 1.48358, train acc: 0.997 valid loss: 1.55250 valid acc: 0.953\n",
            "1-187th: train loss: 1.48348, train acc: 0.997 valid loss: 1.55244 valid acc: 0.953\n",
            "1-188th: train loss: 1.48338, train acc: 0.997 valid loss: 1.55239 valid acc: 0.953\n",
            "1-189th: train loss: 1.48328, train acc: 0.997 valid loss: 1.55233 valid acc: 0.953\n",
            "1-190th: train loss: 1.48318, train acc: 0.997 valid loss: 1.55227 valid acc: 0.953\n",
            "1-191th: train loss: 1.48308, train acc: 0.997 valid loss: 1.55221 valid acc: 0.956\n",
            "1-192th: train loss: 1.48298, train acc: 0.998 valid loss: 1.55216 valid acc: 0.956\n",
            "1-193th: train loss: 1.48288, train acc: 0.998 valid loss: 1.55211 valid acc: 0.956\n",
            "1-194th: train loss: 1.48278, train acc: 0.998 valid loss: 1.55206 valid acc: 0.956\n",
            "1-195th: train loss: 1.48269, train acc: 0.998 valid loss: 1.55202 valid acc: 0.956\n",
            "1-196th: train loss: 1.48259, train acc: 0.998 valid loss: 1.55198 valid acc: 0.956\n",
            "1-197th: train loss: 1.48249, train acc: 0.998 valid loss: 1.55195 valid acc: 0.956\n",
            "1-198th: train loss: 1.48239, train acc: 0.998 valid loss: 1.55193 valid acc: 0.956\n",
            "1-199th: train loss: 1.48229, train acc: 0.998 valid loss: 1.55191 valid acc: 0.956\n",
            "1-200th: train loss: 1.48219, train acc: 0.998 valid loss: 1.55190 valid acc: 0.956\n",
            "1-201th: train loss: 1.48209, train acc: 0.998 valid loss: 1.55190 valid acc: 0.956\n",
            "1-202th: train loss: 1.48199, train acc: 0.998 valid loss: 1.55189 valid acc: 0.956\n",
            "1-203th: train loss: 1.48189, train acc: 0.998 valid loss: 1.55189 valid acc: 0.953\n",
            "1-204th: train loss: 1.48179, train acc: 0.998 valid loss: 1.55189 valid acc: 0.953\n",
            "1-205th: train loss: 1.48170, train acc: 0.998 valid loss: 1.55188 valid acc: 0.953\n",
            "1-206th: train loss: 1.48160, train acc: 0.998 valid loss: 1.55187 valid acc: 0.953\n",
            "1-207th: train loss: 1.48151, train acc: 0.998 valid loss: 1.55185 valid acc: 0.953\n",
            "1-208th: train loss: 1.48142, train acc: 0.998 valid loss: 1.55183 valid acc: 0.953\n",
            "1-209th: train loss: 1.48133, train acc: 0.998 valid loss: 1.55180 valid acc: 0.953\n",
            "1-210th: train loss: 1.48125, train acc: 0.998 valid loss: 1.55176 valid acc: 0.953\n",
            "1-211th: train loss: 1.48117, train acc: 0.998 valid loss: 1.55170 valid acc: 0.953\n",
            "1-212th: train loss: 1.48108, train acc: 0.998 valid loss: 1.55164 valid acc: 0.953\n",
            "1-213th: train loss: 1.48100, train acc: 0.998 valid loss: 1.55157 valid acc: 0.953\n",
            "1-214th: train loss: 1.48093, train acc: 0.998 valid loss: 1.55149 valid acc: 0.953\n",
            "1-215th: train loss: 1.48085, train acc: 0.998 valid loss: 1.55141 valid acc: 0.953\n",
            "1-216th: train loss: 1.48077, train acc: 0.998 valid loss: 1.55132 valid acc: 0.953\n",
            "1-217th: train loss: 1.48069, train acc: 0.998 valid loss: 1.55123 valid acc: 0.953\n",
            "1-218th: train loss: 1.48062, train acc: 0.998 valid loss: 1.55114 valid acc: 0.953\n",
            "1-219th: train loss: 1.48054, train acc: 0.998 valid loss: 1.55106 valid acc: 0.953\n",
            "1-220th: train loss: 1.48047, train acc: 0.998 valid loss: 1.55097 valid acc: 0.953\n",
            "1-221th: train loss: 1.48040, train acc: 0.998 valid loss: 1.55089 valid acc: 0.953\n",
            "1-222th: train loss: 1.48033, train acc: 0.998 valid loss: 1.55082 valid acc: 0.953\n",
            "1-223th: train loss: 1.48025, train acc: 0.998 valid loss: 1.55075 valid acc: 0.956\n",
            "1-224th: train loss: 1.48018, train acc: 0.998 valid loss: 1.55069 valid acc: 0.956\n",
            "1-225th: train loss: 1.48012, train acc: 0.998 valid loss: 1.55063 valid acc: 0.956\n",
            "1-226th: train loss: 1.48005, train acc: 0.998 valid loss: 1.55058 valid acc: 0.956\n",
            "1-227th: train loss: 1.47998, train acc: 0.998 valid loss: 1.55054 valid acc: 0.959\n",
            "1-228th: train loss: 1.47991, train acc: 0.998 valid loss: 1.55049 valid acc: 0.956\n",
            "1-229th: train loss: 1.47985, train acc: 0.998 valid loss: 1.55045 valid acc: 0.956\n",
            "1-230th: train loss: 1.47978, train acc: 0.998 valid loss: 1.55042 valid acc: 0.956\n",
            "1-231th: train loss: 1.47972, train acc: 0.998 valid loss: 1.55038 valid acc: 0.956\n",
            "1-232th: train loss: 1.47965, train acc: 0.998 valid loss: 1.55035 valid acc: 0.956\n",
            "1-233th: train loss: 1.47959, train acc: 0.998 valid loss: 1.55031 valid acc: 0.956\n",
            "1-234th: train loss: 1.47953, train acc: 0.998 valid loss: 1.55028 valid acc: 0.956\n",
            "1-235th: train loss: 1.47946, train acc: 0.998 valid loss: 1.55024 valid acc: 0.956\n",
            "1-236th: train loss: 1.47940, train acc: 0.998 valid loss: 1.55021 valid acc: 0.956\n",
            "1-237th: train loss: 1.47934, train acc: 0.998 valid loss: 1.55017 valid acc: 0.956\n",
            "1-238th: train loss: 1.47928, train acc: 0.998 valid loss: 1.55013 valid acc: 0.956\n",
            "1-239th: train loss: 1.47922, train acc: 0.998 valid loss: 1.55010 valid acc: 0.956\n",
            "1-240th: train loss: 1.47916, train acc: 0.998 valid loss: 1.55006 valid acc: 0.959\n",
            "1-241th: train loss: 1.47911, train acc: 0.998 valid loss: 1.55002 valid acc: 0.962\n",
            "1-242th: train loss: 1.47905, train acc: 0.998 valid loss: 1.54998 valid acc: 0.962\n",
            "1-243th: train loss: 1.47899, train acc: 0.998 valid loss: 1.54994 valid acc: 0.962\n",
            "1-244th: train loss: 1.47893, train acc: 0.998 valid loss: 1.54990 valid acc: 0.962\n",
            "1-245th: train loss: 1.47888, train acc: 0.998 valid loss: 1.54987 valid acc: 0.962\n",
            "1-246th: train loss: 1.47882, train acc: 0.998 valid loss: 1.54983 valid acc: 0.959\n",
            "1-247th: train loss: 1.47877, train acc: 0.998 valid loss: 1.54979 valid acc: 0.959\n",
            "1-248th: train loss: 1.47871, train acc: 0.998 valid loss: 1.54976 valid acc: 0.959\n",
            "1-249th: train loss: 1.47866, train acc: 0.998 valid loss: 1.54973 valid acc: 0.959\n",
            "1-250th: train loss: 1.47860, train acc: 0.998 valid loss: 1.54969 valid acc: 0.956\n",
            "1-251th: train loss: 1.47855, train acc: 0.998 valid loss: 1.54966 valid acc: 0.956\n",
            "1-252th: train loss: 1.47850, train acc: 0.998 valid loss: 1.54963 valid acc: 0.956\n",
            "1-253th: train loss: 1.47844, train acc: 0.998 valid loss: 1.54960 valid acc: 0.953\n",
            "1-254th: train loss: 1.47839, train acc: 0.998 valid loss: 1.54957 valid acc: 0.953\n",
            "1-255th: train loss: 1.47834, train acc: 0.998 valid loss: 1.54955 valid acc: 0.953\n",
            "1-256th: train loss: 1.47829, train acc: 0.998 valid loss: 1.54952 valid acc: 0.953\n",
            "1-257th: train loss: 1.47824, train acc: 0.998 valid loss: 1.54949 valid acc: 0.953\n",
            "1-258th: train loss: 1.47819, train acc: 0.998 valid loss: 1.54947 valid acc: 0.953\n",
            "1-259th: train loss: 1.47814, train acc: 0.998 valid loss: 1.54945 valid acc: 0.953\n",
            "1-260th: train loss: 1.47809, train acc: 0.998 valid loss: 1.54942 valid acc: 0.956\n",
            "1-261th: train loss: 1.47804, train acc: 0.998 valid loss: 1.54940 valid acc: 0.956\n",
            "1-262th: train loss: 1.47799, train acc: 0.998 valid loss: 1.54938 valid acc: 0.956\n",
            "1-263th: train loss: 1.47794, train acc: 0.998 valid loss: 1.54935 valid acc: 0.956\n",
            "1-264th: train loss: 1.47789, train acc: 0.998 valid loss: 1.54933 valid acc: 0.956\n",
            "1-265th: train loss: 1.47784, train acc: 0.998 valid loss: 1.54931 valid acc: 0.956\n",
            "1-266th: train loss: 1.47780, train acc: 0.998 valid loss: 1.54929 valid acc: 0.956\n",
            "1-267th: train loss: 1.47775, train acc: 0.998 valid loss: 1.54927 valid acc: 0.956\n",
            "1-268th: train loss: 1.47770, train acc: 0.998 valid loss: 1.54924 valid acc: 0.956\n",
            "1-269th: train loss: 1.47766, train acc: 0.998 valid loss: 1.54922 valid acc: 0.956\n",
            "1-270th: train loss: 1.47761, train acc: 0.998 valid loss: 1.54920 valid acc: 0.956\n",
            "1-271th: train loss: 1.47756, train acc: 0.998 valid loss: 1.54918 valid acc: 0.956\n",
            "1-272th: train loss: 1.47752, train acc: 0.998 valid loss: 1.54916 valid acc: 0.956\n",
            "1-273th: train loss: 1.47747, train acc: 0.998 valid loss: 1.54914 valid acc: 0.956\n",
            "1-274th: train loss: 1.47743, train acc: 0.998 valid loss: 1.54912 valid acc: 0.956\n",
            "1-275th: train loss: 1.47738, train acc: 0.998 valid loss: 1.54909 valid acc: 0.956\n",
            "1-276th: train loss: 1.47734, train acc: 0.998 valid loss: 1.54907 valid acc: 0.956\n",
            "1-277th: train loss: 1.47730, train acc: 0.998 valid loss: 1.54905 valid acc: 0.956\n",
            "1-278th: train loss: 1.47725, train acc: 0.998 valid loss: 1.54903 valid acc: 0.956\n",
            "1-279th: train loss: 1.47721, train acc: 0.998 valid loss: 1.54901 valid acc: 0.956\n",
            "1-280th: train loss: 1.47717, train acc: 0.998 valid loss: 1.54899 valid acc: 0.956\n",
            "1-281th: train loss: 1.47713, train acc: 0.998 valid loss: 1.54896 valid acc: 0.956\n",
            "1-282th: train loss: 1.47708, train acc: 0.998 valid loss: 1.54894 valid acc: 0.956\n",
            "1-283th: train loss: 1.47704, train acc: 0.998 valid loss: 1.54892 valid acc: 0.956\n",
            "1-284th: train loss: 1.47700, train acc: 0.998 valid loss: 1.54890 valid acc: 0.956\n",
            "1-285th: train loss: 1.47696, train acc: 0.998 valid loss: 1.54887 valid acc: 0.956\n",
            "1-286th: train loss: 1.47692, train acc: 0.998 valid loss: 1.54885 valid acc: 0.956\n",
            "1-287th: train loss: 1.47688, train acc: 0.998 valid loss: 1.54883 valid acc: 0.956\n",
            "1-288th: train loss: 1.47684, train acc: 0.998 valid loss: 1.54881 valid acc: 0.956\n",
            "1-289th: train loss: 1.47680, train acc: 0.998 valid loss: 1.54878 valid acc: 0.956\n",
            "1-290th: train loss: 1.47676, train acc: 0.998 valid loss: 1.54876 valid acc: 0.956\n",
            "1-291th: train loss: 1.47672, train acc: 0.998 valid loss: 1.54874 valid acc: 0.956\n",
            "1-292th: train loss: 1.47668, train acc: 0.998 valid loss: 1.54871 valid acc: 0.956\n",
            "1-293th: train loss: 1.47664, train acc: 0.998 valid loss: 1.54869 valid acc: 0.956\n",
            "1-294th: train loss: 1.47660, train acc: 0.998 valid loss: 1.54866 valid acc: 0.956\n",
            "1-295th: train loss: 1.47656, train acc: 0.998 valid loss: 1.54864 valid acc: 0.956\n",
            "1-296th: train loss: 1.47652, train acc: 0.998 valid loss: 1.54861 valid acc: 0.956\n",
            "1-297th: train loss: 1.47649, train acc: 0.998 valid loss: 1.54859 valid acc: 0.956\n",
            "1-298th: train loss: 1.47645, train acc: 0.998 valid loss: 1.54856 valid acc: 0.956\n",
            "1-299th: train loss: 1.47641, train acc: 0.998 valid loss: 1.54854 valid acc: 0.956\n",
            "2-0th: train loss: 2.31600, train acc: 0.104 valid loss: 2.23865 valid acc: 0.194\n",
            "2-1th: train loss: 2.24560, train acc: 0.198 valid loss: 2.18177 valid acc: 0.285\n",
            "2-2th: train loss: 2.18651, train acc: 0.263 valid loss: 2.12394 valid acc: 0.361\n",
            "2-3th: train loss: 2.12679, train acc: 0.344 valid loss: 2.07586 valid acc: 0.404\n",
            "2-4th: train loss: 2.07492, train acc: 0.411 valid loss: 2.03148 valid acc: 0.464\n",
            "2-5th: train loss: 2.02748, train acc: 0.464 valid loss: 1.98549 valid acc: 0.520\n",
            "2-6th: train loss: 1.98396, train acc: 0.513 valid loss: 1.94338 valid acc: 0.583\n",
            "2-7th: train loss: 1.94636, train acc: 0.553 valid loss: 1.90963 valid acc: 0.602\n",
            "2-8th: train loss: 1.91237, train acc: 0.595 valid loss: 1.88034 valid acc: 0.643\n",
            "2-9th: train loss: 1.87751, train acc: 0.646 valid loss: 1.85654 valid acc: 0.671\n",
            "2-10th: train loss: 1.84643, train acc: 0.679 valid loss: 1.83739 valid acc: 0.683\n",
            "2-11th: train loss: 1.82247, train acc: 0.693 valid loss: 1.81897 valid acc: 0.705\n",
            "2-12th: train loss: 1.80211, train acc: 0.714 valid loss: 1.80160 valid acc: 0.724\n",
            "2-13th: train loss: 1.78419, train acc: 0.738 valid loss: 1.78541 valid acc: 0.734\n",
            "2-14th: train loss: 1.76813, train acc: 0.755 valid loss: 1.76917 valid acc: 0.752\n",
            "2-15th: train loss: 1.75277, train acc: 0.763 valid loss: 1.75307 valid acc: 0.768\n",
            "2-16th: train loss: 1.73775, train acc: 0.780 valid loss: 1.73804 valid acc: 0.803\n",
            "2-17th: train loss: 1.72335, train acc: 0.797 valid loss: 1.72449 valid acc: 0.818\n",
            "2-18th: train loss: 1.71002, train acc: 0.819 valid loss: 1.71225 valid acc: 0.824\n",
            "2-19th: train loss: 1.69859, train acc: 0.836 valid loss: 1.70107 valid acc: 0.850\n",
            "2-20th: train loss: 1.68866, train acc: 0.846 valid loss: 1.68971 valid acc: 0.859\n",
            "2-21th: train loss: 1.67818, train acc: 0.853 valid loss: 1.67857 valid acc: 0.862\n",
            "2-22th: train loss: 1.66709, train acc: 0.860 valid loss: 1.66976 valid acc: 0.865\n",
            "2-23th: train loss: 1.65730, train acc: 0.870 valid loss: 1.66341 valid acc: 0.878\n",
            "2-24th: train loss: 1.64940, train acc: 0.879 valid loss: 1.65771 valid acc: 0.875\n",
            "2-25th: train loss: 1.64231, train acc: 0.882 valid loss: 1.65144 valid acc: 0.884\n",
            "2-26th: train loss: 1.63526, train acc: 0.885 valid loss: 1.64463 valid acc: 0.887\n",
            "2-27th: train loss: 1.62836, train acc: 0.890 valid loss: 1.63783 valid acc: 0.893\n",
            "2-28th: train loss: 1.62184, train acc: 0.897 valid loss: 1.63147 valid acc: 0.887\n",
            "2-29th: train loss: 1.61577, train acc: 0.902 valid loss: 1.62575 valid acc: 0.890\n",
            "2-30th: train loss: 1.61016, train acc: 0.907 valid loss: 1.62058 valid acc: 0.897\n",
            "2-31th: train loss: 1.60491, train acc: 0.911 valid loss: 1.61589 valid acc: 0.906\n",
            "2-32th: train loss: 1.59982, train acc: 0.914 valid loss: 1.61181 valid acc: 0.909\n",
            "2-33th: train loss: 1.59492, train acc: 0.922 valid loss: 1.60855 valid acc: 0.912\n",
            "2-34th: train loss: 1.59044, train acc: 0.923 valid loss: 1.60587 valid acc: 0.912\n",
            "2-35th: train loss: 1.58641, train acc: 0.925 valid loss: 1.60330 valid acc: 0.909\n",
            "2-36th: train loss: 1.58263, train acc: 0.929 valid loss: 1.60066 valid acc: 0.912\n",
            "2-37th: train loss: 1.57900, train acc: 0.932 valid loss: 1.59813 valid acc: 0.909\n",
            "2-38th: train loss: 1.57564, train acc: 0.935 valid loss: 1.59590 valid acc: 0.915\n",
            "2-39th: train loss: 1.57259, train acc: 0.937 valid loss: 1.59392 valid acc: 0.918\n",
            "2-40th: train loss: 1.56969, train acc: 0.940 valid loss: 1.59207 valid acc: 0.918\n",
            "2-41th: train loss: 1.56681, train acc: 0.944 valid loss: 1.59043 valid acc: 0.925\n",
            "2-42th: train loss: 1.56405, train acc: 0.947 valid loss: 1.58904 valid acc: 0.918\n",
            "2-43th: train loss: 1.56153, train acc: 0.948 valid loss: 1.58777 valid acc: 0.918\n",
            "2-44th: train loss: 1.55922, train acc: 0.948 valid loss: 1.58638 valid acc: 0.925\n",
            "2-45th: train loss: 1.55695, train acc: 0.951 valid loss: 1.58487 valid acc: 0.925\n",
            "2-46th: train loss: 1.55470, train acc: 0.953 valid loss: 1.58347 valid acc: 0.925\n",
            "2-47th: train loss: 1.55259, train acc: 0.953 valid loss: 1.58234 valid acc: 0.922\n",
            "2-48th: train loss: 1.55068, train acc: 0.954 valid loss: 1.58140 valid acc: 0.922\n",
            "2-49th: train loss: 1.54891, train acc: 0.954 valid loss: 1.58047 valid acc: 0.918\n",
            "2-50th: train loss: 1.54718, train acc: 0.955 valid loss: 1.57945 valid acc: 0.918\n",
            "2-51th: train loss: 1.54548, train acc: 0.958 valid loss: 1.57839 valid acc: 0.922\n",
            "2-52th: train loss: 1.54385, train acc: 0.958 valid loss: 1.57736 valid acc: 0.928\n",
            "2-53th: train loss: 1.54230, train acc: 0.961 valid loss: 1.57640 valid acc: 0.928\n",
            "2-54th: train loss: 1.54079, train acc: 0.962 valid loss: 1.57554 valid acc: 0.928\n",
            "2-55th: train loss: 1.53929, train acc: 0.963 valid loss: 1.57479 valid acc: 0.922\n",
            "2-56th: train loss: 1.53779, train acc: 0.965 valid loss: 1.57416 valid acc: 0.922\n",
            "2-57th: train loss: 1.53633, train acc: 0.966 valid loss: 1.57358 valid acc: 0.922\n",
            "2-58th: train loss: 1.53491, train acc: 0.967 valid loss: 1.57293 valid acc: 0.922\n",
            "2-59th: train loss: 1.53350, train acc: 0.968 valid loss: 1.57213 valid acc: 0.925\n",
            "2-60th: train loss: 1.53207, train acc: 0.968 valid loss: 1.57121 valid acc: 0.925\n",
            "2-61th: train loss: 1.53064, train acc: 0.970 valid loss: 1.57022 valid acc: 0.928\n",
            "2-62th: train loss: 1.52926, train acc: 0.972 valid loss: 1.56923 valid acc: 0.931\n",
            "2-63th: train loss: 1.52795, train acc: 0.973 valid loss: 1.56829 valid acc: 0.934\n",
            "2-64th: train loss: 1.52673, train acc: 0.973 valid loss: 1.56744 valid acc: 0.940\n",
            "2-65th: train loss: 1.52562, train acc: 0.974 valid loss: 1.56672 valid acc: 0.940\n",
            "2-66th: train loss: 1.52459, train acc: 0.975 valid loss: 1.56609 valid acc: 0.937\n",
            "2-67th: train loss: 1.52364, train acc: 0.975 valid loss: 1.56552 valid acc: 0.937\n",
            "2-68th: train loss: 1.52273, train acc: 0.975 valid loss: 1.56496 valid acc: 0.937\n",
            "2-69th: train loss: 1.52185, train acc: 0.976 valid loss: 1.56440 valid acc: 0.937\n",
            "2-70th: train loss: 1.52098, train acc: 0.976 valid loss: 1.56384 valid acc: 0.937\n",
            "2-71th: train loss: 1.52015, train acc: 0.976 valid loss: 1.56331 valid acc: 0.944\n",
            "2-72th: train loss: 1.51934, train acc: 0.976 valid loss: 1.56284 valid acc: 0.944\n",
            "2-73th: train loss: 1.51855, train acc: 0.976 valid loss: 1.56246 valid acc: 0.944\n",
            "2-74th: train loss: 1.51780, train acc: 0.976 valid loss: 1.56218 valid acc: 0.944\n",
            "2-75th: train loss: 1.51707, train acc: 0.976 valid loss: 1.56196 valid acc: 0.940\n",
            "2-76th: train loss: 1.51635, train acc: 0.976 valid loss: 1.56179 valid acc: 0.940\n",
            "2-77th: train loss: 1.51566, train acc: 0.976 valid loss: 1.56163 valid acc: 0.940\n",
            "2-78th: train loss: 1.51497, train acc: 0.976 valid loss: 1.56147 valid acc: 0.944\n",
            "2-79th: train loss: 1.51429, train acc: 0.978 valid loss: 1.56131 valid acc: 0.944\n",
            "2-80th: train loss: 1.51363, train acc: 0.979 valid loss: 1.56116 valid acc: 0.940\n",
            "2-81th: train loss: 1.51298, train acc: 0.979 valid loss: 1.56103 valid acc: 0.940\n",
            "2-82th: train loss: 1.51234, train acc: 0.980 valid loss: 1.56092 valid acc: 0.940\n",
            "2-83th: train loss: 1.51172, train acc: 0.983 valid loss: 1.56082 valid acc: 0.940\n",
            "2-84th: train loss: 1.51112, train acc: 0.983 valid loss: 1.56073 valid acc: 0.940\n",
            "2-85th: train loss: 1.51054, train acc: 0.984 valid loss: 1.56062 valid acc: 0.940\n",
            "2-86th: train loss: 1.50997, train acc: 0.984 valid loss: 1.56048 valid acc: 0.940\n",
            "2-87th: train loss: 1.50941, train acc: 0.984 valid loss: 1.56029 valid acc: 0.940\n",
            "2-88th: train loss: 1.50886, train acc: 0.984 valid loss: 1.56007 valid acc: 0.940\n",
            "2-89th: train loss: 1.50833, train acc: 0.984 valid loss: 1.55980 valid acc: 0.940\n",
            "2-90th: train loss: 1.50781, train acc: 0.986 valid loss: 1.55950 valid acc: 0.940\n",
            "2-91th: train loss: 1.50729, train acc: 0.986 valid loss: 1.55919 valid acc: 0.940\n",
            "2-92th: train loss: 1.50679, train acc: 0.986 valid loss: 1.55886 valid acc: 0.940\n",
            "2-93th: train loss: 1.50630, train acc: 0.986 valid loss: 1.55852 valid acc: 0.944\n",
            "2-94th: train loss: 1.50581, train acc: 0.986 valid loss: 1.55817 valid acc: 0.944\n",
            "2-95th: train loss: 1.50534, train acc: 0.987 valid loss: 1.55780 valid acc: 0.944\n",
            "2-96th: train loss: 1.50487, train acc: 0.987 valid loss: 1.55742 valid acc: 0.944\n",
            "2-97th: train loss: 1.50441, train acc: 0.987 valid loss: 1.55702 valid acc: 0.944\n",
            "2-98th: train loss: 1.50395, train acc: 0.987 valid loss: 1.55662 valid acc: 0.947\n",
            "2-99th: train loss: 1.50351, train acc: 0.988 valid loss: 1.55621 valid acc: 0.947\n",
            "2-100th: train loss: 1.50307, train acc: 0.988 valid loss: 1.55580 valid acc: 0.947\n",
            "2-101th: train loss: 1.50264, train acc: 0.988 valid loss: 1.55540 valid acc: 0.950\n",
            "2-102th: train loss: 1.50222, train acc: 0.988 valid loss: 1.55499 valid acc: 0.950\n",
            "2-103th: train loss: 1.50181, train acc: 0.989 valid loss: 1.55458 valid acc: 0.953\n",
            "2-104th: train loss: 1.50141, train acc: 0.990 valid loss: 1.55416 valid acc: 0.953\n",
            "2-105th: train loss: 1.50101, train acc: 0.991 valid loss: 1.55374 valid acc: 0.953\n",
            "2-106th: train loss: 1.50063, train acc: 0.991 valid loss: 1.55332 valid acc: 0.953\n",
            "2-107th: train loss: 1.50025, train acc: 0.991 valid loss: 1.55290 valid acc: 0.953\n",
            "2-108th: train loss: 1.49988, train acc: 0.991 valid loss: 1.55248 valid acc: 0.953\n",
            "2-109th: train loss: 1.49951, train acc: 0.991 valid loss: 1.55206 valid acc: 0.953\n",
            "2-110th: train loss: 1.49915, train acc: 0.991 valid loss: 1.55164 valid acc: 0.953\n",
            "2-111th: train loss: 1.49880, train acc: 0.991 valid loss: 1.55123 valid acc: 0.953\n",
            "2-112th: train loss: 1.49846, train acc: 0.991 valid loss: 1.55084 valid acc: 0.953\n",
            "2-113th: train loss: 1.49812, train acc: 0.991 valid loss: 1.55045 valid acc: 0.953\n",
            "2-114th: train loss: 1.49778, train acc: 0.991 valid loss: 1.55008 valid acc: 0.953\n",
            "2-115th: train loss: 1.49746, train acc: 0.991 valid loss: 1.54972 valid acc: 0.953\n",
            "2-116th: train loss: 1.49714, train acc: 0.991 valid loss: 1.54937 valid acc: 0.953\n",
            "2-117th: train loss: 1.49683, train acc: 0.991 valid loss: 1.54904 valid acc: 0.953\n",
            "2-118th: train loss: 1.49653, train acc: 0.991 valid loss: 1.54873 valid acc: 0.953\n",
            "2-119th: train loss: 1.49623, train acc: 0.991 valid loss: 1.54842 valid acc: 0.953\n",
            "2-120th: train loss: 1.49594, train acc: 0.991 valid loss: 1.54813 valid acc: 0.953\n",
            "2-121th: train loss: 1.49565, train acc: 0.991 valid loss: 1.54785 valid acc: 0.953\n",
            "2-122th: train loss: 1.49537, train acc: 0.991 valid loss: 1.54757 valid acc: 0.953\n",
            "2-123th: train loss: 1.49510, train acc: 0.991 valid loss: 1.54731 valid acc: 0.953\n",
            "2-124th: train loss: 1.49483, train acc: 0.991 valid loss: 1.54705 valid acc: 0.953\n",
            "2-125th: train loss: 1.49456, train acc: 0.991 valid loss: 1.54681 valid acc: 0.953\n",
            "2-126th: train loss: 1.49430, train acc: 0.991 valid loss: 1.54657 valid acc: 0.953\n",
            "2-127th: train loss: 1.49404, train acc: 0.991 valid loss: 1.54634 valid acc: 0.953\n",
            "2-128th: train loss: 1.49378, train acc: 0.992 valid loss: 1.54611 valid acc: 0.953\n",
            "2-129th: train loss: 1.49353, train acc: 0.992 valid loss: 1.54589 valid acc: 0.953\n",
            "2-130th: train loss: 1.49328, train acc: 0.992 valid loss: 1.54568 valid acc: 0.953\n",
            "2-131th: train loss: 1.49303, train acc: 0.992 valid loss: 1.54548 valid acc: 0.953\n",
            "2-132th: train loss: 1.49280, train acc: 0.993 valid loss: 1.54530 valid acc: 0.953\n",
            "2-133th: train loss: 1.49256, train acc: 0.993 valid loss: 1.54512 valid acc: 0.953\n",
            "2-134th: train loss: 1.49234, train acc: 0.993 valid loss: 1.54496 valid acc: 0.953\n",
            "2-135th: train loss: 1.49212, train acc: 0.993 valid loss: 1.54481 valid acc: 0.953\n",
            "2-136th: train loss: 1.49191, train acc: 0.993 valid loss: 1.54467 valid acc: 0.953\n",
            "2-137th: train loss: 1.49171, train acc: 0.993 valid loss: 1.54453 valid acc: 0.953\n",
            "2-138th: train loss: 1.49151, train acc: 0.993 valid loss: 1.54439 valid acc: 0.953\n",
            "2-139th: train loss: 1.49131, train acc: 0.993 valid loss: 1.54425 valid acc: 0.953\n",
            "2-140th: train loss: 1.49112, train acc: 0.993 valid loss: 1.54411 valid acc: 0.953\n",
            "2-141th: train loss: 1.49094, train acc: 0.994 valid loss: 1.54397 valid acc: 0.953\n",
            "2-142th: train loss: 1.49076, train acc: 0.994 valid loss: 1.54383 valid acc: 0.953\n",
            "2-143th: train loss: 1.49058, train acc: 0.994 valid loss: 1.54370 valid acc: 0.953\n",
            "2-144th: train loss: 1.49041, train acc: 0.994 valid loss: 1.54357 valid acc: 0.953\n",
            "2-145th: train loss: 1.49024, train acc: 0.994 valid loss: 1.54344 valid acc: 0.953\n",
            "2-146th: train loss: 1.49007, train acc: 0.994 valid loss: 1.54331 valid acc: 0.953\n",
            "2-147th: train loss: 1.48991, train acc: 0.994 valid loss: 1.54318 valid acc: 0.953\n",
            "2-148th: train loss: 1.48975, train acc: 0.994 valid loss: 1.54305 valid acc: 0.953\n",
            "2-149th: train loss: 1.48960, train acc: 0.994 valid loss: 1.54292 valid acc: 0.953\n",
            "2-150th: train loss: 1.48944, train acc: 0.994 valid loss: 1.54279 valid acc: 0.953\n",
            "2-151th: train loss: 1.48929, train acc: 0.994 valid loss: 1.54267 valid acc: 0.953\n",
            "2-152th: train loss: 1.48915, train acc: 0.994 valid loss: 1.54254 valid acc: 0.953\n",
            "2-153th: train loss: 1.48900, train acc: 0.994 valid loss: 1.54242 valid acc: 0.953\n",
            "2-154th: train loss: 1.48886, train acc: 0.994 valid loss: 1.54231 valid acc: 0.953\n",
            "2-155th: train loss: 1.48872, train acc: 0.994 valid loss: 1.54220 valid acc: 0.953\n",
            "2-156th: train loss: 1.48858, train acc: 0.994 valid loss: 1.54208 valid acc: 0.953\n",
            "2-157th: train loss: 1.48845, train acc: 0.994 valid loss: 1.54197 valid acc: 0.953\n",
            "2-158th: train loss: 1.48831, train acc: 0.994 valid loss: 1.54187 valid acc: 0.953\n",
            "2-159th: train loss: 1.48818, train acc: 0.994 valid loss: 1.54176 valid acc: 0.953\n",
            "2-160th: train loss: 1.48805, train acc: 0.994 valid loss: 1.54165 valid acc: 0.953\n",
            "2-161th: train loss: 1.48792, train acc: 0.994 valid loss: 1.54154 valid acc: 0.953\n",
            "2-162th: train loss: 1.48779, train acc: 0.995 valid loss: 1.54143 valid acc: 0.953\n",
            "2-163th: train loss: 1.48767, train acc: 0.995 valid loss: 1.54131 valid acc: 0.953\n",
            "2-164th: train loss: 1.48754, train acc: 0.995 valid loss: 1.54120 valid acc: 0.953\n",
            "2-165th: train loss: 1.48742, train acc: 0.995 valid loss: 1.54109 valid acc: 0.956\n",
            "2-166th: train loss: 1.48730, train acc: 0.995 valid loss: 1.54097 valid acc: 0.956\n",
            "2-167th: train loss: 1.48718, train acc: 0.995 valid loss: 1.54086 valid acc: 0.956\n",
            "2-168th: train loss: 1.48706, train acc: 0.995 valid loss: 1.54074 valid acc: 0.956\n",
            "2-169th: train loss: 1.48694, train acc: 0.995 valid loss: 1.54062 valid acc: 0.956\n",
            "2-170th: train loss: 1.48683, train acc: 0.995 valid loss: 1.54050 valid acc: 0.956\n",
            "2-171th: train loss: 1.48672, train acc: 0.995 valid loss: 1.54038 valid acc: 0.956\n",
            "2-172th: train loss: 1.48661, train acc: 0.995 valid loss: 1.54025 valid acc: 0.956\n",
            "2-173th: train loss: 1.48651, train acc: 0.995 valid loss: 1.54013 valid acc: 0.956\n",
            "2-174th: train loss: 1.48640, train acc: 0.995 valid loss: 1.54000 valid acc: 0.956\n",
            "2-175th: train loss: 1.48630, train acc: 0.995 valid loss: 1.53988 valid acc: 0.956\n",
            "2-176th: train loss: 1.48619, train acc: 0.995 valid loss: 1.53976 valid acc: 0.956\n",
            "2-177th: train loss: 1.48609, train acc: 0.995 valid loss: 1.53963 valid acc: 0.956\n",
            "2-178th: train loss: 1.48599, train acc: 0.995 valid loss: 1.53951 valid acc: 0.956\n",
            "2-179th: train loss: 1.48590, train acc: 0.995 valid loss: 1.53939 valid acc: 0.956\n",
            "2-180th: train loss: 1.48580, train acc: 0.995 valid loss: 1.53927 valid acc: 0.956\n",
            "2-181th: train loss: 1.48570, train acc: 0.995 valid loss: 1.53915 valid acc: 0.956\n",
            "2-182th: train loss: 1.48561, train acc: 0.995 valid loss: 1.53904 valid acc: 0.956\n",
            "2-183th: train loss: 1.48551, train acc: 0.995 valid loss: 1.53892 valid acc: 0.956\n",
            "2-184th: train loss: 1.48542, train acc: 0.995 valid loss: 1.53881 valid acc: 0.956\n",
            "2-185th: train loss: 1.48532, train acc: 0.995 valid loss: 1.53871 valid acc: 0.956\n",
            "2-186th: train loss: 1.48523, train acc: 0.995 valid loss: 1.53860 valid acc: 0.956\n",
            "2-187th: train loss: 1.48514, train acc: 0.995 valid loss: 1.53850 valid acc: 0.956\n",
            "2-188th: train loss: 1.48505, train acc: 0.995 valid loss: 1.53840 valid acc: 0.956\n",
            "2-189th: train loss: 1.48495, train acc: 0.995 valid loss: 1.53831 valid acc: 0.956\n",
            "2-190th: train loss: 1.48486, train acc: 0.995 valid loss: 1.53821 valid acc: 0.956\n",
            "2-191th: train loss: 1.48477, train acc: 0.995 valid loss: 1.53813 valid acc: 0.956\n",
            "2-192th: train loss: 1.48468, train acc: 0.995 valid loss: 1.53804 valid acc: 0.956\n",
            "2-193th: train loss: 1.48459, train acc: 0.995 valid loss: 1.53796 valid acc: 0.956\n",
            "2-194th: train loss: 1.48450, train acc: 0.995 valid loss: 1.53787 valid acc: 0.956\n",
            "2-195th: train loss: 1.48441, train acc: 0.995 valid loss: 1.53779 valid acc: 0.956\n",
            "2-196th: train loss: 1.48432, train acc: 0.995 valid loss: 1.53771 valid acc: 0.956\n",
            "2-197th: train loss: 1.48423, train acc: 0.995 valid loss: 1.53763 valid acc: 0.956\n",
            "2-198th: train loss: 1.48414, train acc: 0.995 valid loss: 1.53755 valid acc: 0.956\n",
            "2-199th: train loss: 1.48406, train acc: 0.995 valid loss: 1.53746 valid acc: 0.956\n",
            "2-200th: train loss: 1.48398, train acc: 0.995 valid loss: 1.53737 valid acc: 0.956\n",
            "2-201th: train loss: 1.48389, train acc: 0.995 valid loss: 1.53728 valid acc: 0.956\n",
            "2-202th: train loss: 1.48381, train acc: 0.995 valid loss: 1.53718 valid acc: 0.956\n",
            "2-203th: train loss: 1.48374, train acc: 0.995 valid loss: 1.53707 valid acc: 0.956\n",
            "2-204th: train loss: 1.48366, train acc: 0.995 valid loss: 1.53695 valid acc: 0.956\n",
            "2-205th: train loss: 1.48358, train acc: 0.995 valid loss: 1.53683 valid acc: 0.956\n",
            "2-206th: train loss: 1.48351, train acc: 0.995 valid loss: 1.53671 valid acc: 0.956\n",
            "2-207th: train loss: 1.48343, train acc: 0.995 valid loss: 1.53657 valid acc: 0.956\n",
            "2-208th: train loss: 1.48336, train acc: 0.995 valid loss: 1.53644 valid acc: 0.956\n",
            "2-209th: train loss: 1.48329, train acc: 0.995 valid loss: 1.53630 valid acc: 0.956\n",
            "2-210th: train loss: 1.48322, train acc: 0.995 valid loss: 1.53615 valid acc: 0.956\n",
            "2-211th: train loss: 1.48315, train acc: 0.995 valid loss: 1.53600 valid acc: 0.956\n",
            "2-212th: train loss: 1.48308, train acc: 0.995 valid loss: 1.53586 valid acc: 0.956\n",
            "2-213th: train loss: 1.48301, train acc: 0.995 valid loss: 1.53571 valid acc: 0.956\n",
            "2-214th: train loss: 1.48294, train acc: 0.995 valid loss: 1.53556 valid acc: 0.956\n",
            "2-215th: train loss: 1.48287, train acc: 0.995 valid loss: 1.53541 valid acc: 0.956\n",
            "2-216th: train loss: 1.48280, train acc: 0.995 valid loss: 1.53526 valid acc: 0.956\n",
            "2-217th: train loss: 1.48274, train acc: 0.995 valid loss: 1.53512 valid acc: 0.956\n",
            "2-218th: train loss: 1.48267, train acc: 0.995 valid loss: 1.53498 valid acc: 0.959\n",
            "2-219th: train loss: 1.48261, train acc: 0.995 valid loss: 1.53483 valid acc: 0.959\n",
            "2-220th: train loss: 1.48255, train acc: 0.995 valid loss: 1.53469 valid acc: 0.959\n",
            "2-221th: train loss: 1.48248, train acc: 0.995 valid loss: 1.53456 valid acc: 0.959\n",
            "2-222th: train loss: 1.48242, train acc: 0.995 valid loss: 1.53442 valid acc: 0.959\n",
            "2-223th: train loss: 1.48236, train acc: 0.995 valid loss: 1.53429 valid acc: 0.959\n",
            "2-224th: train loss: 1.48230, train acc: 0.995 valid loss: 1.53415 valid acc: 0.959\n",
            "2-225th: train loss: 1.48224, train acc: 0.995 valid loss: 1.53402 valid acc: 0.959\n",
            "2-226th: train loss: 1.48218, train acc: 0.995 valid loss: 1.53389 valid acc: 0.959\n",
            "2-227th: train loss: 1.48212, train acc: 0.995 valid loss: 1.53375 valid acc: 0.959\n",
            "2-228th: train loss: 1.48207, train acc: 0.995 valid loss: 1.53362 valid acc: 0.959\n",
            "2-229th: train loss: 1.48201, train acc: 0.995 valid loss: 1.53349 valid acc: 0.959\n",
            "2-230th: train loss: 1.48195, train acc: 0.995 valid loss: 1.53336 valid acc: 0.959\n",
            "2-231th: train loss: 1.48190, train acc: 0.995 valid loss: 1.53322 valid acc: 0.962\n",
            "2-232th: train loss: 1.48184, train acc: 0.995 valid loss: 1.53309 valid acc: 0.962\n",
            "2-233th: train loss: 1.48178, train acc: 0.995 valid loss: 1.53296 valid acc: 0.962\n",
            "2-234th: train loss: 1.48173, train acc: 0.995 valid loss: 1.53283 valid acc: 0.962\n",
            "2-235th: train loss: 1.48168, train acc: 0.995 valid loss: 1.53270 valid acc: 0.962\n",
            "2-236th: train loss: 1.48162, train acc: 0.995 valid loss: 1.53257 valid acc: 0.962\n",
            "2-237th: train loss: 1.48157, train acc: 0.995 valid loss: 1.53244 valid acc: 0.962\n",
            "2-238th: train loss: 1.48152, train acc: 0.995 valid loss: 1.53231 valid acc: 0.962\n",
            "2-239th: train loss: 1.48146, train acc: 0.995 valid loss: 1.53218 valid acc: 0.962\n",
            "2-240th: train loss: 1.48141, train acc: 0.995 valid loss: 1.53205 valid acc: 0.962\n",
            "2-241th: train loss: 1.48136, train acc: 0.995 valid loss: 1.53192 valid acc: 0.962\n",
            "2-242th: train loss: 1.48131, train acc: 0.995 valid loss: 1.53179 valid acc: 0.962\n",
            "2-243th: train loss: 1.48126, train acc: 0.995 valid loss: 1.53166 valid acc: 0.962\n",
            "2-244th: train loss: 1.48121, train acc: 0.995 valid loss: 1.53154 valid acc: 0.962\n",
            "2-245th: train loss: 1.48116, train acc: 0.995 valid loss: 1.53141 valid acc: 0.962\n",
            "2-246th: train loss: 1.48111, train acc: 0.995 valid loss: 1.53128 valid acc: 0.962\n",
            "2-247th: train loss: 1.48106, train acc: 0.995 valid loss: 1.53115 valid acc: 0.966\n",
            "2-248th: train loss: 1.48101, train acc: 0.995 valid loss: 1.53102 valid acc: 0.966\n",
            "2-249th: train loss: 1.48096, train acc: 0.995 valid loss: 1.53090 valid acc: 0.966\n",
            "2-250th: train loss: 1.48091, train acc: 0.995 valid loss: 1.53077 valid acc: 0.966\n",
            "2-251th: train loss: 1.48086, train acc: 0.995 valid loss: 1.53064 valid acc: 0.966\n",
            "2-252th: train loss: 1.48081, train acc: 0.995 valid loss: 1.53051 valid acc: 0.966\n",
            "2-253th: train loss: 1.48076, train acc: 0.995 valid loss: 1.53039 valid acc: 0.966\n",
            "2-254th: train loss: 1.48072, train acc: 0.995 valid loss: 1.53026 valid acc: 0.966\n",
            "2-255th: train loss: 1.48067, train acc: 0.995 valid loss: 1.53013 valid acc: 0.966\n",
            "2-256th: train loss: 1.48062, train acc: 0.995 valid loss: 1.53000 valid acc: 0.966\n",
            "2-257th: train loss: 1.48057, train acc: 0.995 valid loss: 1.52988 valid acc: 0.966\n",
            "2-258th: train loss: 1.48052, train acc: 0.995 valid loss: 1.52975 valid acc: 0.966\n",
            "2-259th: train loss: 1.48047, train acc: 0.995 valid loss: 1.52962 valid acc: 0.966\n",
            "2-260th: train loss: 1.48042, train acc: 0.995 valid loss: 1.52949 valid acc: 0.966\n",
            "2-261th: train loss: 1.48037, train acc: 0.995 valid loss: 1.52936 valid acc: 0.966\n",
            "2-262th: train loss: 1.48031, train acc: 0.995 valid loss: 1.52923 valid acc: 0.966\n",
            "2-263th: train loss: 1.48026, train acc: 0.995 valid loss: 1.52910 valid acc: 0.966\n",
            "2-264th: train loss: 1.48021, train acc: 0.995 valid loss: 1.52897 valid acc: 0.966\n",
            "2-265th: train loss: 1.48015, train acc: 0.995 valid loss: 1.52884 valid acc: 0.966\n",
            "2-266th: train loss: 1.48009, train acc: 0.995 valid loss: 1.52870 valid acc: 0.966\n",
            "2-267th: train loss: 1.48003, train acc: 0.995 valid loss: 1.52857 valid acc: 0.966\n",
            "2-268th: train loss: 1.47997, train acc: 0.996 valid loss: 1.52843 valid acc: 0.966\n",
            "2-269th: train loss: 1.47990, train acc: 0.996 valid loss: 1.52829 valid acc: 0.966\n",
            "2-270th: train loss: 1.47984, train acc: 0.996 valid loss: 1.52815 valid acc: 0.966\n",
            "2-271th: train loss: 1.47977, train acc: 0.996 valid loss: 1.52800 valid acc: 0.966\n",
            "2-272th: train loss: 1.47970, train acc: 0.996 valid loss: 1.52786 valid acc: 0.966\n",
            "2-273th: train loss: 1.47963, train acc: 0.997 valid loss: 1.52771 valid acc: 0.966\n",
            "2-274th: train loss: 1.47956, train acc: 0.997 valid loss: 1.52756 valid acc: 0.966\n",
            "2-275th: train loss: 1.47949, train acc: 0.997 valid loss: 1.52742 valid acc: 0.966\n",
            "2-276th: train loss: 1.47942, train acc: 0.997 valid loss: 1.52728 valid acc: 0.966\n",
            "2-277th: train loss: 1.47935, train acc: 0.997 valid loss: 1.52714 valid acc: 0.966\n",
            "2-278th: train loss: 1.47929, train acc: 0.997 valid loss: 1.52700 valid acc: 0.966\n",
            "2-279th: train loss: 1.47922, train acc: 0.997 valid loss: 1.52687 valid acc: 0.966\n",
            "2-280th: train loss: 1.47916, train acc: 0.997 valid loss: 1.52673 valid acc: 0.966\n",
            "2-281th: train loss: 1.47910, train acc: 0.997 valid loss: 1.52660 valid acc: 0.966\n",
            "2-282th: train loss: 1.47905, train acc: 0.997 valid loss: 1.52646 valid acc: 0.966\n",
            "2-283th: train loss: 1.47899, train acc: 0.997 valid loss: 1.52632 valid acc: 0.966\n",
            "2-284th: train loss: 1.47893, train acc: 0.997 valid loss: 1.52617 valid acc: 0.966\n",
            "2-285th: train loss: 1.47888, train acc: 0.997 valid loss: 1.52601 valid acc: 0.966\n",
            "2-286th: train loss: 1.47882, train acc: 0.997 valid loss: 1.52584 valid acc: 0.966\n",
            "2-287th: train loss: 1.47877, train acc: 0.997 valid loss: 1.52567 valid acc: 0.966\n",
            "2-288th: train loss: 1.47871, train acc: 0.997 valid loss: 1.52549 valid acc: 0.969\n",
            "2-289th: train loss: 1.47866, train acc: 0.997 valid loss: 1.52530 valid acc: 0.969\n",
            "2-290th: train loss: 1.47860, train acc: 0.997 valid loss: 1.52511 valid acc: 0.969\n",
            "2-291th: train loss: 1.47854, train acc: 0.997 valid loss: 1.52490 valid acc: 0.969\n",
            "2-292th: train loss: 1.47849, train acc: 0.997 valid loss: 1.52470 valid acc: 0.969\n",
            "2-293th: train loss: 1.47843, train acc: 0.997 valid loss: 1.52449 valid acc: 0.969\n",
            "2-294th: train loss: 1.47837, train acc: 0.997 valid loss: 1.52427 valid acc: 0.969\n",
            "2-295th: train loss: 1.47830, train acc: 0.997 valid loss: 1.52406 valid acc: 0.969\n",
            "2-296th: train loss: 1.47824, train acc: 0.997 valid loss: 1.52385 valid acc: 0.969\n",
            "2-297th: train loss: 1.47817, train acc: 0.998 valid loss: 1.52363 valid acc: 0.972\n",
            "2-298th: train loss: 1.47811, train acc: 0.998 valid loss: 1.52343 valid acc: 0.972\n",
            "2-299th: train loss: 1.47804, train acc: 0.998 valid loss: 1.52323 valid acc: 0.972\n",
            "3-0th: train loss: 2.32208, train acc: 0.082 valid loss: 2.25025 valid acc: 0.186\n",
            "3-1th: train loss: 2.25152, train acc: 0.206 valid loss: 2.18371 valid acc: 0.296\n",
            "3-2th: train loss: 2.17812, train acc: 0.293 valid loss: 2.11834 valid acc: 0.377\n",
            "3-3th: train loss: 2.10903, train acc: 0.385 valid loss: 2.05579 valid acc: 0.450\n",
            "3-4th: train loss: 2.04602, train acc: 0.454 valid loss: 2.00503 valid acc: 0.487\n",
            "3-5th: train loss: 1.99281, train acc: 0.512 valid loss: 1.96785 valid acc: 0.522\n",
            "3-6th: train loss: 1.94729, train acc: 0.574 valid loss: 1.93322 valid acc: 0.591\n",
            "3-7th: train loss: 1.90327, train acc: 0.625 valid loss: 1.90271 valid acc: 0.616\n",
            "3-8th: train loss: 1.86562, train acc: 0.678 valid loss: 1.88031 valid acc: 0.629\n",
            "3-9th: train loss: 1.83918, train acc: 0.695 valid loss: 1.85997 valid acc: 0.657\n",
            "3-10th: train loss: 1.81619, train acc: 0.715 valid loss: 1.84083 valid acc: 0.667\n",
            "3-11th: train loss: 1.79429, train acc: 0.737 valid loss: 1.82576 valid acc: 0.689\n",
            "3-12th: train loss: 1.77619, train acc: 0.751 valid loss: 1.81455 valid acc: 0.695\n",
            "3-13th: train loss: 1.76232, train acc: 0.757 valid loss: 1.80465 valid acc: 0.701\n",
            "3-14th: train loss: 1.75010, train acc: 0.774 valid loss: 1.79467 valid acc: 0.698\n",
            "3-15th: train loss: 1.73802, train acc: 0.783 valid loss: 1.78412 valid acc: 0.714\n",
            "3-16th: train loss: 1.72595, train acc: 0.797 valid loss: 1.77175 valid acc: 0.733\n",
            "3-17th: train loss: 1.71291, train acc: 0.815 valid loss: 1.75466 valid acc: 0.758\n",
            "3-18th: train loss: 1.69568, train acc: 0.839 valid loss: 1.72992 valid acc: 0.811\n",
            "3-19th: train loss: 1.67189, train acc: 0.875 valid loss: 1.70553 valid acc: 0.821\n",
            "3-20th: train loss: 1.65073, train acc: 0.892 valid loss: 1.69395 valid acc: 0.836\n",
            "3-21th: train loss: 1.63949, train acc: 0.906 valid loss: 1.68728 valid acc: 0.836\n",
            "3-22th: train loss: 1.63138, train acc: 0.909 valid loss: 1.67853 valid acc: 0.843\n",
            "3-23th: train loss: 1.62111, train acc: 0.918 valid loss: 1.66915 valid acc: 0.855\n",
            "3-24th: train loss: 1.61070, train acc: 0.921 valid loss: 1.66134 valid acc: 0.858\n",
            "3-25th: train loss: 1.60240, train acc: 0.931 valid loss: 1.65517 valid acc: 0.862\n",
            "3-26th: train loss: 1.59610, train acc: 0.936 valid loss: 1.65019 valid acc: 0.858\n",
            "3-27th: train loss: 1.59123, train acc: 0.937 valid loss: 1.64603 valid acc: 0.865\n",
            "3-28th: train loss: 1.58720, train acc: 0.939 valid loss: 1.64231 valid acc: 0.868\n",
            "3-29th: train loss: 1.58336, train acc: 0.942 valid loss: 1.63891 valid acc: 0.877\n",
            "3-30th: train loss: 1.57935, train acc: 0.944 valid loss: 1.63597 valid acc: 0.874\n",
            "3-31th: train loss: 1.57532, train acc: 0.947 valid loss: 1.63351 valid acc: 0.877\n",
            "3-32th: train loss: 1.57149, train acc: 0.950 valid loss: 1.63124 valid acc: 0.874\n",
            "3-33th: train loss: 1.56785, train acc: 0.951 valid loss: 1.62883 valid acc: 0.871\n",
            "3-34th: train loss: 1.56439, train acc: 0.953 valid loss: 1.62617 valid acc: 0.874\n",
            "3-35th: train loss: 1.56124, train acc: 0.953 valid loss: 1.62334 valid acc: 0.874\n",
            "3-36th: train loss: 1.55844, train acc: 0.955 valid loss: 1.62037 valid acc: 0.887\n",
            "3-37th: train loss: 1.55577, train acc: 0.958 valid loss: 1.61730 valid acc: 0.887\n",
            "3-38th: train loss: 1.55300, train acc: 0.962 valid loss: 1.61424 valid acc: 0.890\n",
            "3-39th: train loss: 1.55014, train acc: 0.962 valid loss: 1.61138 valid acc: 0.890\n",
            "3-40th: train loss: 1.54742, train acc: 0.963 valid loss: 1.60881 valid acc: 0.899\n",
            "3-41th: train loss: 1.54505, train acc: 0.965 valid loss: 1.60646 valid acc: 0.906\n",
            "3-42th: train loss: 1.54302, train acc: 0.966 valid loss: 1.60422 valid acc: 0.903\n",
            "3-43th: train loss: 1.54121, train acc: 0.967 valid loss: 1.60206 valid acc: 0.903\n",
            "3-44th: train loss: 1.53947, train acc: 0.969 valid loss: 1.60010 valid acc: 0.906\n",
            "3-45th: train loss: 1.53776, train acc: 0.970 valid loss: 1.59845 valid acc: 0.915\n",
            "3-46th: train loss: 1.53611, train acc: 0.970 valid loss: 1.59714 valid acc: 0.918\n",
            "3-47th: train loss: 1.53451, train acc: 0.973 valid loss: 1.59613 valid acc: 0.918\n",
            "3-48th: train loss: 1.53298, train acc: 0.973 valid loss: 1.59534 valid acc: 0.918\n",
            "3-49th: train loss: 1.53154, train acc: 0.974 valid loss: 1.59466 valid acc: 0.918\n",
            "3-50th: train loss: 1.53024, train acc: 0.975 valid loss: 1.59390 valid acc: 0.921\n",
            "3-51th: train loss: 1.52901, train acc: 0.976 valid loss: 1.59292 valid acc: 0.918\n",
            "3-52th: train loss: 1.52780, train acc: 0.976 valid loss: 1.59169 valid acc: 0.918\n",
            "3-53th: train loss: 1.52657, train acc: 0.977 valid loss: 1.59034 valid acc: 0.918\n",
            "3-54th: train loss: 1.52537, train acc: 0.977 valid loss: 1.58901 valid acc: 0.918\n",
            "3-55th: train loss: 1.52425, train acc: 0.977 valid loss: 1.58781 valid acc: 0.921\n",
            "3-56th: train loss: 1.52322, train acc: 0.977 valid loss: 1.58677 valid acc: 0.918\n",
            "3-57th: train loss: 1.52224, train acc: 0.978 valid loss: 1.58586 valid acc: 0.921\n",
            "3-58th: train loss: 1.52129, train acc: 0.980 valid loss: 1.58508 valid acc: 0.921\n",
            "3-59th: train loss: 1.52036, train acc: 0.980 valid loss: 1.58438 valid acc: 0.925\n",
            "3-60th: train loss: 1.51948, train acc: 0.980 valid loss: 1.58373 valid acc: 0.925\n",
            "3-61th: train loss: 1.51863, train acc: 0.980 valid loss: 1.58307 valid acc: 0.925\n",
            "3-62th: train loss: 1.51781, train acc: 0.981 valid loss: 1.58239 valid acc: 0.928\n",
            "3-63th: train loss: 1.51703, train acc: 0.982 valid loss: 1.58170 valid acc: 0.931\n",
            "3-64th: train loss: 1.51627, train acc: 0.982 valid loss: 1.58105 valid acc: 0.931\n",
            "3-65th: train loss: 1.51555, train acc: 0.982 valid loss: 1.58043 valid acc: 0.928\n",
            "3-66th: train loss: 1.51486, train acc: 0.983 valid loss: 1.57985 valid acc: 0.928\n",
            "3-67th: train loss: 1.51418, train acc: 0.983 valid loss: 1.57930 valid acc: 0.928\n",
            "3-68th: train loss: 1.51353, train acc: 0.983 valid loss: 1.57877 valid acc: 0.928\n",
            "3-69th: train loss: 1.51289, train acc: 0.983 valid loss: 1.57824 valid acc: 0.931\n",
            "3-70th: train loss: 1.51228, train acc: 0.983 valid loss: 1.57771 valid acc: 0.931\n",
            "3-71th: train loss: 1.51169, train acc: 0.983 valid loss: 1.57718 valid acc: 0.928\n",
            "3-72th: train loss: 1.51112, train acc: 0.983 valid loss: 1.57668 valid acc: 0.928\n",
            "3-73th: train loss: 1.51058, train acc: 0.983 valid loss: 1.57621 valid acc: 0.928\n",
            "3-74th: train loss: 1.51006, train acc: 0.983 valid loss: 1.57577 valid acc: 0.928\n",
            "3-75th: train loss: 1.50954, train acc: 0.984 valid loss: 1.57538 valid acc: 0.928\n",
            "3-76th: train loss: 1.50903, train acc: 0.984 valid loss: 1.57502 valid acc: 0.931\n",
            "3-77th: train loss: 1.50853, train acc: 0.984 valid loss: 1.57468 valid acc: 0.931\n",
            "3-78th: train loss: 1.50805, train acc: 0.984 valid loss: 1.57434 valid acc: 0.931\n",
            "3-79th: train loss: 1.50759, train acc: 0.984 valid loss: 1.57400 valid acc: 0.931\n",
            "3-80th: train loss: 1.50713, train acc: 0.984 valid loss: 1.57364 valid acc: 0.931\n",
            "3-81th: train loss: 1.50668, train acc: 0.984 valid loss: 1.57327 valid acc: 0.931\n",
            "3-82th: train loss: 1.50624, train acc: 0.985 valid loss: 1.57292 valid acc: 0.931\n",
            "3-83th: train loss: 1.50581, train acc: 0.986 valid loss: 1.57260 valid acc: 0.928\n",
            "3-84th: train loss: 1.50539, train acc: 0.987 valid loss: 1.57230 valid acc: 0.928\n",
            "3-85th: train loss: 1.50497, train acc: 0.987 valid loss: 1.57203 valid acc: 0.928\n",
            "3-86th: train loss: 1.50457, train acc: 0.987 valid loss: 1.57177 valid acc: 0.928\n",
            "3-87th: train loss: 1.50417, train acc: 0.987 valid loss: 1.57151 valid acc: 0.925\n",
            "3-88th: train loss: 1.50378, train acc: 0.987 valid loss: 1.57126 valid acc: 0.925\n",
            "3-89th: train loss: 1.50339, train acc: 0.987 valid loss: 1.57102 valid acc: 0.925\n",
            "3-90th: train loss: 1.50301, train acc: 0.987 valid loss: 1.57079 valid acc: 0.925\n",
            "3-91th: train loss: 1.50264, train acc: 0.987 valid loss: 1.57058 valid acc: 0.925\n",
            "3-92th: train loss: 1.50227, train acc: 0.989 valid loss: 1.57038 valid acc: 0.921\n",
            "3-93th: train loss: 1.50191, train acc: 0.989 valid loss: 1.57018 valid acc: 0.921\n",
            "3-94th: train loss: 1.50156, train acc: 0.990 valid loss: 1.56998 valid acc: 0.921\n",
            "3-95th: train loss: 1.50122, train acc: 0.990 valid loss: 1.56976 valid acc: 0.921\n",
            "3-96th: train loss: 1.50088, train acc: 0.990 valid loss: 1.56953 valid acc: 0.921\n",
            "3-97th: train loss: 1.50055, train acc: 0.990 valid loss: 1.56927 valid acc: 0.921\n",
            "3-98th: train loss: 1.50023, train acc: 0.990 valid loss: 1.56901 valid acc: 0.921\n",
            "3-99th: train loss: 1.49991, train acc: 0.990 valid loss: 1.56874 valid acc: 0.921\n",
            "3-100th: train loss: 1.49960, train acc: 0.990 valid loss: 1.56848 valid acc: 0.921\n",
            "3-101th: train loss: 1.49930, train acc: 0.991 valid loss: 1.56823 valid acc: 0.921\n",
            "3-102th: train loss: 1.49900, train acc: 0.991 valid loss: 1.56800 valid acc: 0.921\n",
            "3-103th: train loss: 1.49871, train acc: 0.991 valid loss: 1.56777 valid acc: 0.921\n",
            "3-104th: train loss: 1.49842, train acc: 0.991 valid loss: 1.56755 valid acc: 0.921\n",
            "3-105th: train loss: 1.49814, train acc: 0.991 valid loss: 1.56732 valid acc: 0.921\n",
            "3-106th: train loss: 1.49786, train acc: 0.991 valid loss: 1.56708 valid acc: 0.921\n",
            "3-107th: train loss: 1.49759, train acc: 0.991 valid loss: 1.56684 valid acc: 0.925\n",
            "3-108th: train loss: 1.49731, train acc: 0.991 valid loss: 1.56660 valid acc: 0.925\n",
            "3-109th: train loss: 1.49704, train acc: 0.991 valid loss: 1.56635 valid acc: 0.925\n",
            "3-110th: train loss: 1.49677, train acc: 0.991 valid loss: 1.56610 valid acc: 0.925\n",
            "3-111th: train loss: 1.49651, train acc: 0.991 valid loss: 1.56584 valid acc: 0.925\n",
            "3-112th: train loss: 1.49625, train acc: 0.991 valid loss: 1.56559 valid acc: 0.931\n",
            "3-113th: train loss: 1.49598, train acc: 0.991 valid loss: 1.56534 valid acc: 0.934\n",
            "3-114th: train loss: 1.49572, train acc: 0.991 valid loss: 1.56508 valid acc: 0.934\n",
            "3-115th: train loss: 1.49547, train acc: 0.991 valid loss: 1.56483 valid acc: 0.934\n",
            "3-116th: train loss: 1.49521, train acc: 0.991 valid loss: 1.56458 valid acc: 0.937\n",
            "3-117th: train loss: 1.49495, train acc: 0.991 valid loss: 1.56434 valid acc: 0.937\n",
            "3-118th: train loss: 1.49470, train acc: 0.992 valid loss: 1.56411 valid acc: 0.937\n",
            "3-119th: train loss: 1.49444, train acc: 0.992 valid loss: 1.56388 valid acc: 0.940\n",
            "3-120th: train loss: 1.49419, train acc: 0.992 valid loss: 1.56366 valid acc: 0.940\n",
            "3-121th: train loss: 1.49394, train acc: 0.992 valid loss: 1.56344 valid acc: 0.940\n",
            "3-122th: train loss: 1.49369, train acc: 0.992 valid loss: 1.56323 valid acc: 0.947\n",
            "3-123th: train loss: 1.49345, train acc: 0.992 valid loss: 1.56301 valid acc: 0.947\n",
            "3-124th: train loss: 1.49320, train acc: 0.992 valid loss: 1.56279 valid acc: 0.950\n",
            "3-125th: train loss: 1.49296, train acc: 0.992 valid loss: 1.56258 valid acc: 0.950\n",
            "3-126th: train loss: 1.49272, train acc: 0.992 valid loss: 1.56237 valid acc: 0.950\n",
            "3-127th: train loss: 1.49247, train acc: 0.992 valid loss: 1.56217 valid acc: 0.950\n",
            "3-128th: train loss: 1.49223, train acc: 0.992 valid loss: 1.56197 valid acc: 0.950\n",
            "3-129th: train loss: 1.49198, train acc: 0.992 valid loss: 1.56179 valid acc: 0.950\n",
            "3-130th: train loss: 1.49174, train acc: 0.993 valid loss: 1.56160 valid acc: 0.947\n",
            "3-131th: train loss: 1.49149, train acc: 0.993 valid loss: 1.56142 valid acc: 0.947\n",
            "3-132th: train loss: 1.49125, train acc: 0.994 valid loss: 1.56123 valid acc: 0.943\n",
            "3-133th: train loss: 1.49101, train acc: 0.995 valid loss: 1.56104 valid acc: 0.943\n",
            "3-134th: train loss: 1.49077, train acc: 0.995 valid loss: 1.56085 valid acc: 0.943\n",
            "3-135th: train loss: 1.49054, train acc: 0.995 valid loss: 1.56065 valid acc: 0.943\n",
            "3-136th: train loss: 1.49031, train acc: 0.995 valid loss: 1.56045 valid acc: 0.943\n",
            "3-137th: train loss: 1.49009, train acc: 0.995 valid loss: 1.56025 valid acc: 0.943\n",
            "3-138th: train loss: 1.48987, train acc: 0.995 valid loss: 1.56005 valid acc: 0.943\n",
            "3-139th: train loss: 1.48965, train acc: 0.995 valid loss: 1.55986 valid acc: 0.943\n",
            "3-140th: train loss: 1.48944, train acc: 0.995 valid loss: 1.55966 valid acc: 0.940\n",
            "3-141th: train loss: 1.48923, train acc: 0.995 valid loss: 1.55947 valid acc: 0.940\n",
            "3-142th: train loss: 1.48903, train acc: 0.995 valid loss: 1.55927 valid acc: 0.940\n",
            "3-143th: train loss: 1.48882, train acc: 0.995 valid loss: 1.55908 valid acc: 0.940\n",
            "3-144th: train loss: 1.48862, train acc: 0.995 valid loss: 1.55890 valid acc: 0.940\n",
            "3-145th: train loss: 1.48842, train acc: 0.995 valid loss: 1.55872 valid acc: 0.940\n",
            "3-146th: train loss: 1.48823, train acc: 0.995 valid loss: 1.55855 valid acc: 0.940\n",
            "3-147th: train loss: 1.48804, train acc: 0.996 valid loss: 1.55839 valid acc: 0.940\n",
            "3-148th: train loss: 1.48785, train acc: 0.996 valid loss: 1.55824 valid acc: 0.940\n",
            "3-149th: train loss: 1.48767, train acc: 0.996 valid loss: 1.55810 valid acc: 0.940\n",
            "3-150th: train loss: 1.48749, train acc: 0.996 valid loss: 1.55797 valid acc: 0.943\n",
            "3-151th: train loss: 1.48732, train acc: 0.996 valid loss: 1.55784 valid acc: 0.943\n",
            "3-152th: train loss: 1.48714, train acc: 0.996 valid loss: 1.55773 valid acc: 0.943\n",
            "3-153th: train loss: 1.48697, train acc: 0.996 valid loss: 1.55762 valid acc: 0.943\n",
            "3-154th: train loss: 1.48681, train acc: 0.996 valid loss: 1.55751 valid acc: 0.943\n",
            "3-155th: train loss: 1.48664, train acc: 0.996 valid loss: 1.55741 valid acc: 0.943\n",
            "3-156th: train loss: 1.48649, train acc: 0.996 valid loss: 1.55732 valid acc: 0.943\n",
            "3-157th: train loss: 1.48633, train acc: 0.996 valid loss: 1.55722 valid acc: 0.943\n",
            "3-158th: train loss: 1.48617, train acc: 0.996 valid loss: 1.55712 valid acc: 0.943\n",
            "3-159th: train loss: 1.48602, train acc: 0.996 valid loss: 1.55703 valid acc: 0.943\n",
            "3-160th: train loss: 1.48587, train acc: 0.996 valid loss: 1.55693 valid acc: 0.943\n",
            "3-161th: train loss: 1.48572, train acc: 0.996 valid loss: 1.55683 valid acc: 0.943\n",
            "3-162th: train loss: 1.48558, train acc: 0.996 valid loss: 1.55673 valid acc: 0.943\n",
            "3-163th: train loss: 1.48543, train acc: 0.996 valid loss: 1.55662 valid acc: 0.943\n",
            "3-164th: train loss: 1.48529, train acc: 0.996 valid loss: 1.55652 valid acc: 0.940\n",
            "3-165th: train loss: 1.48515, train acc: 0.997 valid loss: 1.55641 valid acc: 0.940\n",
            "3-166th: train loss: 1.48501, train acc: 0.997 valid loss: 1.55630 valid acc: 0.940\n",
            "3-167th: train loss: 1.48488, train acc: 0.997 valid loss: 1.55619 valid acc: 0.940\n",
            "3-168th: train loss: 1.48474, train acc: 0.997 valid loss: 1.55608 valid acc: 0.940\n",
            "3-169th: train loss: 1.48461, train acc: 0.997 valid loss: 1.55596 valid acc: 0.940\n",
            "3-170th: train loss: 1.48448, train acc: 0.997 valid loss: 1.55585 valid acc: 0.940\n",
            "3-171th: train loss: 1.48435, train acc: 0.997 valid loss: 1.55574 valid acc: 0.940\n",
            "3-172th: train loss: 1.48422, train acc: 0.997 valid loss: 1.55562 valid acc: 0.940\n",
            "3-173th: train loss: 1.48410, train acc: 0.997 valid loss: 1.55551 valid acc: 0.940\n",
            "3-174th: train loss: 1.48398, train acc: 0.997 valid loss: 1.55539 valid acc: 0.940\n",
            "3-175th: train loss: 1.48386, train acc: 0.997 valid loss: 1.55528 valid acc: 0.943\n",
            "3-176th: train loss: 1.48374, train acc: 0.997 valid loss: 1.55517 valid acc: 0.943\n",
            "3-177th: train loss: 1.48362, train acc: 0.997 valid loss: 1.55506 valid acc: 0.943\n",
            "3-178th: train loss: 1.48351, train acc: 0.997 valid loss: 1.55494 valid acc: 0.943\n",
            "3-179th: train loss: 1.48339, train acc: 0.997 valid loss: 1.55483 valid acc: 0.943\n",
            "3-180th: train loss: 1.48328, train acc: 0.997 valid loss: 1.55472 valid acc: 0.943\n",
            "3-181th: train loss: 1.48317, train acc: 0.997 valid loss: 1.55461 valid acc: 0.947\n",
            "3-182th: train loss: 1.48306, train acc: 0.997 valid loss: 1.55450 valid acc: 0.947\n",
            "3-183th: train loss: 1.48296, train acc: 0.997 valid loss: 1.55439 valid acc: 0.947\n",
            "3-184th: train loss: 1.48285, train acc: 0.997 valid loss: 1.55429 valid acc: 0.947\n",
            "3-185th: train loss: 1.48275, train acc: 0.997 valid loss: 1.55418 valid acc: 0.947\n",
            "3-186th: train loss: 1.48264, train acc: 0.997 valid loss: 1.55408 valid acc: 0.947\n",
            "3-187th: train loss: 1.48254, train acc: 0.997 valid loss: 1.55398 valid acc: 0.947\n",
            "3-188th: train loss: 1.48244, train acc: 0.997 valid loss: 1.55389 valid acc: 0.947\n",
            "3-189th: train loss: 1.48234, train acc: 0.997 valid loss: 1.55380 valid acc: 0.947\n",
            "3-190th: train loss: 1.48224, train acc: 0.997 valid loss: 1.55371 valid acc: 0.947\n",
            "3-191th: train loss: 1.48215, train acc: 0.997 valid loss: 1.55362 valid acc: 0.947\n",
            "3-192th: train loss: 1.48205, train acc: 0.997 valid loss: 1.55354 valid acc: 0.947\n",
            "3-193th: train loss: 1.48196, train acc: 0.997 valid loss: 1.55346 valid acc: 0.947\n",
            "3-194th: train loss: 1.48186, train acc: 0.997 valid loss: 1.55339 valid acc: 0.947\n",
            "3-195th: train loss: 1.48177, train acc: 0.997 valid loss: 1.55332 valid acc: 0.947\n",
            "3-196th: train loss: 1.48168, train acc: 0.997 valid loss: 1.55325 valid acc: 0.947\n",
            "3-197th: train loss: 1.48158, train acc: 0.997 valid loss: 1.55318 valid acc: 0.947\n",
            "3-198th: train loss: 1.48149, train acc: 0.997 valid loss: 1.55312 valid acc: 0.947\n",
            "3-199th: train loss: 1.48140, train acc: 0.997 valid loss: 1.55307 valid acc: 0.947\n",
            "3-200th: train loss: 1.48131, train acc: 0.997 valid loss: 1.55301 valid acc: 0.947\n",
            "3-201th: train loss: 1.48122, train acc: 0.997 valid loss: 1.55296 valid acc: 0.947\n",
            "3-202th: train loss: 1.48113, train acc: 0.998 valid loss: 1.55290 valid acc: 0.947\n",
            "3-203th: train loss: 1.48105, train acc: 0.998 valid loss: 1.55285 valid acc: 0.947\n",
            "3-204th: train loss: 1.48096, train acc: 0.998 valid loss: 1.55280 valid acc: 0.947\n",
            "3-205th: train loss: 1.48087, train acc: 0.998 valid loss: 1.55275 valid acc: 0.947\n",
            "3-206th: train loss: 1.48079, train acc: 0.998 valid loss: 1.55270 valid acc: 0.947\n",
            "3-207th: train loss: 1.48071, train acc: 0.998 valid loss: 1.55265 valid acc: 0.947\n",
            "3-208th: train loss: 1.48062, train acc: 0.998 valid loss: 1.55260 valid acc: 0.947\n",
            "3-209th: train loss: 1.48054, train acc: 0.998 valid loss: 1.55255 valid acc: 0.943\n",
            "3-210th: train loss: 1.48047, train acc: 0.998 valid loss: 1.55249 valid acc: 0.943\n",
            "3-211th: train loss: 1.48039, train acc: 0.998 valid loss: 1.55243 valid acc: 0.943\n",
            "3-212th: train loss: 1.48031, train acc: 0.998 valid loss: 1.55237 valid acc: 0.943\n",
            "3-213th: train loss: 1.48024, train acc: 0.998 valid loss: 1.55231 valid acc: 0.943\n",
            "3-214th: train loss: 1.48017, train acc: 0.998 valid loss: 1.55225 valid acc: 0.943\n",
            "3-215th: train loss: 1.48009, train acc: 0.998 valid loss: 1.55218 valid acc: 0.943\n",
            "3-216th: train loss: 1.48002, train acc: 0.998 valid loss: 1.55212 valid acc: 0.943\n",
            "3-217th: train loss: 1.47995, train acc: 0.998 valid loss: 1.55205 valid acc: 0.943\n",
            "3-218th: train loss: 1.47988, train acc: 0.998 valid loss: 1.55198 valid acc: 0.943\n",
            "3-219th: train loss: 1.47981, train acc: 0.998 valid loss: 1.55192 valid acc: 0.943\n",
            "3-220th: train loss: 1.47974, train acc: 0.998 valid loss: 1.55185 valid acc: 0.943\n",
            "3-221th: train loss: 1.47967, train acc: 0.998 valid loss: 1.55178 valid acc: 0.943\n",
            "3-222th: train loss: 1.47961, train acc: 0.998 valid loss: 1.55171 valid acc: 0.943\n",
            "3-223th: train loss: 1.47954, train acc: 0.998 valid loss: 1.55165 valid acc: 0.943\n",
            "3-224th: train loss: 1.47947, train acc: 0.998 valid loss: 1.55158 valid acc: 0.943\n",
            "3-225th: train loss: 1.47941, train acc: 0.998 valid loss: 1.55152 valid acc: 0.943\n",
            "3-226th: train loss: 1.47934, train acc: 0.998 valid loss: 1.55145 valid acc: 0.943\n",
            "3-227th: train loss: 1.47928, train acc: 0.998 valid loss: 1.55139 valid acc: 0.943\n",
            "3-228th: train loss: 1.47921, train acc: 0.998 valid loss: 1.55133 valid acc: 0.943\n",
            "3-229th: train loss: 1.47915, train acc: 0.998 valid loss: 1.55127 valid acc: 0.943\n",
            "3-230th: train loss: 1.47908, train acc: 0.998 valid loss: 1.55121 valid acc: 0.943\n",
            "3-231th: train loss: 1.47902, train acc: 0.998 valid loss: 1.55115 valid acc: 0.943\n",
            "3-232th: train loss: 1.47895, train acc: 0.998 valid loss: 1.55110 valid acc: 0.943\n",
            "3-233th: train loss: 1.47889, train acc: 0.998 valid loss: 1.55105 valid acc: 0.943\n",
            "3-234th: train loss: 1.47882, train acc: 0.998 valid loss: 1.55100 valid acc: 0.943\n",
            "3-235th: train loss: 1.47876, train acc: 0.998 valid loss: 1.55095 valid acc: 0.943\n",
            "3-236th: train loss: 1.47870, train acc: 0.998 valid loss: 1.55090 valid acc: 0.943\n",
            "3-237th: train loss: 1.47864, train acc: 0.998 valid loss: 1.55086 valid acc: 0.943\n",
            "3-238th: train loss: 1.47858, train acc: 0.998 valid loss: 1.55081 valid acc: 0.940\n",
            "3-239th: train loss: 1.47852, train acc: 0.998 valid loss: 1.55076 valid acc: 0.940\n",
            "3-240th: train loss: 1.47846, train acc: 0.998 valid loss: 1.55072 valid acc: 0.940\n",
            "3-241th: train loss: 1.47841, train acc: 0.998 valid loss: 1.55067 valid acc: 0.940\n",
            "3-242th: train loss: 1.47835, train acc: 0.998 valid loss: 1.55062 valid acc: 0.940\n",
            "3-243th: train loss: 1.47830, train acc: 0.998 valid loss: 1.55056 valid acc: 0.940\n",
            "3-244th: train loss: 1.47824, train acc: 0.998 valid loss: 1.55051 valid acc: 0.940\n",
            "3-245th: train loss: 1.47819, train acc: 0.998 valid loss: 1.55045 valid acc: 0.940\n",
            "3-246th: train loss: 1.47814, train acc: 0.998 valid loss: 1.55039 valid acc: 0.940\n",
            "3-247th: train loss: 1.47809, train acc: 0.998 valid loss: 1.55033 valid acc: 0.940\n",
            "3-248th: train loss: 1.47804, train acc: 0.998 valid loss: 1.55027 valid acc: 0.940\n",
            "3-249th: train loss: 1.47799, train acc: 0.998 valid loss: 1.55020 valid acc: 0.940\n",
            "3-250th: train loss: 1.47794, train acc: 0.998 valid loss: 1.55014 valid acc: 0.940\n",
            "3-251th: train loss: 1.47789, train acc: 0.998 valid loss: 1.55008 valid acc: 0.943\n",
            "3-252th: train loss: 1.47784, train acc: 0.998 valid loss: 1.55002 valid acc: 0.943\n",
            "3-253th: train loss: 1.47779, train acc: 0.998 valid loss: 1.54996 valid acc: 0.943\n",
            "3-254th: train loss: 1.47775, train acc: 0.998 valid loss: 1.54991 valid acc: 0.943\n",
            "3-255th: train loss: 1.47770, train acc: 0.998 valid loss: 1.54985 valid acc: 0.943\n",
            "3-256th: train loss: 1.47766, train acc: 0.998 valid loss: 1.54980 valid acc: 0.943\n",
            "3-257th: train loss: 1.47761, train acc: 0.998 valid loss: 1.54975 valid acc: 0.943\n",
            "3-258th: train loss: 1.47757, train acc: 0.998 valid loss: 1.54969 valid acc: 0.943\n",
            "3-259th: train loss: 1.47752, train acc: 0.998 valid loss: 1.54964 valid acc: 0.943\n",
            "3-260th: train loss: 1.47748, train acc: 0.998 valid loss: 1.54959 valid acc: 0.943\n",
            "3-261th: train loss: 1.47744, train acc: 0.998 valid loss: 1.54954 valid acc: 0.943\n",
            "3-262th: train loss: 1.47740, train acc: 0.998 valid loss: 1.54949 valid acc: 0.943\n",
            "3-263th: train loss: 1.47736, train acc: 0.998 valid loss: 1.54945 valid acc: 0.943\n",
            "3-264th: train loss: 1.47731, train acc: 0.998 valid loss: 1.54940 valid acc: 0.943\n",
            "3-265th: train loss: 1.47727, train acc: 0.998 valid loss: 1.54935 valid acc: 0.943\n",
            "3-266th: train loss: 1.47723, train acc: 0.998 valid loss: 1.54931 valid acc: 0.943\n",
            "3-267th: train loss: 1.47719, train acc: 0.998 valid loss: 1.54926 valid acc: 0.943\n",
            "3-268th: train loss: 1.47715, train acc: 0.998 valid loss: 1.54921 valid acc: 0.943\n",
            "3-269th: train loss: 1.47712, train acc: 0.998 valid loss: 1.54917 valid acc: 0.943\n",
            "3-270th: train loss: 1.47708, train acc: 0.998 valid loss: 1.54912 valid acc: 0.943\n",
            "3-271th: train loss: 1.47704, train acc: 0.998 valid loss: 1.54908 valid acc: 0.943\n",
            "3-272th: train loss: 1.47700, train acc: 0.998 valid loss: 1.54903 valid acc: 0.943\n",
            "3-273th: train loss: 1.47696, train acc: 0.998 valid loss: 1.54899 valid acc: 0.943\n",
            "3-274th: train loss: 1.47693, train acc: 0.998 valid loss: 1.54894 valid acc: 0.943\n",
            "3-275th: train loss: 1.47689, train acc: 0.998 valid loss: 1.54890 valid acc: 0.943\n",
            "3-276th: train loss: 1.47685, train acc: 0.998 valid loss: 1.54885 valid acc: 0.943\n",
            "3-277th: train loss: 1.47682, train acc: 0.998 valid loss: 1.54881 valid acc: 0.943\n",
            "3-278th: train loss: 1.47678, train acc: 0.998 valid loss: 1.54876 valid acc: 0.943\n",
            "3-279th: train loss: 1.47675, train acc: 0.998 valid loss: 1.54872 valid acc: 0.943\n",
            "3-280th: train loss: 1.47671, train acc: 0.998 valid loss: 1.54868 valid acc: 0.943\n",
            "3-281th: train loss: 1.47668, train acc: 0.998 valid loss: 1.54863 valid acc: 0.943\n",
            "3-282th: train loss: 1.47664, train acc: 0.998 valid loss: 1.54859 valid acc: 0.943\n",
            "3-283th: train loss: 1.47661, train acc: 0.998 valid loss: 1.54855 valid acc: 0.943\n",
            "3-284th: train loss: 1.47657, train acc: 0.998 valid loss: 1.54851 valid acc: 0.943\n",
            "3-285th: train loss: 1.47654, train acc: 0.998 valid loss: 1.54846 valid acc: 0.943\n",
            "3-286th: train loss: 1.47651, train acc: 0.998 valid loss: 1.54842 valid acc: 0.943\n",
            "3-287th: train loss: 1.47647, train acc: 0.998 valid loss: 1.54838 valid acc: 0.943\n",
            "3-288th: train loss: 1.47644, train acc: 0.998 valid loss: 1.54834 valid acc: 0.947\n",
            "3-289th: train loss: 1.47641, train acc: 0.998 valid loss: 1.54830 valid acc: 0.947\n",
            "3-290th: train loss: 1.47638, train acc: 0.998 valid loss: 1.54825 valid acc: 0.947\n",
            "3-291th: train loss: 1.47635, train acc: 0.998 valid loss: 1.54821 valid acc: 0.947\n",
            "3-292th: train loss: 1.47631, train acc: 0.998 valid loss: 1.54817 valid acc: 0.947\n",
            "3-293th: train loss: 1.47628, train acc: 0.998 valid loss: 1.54813 valid acc: 0.947\n",
            "3-294th: train loss: 1.47625, train acc: 0.998 valid loss: 1.54809 valid acc: 0.947\n",
            "3-295th: train loss: 1.47622, train acc: 0.998 valid loss: 1.54805 valid acc: 0.943\n",
            "3-296th: train loss: 1.47619, train acc: 0.998 valid loss: 1.54801 valid acc: 0.943\n",
            "3-297th: train loss: 1.47616, train acc: 0.998 valid loss: 1.54797 valid acc: 0.940\n",
            "3-298th: train loss: 1.47613, train acc: 0.998 valid loss: 1.54793 valid acc: 0.940\n",
            "3-299th: train loss: 1.47610, train acc: 0.998 valid loss: 1.54790 valid acc: 0.940\n",
            "4-0th: train loss: 2.34968, train acc: 0.061 valid loss: 2.30346 valid acc: 0.113\n",
            "4-1th: train loss: 2.29167, train acc: 0.132 valid loss: 2.25893 valid acc: 0.170\n",
            "4-2th: train loss: 2.24248, train acc: 0.200 valid loss: 2.19564 valid acc: 0.248\n",
            "4-3th: train loss: 2.17613, train acc: 0.295 valid loss: 2.13861 valid acc: 0.343\n",
            "4-4th: train loss: 2.11668, train acc: 0.375 valid loss: 2.09430 valid acc: 0.390\n",
            "4-5th: train loss: 2.07110, train acc: 0.420 valid loss: 2.05445 valid acc: 0.425\n",
            "4-6th: train loss: 2.03100, train acc: 0.456 valid loss: 2.02370 valid acc: 0.453\n",
            "4-7th: train loss: 1.99781, train acc: 0.478 valid loss: 2.00259 valid acc: 0.465\n",
            "4-8th: train loss: 1.97212, train acc: 0.506 valid loss: 1.98767 valid acc: 0.484\n",
            "4-9th: train loss: 1.95312, train acc: 0.526 valid loss: 1.97531 valid acc: 0.503\n",
            "4-10th: train loss: 1.93652, train acc: 0.542 valid loss: 1.96133 valid acc: 0.513\n",
            "4-11th: train loss: 1.91727, train acc: 0.561 valid loss: 1.94216 valid acc: 0.525\n",
            "4-12th: train loss: 1.89336, train acc: 0.600 valid loss: 1.91773 valid acc: 0.575\n",
            "4-13th: train loss: 1.86718, train acc: 0.628 valid loss: 1.89615 valid acc: 0.591\n",
            "4-14th: train loss: 1.84482, train acc: 0.657 valid loss: 1.88393 valid acc: 0.604\n",
            "4-15th: train loss: 1.83062, train acc: 0.667 valid loss: 1.87265 valid acc: 0.610\n",
            "4-16th: train loss: 1.81725, train acc: 0.684 valid loss: 1.85557 valid acc: 0.642\n",
            "4-17th: train loss: 1.79903, train acc: 0.702 valid loss: 1.83742 valid acc: 0.673\n",
            "4-18th: train loss: 1.78108, train acc: 0.718 valid loss: 1.82180 valid acc: 0.686\n",
            "4-19th: train loss: 1.76541, train acc: 0.736 valid loss: 1.80564 valid acc: 0.708\n",
            "4-20th: train loss: 1.74843, train acc: 0.767 valid loss: 1.78892 valid acc: 0.723\n",
            "4-21th: train loss: 1.73216, train acc: 0.792 valid loss: 1.77855 valid acc: 0.742\n",
            "4-22th: train loss: 1.72464, train acc: 0.802 valid loss: 1.76998 valid acc: 0.752\n",
            "4-23th: train loss: 1.71725, train acc: 0.802 valid loss: 1.75800 valid acc: 0.755\n",
            "4-24th: train loss: 1.70363, train acc: 0.815 valid loss: 1.74813 valid acc: 0.764\n",
            "4-25th: train loss: 1.69065, train acc: 0.822 valid loss: 1.74313 valid acc: 0.764\n",
            "4-26th: train loss: 1.68317, train acc: 0.829 valid loss: 1.74013 valid acc: 0.770\n",
            "4-27th: train loss: 1.67885, train acc: 0.829 valid loss: 1.73600 valid acc: 0.780\n",
            "4-28th: train loss: 1.67421, train acc: 0.835 valid loss: 1.73027 valid acc: 0.767\n",
            "4-29th: train loss: 1.66862, train acc: 0.840 valid loss: 1.72417 valid acc: 0.786\n",
            "4-30th: train loss: 1.66317, train acc: 0.843 valid loss: 1.71893 valid acc: 0.802\n",
            "4-31th: train loss: 1.65875, train acc: 0.847 valid loss: 1.71487 valid acc: 0.802\n",
            "4-32th: train loss: 1.65530, train acc: 0.849 valid loss: 1.71152 valid acc: 0.802\n",
            "4-33th: train loss: 1.65216, train acc: 0.849 valid loss: 1.70834 valid acc: 0.799\n",
            "4-34th: train loss: 1.64886, train acc: 0.853 valid loss: 1.70527 valid acc: 0.796\n",
            "4-35th: train loss: 1.64553, train acc: 0.855 valid loss: 1.70249 valid acc: 0.799\n",
            "4-36th: train loss: 1.64249, train acc: 0.859 valid loss: 1.69996 valid acc: 0.805\n",
            "4-37th: train loss: 1.63977, train acc: 0.860 valid loss: 1.69737 valid acc: 0.808\n",
            "4-38th: train loss: 1.63716, train acc: 0.862 valid loss: 1.69456 valid acc: 0.808\n",
            "4-39th: train loss: 1.63450, train acc: 0.863 valid loss: 1.69168 valid acc: 0.805\n",
            "4-40th: train loss: 1.63188, train acc: 0.864 valid loss: 1.68902 valid acc: 0.811\n",
            "4-41th: train loss: 1.62948, train acc: 0.865 valid loss: 1.68677 valid acc: 0.814\n",
            "4-42th: train loss: 1.62742, train acc: 0.866 valid loss: 1.68487 valid acc: 0.814\n",
            "4-43th: train loss: 1.62559, train acc: 0.867 valid loss: 1.68315 valid acc: 0.811\n",
            "4-44th: train loss: 1.62379, train acc: 0.870 valid loss: 1.68151 valid acc: 0.811\n",
            "4-45th: train loss: 1.62188, train acc: 0.871 valid loss: 1.67992 valid acc: 0.811\n",
            "4-46th: train loss: 1.61987, train acc: 0.874 valid loss: 1.67830 valid acc: 0.818\n",
            "4-47th: train loss: 1.61786, train acc: 0.874 valid loss: 1.67640 valid acc: 0.814\n",
            "4-48th: train loss: 1.61587, train acc: 0.876 valid loss: 1.67374 valid acc: 0.824\n",
            "4-49th: train loss: 1.61370, train acc: 0.880 valid loss: 1.66970 valid acc: 0.824\n",
            "4-50th: train loss: 1.61096, train acc: 0.885 valid loss: 1.66397 valid acc: 0.836\n",
            "4-51th: train loss: 1.60724, train acc: 0.886 valid loss: 1.65714 valid acc: 0.846\n",
            "4-52th: train loss: 1.60240, train acc: 0.892 valid loss: 1.65085 valid acc: 0.846\n",
            "4-53th: train loss: 1.59654, train acc: 0.896 valid loss: 1.64636 valid acc: 0.849\n",
            "4-54th: train loss: 1.58956, train acc: 0.906 valid loss: 1.64436 valid acc: 0.849\n",
            "4-55th: train loss: 1.58164, train acc: 0.920 valid loss: 1.64668 valid acc: 0.855\n",
            "4-56th: train loss: 1.57595, train acc: 0.929 valid loss: 1.65096 valid acc: 0.846\n",
            "4-57th: train loss: 1.57432, train acc: 0.933 valid loss: 1.64935 valid acc: 0.846\n",
            "4-58th: train loss: 1.57054, train acc: 0.937 valid loss: 1.64163 valid acc: 0.855\n",
            "4-59th: train loss: 1.56369, train acc: 0.940 valid loss: 1.63318 valid acc: 0.868\n",
            "4-60th: train loss: 1.55795, train acc: 0.940 valid loss: 1.62706 valid acc: 0.868\n",
            "4-61th: train loss: 1.55457, train acc: 0.945 valid loss: 1.62294 valid acc: 0.877\n",
            "4-62th: train loss: 1.55245, train acc: 0.947 valid loss: 1.61977 valid acc: 0.893\n",
            "4-63th: train loss: 1.55048, train acc: 0.947 valid loss: 1.61701 valid acc: 0.899\n",
            "4-64th: train loss: 1.54817, train acc: 0.948 valid loss: 1.61481 valid acc: 0.899\n",
            "4-65th: train loss: 1.54541, train acc: 0.952 valid loss: 1.61349 valid acc: 0.909\n",
            "4-66th: train loss: 1.54221, train acc: 0.960 valid loss: 1.61314 valid acc: 0.906\n",
            "4-67th: train loss: 1.53881, train acc: 0.966 valid loss: 1.61331 valid acc: 0.912\n",
            "4-68th: train loss: 1.53589, train acc: 0.969 valid loss: 1.61325 valid acc: 0.906\n",
            "4-69th: train loss: 1.53378, train acc: 0.974 valid loss: 1.61222 valid acc: 0.906\n",
            "4-70th: train loss: 1.53178, train acc: 0.975 valid loss: 1.61018 valid acc: 0.903\n",
            "4-71th: train loss: 1.52918, train acc: 0.975 valid loss: 1.60803 valid acc: 0.909\n",
            "4-72th: train loss: 1.52652, train acc: 0.975 valid loss: 1.60646 valid acc: 0.915\n",
            "4-73th: train loss: 1.52455, train acc: 0.976 valid loss: 1.60513 valid acc: 0.909\n",
            "4-74th: train loss: 1.52302, train acc: 0.979 valid loss: 1.60356 valid acc: 0.909\n",
            "4-75th: train loss: 1.52136, train acc: 0.980 valid loss: 1.60191 valid acc: 0.909\n",
            "4-76th: train loss: 1.51966, train acc: 0.980 valid loss: 1.60061 valid acc: 0.915\n",
            "4-77th: train loss: 1.51831, train acc: 0.982 valid loss: 1.59955 valid acc: 0.915\n",
            "4-78th: train loss: 1.51719, train acc: 0.983 valid loss: 1.59832 valid acc: 0.915\n",
            "4-79th: train loss: 1.51592, train acc: 0.984 valid loss: 1.59688 valid acc: 0.915\n",
            "4-80th: train loss: 1.51449, train acc: 0.985 valid loss: 1.59564 valid acc: 0.915\n",
            "4-81th: train loss: 1.51328, train acc: 0.985 valid loss: 1.59481 valid acc: 0.915\n",
            "4-82th: train loss: 1.51248, train acc: 0.986 valid loss: 1.59417 valid acc: 0.915\n",
            "4-83th: train loss: 1.51184, train acc: 0.986 valid loss: 1.59342 valid acc: 0.918\n",
            "4-84th: train loss: 1.51100, train acc: 0.986 valid loss: 1.59261 valid acc: 0.918\n",
            "4-85th: train loss: 1.50998, train acc: 0.986 valid loss: 1.59199 valid acc: 0.918\n",
            "4-86th: train loss: 1.50901, train acc: 0.986 valid loss: 1.59168 valid acc: 0.918\n",
            "4-87th: train loss: 1.50822, train acc: 0.986 valid loss: 1.59149 valid acc: 0.918\n",
            "4-88th: train loss: 1.50751, train acc: 0.986 valid loss: 1.59116 valid acc: 0.921\n",
            "4-89th: train loss: 1.50676, train acc: 0.986 valid loss: 1.59062 valid acc: 0.921\n",
            "4-90th: train loss: 1.50594, train acc: 0.987 valid loss: 1.58998 valid acc: 0.925\n",
            "4-91th: train loss: 1.50517, train acc: 0.987 valid loss: 1.58932 valid acc: 0.925\n",
            "4-92th: train loss: 1.50448, train acc: 0.988 valid loss: 1.58866 valid acc: 0.925\n",
            "4-93th: train loss: 1.50383, train acc: 0.989 valid loss: 1.58802 valid acc: 0.925\n",
            "4-94th: train loss: 1.50319, train acc: 0.989 valid loss: 1.58745 valid acc: 0.925\n",
            "4-95th: train loss: 1.50258, train acc: 0.989 valid loss: 1.58699 valid acc: 0.928\n",
            "4-96th: train loss: 1.50203, train acc: 0.989 valid loss: 1.58665 valid acc: 0.925\n",
            "4-97th: train loss: 1.50155, train acc: 0.989 valid loss: 1.58637 valid acc: 0.928\n",
            "4-98th: train loss: 1.50105, train acc: 0.989 valid loss: 1.58612 valid acc: 0.931\n",
            "4-99th: train loss: 1.50053, train acc: 0.989 valid loss: 1.58592 valid acc: 0.931\n",
            "4-100th: train loss: 1.50001, train acc: 0.989 valid loss: 1.58580 valid acc: 0.931\n",
            "4-101th: train loss: 1.49952, train acc: 0.990 valid loss: 1.58570 valid acc: 0.931\n",
            "4-102th: train loss: 1.49908, train acc: 0.991 valid loss: 1.58555 valid acc: 0.928\n",
            "4-103th: train loss: 1.49866, train acc: 0.991 valid loss: 1.58532 valid acc: 0.928\n",
            "4-104th: train loss: 1.49823, train acc: 0.991 valid loss: 1.58500 valid acc: 0.928\n",
            "4-105th: train loss: 1.49780, train acc: 0.991 valid loss: 1.58461 valid acc: 0.928\n",
            "4-106th: train loss: 1.49740, train acc: 0.991 valid loss: 1.58417 valid acc: 0.925\n",
            "4-107th: train loss: 1.49703, train acc: 0.991 valid loss: 1.58370 valid acc: 0.925\n",
            "4-108th: train loss: 1.49667, train acc: 0.991 valid loss: 1.58320 valid acc: 0.925\n",
            "4-109th: train loss: 1.49631, train acc: 0.991 valid loss: 1.58270 valid acc: 0.921\n",
            "4-110th: train loss: 1.49596, train acc: 0.991 valid loss: 1.58224 valid acc: 0.921\n",
            "4-111th: train loss: 1.49563, train acc: 0.991 valid loss: 1.58182 valid acc: 0.928\n",
            "4-112th: train loss: 1.49531, train acc: 0.991 valid loss: 1.58144 valid acc: 0.928\n",
            "4-113th: train loss: 1.49499, train acc: 0.991 valid loss: 1.58109 valid acc: 0.928\n",
            "4-114th: train loss: 1.49469, train acc: 0.991 valid loss: 1.58078 valid acc: 0.928\n",
            "4-115th: train loss: 1.49439, train acc: 0.991 valid loss: 1.58050 valid acc: 0.928\n",
            "4-116th: train loss: 1.49410, train acc: 0.991 valid loss: 1.58022 valid acc: 0.931\n",
            "4-117th: train loss: 1.49382, train acc: 0.991 valid loss: 1.57994 valid acc: 0.928\n",
            "4-118th: train loss: 1.49354, train acc: 0.991 valid loss: 1.57966 valid acc: 0.928\n",
            "4-119th: train loss: 1.49326, train acc: 0.991 valid loss: 1.57937 valid acc: 0.928\n",
            "4-120th: train loss: 1.49299, train acc: 0.991 valid loss: 1.57908 valid acc: 0.928\n",
            "4-121th: train loss: 1.49272, train acc: 0.991 valid loss: 1.57880 valid acc: 0.928\n",
            "4-122th: train loss: 1.49246, train acc: 0.991 valid loss: 1.57853 valid acc: 0.928\n",
            "4-123th: train loss: 1.49220, train acc: 0.991 valid loss: 1.57827 valid acc: 0.928\n",
            "4-124th: train loss: 1.49194, train acc: 0.992 valid loss: 1.57803 valid acc: 0.928\n",
            "4-125th: train loss: 1.49169, train acc: 0.993 valid loss: 1.57781 valid acc: 0.928\n",
            "4-126th: train loss: 1.49145, train acc: 0.993 valid loss: 1.57761 valid acc: 0.928\n",
            "4-127th: train loss: 1.49122, train acc: 0.993 valid loss: 1.57741 valid acc: 0.931\n",
            "4-128th: train loss: 1.49099, train acc: 0.993 valid loss: 1.57721 valid acc: 0.931\n",
            "4-129th: train loss: 1.49077, train acc: 0.993 valid loss: 1.57701 valid acc: 0.931\n",
            "4-130th: train loss: 1.49056, train acc: 0.993 valid loss: 1.57679 valid acc: 0.931\n",
            "4-131th: train loss: 1.49036, train acc: 0.993 valid loss: 1.57656 valid acc: 0.931\n",
            "4-132th: train loss: 1.49016, train acc: 0.993 valid loss: 1.57631 valid acc: 0.931\n",
            "4-133th: train loss: 1.48996, train acc: 0.993 valid loss: 1.57606 valid acc: 0.934\n",
            "4-134th: train loss: 1.48977, train acc: 0.993 valid loss: 1.57581 valid acc: 0.934\n",
            "4-135th: train loss: 1.48959, train acc: 0.993 valid loss: 1.57557 valid acc: 0.934\n",
            "4-136th: train loss: 1.48941, train acc: 0.994 valid loss: 1.57534 valid acc: 0.934\n",
            "4-137th: train loss: 1.48923, train acc: 0.994 valid loss: 1.57512 valid acc: 0.934\n",
            "4-138th: train loss: 1.48906, train acc: 0.994 valid loss: 1.57491 valid acc: 0.934\n",
            "4-139th: train loss: 1.48889, train acc: 0.994 valid loss: 1.57472 valid acc: 0.934\n",
            "4-140th: train loss: 1.48872, train acc: 0.994 valid loss: 1.57453 valid acc: 0.934\n",
            "4-141th: train loss: 1.48856, train acc: 0.994 valid loss: 1.57435 valid acc: 0.934\n",
            "4-142th: train loss: 1.48840, train acc: 0.994 valid loss: 1.57417 valid acc: 0.934\n",
            "4-143th: train loss: 1.48825, train acc: 0.994 valid loss: 1.57399 valid acc: 0.934\n",
            "4-144th: train loss: 1.48810, train acc: 0.994 valid loss: 1.57381 valid acc: 0.934\n",
            "4-145th: train loss: 1.48795, train acc: 0.994 valid loss: 1.57363 valid acc: 0.934\n",
            "4-146th: train loss: 1.48780, train acc: 0.994 valid loss: 1.57345 valid acc: 0.934\n",
            "4-147th: train loss: 1.48765, train acc: 0.994 valid loss: 1.57328 valid acc: 0.934\n",
            "4-148th: train loss: 1.48751, train acc: 0.995 valid loss: 1.57311 valid acc: 0.934\n",
            "4-149th: train loss: 1.48737, train acc: 0.995 valid loss: 1.57295 valid acc: 0.934\n",
            "4-150th: train loss: 1.48724, train acc: 0.995 valid loss: 1.57279 valid acc: 0.934\n",
            "4-151th: train loss: 1.48710, train acc: 0.995 valid loss: 1.57264 valid acc: 0.934\n",
            "4-152th: train loss: 1.48697, train acc: 0.995 valid loss: 1.57250 valid acc: 0.934\n",
            "4-153th: train loss: 1.48684, train acc: 0.995 valid loss: 1.57235 valid acc: 0.934\n",
            "4-154th: train loss: 1.48671, train acc: 0.995 valid loss: 1.57221 valid acc: 0.934\n",
            "4-155th: train loss: 1.48658, train acc: 0.995 valid loss: 1.57206 valid acc: 0.934\n",
            "4-156th: train loss: 1.48645, train acc: 0.995 valid loss: 1.57191 valid acc: 0.934\n",
            "4-157th: train loss: 1.48633, train acc: 0.995 valid loss: 1.57176 valid acc: 0.934\n",
            "4-158th: train loss: 1.48620, train acc: 0.995 valid loss: 1.57160 valid acc: 0.934\n",
            "4-159th: train loss: 1.48608, train acc: 0.995 valid loss: 1.57143 valid acc: 0.934\n",
            "4-160th: train loss: 1.48596, train acc: 0.995 valid loss: 1.57127 valid acc: 0.934\n",
            "4-161th: train loss: 1.48585, train acc: 0.995 valid loss: 1.57111 valid acc: 0.934\n",
            "4-162th: train loss: 1.48573, train acc: 0.995 valid loss: 1.57095 valid acc: 0.934\n",
            "4-163th: train loss: 1.48562, train acc: 0.995 valid loss: 1.57079 valid acc: 0.934\n",
            "4-164th: train loss: 1.48551, train acc: 0.995 valid loss: 1.57064 valid acc: 0.934\n",
            "4-165th: train loss: 1.48540, train acc: 0.995 valid loss: 1.57050 valid acc: 0.934\n",
            "4-166th: train loss: 1.48530, train acc: 0.995 valid loss: 1.57036 valid acc: 0.931\n",
            "4-167th: train loss: 1.48519, train acc: 0.995 valid loss: 1.57022 valid acc: 0.931\n",
            "4-168th: train loss: 1.48509, train acc: 0.995 valid loss: 1.57008 valid acc: 0.931\n",
            "4-169th: train loss: 1.48499, train acc: 0.995 valid loss: 1.56995 valid acc: 0.931\n",
            "4-170th: train loss: 1.48490, train acc: 0.995 valid loss: 1.56982 valid acc: 0.931\n",
            "4-171th: train loss: 1.48480, train acc: 0.995 valid loss: 1.56969 valid acc: 0.931\n",
            "4-172th: train loss: 1.48470, train acc: 0.995 valid loss: 1.56956 valid acc: 0.928\n",
            "4-173th: train loss: 1.48461, train acc: 0.995 valid loss: 1.56944 valid acc: 0.931\n",
            "4-174th: train loss: 1.48452, train acc: 0.995 valid loss: 1.56931 valid acc: 0.931\n",
            "4-175th: train loss: 1.48443, train acc: 0.995 valid loss: 1.56918 valid acc: 0.931\n",
            "4-176th: train loss: 1.48434, train acc: 0.995 valid loss: 1.56905 valid acc: 0.931\n",
            "4-177th: train loss: 1.48425, train acc: 0.995 valid loss: 1.56893 valid acc: 0.931\n",
            "4-178th: train loss: 1.48416, train acc: 0.995 valid loss: 1.56880 valid acc: 0.931\n",
            "4-179th: train loss: 1.48407, train acc: 0.995 valid loss: 1.56868 valid acc: 0.931\n",
            "4-180th: train loss: 1.48399, train acc: 0.995 valid loss: 1.56855 valid acc: 0.931\n",
            "4-181th: train loss: 1.48390, train acc: 0.995 valid loss: 1.56843 valid acc: 0.931\n",
            "4-182th: train loss: 1.48382, train acc: 0.995 valid loss: 1.56831 valid acc: 0.931\n",
            "4-183th: train loss: 1.48374, train acc: 0.995 valid loss: 1.56818 valid acc: 0.931\n",
            "4-184th: train loss: 1.48365, train acc: 0.995 valid loss: 1.56806 valid acc: 0.931\n",
            "4-185th: train loss: 1.48357, train acc: 0.995 valid loss: 1.56794 valid acc: 0.934\n",
            "4-186th: train loss: 1.48349, train acc: 0.995 valid loss: 1.56781 valid acc: 0.934\n",
            "4-187th: train loss: 1.48341, train acc: 0.995 valid loss: 1.56769 valid acc: 0.934\n",
            "4-188th: train loss: 1.48333, train acc: 0.995 valid loss: 1.56756 valid acc: 0.934\n",
            "4-189th: train loss: 1.48325, train acc: 0.995 valid loss: 1.56744 valid acc: 0.934\n",
            "4-190th: train loss: 1.48317, train acc: 0.995 valid loss: 1.56731 valid acc: 0.934\n",
            "4-191th: train loss: 1.48309, train acc: 0.995 valid loss: 1.56719 valid acc: 0.934\n",
            "4-192th: train loss: 1.48301, train acc: 0.995 valid loss: 1.56707 valid acc: 0.934\n",
            "4-193th: train loss: 1.48293, train acc: 0.995 valid loss: 1.56694 valid acc: 0.934\n",
            "4-194th: train loss: 1.48285, train acc: 0.995 valid loss: 1.56682 valid acc: 0.934\n",
            "4-195th: train loss: 1.48277, train acc: 0.995 valid loss: 1.56669 valid acc: 0.934\n",
            "4-196th: train loss: 1.48268, train acc: 0.995 valid loss: 1.56657 valid acc: 0.931\n",
            "4-197th: train loss: 1.48260, train acc: 0.995 valid loss: 1.56644 valid acc: 0.931\n",
            "4-198th: train loss: 1.48252, train acc: 0.995 valid loss: 1.56632 valid acc: 0.931\n",
            "4-199th: train loss: 1.48245, train acc: 0.995 valid loss: 1.56619 valid acc: 0.931\n",
            "4-200th: train loss: 1.48237, train acc: 0.995 valid loss: 1.56606 valid acc: 0.931\n",
            "4-201th: train loss: 1.48229, train acc: 0.995 valid loss: 1.56594 valid acc: 0.931\n",
            "4-202th: train loss: 1.48222, train acc: 0.995 valid loss: 1.56581 valid acc: 0.931\n",
            "4-203th: train loss: 1.48214, train acc: 0.995 valid loss: 1.56569 valid acc: 0.931\n",
            "4-204th: train loss: 1.48207, train acc: 0.995 valid loss: 1.56557 valid acc: 0.934\n",
            "4-205th: train loss: 1.48200, train acc: 0.995 valid loss: 1.56545 valid acc: 0.934\n",
            "4-206th: train loss: 1.48192, train acc: 0.995 valid loss: 1.56534 valid acc: 0.934\n",
            "4-207th: train loss: 1.48185, train acc: 0.995 valid loss: 1.56522 valid acc: 0.934\n",
            "4-208th: train loss: 1.48178, train acc: 0.995 valid loss: 1.56512 valid acc: 0.934\n",
            "4-209th: train loss: 1.48171, train acc: 0.995 valid loss: 1.56501 valid acc: 0.934\n",
            "4-210th: train loss: 1.48164, train acc: 0.995 valid loss: 1.56491 valid acc: 0.934\n",
            "4-211th: train loss: 1.48157, train acc: 0.995 valid loss: 1.56481 valid acc: 0.934\n",
            "4-212th: train loss: 1.48150, train acc: 0.995 valid loss: 1.56471 valid acc: 0.934\n",
            "4-213th: train loss: 1.48143, train acc: 0.995 valid loss: 1.56462 valid acc: 0.934\n",
            "4-214th: train loss: 1.48136, train acc: 0.996 valid loss: 1.56452 valid acc: 0.934\n",
            "4-215th: train loss: 1.48130, train acc: 0.996 valid loss: 1.56443 valid acc: 0.934\n",
            "4-216th: train loss: 1.48123, train acc: 0.996 valid loss: 1.56435 valid acc: 0.934\n",
            "4-217th: train loss: 1.48116, train acc: 0.996 valid loss: 1.56426 valid acc: 0.934\n",
            "4-218th: train loss: 1.48110, train acc: 0.996 valid loss: 1.56417 valid acc: 0.934\n",
            "4-219th: train loss: 1.48103, train acc: 0.996 valid loss: 1.56409 valid acc: 0.934\n",
            "4-220th: train loss: 1.48097, train acc: 0.996 valid loss: 1.56401 valid acc: 0.934\n",
            "4-221th: train loss: 1.48090, train acc: 0.996 valid loss: 1.56392 valid acc: 0.934\n",
            "4-222th: train loss: 1.48084, train acc: 0.996 valid loss: 1.56384 valid acc: 0.934\n",
            "4-223th: train loss: 1.48078, train acc: 0.996 valid loss: 1.56376 valid acc: 0.934\n",
            "4-224th: train loss: 1.48072, train acc: 0.996 valid loss: 1.56368 valid acc: 0.934\n",
            "4-225th: train loss: 1.48066, train acc: 0.996 valid loss: 1.56360 valid acc: 0.934\n",
            "4-226th: train loss: 1.48060, train acc: 0.996 valid loss: 1.56352 valid acc: 0.934\n",
            "4-227th: train loss: 1.48055, train acc: 0.996 valid loss: 1.56344 valid acc: 0.934\n",
            "4-228th: train loss: 1.48049, train acc: 0.996 valid loss: 1.56336 valid acc: 0.934\n",
            "4-229th: train loss: 1.48043, train acc: 0.996 valid loss: 1.56329 valid acc: 0.934\n",
            "4-230th: train loss: 1.48038, train acc: 0.996 valid loss: 1.56321 valid acc: 0.934\n",
            "4-231th: train loss: 1.48032, train acc: 0.996 valid loss: 1.56313 valid acc: 0.931\n",
            "4-232th: train loss: 1.48026, train acc: 0.996 valid loss: 1.56305 valid acc: 0.931\n",
            "4-233th: train loss: 1.48021, train acc: 0.996 valid loss: 1.56298 valid acc: 0.931\n",
            "4-234th: train loss: 1.48015, train acc: 0.996 valid loss: 1.56290 valid acc: 0.931\n",
            "4-235th: train loss: 1.48010, train acc: 0.996 valid loss: 1.56283 valid acc: 0.931\n",
            "4-236th: train loss: 1.48005, train acc: 0.996 valid loss: 1.56276 valid acc: 0.931\n",
            "4-237th: train loss: 1.47999, train acc: 0.996 valid loss: 1.56268 valid acc: 0.931\n",
            "4-238th: train loss: 1.47994, train acc: 0.996 valid loss: 1.56261 valid acc: 0.934\n",
            "4-239th: train loss: 1.47988, train acc: 0.996 valid loss: 1.56254 valid acc: 0.934\n",
            "4-240th: train loss: 1.47983, train acc: 0.996 valid loss: 1.56247 valid acc: 0.934\n",
            "4-241th: train loss: 1.47978, train acc: 0.996 valid loss: 1.56240 valid acc: 0.934\n",
            "4-242th: train loss: 1.47972, train acc: 0.996 valid loss: 1.56233 valid acc: 0.934\n",
            "4-243th: train loss: 1.47967, train acc: 0.996 valid loss: 1.56226 valid acc: 0.934\n",
            "4-244th: train loss: 1.47961, train acc: 0.996 valid loss: 1.56220 valid acc: 0.934\n",
            "4-245th: train loss: 1.47956, train acc: 0.996 valid loss: 1.56214 valid acc: 0.934\n",
            "4-246th: train loss: 1.47950, train acc: 0.996 valid loss: 1.56207 valid acc: 0.934\n",
            "4-247th: train loss: 1.47944, train acc: 0.996 valid loss: 1.56202 valid acc: 0.934\n",
            "4-248th: train loss: 1.47938, train acc: 0.996 valid loss: 1.56196 valid acc: 0.934\n",
            "4-249th: train loss: 1.47932, train acc: 0.996 valid loss: 1.56191 valid acc: 0.934\n",
            "4-250th: train loss: 1.47926, train acc: 0.996 valid loss: 1.56186 valid acc: 0.934\n",
            "4-251th: train loss: 1.47920, train acc: 0.997 valid loss: 1.56182 valid acc: 0.934\n",
            "4-252th: train loss: 1.47914, train acc: 0.997 valid loss: 1.56178 valid acc: 0.934\n",
            "4-253th: train loss: 1.47908, train acc: 0.997 valid loss: 1.56174 valid acc: 0.934\n",
            "4-254th: train loss: 1.47902, train acc: 0.997 valid loss: 1.56170 valid acc: 0.934\n",
            "4-255th: train loss: 1.47896, train acc: 0.997 valid loss: 1.56166 valid acc: 0.934\n",
            "4-256th: train loss: 1.47890, train acc: 0.997 valid loss: 1.56162 valid acc: 0.934\n",
            "4-257th: train loss: 1.47885, train acc: 0.997 valid loss: 1.56157 valid acc: 0.934\n",
            "4-258th: train loss: 1.47880, train acc: 0.997 valid loss: 1.56152 valid acc: 0.934\n",
            "4-259th: train loss: 1.47875, train acc: 0.997 valid loss: 1.56146 valid acc: 0.931\n",
            "4-260th: train loss: 1.47870, train acc: 0.997 valid loss: 1.56140 valid acc: 0.931\n",
            "4-261th: train loss: 1.47865, train acc: 0.997 valid loss: 1.56132 valid acc: 0.931\n",
            "4-262th: train loss: 1.47860, train acc: 0.997 valid loss: 1.56124 valid acc: 0.931\n",
            "4-263th: train loss: 1.47855, train acc: 0.997 valid loss: 1.56115 valid acc: 0.931\n",
            "4-264th: train loss: 1.47851, train acc: 0.997 valid loss: 1.56106 valid acc: 0.931\n",
            "4-265th: train loss: 1.47846, train acc: 0.997 valid loss: 1.56096 valid acc: 0.931\n",
            "4-266th: train loss: 1.47841, train acc: 0.997 valid loss: 1.56087 valid acc: 0.931\n",
            "4-267th: train loss: 1.47837, train acc: 0.997 valid loss: 1.56077 valid acc: 0.931\n",
            "4-268th: train loss: 1.47832, train acc: 0.997 valid loss: 1.56068 valid acc: 0.931\n",
            "4-269th: train loss: 1.47828, train acc: 0.997 valid loss: 1.56059 valid acc: 0.931\n",
            "4-270th: train loss: 1.47823, train acc: 0.997 valid loss: 1.56050 valid acc: 0.931\n",
            "4-271th: train loss: 1.47819, train acc: 0.997 valid loss: 1.56042 valid acc: 0.931\n",
            "4-272th: train loss: 1.47814, train acc: 0.997 valid loss: 1.56034 valid acc: 0.934\n",
            "4-273th: train loss: 1.47810, train acc: 0.997 valid loss: 1.56027 valid acc: 0.934\n",
            "4-274th: train loss: 1.47806, train acc: 0.997 valid loss: 1.56020 valid acc: 0.934\n",
            "4-275th: train loss: 1.47802, train acc: 0.997 valid loss: 1.56014 valid acc: 0.934\n",
            "4-276th: train loss: 1.47798, train acc: 0.997 valid loss: 1.56008 valid acc: 0.934\n",
            "4-277th: train loss: 1.47794, train acc: 0.997 valid loss: 1.56003 valid acc: 0.934\n",
            "4-278th: train loss: 1.47790, train acc: 0.997 valid loss: 1.55997 valid acc: 0.934\n",
            "4-279th: train loss: 1.47786, train acc: 0.997 valid loss: 1.55992 valid acc: 0.934\n",
            "4-280th: train loss: 1.47782, train acc: 0.997 valid loss: 1.55987 valid acc: 0.934\n",
            "4-281th: train loss: 1.47778, train acc: 0.997 valid loss: 1.55982 valid acc: 0.934\n",
            "4-282th: train loss: 1.47774, train acc: 0.997 valid loss: 1.55977 valid acc: 0.934\n",
            "4-283th: train loss: 1.47770, train acc: 0.997 valid loss: 1.55972 valid acc: 0.934\n",
            "4-284th: train loss: 1.47767, train acc: 0.997 valid loss: 1.55967 valid acc: 0.934\n",
            "4-285th: train loss: 1.47763, train acc: 0.997 valid loss: 1.55962 valid acc: 0.934\n",
            "4-286th: train loss: 1.47759, train acc: 0.997 valid loss: 1.55956 valid acc: 0.934\n",
            "4-287th: train loss: 1.47755, train acc: 0.997 valid loss: 1.55951 valid acc: 0.934\n",
            "4-288th: train loss: 1.47752, train acc: 0.997 valid loss: 1.55945 valid acc: 0.931\n",
            "4-289th: train loss: 1.47748, train acc: 0.997 valid loss: 1.55939 valid acc: 0.931\n",
            "4-290th: train loss: 1.47745, train acc: 0.997 valid loss: 1.55934 valid acc: 0.931\n",
            "4-291th: train loss: 1.47741, train acc: 0.997 valid loss: 1.55928 valid acc: 0.931\n",
            "4-292th: train loss: 1.47738, train acc: 0.997 valid loss: 1.55922 valid acc: 0.931\n",
            "4-293th: train loss: 1.47734, train acc: 0.997 valid loss: 1.55917 valid acc: 0.931\n",
            "4-294th: train loss: 1.47730, train acc: 0.997 valid loss: 1.55911 valid acc: 0.928\n",
            "4-295th: train loss: 1.47727, train acc: 0.997 valid loss: 1.55905 valid acc: 0.928\n",
            "4-296th: train loss: 1.47724, train acc: 0.997 valid loss: 1.55900 valid acc: 0.928\n",
            "4-297th: train loss: 1.47720, train acc: 0.997 valid loss: 1.55895 valid acc: 0.928\n",
            "4-298th: train loss: 1.47717, train acc: 0.997 valid loss: 1.55889 valid acc: 0.928\n",
            "4-299th: train loss: 1.47713, train acc: 0.997 valid loss: 1.55884 valid acc: 0.928\n"
          ]
        }
      ],
      "source": [
        "all_all_tr_loss = []\n",
        "all_all_valid_loss = []\n",
        "all_all_tr_acc = []\n",
        "all_all_valid_acc = []\n",
        "\n",
        "max_epochs = 300\n",
        "lr = 0.005\n",
        "n_fold = 5\n",
        "skf = StratifiedKFold(n_splits=n_fold)\n",
        "for i_fold, (tr, te) in enumerate(skf.split(data, label)):\n",
        "    data_tr, data_te, label_tr, label_te = data[tr].to(device), data[te].to(device), label[tr].to(device), label[te].to(device)\n",
        "    model = torch.nn.Sequential(\n",
        "        QNNModel(),\n",
        "        ConstCoeffLayer(20),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=5e-5)\n",
        "    all_tr_loss = []\n",
        "    all_valid_loss = []\n",
        "    all_tr_acc = []\n",
        "    all_valid_acc = []\n",
        "    for i_epoch in range(max_epochs):\n",
        "        print(f\"{i_fold}-{i_epoch}th:\", end=\" \")\n",
        "        loss_tr, acc_tr = train(data_tr, label_tr, model, optimizer)\n",
        "        loss_valid, acc_valid = valid(data_te, label_te, model)\n",
        "        all_tr_loss.append(loss_tr)\n",
        "        all_valid_loss.append(loss_valid)\n",
        "        all_tr_acc.append(acc_tr)\n",
        "        all_valid_acc.append(acc_valid)\n",
        "        ###\n",
        "    all_all_tr_loss.append(all_tr_loss)\n",
        "    all_all_valid_loss.append(all_valid_loss)\n",
        "    all_all_tr_acc.append(all_tr_acc)\n",
        "    all_all_valid_acc.append(all_valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T22:43:15.354983Z",
          "iopub.status.busy": "2023-12-06T22:43:15.354793Z",
          "iopub.status.idle": "2023-12-06T22:43:15.358333Z",
          "shell.execute_reply": "2023-12-06T22:43:15.357831Z"
        },
        "id": "H9RZHvE3k55h",
        "outputId": "362072fe-044b-4bfa-e118-4569faa08f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train acc: 0.9976452119309263, test acc: 0.9435736677115988, train loss: 1.4784959554672241, valid loss: 1.5421608686447144\n",
            "train acc: 0.9984301412872841, test acc: 0.9561128526645768, train loss: 1.4764117002487183, valid loss: 1.548536777496338\n",
            "train acc: 0.9976452119309263, test acc: 0.9717868338557993, train loss: 1.4780439138412476, valid loss: 1.523233413696289\n",
            "train acc: 0.9984313725490196, test acc: 0.940251572327044, train loss: 1.4760968685150146, valid loss: 1.5478966236114502\n",
            "train acc: 0.9968627450980392, test acc: 0.9276729559748428, train loss: 1.4771347045898438, valid loss: 1.558837652206421\n",
            "0.9978029365592391 0.9478795765067722\n",
            "0.0005868614256533677 0.014995856773675714\n",
            "1.4772366285324097 1.5441330671310425\n",
            "0.0009195174777206988 0.011751314183221773\n"
          ]
        }
      ],
      "source": [
        "train_acc = []\n",
        "valid_acc = []\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "for i in range(len(all_all_tr_acc)):\n",
        "    train_acc.append(all_all_tr_acc[i][-1])\n",
        "    valid_acc.append(all_all_valid_acc[i][-1])\n",
        "    train_loss.append(all_all_tr_loss[i][-1])\n",
        "    valid_loss.append(all_all_valid_loss[i][-1])\n",
        "    print(f\"train acc: {train_acc[-1]}, test acc: {valid_acc[-1]}, train loss: {train_loss[-1]}, valid loss: {valid_loss[-1]}\")\n",
        "\n",
        "print( np.mean(train_acc), np.mean(valid_acc) )\n",
        "print( np.std(train_acc), np.std(valid_acc) )\n",
        "print( np.mean(train_loss), np.mean(valid_loss))\n",
        "print( np.std(train_loss), np.std(valid_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T22:43:15.360598Z",
          "iopub.status.busy": "2023-12-06T22:43:15.360408Z",
          "iopub.status.idle": "2023-12-06T22:43:15.410909Z",
          "shell.execute_reply": "2023-12-06T22:43:15.410462Z"
        },
        "id": "DFnNQRLu1tYw"
      },
      "outputs": [],
      "source": [
        "nu0 = model[0].qnn1.n_depth_per_block\n",
        "c0 = int(model[1].coeff)\n",
        "prefix_name = dataset_name+\"_\"+\"2qnn\"+str(nu0)+\"_c\"+str(c0)+\"_\"+str(n_qubits)+\"qubits_\"\n",
        "if False:\n",
        "    pd.DataFrame(all_all_tr_acc).to_csv(prefix_name+\"_tr_acc.csv\", index=False)\n",
        "    pd.DataFrame(all_all_valid_acc).to_csv(prefix_name+\"_valid_acc.csv\", index=False)\n",
        "    pd.DataFrame(all_all_tr_loss).to_csv(prefix_name+\"_tr_loss.csv\", index=False)\n",
        "    pd.DataFrame(all_all_valid_loss).to_csv(prefix_name+\"_valid_loss.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz0oPaAQk55i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
