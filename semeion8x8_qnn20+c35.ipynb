{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:22.779683Z",
          "iopub.status.busy": "2023-12-06T08:56:22.779592Z",
          "iopub.status.idle": "2023-12-06T08:56:24.578226Z",
          "shell.execute_reply": "2023-12-06T08:56:24.577785Z"
        },
        "id": "UEv1RLJ01tYq"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import gradcheck\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:24.581862Z",
          "iopub.status.busy": "2023-12-06T08:56:24.581643Z",
          "iopub.status.idle": "2023-12-06T08:56:24.583627Z",
          "shell.execute_reply": "2023-12-06T08:56:24.583278Z"
        },
        "id": "UHp0vfRc1-T_",
        "outputId": "76192af5-b067-4fea-c5cc-62ea50f68a26"
      },
      "outputs": [],
      "source": [
        "# !pip install torchquantum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:24.587213Z",
          "iopub.status.busy": "2023-12-06T08:56:24.586935Z",
          "iopub.status.idle": "2023-12-06T08:56:26.010716Z",
          "shell.execute_reply": "2023-12-06T08:56:26.010330Z"
        },
        "id": "cDueIyyE1-5L"
      },
      "outputs": [],
      "source": [
        "import torchquantum as tq\n",
        "from torchquantum.measurement import expval_joint_analytical\n",
        "import warnings\n",
        "\n",
        "seed = 1001\n",
        "#random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "warnings.simplefilter('ignore', UserWarning)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# NZ_INPUT_ANGLE = 2\n",
        "# device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.013653Z",
          "iopub.status.busy": "2023-12-06T08:56:26.013313Z",
          "iopub.status.idle": "2023-12-06T08:56:26.386525Z",
          "shell.execute_reply": "2023-12-06T08:56:26.385940Z"
        },
        "id": "UKTP2AJ-1tYs",
        "outputId": "79239391-978d-4889-f734-e1152ae9f68b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "semeion_data = torchvision.datasets.SEMEION(root='./data', download=True)\n",
        "dataset_name = 'semeion'\n",
        "data, label = semeion_data.data, semeion_data.labels\n",
        "data = data/255*math.pi/8 # pi/2\n",
        "n_qubits = 8\n",
        "n_class = len(np.unique(label))\n",
        "\n",
        "data = torch.nn.AvgPool2d( (2,2), stride=(2,2) )( torch.from_numpy(data) ) # # (1593, 16, 16) => (1593, 8, 8)\n",
        "data = data.reshape(-1,data.shape[1]*data.shape[2]) # (1593, 8, 8) => (1593, 64)\n",
        "label = torch.from_numpy(label)\n",
        "n_data, n_features = data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.419345Z",
          "iopub.status.busy": "2023-12-06T08:56:26.419160Z",
          "iopub.status.idle": "2023-12-06T08:56:26.421654Z",
          "shell.execute_reply": "2023-12-06T08:56:26.421277Z"
        },
        "id": "YPw4rzwS1tYt"
      },
      "outputs": [],
      "source": [
        "class CoeffLayer(nn.Module):\n",
        "    def __init__(self, coeff):\n",
        "        super().__init__()\n",
        "        self.coeff = torch.nn.Parameter(coeff)\n",
        "    def forward(self, x):\n",
        "        ret = x * self.coeff\n",
        "        return ret\n",
        "\n",
        "class ConstCoeffLayer(nn.Module):\n",
        "    def __init__(self, coeff):\n",
        "        super().__init__()\n",
        "        self.coeff = coeff\n",
        "    def forward(self, x):\n",
        "        ret = x * self.coeff\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.423671Z",
          "iopub.status.busy": "2023-12-06T08:56:26.423478Z",
          "iopub.status.idle": "2023-12-06T08:56:26.431021Z",
          "shell.execute_reply": "2023-12-06T08:56:26.430568Z"
        },
        "id": "k4_zRBXbk55h"
      },
      "outputs": [],
      "source": [
        "class QNNsubModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        # params is numpy array\n",
        "        super().__init__()\n",
        "        self.n_wires = n_qubits\n",
        "        self.encoder_gates_x = ([tq.functional.rx] * self.n_wires + [tq.functional.ry] * self.n_wires)*4\n",
        "        self.n_block = 5\n",
        "        self.n_depth_per_block = 20\n",
        "        params = np.random.rand( self.n_wires*self.n_depth_per_block*self.n_block*2)*math.pi\n",
        "        self.u_layers = tq.QuantumModuleList()\n",
        "        for j in range(self.n_depth_per_block*self.n_block):\n",
        "            for i in range(self.n_wires):\n",
        "                self.u_layers.append( tq.RX(has_params=True, trainable=True, init_params=params[i+(2*j)*self.n_wires]) )\n",
        "            for i in range(self.n_wires):\n",
        "                self.u_layers.append( tq.RY(has_params=True, trainable=True, init_params=params[i+(2*j+1)*self.n_wires]) )\n",
        "\n",
        "    def forward(self, x):\n",
        "        bsz, nx_features = x.shape\n",
        "        qdev = tq.QuantumDevice(\n",
        "            n_wires=self.n_wires, bsz = bsz, device=x.device, record_op=False\n",
        "        )\n",
        "        n_depth_per_block = self.n_depth_per_block\n",
        "        for d in range(self.n_block-1): # (2,4)\n",
        "            for k in range(n_depth_per_block):\n",
        "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
        "                    for i in range(self.n_wires):\n",
        "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
        "                for i in range(self.n_wires):\n",
        "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "            # data encoding\n",
        "            for j in range(2*d,2*d+2): # (0,2) (2,4)\n",
        "                for k in range(self.n_wires):\n",
        "                    self.encoder_gates_x[k+j*self.n_wires](qdev, wires=k, params=x[:, (k+j*self.n_wires)])\n",
        "            for i in range(self.n_wires):\n",
        "                qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "        for d in range(self.n_block-1,self.n_block): # (4,5)\n",
        "            for k in range(n_depth_per_block):\n",
        "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
        "                    for i in range(self.n_wires):\n",
        "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
        "                if k==n_depth_per_block-1:\n",
        "                    break\n",
        "                for i in range(self.n_wires):\n",
        "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "\n",
        "        obs_list = [ expval_joint_analytical(qdev, \"I\"*i+Pauli+\"I\"*(self.n_wires-1-i)) for Pauli in [\"X\",\"Z\"] for i in range(n_class//2)]\n",
        "        ret = torch.stack(obs_list, dim=1)\n",
        "        return ret\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.432949Z",
          "iopub.status.busy": "2023-12-06T08:56:26.432774Z",
          "iopub.status.idle": "2023-12-06T08:56:26.435667Z",
          "shell.execute_reply": "2023-12-06T08:56:26.435280Z"
        },
        "id": "n3w6djyB1tYv"
      },
      "outputs": [],
      "source": [
        "class QNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.qnn1 = QNNsubModel()\n",
        "        self.qnn2 = QNNsubModel()\n",
        "    def forward(self, x):\n",
        "        ret = self.qnn1(x)\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.442298Z",
          "iopub.status.busy": "2023-12-06T08:56:26.442097Z",
          "iopub.status.idle": "2023-12-06T08:56:26.445630Z",
          "shell.execute_reply": "2023-12-06T08:56:26.445212Z"
        },
        "id": "F-7DW09j1tYv"
      },
      "outputs": [],
      "source": [
        "def train(data, label, model, optimizer):\n",
        "    model.train(mode=True)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
        "    acc = (pred.argmax(axis=1) == label).sum().item() / len(label)\n",
        "    # acc = accuracy_score(y_tr, pred.argmax(axis=1).cpu().detach().numpy() )\n",
        "    print(f\"train loss: {loss.item():.5f}, train acc: {acc:.3f}\", end=' ')\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item(), acc\n",
        "\n",
        "def valid(data, label, model):\n",
        "    model.train(mode=False)\n",
        "    with torch.no_grad():\n",
        "        pred = model(data)\n",
        "        loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
        "    acc = (pred.argmax(axis=1) == label).sum().item() / len(label)\n",
        "    # acc = accuracy_score(y_te, pred.argmax(axis=1).cpu().detach().numpy() )\n",
        "    print(f\"valid loss: {loss.item():.5f} valid acc: {acc:.3f}\")\n",
        "    return loss.item(), acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.447501Z",
          "iopub.status.busy": "2023-12-06T08:56:26.447318Z",
          "iopub.status.idle": "2023-12-06T22:43:15.347017Z",
          "shell.execute_reply": "2023-12-06T22:43:15.346447Z"
        },
        "id": "MarqNpSo1tYv",
        "outputId": "2300ba01-717a-40dc-ac29-7070f017f0aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0-0th: train loss: 2.32899, train acc: 0.104 valid loss: 2.29183 valid acc: 0.129\n",
            "0-1th: train loss: 2.28118, train acc: 0.143 valid loss: 2.21703 valid acc: 0.241\n",
            "0-2th: train loss: 2.19432, train acc: 0.273 valid loss: 2.16135 valid acc: 0.310\n",
            "0-3th: train loss: 2.14403, train acc: 0.330 valid loss: 2.09081 valid acc: 0.417\n",
            "0-4th: train loss: 2.07714, train acc: 0.409 valid loss: 2.03751 valid acc: 0.467\n",
            "0-5th: train loss: 2.02798, train acc: 0.473 valid loss: 2.00979 valid acc: 0.473\n",
            "0-6th: train loss: 1.99736, train acc: 0.487 valid loss: 1.98677 valid acc: 0.489\n",
            "0-7th: train loss: 1.97113, train acc: 0.509 valid loss: 1.96412 valid acc: 0.502\n",
            "0-8th: train loss: 1.94846, train acc: 0.529 valid loss: 1.94507 valid acc: 0.527\n",
            "0-9th: train loss: 1.92822, train acc: 0.542 valid loss: 1.93076 valid acc: 0.542\n",
            "0-10th: train loss: 1.90896, train acc: 0.576 valid loss: 1.92855 valid acc: 0.567\n",
            "0-11th: train loss: 1.90284, train acc: 0.592 valid loss: 1.91826 valid acc: 0.564\n",
            "0-12th: train loss: 1.89107, train acc: 0.601 valid loss: 1.90162 valid acc: 0.596\n",
            "0-13th: train loss: 1.87329, train acc: 0.612 valid loss: 1.89503 valid acc: 0.577\n",
            "0-14th: train loss: 1.86470, train acc: 0.621 valid loss: 1.88718 valid acc: 0.586\n",
            "0-15th: train loss: 1.85573, train acc: 0.630 valid loss: 1.87216 valid acc: 0.608\n",
            "0-16th: train loss: 1.84073, train acc: 0.655 valid loss: 1.85356 valid acc: 0.652\n",
            "0-17th: train loss: 1.82513, train acc: 0.677 valid loss: 1.83806 valid acc: 0.665\n",
            "0-18th: train loss: 1.81429, train acc: 0.696 valid loss: 1.82034 valid acc: 0.708\n",
            "0-19th: train loss: 1.79424, train acc: 0.731 valid loss: 1.80461 valid acc: 0.734\n",
            "0-20th: train loss: 1.77308, train acc: 0.754 valid loss: 1.79000 valid acc: 0.734\n",
            "0-21th: train loss: 1.75617, train acc: 0.765 valid loss: 1.77599 valid acc: 0.737\n",
            "0-22th: train loss: 1.74321, train acc: 0.772 valid loss: 1.76086 valid acc: 0.752\n",
            "0-23th: train loss: 1.73162, train acc: 0.782 valid loss: 1.74668 valid acc: 0.771\n",
            "0-24th: train loss: 1.72163, train acc: 0.790 valid loss: 1.73759 valid acc: 0.774\n",
            "0-25th: train loss: 1.71530, train acc: 0.797 valid loss: 1.73238 valid acc: 0.781\n",
            "0-26th: train loss: 1.70981, train acc: 0.805 valid loss: 1.72867 valid acc: 0.781\n",
            "0-27th: train loss: 1.70414, train acc: 0.812 valid loss: 1.72502 valid acc: 0.774\n",
            "0-28th: train loss: 1.69849, train acc: 0.816 valid loss: 1.72111 valid acc: 0.781\n",
            "0-29th: train loss: 1.69283, train acc: 0.819 valid loss: 1.71713 valid acc: 0.777\n",
            "0-30th: train loss: 1.68735, train acc: 0.821 valid loss: 1.71407 valid acc: 0.790\n",
            "0-31th: train loss: 1.68290, train acc: 0.824 valid loss: 1.71189 valid acc: 0.787\n",
            "0-32th: train loss: 1.67872, train acc: 0.832 valid loss: 1.70998 valid acc: 0.784\n",
            "0-33th: train loss: 1.67439, train acc: 0.837 valid loss: 1.70797 valid acc: 0.793\n",
            "0-34th: train loss: 1.67063, train acc: 0.841 valid loss: 1.70537 valid acc: 0.793\n",
            "0-35th: train loss: 1.66751, train acc: 0.843 valid loss: 1.70218 valid acc: 0.796\n",
            "0-36th: train loss: 1.66470, train acc: 0.841 valid loss: 1.69899 valid acc: 0.799\n",
            "0-37th: train loss: 1.66190, train acc: 0.843 valid loss: 1.69663 valid acc: 0.796\n",
            "0-38th: train loss: 1.65917, train acc: 0.847 valid loss: 1.69528 valid acc: 0.790\n",
            "0-39th: train loss: 1.65677, train acc: 0.848 valid loss: 1.69429 valid acc: 0.793\n",
            "0-40th: train loss: 1.65458, train acc: 0.850 valid loss: 1.69268 valid acc: 0.803\n",
            "0-41th: train loss: 1.65229, train acc: 0.853 valid loss: 1.69018 valid acc: 0.815\n",
            "0-42th: train loss: 1.65000, train acc: 0.856 valid loss: 1.68721 valid acc: 0.818\n",
            "0-43th: train loss: 1.64797, train acc: 0.856 valid loss: 1.68428 valid acc: 0.818\n",
            "0-44th: train loss: 1.64598, train acc: 0.857 valid loss: 1.68200 valid acc: 0.818\n",
            "0-45th: train loss: 1.64405, train acc: 0.859 valid loss: 1.68048 valid acc: 0.815\n",
            "0-46th: train loss: 1.64231, train acc: 0.859 valid loss: 1.67923 valid acc: 0.818\n",
            "0-47th: train loss: 1.64058, train acc: 0.862 valid loss: 1.67785 valid acc: 0.821\n",
            "0-48th: train loss: 1.63883, train acc: 0.863 valid loss: 1.67645 valid acc: 0.824\n",
            "0-49th: train loss: 1.63733, train acc: 0.864 valid loss: 1.67501 valid acc: 0.828\n",
            "0-50th: train loss: 1.63597, train acc: 0.863 valid loss: 1.67343 valid acc: 0.828\n",
            "0-51th: train loss: 1.63441, train acc: 0.864 valid loss: 1.67207 valid acc: 0.828\n",
            "0-52th: train loss: 1.63292, train acc: 0.866 valid loss: 1.67103 valid acc: 0.824\n",
            "0-53th: train loss: 1.63173, train acc: 0.867 valid loss: 1.66989 valid acc: 0.824\n",
            "0-54th: train loss: 1.63049, train acc: 0.868 valid loss: 1.66864 valid acc: 0.831\n",
            "0-55th: train loss: 1.62912, train acc: 0.868 valid loss: 1.66774 valid acc: 0.834\n",
            "0-56th: train loss: 1.62794, train acc: 0.868 valid loss: 1.66719 valid acc: 0.834\n",
            "0-57th: train loss: 1.62691, train acc: 0.868 valid loss: 1.66663 valid acc: 0.834\n",
            "0-58th: train loss: 1.62577, train acc: 0.869 valid loss: 1.66591 valid acc: 0.834\n",
            "0-59th: train loss: 1.62467, train acc: 0.870 valid loss: 1.66504 valid acc: 0.837\n",
            "0-60th: train loss: 1.62371, train acc: 0.871 valid loss: 1.66398 valid acc: 0.837\n",
            "0-61th: train loss: 1.62276, train acc: 0.872 valid loss: 1.66297 valid acc: 0.840\n",
            "0-62th: train loss: 1.62179, train acc: 0.873 valid loss: 1.66233 valid acc: 0.843\n",
            "0-63th: train loss: 1.62092, train acc: 0.872 valid loss: 1.66197 valid acc: 0.843\n",
            "0-64th: train loss: 1.62008, train acc: 0.873 valid loss: 1.66163 valid acc: 0.843\n",
            "0-65th: train loss: 1.61922, train acc: 0.873 valid loss: 1.66118 valid acc: 0.843\n",
            "0-66th: train loss: 1.61840, train acc: 0.874 valid loss: 1.66055 valid acc: 0.840\n",
            "0-67th: train loss: 1.61763, train acc: 0.874 valid loss: 1.65981 valid acc: 0.840\n",
            "0-68th: train loss: 1.61684, train acc: 0.874 valid loss: 1.65912 valid acc: 0.843\n",
            "0-69th: train loss: 1.61604, train acc: 0.875 valid loss: 1.65863 valid acc: 0.843\n",
            "0-70th: train loss: 1.61529, train acc: 0.875 valid loss: 1.65824 valid acc: 0.843\n",
            "0-71th: train loss: 1.61454, train acc: 0.876 valid loss: 1.65779 valid acc: 0.840\n",
            "0-72th: train loss: 1.61375, train acc: 0.877 valid loss: 1.65723 valid acc: 0.840\n",
            "0-73th: train loss: 1.61294, train acc: 0.877 valid loss: 1.65652 valid acc: 0.840\n",
            "0-74th: train loss: 1.61209, train acc: 0.877 valid loss: 1.65561 valid acc: 0.840\n",
            "0-75th: train loss: 1.61105, train acc: 0.878 valid loss: 1.65433 valid acc: 0.840\n",
            "0-76th: train loss: 1.60960, train acc: 0.880 valid loss: 1.65202 valid acc: 0.840\n",
            "0-77th: train loss: 1.60711, train acc: 0.885 valid loss: 1.64645 valid acc: 0.856\n",
            "0-78th: train loss: 1.60187, train acc: 0.898 valid loss: 1.63717 valid acc: 0.893\n",
            "0-79th: train loss: 1.59377, train acc: 0.922 valid loss: 1.63611 valid acc: 0.887\n",
            "0-80th: train loss: 1.59210, train acc: 0.941 valid loss: 1.62289 valid acc: 0.890\n",
            "0-81th: train loss: 1.57724, train acc: 0.943 valid loss: 1.61900 valid acc: 0.887\n",
            "0-82th: train loss: 1.57249, train acc: 0.941 valid loss: 1.60828 valid acc: 0.906\n",
            "0-83th: train loss: 1.56384, train acc: 0.951 valid loss: 1.60262 valid acc: 0.918\n",
            "0-84th: train loss: 1.56172, train acc: 0.958 valid loss: 1.59964 valid acc: 0.928\n",
            "0-85th: train loss: 1.55903, train acc: 0.959 valid loss: 1.59825 valid acc: 0.909\n",
            "0-86th: train loss: 1.55575, train acc: 0.958 valid loss: 1.59941 valid acc: 0.909\n",
            "0-87th: train loss: 1.55572, train acc: 0.954 valid loss: 1.59541 valid acc: 0.909\n",
            "0-88th: train loss: 1.55257, train acc: 0.960 valid loss: 1.59243 valid acc: 0.915\n",
            "0-89th: train loss: 1.55077, train acc: 0.964 valid loss: 1.59145 valid acc: 0.912\n",
            "0-90th: train loss: 1.54958, train acc: 0.965 valid loss: 1.58962 valid acc: 0.918\n",
            "0-91th: train loss: 1.54649, train acc: 0.964 valid loss: 1.58931 valid acc: 0.922\n",
            "0-92th: train loss: 1.54526, train acc: 0.963 valid loss: 1.58742 valid acc: 0.928\n",
            "0-93th: train loss: 1.54372, train acc: 0.963 valid loss: 1.58414 valid acc: 0.925\n",
            "0-94th: train loss: 1.54159, train acc: 0.965 valid loss: 1.58266 valid acc: 0.925\n",
            "0-95th: train loss: 1.54072, train acc: 0.969 valid loss: 1.58187 valid acc: 0.925\n",
            "0-96th: train loss: 1.53926, train acc: 0.970 valid loss: 1.58158 valid acc: 0.928\n",
            "0-97th: train loss: 1.53770, train acc: 0.969 valid loss: 1.58146 valid acc: 0.925\n",
            "0-98th: train loss: 1.53692, train acc: 0.968 valid loss: 1.57941 valid acc: 0.922\n",
            "0-99th: train loss: 1.53548, train acc: 0.970 valid loss: 1.57685 valid acc: 0.928\n",
            "0-100th: train loss: 1.53420, train acc: 0.971 valid loss: 1.57556 valid acc: 0.925\n",
            "0-101th: train loss: 1.53345, train acc: 0.973 valid loss: 1.57516 valid acc: 0.928\n",
            "0-102th: train loss: 1.53220, train acc: 0.973 valid loss: 1.57570 valid acc: 0.928\n",
            "0-103th: train loss: 1.53124, train acc: 0.973 valid loss: 1.57600 valid acc: 0.928\n",
            "0-104th: train loss: 1.53055, train acc: 0.974 valid loss: 1.57500 valid acc: 0.928\n",
            "0-105th: train loss: 1.52957, train acc: 0.976 valid loss: 1.57367 valid acc: 0.928\n",
            "0-106th: train loss: 1.52887, train acc: 0.977 valid loss: 1.57277 valid acc: 0.928\n",
            "0-107th: train loss: 1.52817, train acc: 0.977 valid loss: 1.57255 valid acc: 0.931\n",
            "0-108th: train loss: 1.52735, train acc: 0.978 valid loss: 1.57283 valid acc: 0.934\n",
            "0-109th: train loss: 1.52675, train acc: 0.978 valid loss: 1.57269 valid acc: 0.934\n",
            "0-110th: train loss: 1.52603, train acc: 0.980 valid loss: 1.57202 valid acc: 0.925\n",
            "0-111th: train loss: 1.52529, train acc: 0.980 valid loss: 1.57139 valid acc: 0.928\n",
            "0-112th: train loss: 1.52473, train acc: 0.979 valid loss: 1.57093 valid acc: 0.931\n",
            "0-113th: train loss: 1.52403, train acc: 0.980 valid loss: 1.57070 valid acc: 0.934\n",
            "0-114th: train loss: 1.52338, train acc: 0.980 valid loss: 1.57047 valid acc: 0.928\n",
            "0-115th: train loss: 1.52286, train acc: 0.980 valid loss: 1.56992 valid acc: 0.928\n",
            "0-116th: train loss: 1.52225, train acc: 0.980 valid loss: 1.56939 valid acc: 0.928\n",
            "0-117th: train loss: 1.52170, train acc: 0.980 valid loss: 1.56919 valid acc: 0.928\n",
            "0-118th: train loss: 1.52124, train acc: 0.981 valid loss: 1.56922 valid acc: 0.925\n",
            "0-119th: train loss: 1.52073, train acc: 0.980 valid loss: 1.56922 valid acc: 0.928\n",
            "0-120th: train loss: 1.52025, train acc: 0.980 valid loss: 1.56900 valid acc: 0.928\n",
            "0-121th: train loss: 1.51982, train acc: 0.981 valid loss: 1.56855 valid acc: 0.925\n",
            "0-122th: train loss: 1.51936, train acc: 0.981 valid loss: 1.56823 valid acc: 0.925\n",
            "0-123th: train loss: 1.51891, train acc: 0.981 valid loss: 1.56823 valid acc: 0.925\n",
            "0-124th: train loss: 1.51850, train acc: 0.982 valid loss: 1.56838 valid acc: 0.925\n",
            "0-125th: train loss: 1.51807, train acc: 0.982 valid loss: 1.56840 valid acc: 0.922\n",
            "0-126th: train loss: 1.51765, train acc: 0.982 valid loss: 1.56816 valid acc: 0.922\n",
            "0-127th: train loss: 1.51726, train acc: 0.982 valid loss: 1.56775 valid acc: 0.922\n",
            "0-128th: train loss: 1.51685, train acc: 0.983 valid loss: 1.56748 valid acc: 0.928\n",
            "0-129th: train loss: 1.51648, train acc: 0.984 valid loss: 1.56741 valid acc: 0.928\n",
            "0-130th: train loss: 1.51611, train acc: 0.983 valid loss: 1.56738 valid acc: 0.925\n",
            "0-131th: train loss: 1.51573, train acc: 0.984 valid loss: 1.56723 valid acc: 0.925\n",
            "0-132th: train loss: 1.51538, train acc: 0.984 valid loss: 1.56688 valid acc: 0.925\n",
            "0-133th: train loss: 1.51504, train acc: 0.984 valid loss: 1.56647 valid acc: 0.931\n",
            "0-134th: train loss: 1.51469, train acc: 0.984 valid loss: 1.56618 valid acc: 0.934\n",
            "0-135th: train loss: 1.51436, train acc: 0.984 valid loss: 1.56604 valid acc: 0.934\n",
            "0-136th: train loss: 1.51403, train acc: 0.984 valid loss: 1.56595 valid acc: 0.931\n",
            "0-137th: train loss: 1.51371, train acc: 0.985 valid loss: 1.56579 valid acc: 0.928\n",
            "0-138th: train loss: 1.51340, train acc: 0.985 valid loss: 1.56553 valid acc: 0.928\n",
            "0-139th: train loss: 1.51308, train acc: 0.985 valid loss: 1.56523 valid acc: 0.931\n",
            "0-140th: train loss: 1.51278, train acc: 0.985 valid loss: 1.56499 valid acc: 0.934\n",
            "0-141th: train loss: 1.51248, train acc: 0.985 valid loss: 1.56486 valid acc: 0.931\n",
            "0-142th: train loss: 1.51218, train acc: 0.985 valid loss: 1.56478 valid acc: 0.931\n",
            "0-143th: train loss: 1.51190, train acc: 0.985 valid loss: 1.56466 valid acc: 0.928\n",
            "0-144th: train loss: 1.51161, train acc: 0.986 valid loss: 1.56447 valid acc: 0.928\n",
            "0-145th: train loss: 1.51133, train acc: 0.987 valid loss: 1.56423 valid acc: 0.931\n",
            "0-146th: train loss: 1.51106, train acc: 0.987 valid loss: 1.56402 valid acc: 0.934\n",
            "0-147th: train loss: 1.51079, train acc: 0.987 valid loss: 1.56386 valid acc: 0.934\n",
            "0-148th: train loss: 1.51053, train acc: 0.987 valid loss: 1.56373 valid acc: 0.928\n",
            "0-149th: train loss: 1.51027, train acc: 0.987 valid loss: 1.56356 valid acc: 0.931\n",
            "0-150th: train loss: 1.51001, train acc: 0.987 valid loss: 1.56335 valid acc: 0.934\n",
            "0-151th: train loss: 1.50976, train acc: 0.987 valid loss: 1.56314 valid acc: 0.934\n",
            "0-152th: train loss: 1.50951, train acc: 0.987 valid loss: 1.56295 valid acc: 0.934\n",
            "0-153th: train loss: 1.50926, train acc: 0.987 valid loss: 1.56280 valid acc: 0.934\n",
            "0-154th: train loss: 1.50902, train acc: 0.988 valid loss: 1.56264 valid acc: 0.934\n",
            "0-155th: train loss: 1.50879, train acc: 0.988 valid loss: 1.56245 valid acc: 0.934\n",
            "0-156th: train loss: 1.50855, train acc: 0.988 valid loss: 1.56226 valid acc: 0.934\n",
            "0-157th: train loss: 1.50832, train acc: 0.988 valid loss: 1.56212 valid acc: 0.934\n",
            "0-158th: train loss: 1.50810, train acc: 0.988 valid loss: 1.56201 valid acc: 0.934\n",
            "0-159th: train loss: 1.50787, train acc: 0.988 valid loss: 1.56190 valid acc: 0.934\n",
            "0-160th: train loss: 1.50765, train acc: 0.989 valid loss: 1.56174 valid acc: 0.934\n",
            "0-161th: train loss: 1.50743, train acc: 0.989 valid loss: 1.56156 valid acc: 0.934\n",
            "0-162th: train loss: 1.50722, train acc: 0.989 valid loss: 1.56143 valid acc: 0.934\n",
            "0-163th: train loss: 1.50701, train acc: 0.989 valid loss: 1.56134 valid acc: 0.934\n",
            "0-164th: train loss: 1.50680, train acc: 0.989 valid loss: 1.56127 valid acc: 0.934\n",
            "0-165th: train loss: 1.50659, train acc: 0.989 valid loss: 1.56116 valid acc: 0.934\n",
            "0-166th: train loss: 1.50639, train acc: 0.989 valid loss: 1.56099 valid acc: 0.934\n",
            "0-167th: train loss: 1.50618, train acc: 0.989 valid loss: 1.56083 valid acc: 0.937\n",
            "0-168th: train loss: 1.50599, train acc: 0.989 valid loss: 1.56072 valid acc: 0.934\n",
            "0-169th: train loss: 1.50579, train acc: 0.989 valid loss: 1.56064 valid acc: 0.934\n",
            "0-170th: train loss: 1.50560, train acc: 0.989 valid loss: 1.56055 valid acc: 0.934\n",
            "0-171th: train loss: 1.50540, train acc: 0.989 valid loss: 1.56040 valid acc: 0.934\n",
            "0-172th: train loss: 1.50521, train acc: 0.989 valid loss: 1.56023 valid acc: 0.934\n",
            "0-173th: train loss: 1.50503, train acc: 0.989 valid loss: 1.56009 valid acc: 0.937\n",
            "0-174th: train loss: 1.50484, train acc: 0.989 valid loss: 1.55998 valid acc: 0.937\n",
            "0-175th: train loss: 1.50466, train acc: 0.989 valid loss: 1.55989 valid acc: 0.940\n",
            "0-176th: train loss: 1.50448, train acc: 0.989 valid loss: 1.55977 valid acc: 0.940\n",
            "0-177th: train loss: 1.50430, train acc: 0.989 valid loss: 1.55962 valid acc: 0.940\n",
            "0-178th: train loss: 1.50413, train acc: 0.989 valid loss: 1.55947 valid acc: 0.937\n",
            "0-179th: train loss: 1.50395, train acc: 0.989 valid loss: 1.55936 valid acc: 0.937\n",
            "0-180th: train loss: 1.50378, train acc: 0.989 valid loss: 1.55926 valid acc: 0.937\n",
            "0-181th: train loss: 1.50361, train acc: 0.989 valid loss: 1.55915 valid acc: 0.937\n",
            "0-182th: train loss: 1.50345, train acc: 0.989 valid loss: 1.55902 valid acc: 0.937\n",
            "0-183th: train loss: 1.50328, train acc: 0.989 valid loss: 1.55888 valid acc: 0.937\n",
            "0-184th: train loss: 1.50312, train acc: 0.989 valid loss: 1.55877 valid acc: 0.937\n",
            "0-185th: train loss: 1.50296, train acc: 0.990 valid loss: 1.55868 valid acc: 0.937\n",
            "0-186th: train loss: 1.50280, train acc: 0.990 valid loss: 1.55857 valid acc: 0.937\n",
            "0-187th: train loss: 1.50264, train acc: 0.990 valid loss: 1.55845 valid acc: 0.937\n",
            "0-188th: train loss: 1.50249, train acc: 0.990 valid loss: 1.55832 valid acc: 0.937\n",
            "0-189th: train loss: 1.50233, train acc: 0.990 valid loss: 1.55820 valid acc: 0.937\n",
            "0-190th: train loss: 1.50218, train acc: 0.990 valid loss: 1.55810 valid acc: 0.937\n",
            "0-191th: train loss: 1.50203, train acc: 0.990 valid loss: 1.55800 valid acc: 0.937\n",
            "0-192th: train loss: 1.50188, train acc: 0.990 valid loss: 1.55789 valid acc: 0.937\n",
            "0-193th: train loss: 1.50173, train acc: 0.990 valid loss: 1.55776 valid acc: 0.937\n",
            "0-194th: train loss: 1.50159, train acc: 0.990 valid loss: 1.55765 valid acc: 0.937\n",
            "0-195th: train loss: 1.50144, train acc: 0.990 valid loss: 1.55755 valid acc: 0.937\n",
            "0-196th: train loss: 1.50130, train acc: 0.990 valid loss: 1.55745 valid acc: 0.937\n",
            "0-197th: train loss: 1.50116, train acc: 0.990 valid loss: 1.55734 valid acc: 0.937\n",
            "0-198th: train loss: 1.50102, train acc: 0.990 valid loss: 1.55723 valid acc: 0.937\n",
            "0-199th: train loss: 1.50088, train acc: 0.990 valid loss: 1.55711 valid acc: 0.937\n",
            "0-200th: train loss: 1.50075, train acc: 0.991 valid loss: 1.55701 valid acc: 0.937\n",
            "0-201th: train loss: 1.50061, train acc: 0.991 valid loss: 1.55692 valid acc: 0.937\n",
            "0-202th: train loss: 1.50048, train acc: 0.991 valid loss: 1.55682 valid acc: 0.937\n",
            "0-203th: train loss: 1.50035, train acc: 0.991 valid loss: 1.55671 valid acc: 0.937\n",
            "0-204th: train loss: 1.50022, train acc: 0.991 valid loss: 1.55660 valid acc: 0.937\n",
            "0-205th: train loss: 1.50009, train acc: 0.991 valid loss: 1.55650 valid acc: 0.937\n",
            "0-206th: train loss: 1.49996, train acc: 0.991 valid loss: 1.55641 valid acc: 0.937\n",
            "0-207th: train loss: 1.49983, train acc: 0.991 valid loss: 1.55632 valid acc: 0.937\n",
            "0-208th: train loss: 1.49971, train acc: 0.991 valid loss: 1.55622 valid acc: 0.937\n",
            "0-209th: train loss: 1.49958, train acc: 0.991 valid loss: 1.55612 valid acc: 0.937\n",
            "0-210th: train loss: 1.49946, train acc: 0.991 valid loss: 1.55602 valid acc: 0.937\n",
            "0-211th: train loss: 1.49934, train acc: 0.991 valid loss: 1.55593 valid acc: 0.937\n",
            "0-212th: train loss: 1.49921, train acc: 0.991 valid loss: 1.55584 valid acc: 0.937\n",
            "0-213th: train loss: 1.49909, train acc: 0.991 valid loss: 1.55575 valid acc: 0.937\n",
            "0-214th: train loss: 1.49897, train acc: 0.991 valid loss: 1.55565 valid acc: 0.937\n",
            "0-215th: train loss: 1.49886, train acc: 0.991 valid loss: 1.55556 valid acc: 0.937\n",
            "0-216th: train loss: 1.49874, train acc: 0.991 valid loss: 1.55548 valid acc: 0.937\n",
            "0-217th: train loss: 1.49862, train acc: 0.991 valid loss: 1.55539 valid acc: 0.937\n",
            "0-218th: train loss: 1.49851, train acc: 0.991 valid loss: 1.55531 valid acc: 0.937\n",
            "0-219th: train loss: 1.49839, train acc: 0.991 valid loss: 1.55522 valid acc: 0.937\n",
            "0-220th: train loss: 1.49828, train acc: 0.991 valid loss: 1.55513 valid acc: 0.937\n",
            "0-221th: train loss: 1.49817, train acc: 0.991 valid loss: 1.55506 valid acc: 0.940\n",
            "0-222th: train loss: 1.49805, train acc: 0.991 valid loss: 1.55498 valid acc: 0.940\n",
            "0-223th: train loss: 1.49794, train acc: 0.991 valid loss: 1.55490 valid acc: 0.940\n",
            "0-224th: train loss: 1.49783, train acc: 0.991 valid loss: 1.55481 valid acc: 0.940\n",
            "0-225th: train loss: 1.49772, train acc: 0.991 valid loss: 1.55474 valid acc: 0.940\n",
            "0-226th: train loss: 1.49761, train acc: 0.991 valid loss: 1.55466 valid acc: 0.940\n",
            "0-227th: train loss: 1.49750, train acc: 0.991 valid loss: 1.55459 valid acc: 0.940\n",
            "0-228th: train loss: 1.49739, train acc: 0.991 valid loss: 1.55451 valid acc: 0.940\n",
            "0-229th: train loss: 1.49728, train acc: 0.991 valid loss: 1.55444 valid acc: 0.940\n",
            "0-230th: train loss: 1.49718, train acc: 0.991 valid loss: 1.55436 valid acc: 0.940\n",
            "0-231th: train loss: 1.49707, train acc: 0.991 valid loss: 1.55429 valid acc: 0.940\n",
            "0-232th: train loss: 1.49696, train acc: 0.992 valid loss: 1.55422 valid acc: 0.937\n",
            "0-233th: train loss: 1.49686, train acc: 0.992 valid loss: 1.55415 valid acc: 0.937\n",
            "0-234th: train loss: 1.49675, train acc: 0.992 valid loss: 1.55408 valid acc: 0.937\n",
            "0-235th: train loss: 1.49665, train acc: 0.992 valid loss: 1.55401 valid acc: 0.937\n",
            "0-236th: train loss: 1.49655, train acc: 0.992 valid loss: 1.55394 valid acc: 0.937\n",
            "0-237th: train loss: 1.49644, train acc: 0.992 valid loss: 1.55387 valid acc: 0.937\n",
            "0-238th: train loss: 1.49634, train acc: 0.992 valid loss: 1.55380 valid acc: 0.937\n",
            "0-239th: train loss: 1.49624, train acc: 0.992 valid loss: 1.55373 valid acc: 0.937\n",
            "0-240th: train loss: 1.49614, train acc: 0.992 valid loss: 1.55366 valid acc: 0.937\n",
            "0-241th: train loss: 1.49605, train acc: 0.992 valid loss: 1.55359 valid acc: 0.937\n",
            "0-242th: train loss: 1.49595, train acc: 0.992 valid loss: 1.55352 valid acc: 0.937\n",
            "0-243th: train loss: 1.49585, train acc: 0.992 valid loss: 1.55344 valid acc: 0.937\n",
            "0-244th: train loss: 1.49576, train acc: 0.992 valid loss: 1.55337 valid acc: 0.937\n",
            "0-245th: train loss: 1.49566, train acc: 0.992 valid loss: 1.55329 valid acc: 0.937\n",
            "0-246th: train loss: 1.49557, train acc: 0.992 valid loss: 1.55321 valid acc: 0.937\n",
            "0-247th: train loss: 1.49548, train acc: 0.992 valid loss: 1.55313 valid acc: 0.937\n",
            "0-248th: train loss: 1.49539, train acc: 0.992 valid loss: 1.55305 valid acc: 0.937\n",
            "0-249th: train loss: 1.49530, train acc: 0.992 valid loss: 1.55297 valid acc: 0.937\n",
            "0-250th: train loss: 1.49521, train acc: 0.992 valid loss: 1.55288 valid acc: 0.937\n",
            "0-251th: train loss: 1.49512, train acc: 0.992 valid loss: 1.55279 valid acc: 0.937\n",
            "0-252th: train loss: 1.49504, train acc: 0.992 valid loss: 1.55270 valid acc: 0.937\n",
            "0-253th: train loss: 1.49495, train acc: 0.992 valid loss: 1.55261 valid acc: 0.937\n",
            "0-254th: train loss: 1.49487, train acc: 0.992 valid loss: 1.55252 valid acc: 0.937\n",
            "0-255th: train loss: 1.49478, train acc: 0.992 valid loss: 1.55242 valid acc: 0.937\n",
            "0-256th: train loss: 1.49470, train acc: 0.992 valid loss: 1.55233 valid acc: 0.937\n",
            "0-257th: train loss: 1.49462, train acc: 0.992 valid loss: 1.55223 valid acc: 0.937\n",
            "0-258th: train loss: 1.49454, train acc: 0.992 valid loss: 1.55214 valid acc: 0.937\n",
            "0-259th: train loss: 1.49446, train acc: 0.992 valid loss: 1.55204 valid acc: 0.940\n",
            "0-260th: train loss: 1.49438, train acc: 0.992 valid loss: 1.55194 valid acc: 0.940\n",
            "0-261th: train loss: 1.49430, train acc: 0.992 valid loss: 1.55185 valid acc: 0.940\n",
            "0-262th: train loss: 1.49423, train acc: 0.992 valid loss: 1.55175 valid acc: 0.940\n",
            "0-263th: train loss: 1.49415, train acc: 0.992 valid loss: 1.55165 valid acc: 0.940\n",
            "0-264th: train loss: 1.49407, train acc: 0.992 valid loss: 1.55156 valid acc: 0.940\n",
            "0-265th: train loss: 1.49400, train acc: 0.992 valid loss: 1.55146 valid acc: 0.940\n",
            "0-266th: train loss: 1.49392, train acc: 0.992 valid loss: 1.55137 valid acc: 0.940\n",
            "0-267th: train loss: 1.49385, train acc: 0.992 valid loss: 1.55128 valid acc: 0.940\n",
            "0-268th: train loss: 1.49378, train acc: 0.992 valid loss: 1.55118 valid acc: 0.940\n",
            "0-269th: train loss: 1.49371, train acc: 0.992 valid loss: 1.55109 valid acc: 0.940\n",
            "0-270th: train loss: 1.49364, train acc: 0.992 valid loss: 1.55100 valid acc: 0.940\n",
            "0-271th: train loss: 1.49356, train acc: 0.992 valid loss: 1.55091 valid acc: 0.944\n",
            "0-272th: train loss: 1.49350, train acc: 0.992 valid loss: 1.55083 valid acc: 0.944\n",
            "0-273th: train loss: 1.49343, train acc: 0.992 valid loss: 1.55074 valid acc: 0.944\n",
            "0-274th: train loss: 1.49336, train acc: 0.992 valid loss: 1.55065 valid acc: 0.944\n",
            "0-275th: train loss: 1.49329, train acc: 0.992 valid loss: 1.55057 valid acc: 0.944\n",
            "0-276th: train loss: 1.49322, train acc: 0.992 valid loss: 1.55048 valid acc: 0.944\n",
            "0-277th: train loss: 1.49316, train acc: 0.992 valid loss: 1.55040 valid acc: 0.944\n",
            "0-278th: train loss: 1.49309, train acc: 0.992 valid loss: 1.55032 valid acc: 0.944\n",
            "0-279th: train loss: 1.49302, train acc: 0.992 valid loss: 1.55024 valid acc: 0.944\n",
            "0-280th: train loss: 1.49296, train acc: 0.992 valid loss: 1.55016 valid acc: 0.944\n",
            "0-281th: train loss: 1.49289, train acc: 0.992 valid loss: 1.55008 valid acc: 0.944\n",
            "0-282th: train loss: 1.49283, train acc: 0.992 valid loss: 1.55000 valid acc: 0.944\n",
            "0-283th: train loss: 1.49277, train acc: 0.992 valid loss: 1.54992 valid acc: 0.944\n",
            "0-284th: train loss: 1.49271, train acc: 0.992 valid loss: 1.54984 valid acc: 0.944\n",
            "0-285th: train loss: 1.49264, train acc: 0.992 valid loss: 1.54976 valid acc: 0.944\n",
            "0-286th: train loss: 1.49258, train acc: 0.992 valid loss: 1.54968 valid acc: 0.944\n",
            "0-287th: train loss: 1.49252, train acc: 0.992 valid loss: 1.54961 valid acc: 0.944\n",
            "0-288th: train loss: 1.49246, train acc: 0.992 valid loss: 1.54953 valid acc: 0.944\n",
            "0-289th: train loss: 1.49240, train acc: 0.992 valid loss: 1.54945 valid acc: 0.944\n",
            "0-290th: train loss: 1.49234, train acc: 0.992 valid loss: 1.54938 valid acc: 0.944\n",
            "0-291th: train loss: 1.49228, train acc: 0.992 valid loss: 1.54930 valid acc: 0.944\n",
            "0-292th: train loss: 1.49222, train acc: 0.992 valid loss: 1.54922 valid acc: 0.944\n",
            "0-293th: train loss: 1.49216, train acc: 0.992 valid loss: 1.54915 valid acc: 0.944\n",
            "0-294th: train loss: 1.49210, train acc: 0.992 valid loss: 1.54907 valid acc: 0.944\n",
            "0-295th: train loss: 1.49205, train acc: 0.992 valid loss: 1.54900 valid acc: 0.944\n",
            "0-296th: train loss: 1.49199, train acc: 0.992 valid loss: 1.54892 valid acc: 0.944\n",
            "0-297th: train loss: 1.49193, train acc: 0.992 valid loss: 1.54885 valid acc: 0.944\n",
            "0-298th: train loss: 1.49188, train acc: 0.992 valid loss: 1.54878 valid acc: 0.944\n",
            "0-299th: train loss: 1.49182, train acc: 0.992 valid loss: 1.54870 valid acc: 0.944\n",
            "1-0th: train loss: 2.33431, train acc: 0.077 valid loss: 2.29554 valid acc: 0.129\n",
            "1-1th: train loss: 2.28781, train acc: 0.150 valid loss: 2.19649 valid acc: 0.276\n",
            "1-2th: train loss: 2.20202, train acc: 0.269 valid loss: 2.15228 valid acc: 0.320\n",
            "1-3th: train loss: 2.15842, train acc: 0.312 valid loss: 2.09498 valid acc: 0.395\n",
            "1-4th: train loss: 2.10502, train acc: 0.373 valid loss: 2.05559 valid acc: 0.436\n",
            "1-5th: train loss: 2.06108, train acc: 0.417 valid loss: 2.03929 valid acc: 0.445\n",
            "1-6th: train loss: 2.03688, train acc: 0.439 valid loss: 2.02019 valid acc: 0.480\n",
            "1-7th: train loss: 2.01570, train acc: 0.467 valid loss: 1.99828 valid acc: 0.483\n",
            "1-8th: train loss: 1.99225, train acc: 0.492 valid loss: 1.98825 valid acc: 0.508\n",
            "1-9th: train loss: 1.98037, train acc: 0.511 valid loss: 1.97856 valid acc: 0.517\n",
            "1-10th: train loss: 1.96985, train acc: 0.520 valid loss: 1.96637 valid acc: 0.520\n",
            "1-11th: train loss: 1.95777, train acc: 0.525 valid loss: 1.95611 valid acc: 0.536\n",
            "1-12th: train loss: 1.94714, train acc: 0.534 valid loss: 1.94870 valid acc: 0.539\n",
            "1-13th: train loss: 1.93955, train acc: 0.542 valid loss: 1.94117 valid acc: 0.542\n",
            "1-14th: train loss: 1.93196, train acc: 0.551 valid loss: 1.93580 valid acc: 0.552\n",
            "1-15th: train loss: 1.92547, train acc: 0.557 valid loss: 1.93224 valid acc: 0.564\n",
            "1-16th: train loss: 1.91829, train acc: 0.568 valid loss: 1.92944 valid acc: 0.552\n",
            "1-17th: train loss: 1.91000, train acc: 0.578 valid loss: 1.92615 valid acc: 0.561\n",
            "1-18th: train loss: 1.90239, train acc: 0.588 valid loss: 1.91981 valid acc: 0.561\n",
            "1-19th: train loss: 1.89436, train acc: 0.590 valid loss: 1.91028 valid acc: 0.580\n",
            "1-20th: train loss: 1.88443, train acc: 0.601 valid loss: 1.89963 valid acc: 0.586\n",
            "1-21th: train loss: 1.87305, train acc: 0.617 valid loss: 1.89088 valid acc: 0.592\n",
            "1-22th: train loss: 1.86304, train acc: 0.625 valid loss: 1.88489 valid acc: 0.605\n",
            "1-23th: train loss: 1.85584, train acc: 0.631 valid loss: 1.87883 valid acc: 0.611\n",
            "1-24th: train loss: 1.84883, train acc: 0.637 valid loss: 1.87216 valid acc: 0.618\n",
            "1-25th: train loss: 1.84163, train acc: 0.645 valid loss: 1.86727 valid acc: 0.624\n",
            "1-26th: train loss: 1.83665, train acc: 0.649 valid loss: 1.86433 valid acc: 0.627\n",
            "1-27th: train loss: 1.83353, train acc: 0.652 valid loss: 1.86135 valid acc: 0.627\n",
            "1-28th: train loss: 1.83034, train acc: 0.655 valid loss: 1.85821 valid acc: 0.633\n",
            "1-29th: train loss: 1.82736, train acc: 0.660 valid loss: 1.85550 valid acc: 0.639\n",
            "1-30th: train loss: 1.82521, train acc: 0.665 valid loss: 1.85316 valid acc: 0.643\n",
            "1-31th: train loss: 1.82311, train acc: 0.666 valid loss: 1.85084 valid acc: 0.646\n",
            "1-32th: train loss: 1.82013, train acc: 0.667 valid loss: 1.84848 valid acc: 0.649\n",
            "1-33th: train loss: 1.81633, train acc: 0.668 valid loss: 1.84545 valid acc: 0.652\n",
            "1-34th: train loss: 1.81114, train acc: 0.677 valid loss: 1.83979 valid acc: 0.646\n",
            "1-35th: train loss: 1.80234, train acc: 0.687 valid loss: 1.82984 valid acc: 0.668\n",
            "1-36th: train loss: 1.78991, train acc: 0.709 valid loss: 1.82177 valid acc: 0.683\n",
            "1-37th: train loss: 1.78114, train acc: 0.724 valid loss: 1.80861 valid acc: 0.702\n",
            "1-38th: train loss: 1.76477, train acc: 0.740 valid loss: 1.79948 valid acc: 0.702\n",
            "1-39th: train loss: 1.75120, train acc: 0.752 valid loss: 1.79533 valid acc: 0.702\n",
            "1-40th: train loss: 1.74514, train acc: 0.754 valid loss: 1.78783 valid acc: 0.705\n",
            "1-41th: train loss: 1.73899, train acc: 0.759 valid loss: 1.78240 valid acc: 0.721\n",
            "1-42th: train loss: 1.73616, train acc: 0.764 valid loss: 1.78059 valid acc: 0.724\n",
            "1-43th: train loss: 1.73574, train acc: 0.765 valid loss: 1.77979 valid acc: 0.721\n",
            "1-44th: train loss: 1.73473, train acc: 0.766 valid loss: 1.77934 valid acc: 0.708\n",
            "1-45th: train loss: 1.73332, train acc: 0.766 valid loss: 1.77811 valid acc: 0.712\n",
            "1-46th: train loss: 1.73156, train acc: 0.765 valid loss: 1.77597 valid acc: 0.721\n",
            "1-47th: train loss: 1.72979, train acc: 0.766 valid loss: 1.77299 valid acc: 0.724\n",
            "1-48th: train loss: 1.72766, train acc: 0.766 valid loss: 1.76901 valid acc: 0.727\n",
            "1-49th: train loss: 1.72466, train acc: 0.769 valid loss: 1.76522 valid acc: 0.734\n",
            "1-50th: train loss: 1.72184, train acc: 0.772 valid loss: 1.76226 valid acc: 0.743\n",
            "1-51th: train loss: 1.71962, train acc: 0.774 valid loss: 1.75968 valid acc: 0.737\n",
            "1-52th: train loss: 1.71756, train acc: 0.773 valid loss: 1.75742 valid acc: 0.740\n",
            "1-53th: train loss: 1.71561, train acc: 0.776 valid loss: 1.75540 valid acc: 0.740\n",
            "1-54th: train loss: 1.71382, train acc: 0.775 valid loss: 1.75360 valid acc: 0.743\n",
            "1-55th: train loss: 1.71239, train acc: 0.776 valid loss: 1.75183 valid acc: 0.749\n",
            "1-56th: train loss: 1.71127, train acc: 0.778 valid loss: 1.74986 valid acc: 0.752\n",
            "1-57th: train loss: 1.71003, train acc: 0.779 valid loss: 1.74808 valid acc: 0.752\n",
            "1-58th: train loss: 1.70868, train acc: 0.778 valid loss: 1.74714 valid acc: 0.752\n",
            "1-59th: train loss: 1.70752, train acc: 0.779 valid loss: 1.74684 valid acc: 0.743\n",
            "1-60th: train loss: 1.70650, train acc: 0.779 valid loss: 1.74644 valid acc: 0.746\n",
            "1-61th: train loss: 1.70539, train acc: 0.779 valid loss: 1.74555 valid acc: 0.752\n",
            "1-62th: train loss: 1.70426, train acc: 0.779 valid loss: 1.74435 valid acc: 0.755\n",
            "1-63th: train loss: 1.70325, train acc: 0.779 valid loss: 1.74336 valid acc: 0.755\n",
            "1-64th: train loss: 1.70243, train acc: 0.780 valid loss: 1.74277 valid acc: 0.752\n",
            "1-65th: train loss: 1.70164, train acc: 0.782 valid loss: 1.74256 valid acc: 0.752\n",
            "1-66th: train loss: 1.70075, train acc: 0.782 valid loss: 1.74267 valid acc: 0.749\n",
            "1-67th: train loss: 1.69995, train acc: 0.784 valid loss: 1.74274 valid acc: 0.749\n",
            "1-68th: train loss: 1.69931, train acc: 0.784 valid loss: 1.74232 valid acc: 0.752\n",
            "1-69th: train loss: 1.69858, train acc: 0.784 valid loss: 1.74156 valid acc: 0.752\n",
            "1-70th: train loss: 1.69777, train acc: 0.785 valid loss: 1.74100 valid acc: 0.749\n",
            "1-71th: train loss: 1.69705, train acc: 0.785 valid loss: 1.74081 valid acc: 0.749\n",
            "1-72th: train loss: 1.69638, train acc: 0.786 valid loss: 1.74078 valid acc: 0.752\n",
            "1-73th: train loss: 1.69572, train acc: 0.786 valid loss: 1.74062 valid acc: 0.752\n",
            "1-74th: train loss: 1.69503, train acc: 0.787 valid loss: 1.74022 valid acc: 0.752\n",
            "1-75th: train loss: 1.69437, train acc: 0.787 valid loss: 1.73970 valid acc: 0.752\n",
            "1-76th: train loss: 1.69378, train acc: 0.788 valid loss: 1.73912 valid acc: 0.752\n",
            "1-77th: train loss: 1.69315, train acc: 0.789 valid loss: 1.73854 valid acc: 0.755\n",
            "1-78th: train loss: 1.69243, train acc: 0.790 valid loss: 1.73800 valid acc: 0.755\n",
            "1-79th: train loss: 1.69162, train acc: 0.792 valid loss: 1.73733 valid acc: 0.755\n",
            "1-80th: train loss: 1.69058, train acc: 0.793 valid loss: 1.73630 valid acc: 0.755\n",
            "1-81th: train loss: 1.68893, train acc: 0.794 valid loss: 1.73437 valid acc: 0.759\n",
            "1-82th: train loss: 1.68558, train acc: 0.797 valid loss: 1.72949 valid acc: 0.768\n",
            "1-83th: train loss: 1.67731, train acc: 0.812 valid loss: 1.71840 valid acc: 0.790\n",
            "1-84th: train loss: 1.66463, train acc: 0.833 valid loss: 1.71757 valid acc: 0.793\n",
            "1-85th: train loss: 1.66861, train acc: 0.840 valid loss: 1.70458 valid acc: 0.796\n",
            "1-86th: train loss: 1.65440, train acc: 0.852 valid loss: 1.69879 valid acc: 0.803\n",
            "1-87th: train loss: 1.64873, train acc: 0.846 valid loss: 1.69280 valid acc: 0.815\n",
            "1-88th: train loss: 1.64460, train acc: 0.847 valid loss: 1.68308 valid acc: 0.812\n",
            "1-89th: train loss: 1.63862, train acc: 0.856 valid loss: 1.67861 valid acc: 0.815\n",
            "1-90th: train loss: 1.63554, train acc: 0.865 valid loss: 1.67800 valid acc: 0.824\n",
            "1-91th: train loss: 1.63385, train acc: 0.870 valid loss: 1.67624 valid acc: 0.821\n",
            "1-92th: train loss: 1.63133, train acc: 0.867 valid loss: 1.67547 valid acc: 0.831\n",
            "1-93th: train loss: 1.63002, train acc: 0.868 valid loss: 1.67362 valid acc: 0.831\n",
            "1-94th: train loss: 1.62735, train acc: 0.871 valid loss: 1.67065 valid acc: 0.831\n",
            "1-95th: train loss: 1.62462, train acc: 0.872 valid loss: 1.66748 valid acc: 0.828\n",
            "1-96th: train loss: 1.62255, train acc: 0.872 valid loss: 1.66137 valid acc: 0.840\n",
            "1-97th: train loss: 1.61725, train acc: 0.885 valid loss: 1.65441 valid acc: 0.862\n",
            "1-98th: train loss: 1.60939, train acc: 0.900 valid loss: 1.65485 valid acc: 0.862\n",
            "1-99th: train loss: 1.60408, train acc: 0.911 valid loss: 1.64905 valid acc: 0.881\n",
            "1-100th: train loss: 1.59464, train acc: 0.922 valid loss: 1.63685 valid acc: 0.884\n",
            "1-101th: train loss: 1.58307, train acc: 0.930 valid loss: 1.62823 valid acc: 0.890\n",
            "1-102th: train loss: 1.57451, train acc: 0.936 valid loss: 1.62270 valid acc: 0.881\n",
            "1-103th: train loss: 1.56785, train acc: 0.941 valid loss: 1.62293 valid acc: 0.884\n",
            "1-104th: train loss: 1.56578, train acc: 0.943 valid loss: 1.62406 valid acc: 0.884\n",
            "1-105th: train loss: 1.56426, train acc: 0.944 valid loss: 1.62292 valid acc: 0.884\n",
            "1-106th: train loss: 1.56159, train acc: 0.948 valid loss: 1.62224 valid acc: 0.890\n",
            "1-107th: train loss: 1.56039, train acc: 0.949 valid loss: 1.62124 valid acc: 0.884\n",
            "1-108th: train loss: 1.55940, train acc: 0.951 valid loss: 1.61805 valid acc: 0.903\n",
            "1-109th: train loss: 1.55672, train acc: 0.954 valid loss: 1.61540 valid acc: 0.897\n",
            "1-110th: train loss: 1.55429, train acc: 0.953 valid loss: 1.61390 valid acc: 0.890\n",
            "1-111th: train loss: 1.55221, train acc: 0.955 valid loss: 1.61200 valid acc: 0.890\n",
            "1-112th: train loss: 1.54956, train acc: 0.958 valid loss: 1.61001 valid acc: 0.897\n",
            "1-113th: train loss: 1.54722, train acc: 0.962 valid loss: 1.60746 valid acc: 0.903\n",
            "1-114th: train loss: 1.54510, train acc: 0.965 valid loss: 1.60408 valid acc: 0.912\n",
            "1-115th: train loss: 1.54292, train acc: 0.965 valid loss: 1.60131 valid acc: 0.915\n",
            "1-116th: train loss: 1.54139, train acc: 0.967 valid loss: 1.59947 valid acc: 0.918\n",
            "1-117th: train loss: 1.53992, train acc: 0.969 valid loss: 1.59812 valid acc: 0.918\n",
            "1-118th: train loss: 1.53809, train acc: 0.973 valid loss: 1.59729 valid acc: 0.922\n",
            "1-119th: train loss: 1.53688, train acc: 0.975 valid loss: 1.59566 valid acc: 0.922\n",
            "1-120th: train loss: 1.53560, train acc: 0.976 valid loss: 1.59321 valid acc: 0.922\n",
            "1-121th: train loss: 1.53396, train acc: 0.976 valid loss: 1.59130 valid acc: 0.918\n",
            "1-122th: train loss: 1.53266, train acc: 0.976 valid loss: 1.59030 valid acc: 0.925\n",
            "1-123th: train loss: 1.53143, train acc: 0.977 valid loss: 1.58995 valid acc: 0.918\n",
            "1-124th: train loss: 1.53030, train acc: 0.977 valid loss: 1.58939 valid acc: 0.918\n",
            "1-125th: train loss: 1.52914, train acc: 0.977 valid loss: 1.58862 valid acc: 0.912\n",
            "1-126th: train loss: 1.52829, train acc: 0.978 valid loss: 1.58769 valid acc: 0.918\n",
            "1-127th: train loss: 1.52753, train acc: 0.978 valid loss: 1.58667 valid acc: 0.915\n",
            "1-128th: train loss: 1.52664, train acc: 0.980 valid loss: 1.58592 valid acc: 0.922\n",
            "1-129th: train loss: 1.52593, train acc: 0.980 valid loss: 1.58529 valid acc: 0.922\n",
            "1-130th: train loss: 1.52522, train acc: 0.980 valid loss: 1.58481 valid acc: 0.928\n",
            "1-131th: train loss: 1.52445, train acc: 0.980 valid loss: 1.58462 valid acc: 0.928\n",
            "1-132th: train loss: 1.52374, train acc: 0.980 valid loss: 1.58448 valid acc: 0.925\n",
            "1-133th: train loss: 1.52308, train acc: 0.980 valid loss: 1.58397 valid acc: 0.928\n",
            "1-134th: train loss: 1.52242, train acc: 0.980 valid loss: 1.58304 valid acc: 0.928\n",
            "1-135th: train loss: 1.52178, train acc: 0.981 valid loss: 1.58209 valid acc: 0.928\n",
            "1-136th: train loss: 1.52120, train acc: 0.981 valid loss: 1.58149 valid acc: 0.931\n",
            "1-137th: train loss: 1.52064, train acc: 0.982 valid loss: 1.58135 valid acc: 0.931\n",
            "1-138th: train loss: 1.52012, train acc: 0.981 valid loss: 1.58133 valid acc: 0.931\n",
            "1-139th: train loss: 1.51961, train acc: 0.982 valid loss: 1.58112 valid acc: 0.928\n",
            "1-140th: train loss: 1.51912, train acc: 0.982 valid loss: 1.58072 valid acc: 0.928\n",
            "1-141th: train loss: 1.51870, train acc: 0.982 valid loss: 1.58024 valid acc: 0.928\n",
            "1-142th: train loss: 1.51827, train acc: 0.982 valid loss: 1.57978 valid acc: 0.931\n",
            "1-143th: train loss: 1.51781, train acc: 0.982 valid loss: 1.57935 valid acc: 0.931\n",
            "1-144th: train loss: 1.51740, train acc: 0.982 valid loss: 1.57885 valid acc: 0.934\n",
            "1-145th: train loss: 1.51700, train acc: 0.982 valid loss: 1.57832 valid acc: 0.931\n",
            "1-146th: train loss: 1.51659, train acc: 0.982 valid loss: 1.57790 valid acc: 0.931\n",
            "1-147th: train loss: 1.51617, train acc: 0.982 valid loss: 1.57767 valid acc: 0.931\n",
            "1-148th: train loss: 1.51579, train acc: 0.982 valid loss: 1.57744 valid acc: 0.934\n",
            "1-149th: train loss: 1.51542, train acc: 0.982 valid loss: 1.57708 valid acc: 0.934\n",
            "1-150th: train loss: 1.51504, train acc: 0.982 valid loss: 1.57663 valid acc: 0.934\n",
            "1-151th: train loss: 1.51468, train acc: 0.982 valid loss: 1.57621 valid acc: 0.934\n",
            "1-152th: train loss: 1.51434, train acc: 0.983 valid loss: 1.57590 valid acc: 0.934\n",
            "1-153th: train loss: 1.51399, train acc: 0.983 valid loss: 1.57568 valid acc: 0.934\n",
            "1-154th: train loss: 1.51366, train acc: 0.983 valid loss: 1.57550 valid acc: 0.934\n",
            "1-155th: train loss: 1.51333, train acc: 0.983 valid loss: 1.57534 valid acc: 0.934\n",
            "1-156th: train loss: 1.51302, train acc: 0.983 valid loss: 1.57521 valid acc: 0.934\n",
            "1-157th: train loss: 1.51271, train acc: 0.983 valid loss: 1.57507 valid acc: 0.934\n",
            "1-158th: train loss: 1.51240, train acc: 0.984 valid loss: 1.57487 valid acc: 0.934\n",
            "1-159th: train loss: 1.51210, train acc: 0.984 valid loss: 1.57460 valid acc: 0.934\n",
            "1-160th: train loss: 1.51180, train acc: 0.986 valid loss: 1.57435 valid acc: 0.934\n",
            "1-161th: train loss: 1.51151, train acc: 0.985 valid loss: 1.57420 valid acc: 0.934\n",
            "1-162th: train loss: 1.51123, train acc: 0.985 valid loss: 1.57411 valid acc: 0.937\n",
            "1-163th: train loss: 1.51095, train acc: 0.987 valid loss: 1.57397 valid acc: 0.934\n",
            "1-164th: train loss: 1.51067, train acc: 0.987 valid loss: 1.57372 valid acc: 0.937\n",
            "1-165th: train loss: 1.51040, train acc: 0.987 valid loss: 1.57339 valid acc: 0.937\n",
            "1-166th: train loss: 1.51014, train acc: 0.987 valid loss: 1.57309 valid acc: 0.937\n",
            "1-167th: train loss: 1.50988, train acc: 0.987 valid loss: 1.57288 valid acc: 0.937\n",
            "1-168th: train loss: 1.50962, train acc: 0.987 valid loss: 1.57273 valid acc: 0.937\n",
            "1-169th: train loss: 1.50937, train acc: 0.987 valid loss: 1.57257 valid acc: 0.940\n",
            "1-170th: train loss: 1.50912, train acc: 0.987 valid loss: 1.57237 valid acc: 0.940\n",
            "1-171th: train loss: 1.50888, train acc: 0.987 valid loss: 1.57215 valid acc: 0.940\n",
            "1-172th: train loss: 1.50864, train acc: 0.987 valid loss: 1.57193 valid acc: 0.940\n",
            "1-173th: train loss: 1.50840, train acc: 0.987 valid loss: 1.57171 valid acc: 0.940\n",
            "1-174th: train loss: 1.50817, train acc: 0.987 valid loss: 1.57150 valid acc: 0.940\n",
            "1-175th: train loss: 1.50794, train acc: 0.987 valid loss: 1.57131 valid acc: 0.940\n",
            "1-176th: train loss: 1.50772, train acc: 0.987 valid loss: 1.57116 valid acc: 0.940\n",
            "1-177th: train loss: 1.50750, train acc: 0.987 valid loss: 1.57102 valid acc: 0.940\n",
            "1-178th: train loss: 1.50728, train acc: 0.987 valid loss: 1.57086 valid acc: 0.940\n",
            "1-179th: train loss: 1.50707, train acc: 0.987 valid loss: 1.57066 valid acc: 0.940\n",
            "1-180th: train loss: 1.50686, train acc: 0.988 valid loss: 1.57045 valid acc: 0.940\n",
            "1-181th: train loss: 1.50665, train acc: 0.988 valid loss: 1.57025 valid acc: 0.940\n",
            "1-182th: train loss: 1.50645, train acc: 0.988 valid loss: 1.57008 valid acc: 0.940\n",
            "1-183th: train loss: 1.50624, train acc: 0.988 valid loss: 1.56990 valid acc: 0.940\n",
            "1-184th: train loss: 1.50605, train acc: 0.988 valid loss: 1.56971 valid acc: 0.940\n",
            "1-185th: train loss: 1.50585, train acc: 0.988 valid loss: 1.56950 valid acc: 0.940\n",
            "1-186th: train loss: 1.50566, train acc: 0.988 valid loss: 1.56931 valid acc: 0.940\n",
            "1-187th: train loss: 1.50547, train acc: 0.988 valid loss: 1.56914 valid acc: 0.940\n",
            "1-188th: train loss: 1.50528, train acc: 0.988 valid loss: 1.56897 valid acc: 0.940\n",
            "1-189th: train loss: 1.50509, train acc: 0.989 valid loss: 1.56879 valid acc: 0.940\n",
            "1-190th: train loss: 1.50491, train acc: 0.989 valid loss: 1.56860 valid acc: 0.940\n",
            "1-191th: train loss: 1.50473, train acc: 0.989 valid loss: 1.56842 valid acc: 0.940\n",
            "1-192th: train loss: 1.50455, train acc: 0.989 valid loss: 1.56825 valid acc: 0.940\n",
            "1-193th: train loss: 1.50437, train acc: 0.990 valid loss: 1.56808 valid acc: 0.940\n",
            "1-194th: train loss: 1.50420, train acc: 0.990 valid loss: 1.56790 valid acc: 0.940\n",
            "1-195th: train loss: 1.50402, train acc: 0.990 valid loss: 1.56772 valid acc: 0.940\n",
            "1-196th: train loss: 1.50385, train acc: 0.990 valid loss: 1.56756 valid acc: 0.940\n",
            "1-197th: train loss: 1.50368, train acc: 0.990 valid loss: 1.56742 valid acc: 0.940\n",
            "1-198th: train loss: 1.50351, train acc: 0.990 valid loss: 1.56727 valid acc: 0.940\n",
            "1-199th: train loss: 1.50335, train acc: 0.990 valid loss: 1.56712 valid acc: 0.940\n",
            "1-200th: train loss: 1.50318, train acc: 0.990 valid loss: 1.56696 valid acc: 0.940\n",
            "1-201th: train loss: 1.50302, train acc: 0.990 valid loss: 1.56681 valid acc: 0.940\n",
            "1-202th: train loss: 1.50286, train acc: 0.990 valid loss: 1.56667 valid acc: 0.940\n",
            "1-203th: train loss: 1.50270, train acc: 0.990 valid loss: 1.56654 valid acc: 0.940\n",
            "1-204th: train loss: 1.50254, train acc: 0.991 valid loss: 1.56639 valid acc: 0.940\n",
            "1-205th: train loss: 1.50239, train acc: 0.991 valid loss: 1.56626 valid acc: 0.940\n",
            "1-206th: train loss: 1.50223, train acc: 0.991 valid loss: 1.56613 valid acc: 0.940\n",
            "1-207th: train loss: 1.50208, train acc: 0.991 valid loss: 1.56602 valid acc: 0.940\n",
            "1-208th: train loss: 1.50193, train acc: 0.991 valid loss: 1.56591 valid acc: 0.940\n",
            "1-209th: train loss: 1.50178, train acc: 0.991 valid loss: 1.56578 valid acc: 0.940\n",
            "1-210th: train loss: 1.50163, train acc: 0.991 valid loss: 1.56566 valid acc: 0.940\n",
            "1-211th: train loss: 1.50148, train acc: 0.991 valid loss: 1.56555 valid acc: 0.940\n",
            "1-212th: train loss: 1.50134, train acc: 0.991 valid loss: 1.56544 valid acc: 0.937\n",
            "1-213th: train loss: 1.50119, train acc: 0.991 valid loss: 1.56534 valid acc: 0.937\n",
            "1-214th: train loss: 1.50105, train acc: 0.991 valid loss: 1.56524 valid acc: 0.937\n",
            "1-215th: train loss: 1.50091, train acc: 0.991 valid loss: 1.56514 valid acc: 0.937\n",
            "1-216th: train loss: 1.50077, train acc: 0.991 valid loss: 1.56505 valid acc: 0.937\n",
            "1-217th: train loss: 1.50063, train acc: 0.991 valid loss: 1.56496 valid acc: 0.937\n",
            "1-218th: train loss: 1.50050, train acc: 0.992 valid loss: 1.56487 valid acc: 0.937\n",
            "1-219th: train loss: 1.50036, train acc: 0.992 valid loss: 1.56477 valid acc: 0.937\n",
            "1-220th: train loss: 1.50023, train acc: 0.992 valid loss: 1.56469 valid acc: 0.937\n",
            "1-221th: train loss: 1.50010, train acc: 0.993 valid loss: 1.56461 valid acc: 0.937\n",
            "1-222th: train loss: 1.49997, train acc: 0.993 valid loss: 1.56453 valid acc: 0.937\n",
            "1-223th: train loss: 1.49984, train acc: 0.993 valid loss: 1.56445 valid acc: 0.937\n",
            "1-224th: train loss: 1.49971, train acc: 0.993 valid loss: 1.56436 valid acc: 0.937\n",
            "1-225th: train loss: 1.49958, train acc: 0.993 valid loss: 1.56428 valid acc: 0.937\n",
            "1-226th: train loss: 1.49946, train acc: 0.993 valid loss: 1.56420 valid acc: 0.937\n",
            "1-227th: train loss: 1.49933, train acc: 0.993 valid loss: 1.56414 valid acc: 0.937\n",
            "1-228th: train loss: 1.49921, train acc: 0.993 valid loss: 1.56406 valid acc: 0.937\n",
            "1-229th: train loss: 1.49909, train acc: 0.993 valid loss: 1.56399 valid acc: 0.937\n",
            "1-230th: train loss: 1.49897, train acc: 0.993 valid loss: 1.56392 valid acc: 0.937\n",
            "1-231th: train loss: 1.49885, train acc: 0.993 valid loss: 1.56386 valid acc: 0.937\n",
            "1-232th: train loss: 1.49873, train acc: 0.993 valid loss: 1.56379 valid acc: 0.937\n",
            "1-233th: train loss: 1.49862, train acc: 0.993 valid loss: 1.56373 valid acc: 0.937\n",
            "1-234th: train loss: 1.49850, train acc: 0.993 valid loss: 1.56367 valid acc: 0.937\n",
            "1-235th: train loss: 1.49839, train acc: 0.993 valid loss: 1.56362 valid acc: 0.937\n",
            "1-236th: train loss: 1.49828, train acc: 0.993 valid loss: 1.56357 valid acc: 0.940\n",
            "1-237th: train loss: 1.49816, train acc: 0.993 valid loss: 1.56352 valid acc: 0.940\n",
            "1-238th: train loss: 1.49805, train acc: 0.993 valid loss: 1.56347 valid acc: 0.940\n",
            "1-239th: train loss: 1.49794, train acc: 0.993 valid loss: 1.56343 valid acc: 0.940\n",
            "1-240th: train loss: 1.49783, train acc: 0.993 valid loss: 1.56339 valid acc: 0.940\n",
            "1-241th: train loss: 1.49773, train acc: 0.993 valid loss: 1.56335 valid acc: 0.940\n",
            "1-242th: train loss: 1.49762, train acc: 0.993 valid loss: 1.56331 valid acc: 0.940\n",
            "1-243th: train loss: 1.49751, train acc: 0.993 valid loss: 1.56327 valid acc: 0.940\n",
            "1-244th: train loss: 1.49741, train acc: 0.993 valid loss: 1.56323 valid acc: 0.940\n",
            "1-245th: train loss: 1.49730, train acc: 0.993 valid loss: 1.56320 valid acc: 0.940\n",
            "1-246th: train loss: 1.49720, train acc: 0.993 valid loss: 1.56317 valid acc: 0.937\n",
            "1-247th: train loss: 1.49710, train acc: 0.993 valid loss: 1.56314 valid acc: 0.937\n",
            "1-248th: train loss: 1.49700, train acc: 0.993 valid loss: 1.56310 valid acc: 0.937\n",
            "1-249th: train loss: 1.49690, train acc: 0.993 valid loss: 1.56308 valid acc: 0.937\n",
            "1-250th: train loss: 1.49680, train acc: 0.993 valid loss: 1.56305 valid acc: 0.937\n",
            "1-251th: train loss: 1.49670, train acc: 0.993 valid loss: 1.56302 valid acc: 0.937\n",
            "1-252th: train loss: 1.49660, train acc: 0.993 valid loss: 1.56300 valid acc: 0.937\n",
            "1-253th: train loss: 1.49650, train acc: 0.993 valid loss: 1.56297 valid acc: 0.937\n",
            "1-254th: train loss: 1.49640, train acc: 0.993 valid loss: 1.56295 valid acc: 0.937\n",
            "1-255th: train loss: 1.49631, train acc: 0.993 valid loss: 1.56292 valid acc: 0.934\n",
            "1-256th: train loss: 1.49621, train acc: 0.993 valid loss: 1.56290 valid acc: 0.934\n",
            "1-257th: train loss: 1.49612, train acc: 0.993 valid loss: 1.56288 valid acc: 0.934\n",
            "1-258th: train loss: 1.49602, train acc: 0.993 valid loss: 1.56286 valid acc: 0.934\n",
            "1-259th: train loss: 1.49593, train acc: 0.993 valid loss: 1.56284 valid acc: 0.934\n",
            "1-260th: train loss: 1.49583, train acc: 0.993 valid loss: 1.56282 valid acc: 0.934\n",
            "1-261th: train loss: 1.49574, train acc: 0.993 valid loss: 1.56280 valid acc: 0.934\n",
            "1-262th: train loss: 1.49565, train acc: 0.993 valid loss: 1.56279 valid acc: 0.934\n",
            "1-263th: train loss: 1.49556, train acc: 0.993 valid loss: 1.56277 valid acc: 0.934\n",
            "1-264th: train loss: 1.49547, train acc: 0.993 valid loss: 1.56276 valid acc: 0.934\n",
            "1-265th: train loss: 1.49538, train acc: 0.993 valid loss: 1.56275 valid acc: 0.934\n",
            "1-266th: train loss: 1.49529, train acc: 0.993 valid loss: 1.56273 valid acc: 0.934\n",
            "1-267th: train loss: 1.49520, train acc: 0.993 valid loss: 1.56272 valid acc: 0.934\n",
            "1-268th: train loss: 1.49511, train acc: 0.994 valid loss: 1.56271 valid acc: 0.934\n",
            "1-269th: train loss: 1.49502, train acc: 0.994 valid loss: 1.56271 valid acc: 0.934\n",
            "1-270th: train loss: 1.49493, train acc: 0.994 valid loss: 1.56270 valid acc: 0.934\n",
            "1-271th: train loss: 1.49484, train acc: 0.994 valid loss: 1.56269 valid acc: 0.934\n",
            "1-272th: train loss: 1.49475, train acc: 0.994 valid loss: 1.56269 valid acc: 0.934\n",
            "1-273th: train loss: 1.49466, train acc: 0.994 valid loss: 1.56268 valid acc: 0.934\n",
            "1-274th: train loss: 1.49458, train acc: 0.994 valid loss: 1.56268 valid acc: 0.934\n",
            "1-275th: train loss: 1.49449, train acc: 0.994 valid loss: 1.56267 valid acc: 0.934\n",
            "1-276th: train loss: 1.49440, train acc: 0.994 valid loss: 1.56267 valid acc: 0.934\n",
            "1-277th: train loss: 1.49431, train acc: 0.994 valid loss: 1.56267 valid acc: 0.934\n",
            "1-278th: train loss: 1.49422, train acc: 0.994 valid loss: 1.56267 valid acc: 0.934\n",
            "1-279th: train loss: 1.49414, train acc: 0.994 valid loss: 1.56267 valid acc: 0.934\n",
            "1-280th: train loss: 1.49405, train acc: 0.994 valid loss: 1.56267 valid acc: 0.934\n",
            "1-281th: train loss: 1.49396, train acc: 0.994 valid loss: 1.56268 valid acc: 0.934\n",
            "1-282th: train loss: 1.49387, train acc: 0.994 valid loss: 1.56268 valid acc: 0.931\n",
            "1-283th: train loss: 1.49378, train acc: 0.994 valid loss: 1.56269 valid acc: 0.931\n",
            "1-284th: train loss: 1.49369, train acc: 0.994 valid loss: 1.56270 valid acc: 0.931\n",
            "1-285th: train loss: 1.49360, train acc: 0.994 valid loss: 1.56271 valid acc: 0.931\n",
            "1-286th: train loss: 1.49351, train acc: 0.994 valid loss: 1.56272 valid acc: 0.931\n",
            "1-287th: train loss: 1.49342, train acc: 0.995 valid loss: 1.56273 valid acc: 0.931\n",
            "1-288th: train loss: 1.49334, train acc: 0.995 valid loss: 1.56275 valid acc: 0.931\n",
            "1-289th: train loss: 1.49325, train acc: 0.995 valid loss: 1.56276 valid acc: 0.931\n",
            "1-290th: train loss: 1.49316, train acc: 0.995 valid loss: 1.56277 valid acc: 0.931\n",
            "1-291th: train loss: 1.49308, train acc: 0.995 valid loss: 1.56278 valid acc: 0.931\n",
            "1-292th: train loss: 1.49300, train acc: 0.995 valid loss: 1.56279 valid acc: 0.931\n",
            "1-293th: train loss: 1.49291, train acc: 0.995 valid loss: 1.56280 valid acc: 0.931\n",
            "1-294th: train loss: 1.49283, train acc: 0.995 valid loss: 1.56280 valid acc: 0.931\n",
            "1-295th: train loss: 1.49275, train acc: 0.995 valid loss: 1.56280 valid acc: 0.931\n",
            "1-296th: train loss: 1.49267, train acc: 0.995 valid loss: 1.56280 valid acc: 0.931\n",
            "1-297th: train loss: 1.49260, train acc: 0.995 valid loss: 1.56280 valid acc: 0.931\n",
            "1-298th: train loss: 1.49252, train acc: 0.995 valid loss: 1.56280 valid acc: 0.931\n",
            "1-299th: train loss: 1.49244, train acc: 0.995 valid loss: 1.56280 valid acc: 0.931\n",
            "2-0th: train loss: 2.33883, train acc: 0.073 valid loss: 2.24720 valid acc: 0.210\n",
            "2-1th: train loss: 2.24934, train acc: 0.202 valid loss: 2.17696 valid acc: 0.276\n",
            "2-2th: train loss: 2.18631, train acc: 0.268 valid loss: 2.12125 valid acc: 0.364\n",
            "2-3th: train loss: 2.12105, train acc: 0.352 valid loss: 2.07787 valid acc: 0.404\n",
            "2-4th: train loss: 2.07531, train acc: 0.397 valid loss: 2.04729 valid acc: 0.423\n",
            "2-5th: train loss: 2.04070, train acc: 0.437 valid loss: 2.02173 valid acc: 0.448\n",
            "2-6th: train loss: 2.01010, train acc: 0.458 valid loss: 2.00038 valid acc: 0.467\n",
            "2-7th: train loss: 1.98725, train acc: 0.481 valid loss: 1.98312 valid acc: 0.486\n",
            "2-8th: train loss: 1.97133, train acc: 0.497 valid loss: 1.97193 valid acc: 0.502\n",
            "2-9th: train loss: 1.95868, train acc: 0.506 valid loss: 1.96375 valid acc: 0.514\n",
            "2-10th: train loss: 1.94485, train acc: 0.526 valid loss: 1.95975 valid acc: 0.502\n",
            "2-11th: train loss: 1.93552, train acc: 0.532 valid loss: 1.95542 valid acc: 0.511\n",
            "2-12th: train loss: 1.92827, train acc: 0.549 valid loss: 1.94725 valid acc: 0.520\n",
            "2-13th: train loss: 1.92054, train acc: 0.552 valid loss: 1.93842 valid acc: 0.539\n",
            "2-14th: train loss: 1.91233, train acc: 0.568 valid loss: 1.92880 valid acc: 0.539\n",
            "2-15th: train loss: 1.90011, train acc: 0.585 valid loss: 1.91956 valid acc: 0.558\n",
            "2-16th: train loss: 1.89041, train acc: 0.607 valid loss: 1.91080 valid acc: 0.564\n",
            "2-17th: train loss: 1.88419, train acc: 0.619 valid loss: 1.89298 valid acc: 0.589\n",
            "2-18th: train loss: 1.86716, train acc: 0.630 valid loss: 1.87973 valid acc: 0.602\n",
            "2-19th: train loss: 1.85601, train acc: 0.637 valid loss: 1.86824 valid acc: 0.630\n",
            "2-20th: train loss: 1.84594, train acc: 0.643 valid loss: 1.85613 valid acc: 0.639\n",
            "2-21th: train loss: 1.83430, train acc: 0.659 valid loss: 1.84967 valid acc: 0.630\n",
            "2-22th: train loss: 1.82693, train acc: 0.665 valid loss: 1.84364 valid acc: 0.643\n",
            "2-23th: train loss: 1.82092, train acc: 0.668 valid loss: 1.83321 valid acc: 0.665\n",
            "2-24th: train loss: 1.81201, train acc: 0.672 valid loss: 1.82378 valid acc: 0.668\n",
            "2-25th: train loss: 1.80431, train acc: 0.688 valid loss: 1.81792 valid acc: 0.671\n",
            "2-26th: train loss: 1.79811, train acc: 0.702 valid loss: 1.81450 valid acc: 0.687\n",
            "2-27th: train loss: 1.79212, train acc: 0.713 valid loss: 1.80777 valid acc: 0.693\n",
            "2-28th: train loss: 1.78263, train acc: 0.721 valid loss: 1.80031 valid acc: 0.702\n",
            "2-29th: train loss: 1.77433, train acc: 0.728 valid loss: 1.79389 valid acc: 0.708\n",
            "2-30th: train loss: 1.76872, train acc: 0.729 valid loss: 1.78595 valid acc: 0.712\n",
            "2-31th: train loss: 1.76243, train acc: 0.737 valid loss: 1.77994 valid acc: 0.712\n",
            "2-32th: train loss: 1.75700, train acc: 0.743 valid loss: 1.77747 valid acc: 0.715\n",
            "2-33th: train loss: 1.75425, train acc: 0.746 valid loss: 1.77378 valid acc: 0.727\n",
            "2-34th: train loss: 1.75073, train acc: 0.745 valid loss: 1.76969 valid acc: 0.734\n",
            "2-35th: train loss: 1.74709, train acc: 0.746 valid loss: 1.76649 valid acc: 0.734\n",
            "2-36th: train loss: 1.74475, train acc: 0.743 valid loss: 1.76254 valid acc: 0.734\n",
            "2-37th: train loss: 1.74205, train acc: 0.747 valid loss: 1.75852 valid acc: 0.734\n",
            "2-38th: train loss: 1.73902, train acc: 0.751 valid loss: 1.75571 valid acc: 0.740\n",
            "2-39th: train loss: 1.73657, train acc: 0.753 valid loss: 1.75353 valid acc: 0.746\n",
            "2-40th: train loss: 1.73415, train acc: 0.755 valid loss: 1.75145 valid acc: 0.746\n",
            "2-41th: train loss: 1.73164, train acc: 0.757 valid loss: 1.74957 valid acc: 0.746\n",
            "2-42th: train loss: 1.72944, train acc: 0.759 valid loss: 1.74748 valid acc: 0.746\n",
            "2-43th: train loss: 1.72730, train acc: 0.761 valid loss: 1.74529 valid acc: 0.746\n",
            "2-44th: train loss: 1.72527, train acc: 0.763 valid loss: 1.74358 valid acc: 0.752\n",
            "2-45th: train loss: 1.72359, train acc: 0.768 valid loss: 1.74243 valid acc: 0.752\n",
            "2-46th: train loss: 1.72199, train acc: 0.770 valid loss: 1.74188 valid acc: 0.752\n",
            "2-47th: train loss: 1.72033, train acc: 0.772 valid loss: 1.74195 valid acc: 0.749\n",
            "2-48th: train loss: 1.71891, train acc: 0.772 valid loss: 1.74182 valid acc: 0.746\n",
            "2-49th: train loss: 1.71768, train acc: 0.772 valid loss: 1.74078 valid acc: 0.749\n",
            "2-50th: train loss: 1.71634, train acc: 0.772 valid loss: 1.73941 valid acc: 0.755\n",
            "2-51th: train loss: 1.71506, train acc: 0.772 valid loss: 1.73834 valid acc: 0.755\n",
            "2-52th: train loss: 1.71391, train acc: 0.775 valid loss: 1.73766 valid acc: 0.755\n",
            "2-53th: train loss: 1.71275, train acc: 0.775 valid loss: 1.73718 valid acc: 0.755\n",
            "2-54th: train loss: 1.71161, train acc: 0.776 valid loss: 1.73653 valid acc: 0.752\n",
            "2-55th: train loss: 1.71048, train acc: 0.776 valid loss: 1.73565 valid acc: 0.752\n",
            "2-56th: train loss: 1.70944, train acc: 0.776 valid loss: 1.73464 valid acc: 0.752\n",
            "2-57th: train loss: 1.70842, train acc: 0.777 valid loss: 1.73358 valid acc: 0.752\n",
            "2-58th: train loss: 1.70732, train acc: 0.777 valid loss: 1.73261 valid acc: 0.752\n",
            "2-59th: train loss: 1.70625, train acc: 0.778 valid loss: 1.73155 valid acc: 0.752\n",
            "2-60th: train loss: 1.70515, train acc: 0.779 valid loss: 1.73009 valid acc: 0.752\n",
            "2-61th: train loss: 1.70367, train acc: 0.781 valid loss: 1.72820 valid acc: 0.752\n",
            "2-62th: train loss: 1.70153, train acc: 0.779 valid loss: 1.72455 valid acc: 0.759\n",
            "2-63th: train loss: 1.69702, train acc: 0.783 valid loss: 1.71252 valid acc: 0.784\n",
            "2-64th: train loss: 1.68381, train acc: 0.808 valid loss: 1.69482 valid acc: 0.821\n",
            "2-65th: train loss: 1.66864, train acc: 0.848 valid loss: 1.69112 valid acc: 0.809\n",
            "2-66th: train loss: 1.66602, train acc: 0.845 valid loss: 1.67508 valid acc: 0.831\n",
            "2-67th: train loss: 1.64771, train acc: 0.856 valid loss: 1.67577 valid acc: 0.818\n",
            "2-68th: train loss: 1.64731, train acc: 0.850 valid loss: 1.67192 valid acc: 0.815\n",
            "2-69th: train loss: 1.64446, train acc: 0.854 valid loss: 1.66629 valid acc: 0.831\n",
            "2-70th: train loss: 1.64116, train acc: 0.860 valid loss: 1.66289 valid acc: 0.843\n",
            "2-71th: train loss: 1.63848, train acc: 0.864 valid loss: 1.66254 valid acc: 0.840\n",
            "2-72th: train loss: 1.63709, train acc: 0.867 valid loss: 1.66412 valid acc: 0.846\n",
            "2-73th: train loss: 1.63725, train acc: 0.866 valid loss: 1.66322 valid acc: 0.843\n",
            "2-74th: train loss: 1.63486, train acc: 0.867 valid loss: 1.66073 valid acc: 0.834\n",
            "2-75th: train loss: 1.63132, train acc: 0.872 valid loss: 1.65900 valid acc: 0.837\n",
            "2-76th: train loss: 1.62913, train acc: 0.872 valid loss: 1.65805 valid acc: 0.843\n",
            "2-77th: train loss: 1.62774, train acc: 0.872 valid loss: 1.65738 valid acc: 0.843\n",
            "2-78th: train loss: 1.62639, train acc: 0.871 valid loss: 1.65554 valid acc: 0.840\n",
            "2-79th: train loss: 1.62357, train acc: 0.874 valid loss: 1.65396 valid acc: 0.846\n",
            "2-80th: train loss: 1.62099, train acc: 0.877 valid loss: 1.65387 valid acc: 0.850\n",
            "2-81th: train loss: 1.62041, train acc: 0.878 valid loss: 1.65305 valid acc: 0.846\n",
            "2-82th: train loss: 1.61925, train acc: 0.878 valid loss: 1.65131 valid acc: 0.843\n",
            "2-83th: train loss: 1.61719, train acc: 0.879 valid loss: 1.64990 valid acc: 0.843\n",
            "2-84th: train loss: 1.61572, train acc: 0.880 valid loss: 1.64900 valid acc: 0.843\n",
            "2-85th: train loss: 1.61467, train acc: 0.879 valid loss: 1.64866 valid acc: 0.850\n",
            "2-86th: train loss: 1.61388, train acc: 0.881 valid loss: 1.64800 valid acc: 0.850\n",
            "2-87th: train loss: 1.61277, train acc: 0.881 valid loss: 1.64680 valid acc: 0.853\n",
            "2-88th: train loss: 1.61146, train acc: 0.881 valid loss: 1.64587 valid acc: 0.853\n",
            "2-89th: train loss: 1.61079, train acc: 0.883 valid loss: 1.64509 valid acc: 0.853\n",
            "2-90th: train loss: 1.61035, train acc: 0.883 valid loss: 1.64413 valid acc: 0.853\n",
            "2-91th: train loss: 1.60947, train acc: 0.884 valid loss: 1.64342 valid acc: 0.850\n",
            "2-92th: train loss: 1.60852, train acc: 0.883 valid loss: 1.64326 valid acc: 0.850\n",
            "2-93th: train loss: 1.60789, train acc: 0.883 valid loss: 1.64330 valid acc: 0.850\n",
            "2-94th: train loss: 1.60743, train acc: 0.884 valid loss: 1.64289 valid acc: 0.853\n",
            "2-95th: train loss: 1.60672, train acc: 0.884 valid loss: 1.64210 valid acc: 0.853\n",
            "2-96th: train loss: 1.60586, train acc: 0.884 valid loss: 1.64160 valid acc: 0.853\n",
            "2-97th: train loss: 1.60531, train acc: 0.884 valid loss: 1.64133 valid acc: 0.853\n",
            "2-98th: train loss: 1.60491, train acc: 0.885 valid loss: 1.64093 valid acc: 0.853\n",
            "2-99th: train loss: 1.60428, train acc: 0.885 valid loss: 1.64068 valid acc: 0.853\n",
            "2-100th: train loss: 1.60364, train acc: 0.885 valid loss: 1.64071 valid acc: 0.853\n",
            "2-101th: train loss: 1.60321, train acc: 0.886 valid loss: 1.64063 valid acc: 0.853\n",
            "2-102th: train loss: 1.60281, train acc: 0.886 valid loss: 1.64022 valid acc: 0.856\n",
            "2-103th: train loss: 1.60233, train acc: 0.886 valid loss: 1.63960 valid acc: 0.856\n",
            "2-104th: train loss: 1.60182, train acc: 0.886 valid loss: 1.63908 valid acc: 0.856\n",
            "2-105th: train loss: 1.60141, train acc: 0.886 valid loss: 1.63880 valid acc: 0.859\n",
            "2-106th: train loss: 1.60107, train acc: 0.886 valid loss: 1.63866 valid acc: 0.856\n",
            "2-107th: train loss: 1.60066, train acc: 0.886 valid loss: 1.63859 valid acc: 0.859\n",
            "2-108th: train loss: 1.60022, train acc: 0.886 valid loss: 1.63853 valid acc: 0.859\n",
            "2-109th: train loss: 1.59988, train acc: 0.886 valid loss: 1.63834 valid acc: 0.859\n",
            "2-110th: train loss: 1.59956, train acc: 0.886 valid loss: 1.63800 valid acc: 0.859\n",
            "2-111th: train loss: 1.59921, train acc: 0.886 valid loss: 1.63765 valid acc: 0.862\n",
            "2-112th: train loss: 1.59884, train acc: 0.886 valid loss: 1.63741 valid acc: 0.862\n",
            "2-113th: train loss: 1.59851, train acc: 0.886 valid loss: 1.63730 valid acc: 0.859\n",
            "2-114th: train loss: 1.59822, train acc: 0.886 valid loss: 1.63723 valid acc: 0.862\n",
            "2-115th: train loss: 1.59790, train acc: 0.886 valid loss: 1.63713 valid acc: 0.862\n",
            "2-116th: train loss: 1.59756, train acc: 0.886 valid loss: 1.63704 valid acc: 0.862\n",
            "2-117th: train loss: 1.59725, train acc: 0.887 valid loss: 1.63692 valid acc: 0.862\n",
            "2-118th: train loss: 1.59697, train acc: 0.887 valid loss: 1.63676 valid acc: 0.859\n",
            "2-119th: train loss: 1.59668, train acc: 0.887 valid loss: 1.63657 valid acc: 0.862\n",
            "2-120th: train loss: 1.59637, train acc: 0.887 valid loss: 1.63640 valid acc: 0.862\n",
            "2-121th: train loss: 1.59609, train acc: 0.887 valid loss: 1.63625 valid acc: 0.862\n",
            "2-122th: train loss: 1.59582, train acc: 0.887 valid loss: 1.63610 valid acc: 0.859\n",
            "2-123th: train loss: 1.59555, train acc: 0.887 valid loss: 1.63595 valid acc: 0.859\n",
            "2-124th: train loss: 1.59526, train acc: 0.887 valid loss: 1.63582 valid acc: 0.859\n",
            "2-125th: train loss: 1.59499, train acc: 0.888 valid loss: 1.63571 valid acc: 0.862\n",
            "2-126th: train loss: 1.59472, train acc: 0.889 valid loss: 1.63559 valid acc: 0.862\n",
            "2-127th: train loss: 1.59442, train acc: 0.889 valid loss: 1.63545 valid acc: 0.862\n",
            "2-128th: train loss: 1.59410, train acc: 0.889 valid loss: 1.63527 valid acc: 0.859\n",
            "2-129th: train loss: 1.59374, train acc: 0.889 valid loss: 1.63504 valid acc: 0.859\n",
            "2-130th: train loss: 1.59330, train acc: 0.889 valid loss: 1.63476 valid acc: 0.859\n",
            "2-131th: train loss: 1.59262, train acc: 0.890 valid loss: 1.63425 valid acc: 0.856\n",
            "2-132th: train loss: 1.59133, train acc: 0.891 valid loss: 1.63247 valid acc: 0.865\n",
            "2-133th: train loss: 1.58803, train acc: 0.895 valid loss: 1.62532 valid acc: 0.881\n",
            "2-134th: train loss: 1.57734, train acc: 0.916 valid loss: 1.62711 valid acc: 0.890\n",
            "2-135th: train loss: 1.57655, train acc: 0.939 valid loss: 1.60480 valid acc: 0.928\n",
            "2-136th: train loss: 1.55791, train acc: 0.953 valid loss: 1.59682 valid acc: 0.918\n",
            "2-137th: train loss: 1.55363, train acc: 0.954 valid loss: 1.58519 valid acc: 0.940\n",
            "2-138th: train loss: 1.54481, train acc: 0.964 valid loss: 1.58355 valid acc: 0.937\n",
            "2-139th: train loss: 1.54313, train acc: 0.965 valid loss: 1.57371 valid acc: 0.947\n",
            "2-140th: train loss: 1.53816, train acc: 0.967 valid loss: 1.57447 valid acc: 0.947\n",
            "2-141th: train loss: 1.53950, train acc: 0.972 valid loss: 1.56784 valid acc: 0.959\n",
            "2-142th: train loss: 1.53578, train acc: 0.976 valid loss: 1.56747 valid acc: 0.969\n",
            "2-143th: train loss: 1.53699, train acc: 0.975 valid loss: 1.56480 valid acc: 0.962\n",
            "2-144th: train loss: 1.53428, train acc: 0.976 valid loss: 1.56543 valid acc: 0.962\n",
            "2-145th: train loss: 1.53289, train acc: 0.976 valid loss: 1.56596 valid acc: 0.959\n",
            "2-146th: train loss: 1.53153, train acc: 0.976 valid loss: 1.56326 valid acc: 0.966\n",
            "2-147th: train loss: 1.52870, train acc: 0.979 valid loss: 1.56370 valid acc: 0.959\n",
            "2-148th: train loss: 1.52831, train acc: 0.980 valid loss: 1.56198 valid acc: 0.959\n",
            "2-149th: train loss: 1.52549, train acc: 0.979 valid loss: 1.56286 valid acc: 0.959\n",
            "2-150th: train loss: 1.52498, train acc: 0.980 valid loss: 1.56235 valid acc: 0.950\n",
            "2-151th: train loss: 1.52342, train acc: 0.980 valid loss: 1.56243 valid acc: 0.950\n",
            "2-152th: train loss: 1.52221, train acc: 0.981 valid loss: 1.56294 valid acc: 0.950\n",
            "2-153th: train loss: 1.52160, train acc: 0.981 valid loss: 1.56251 valid acc: 0.953\n",
            "2-154th: train loss: 1.52052, train acc: 0.981 valid loss: 1.56222 valid acc: 0.950\n",
            "2-155th: train loss: 1.52000, train acc: 0.980 valid loss: 1.56099 valid acc: 0.950\n",
            "2-156th: train loss: 1.51900, train acc: 0.981 valid loss: 1.56100 valid acc: 0.947\n",
            "2-157th: train loss: 1.51872, train acc: 0.980 valid loss: 1.56030 valid acc: 0.953\n",
            "2-158th: train loss: 1.51765, train acc: 0.982 valid loss: 1.56043 valid acc: 0.950\n",
            "2-159th: train loss: 1.51727, train acc: 0.983 valid loss: 1.55936 valid acc: 0.953\n",
            "2-160th: train loss: 1.51646, train acc: 0.984 valid loss: 1.55798 valid acc: 0.953\n",
            "2-161th: train loss: 1.51582, train acc: 0.984 valid loss: 1.55694 valid acc: 0.953\n",
            "2-162th: train loss: 1.51523, train acc: 0.984 valid loss: 1.55623 valid acc: 0.947\n",
            "2-163th: train loss: 1.51452, train acc: 0.985 valid loss: 1.55592 valid acc: 0.944\n",
            "2-164th: train loss: 1.51413, train acc: 0.985 valid loss: 1.55484 valid acc: 0.953\n",
            "2-165th: train loss: 1.51343, train acc: 0.985 valid loss: 1.55402 valid acc: 0.953\n",
            "2-166th: train loss: 1.51310, train acc: 0.985 valid loss: 1.55322 valid acc: 0.953\n",
            "2-167th: train loss: 1.51259, train acc: 0.986 valid loss: 1.55283 valid acc: 0.953\n",
            "2-168th: train loss: 1.51218, train acc: 0.987 valid loss: 1.55255 valid acc: 0.953\n",
            "2-169th: train loss: 1.51179, train acc: 0.986 valid loss: 1.55219 valid acc: 0.950\n",
            "2-170th: train loss: 1.51136, train acc: 0.986 valid loss: 1.55194 valid acc: 0.953\n",
            "2-171th: train loss: 1.51104, train acc: 0.986 valid loss: 1.55156 valid acc: 0.953\n",
            "2-172th: train loss: 1.51058, train acc: 0.987 valid loss: 1.55134 valid acc: 0.953\n",
            "2-173th: train loss: 1.51028, train acc: 0.987 valid loss: 1.55101 valid acc: 0.953\n",
            "2-174th: train loss: 1.50989, train acc: 0.987 valid loss: 1.55088 valid acc: 0.953\n",
            "2-175th: train loss: 1.50955, train acc: 0.987 valid loss: 1.55093 valid acc: 0.953\n",
            "2-176th: train loss: 1.50922, train acc: 0.987 valid loss: 1.55105 valid acc: 0.950\n",
            "2-177th: train loss: 1.50890, train acc: 0.987 valid loss: 1.55106 valid acc: 0.953\n",
            "2-178th: train loss: 1.50861, train acc: 0.988 valid loss: 1.55080 valid acc: 0.953\n",
            "2-179th: train loss: 1.50828, train acc: 0.988 valid loss: 1.55057 valid acc: 0.953\n",
            "2-180th: train loss: 1.50804, train acc: 0.988 valid loss: 1.55038 valid acc: 0.950\n",
            "2-181th: train loss: 1.50773, train acc: 0.988 valid loss: 1.55046 valid acc: 0.944\n",
            "2-182th: train loss: 1.50748, train acc: 0.988 valid loss: 1.55052 valid acc: 0.944\n",
            "2-183th: train loss: 1.50722, train acc: 0.988 valid loss: 1.55039 valid acc: 0.950\n",
            "2-184th: train loss: 1.50696, train acc: 0.988 valid loss: 1.55005 valid acc: 0.950\n",
            "2-185th: train loss: 1.50671, train acc: 0.988 valid loss: 1.54960 valid acc: 0.950\n",
            "2-186th: train loss: 1.50645, train acc: 0.988 valid loss: 1.54929 valid acc: 0.953\n",
            "2-187th: train loss: 1.50624, train acc: 0.988 valid loss: 1.54907 valid acc: 0.950\n",
            "2-188th: train loss: 1.50599, train acc: 0.989 valid loss: 1.54894 valid acc: 0.950\n",
            "2-189th: train loss: 1.50577, train acc: 0.989 valid loss: 1.54874 valid acc: 0.950\n",
            "2-190th: train loss: 1.50555, train acc: 0.989 valid loss: 1.54838 valid acc: 0.950\n",
            "2-191th: train loss: 1.50533, train acc: 0.989 valid loss: 1.54793 valid acc: 0.953\n",
            "2-192th: train loss: 1.50512, train acc: 0.989 valid loss: 1.54754 valid acc: 0.953\n",
            "2-193th: train loss: 1.50491, train acc: 0.989 valid loss: 1.54732 valid acc: 0.956\n",
            "2-194th: train loss: 1.50472, train acc: 0.990 valid loss: 1.54721 valid acc: 0.956\n",
            "2-195th: train loss: 1.50451, train acc: 0.990 valid loss: 1.54710 valid acc: 0.953\n",
            "2-196th: train loss: 1.50432, train acc: 0.990 valid loss: 1.54686 valid acc: 0.956\n",
            "2-197th: train loss: 1.50412, train acc: 0.991 valid loss: 1.54660 valid acc: 0.956\n",
            "2-198th: train loss: 1.50393, train acc: 0.991 valid loss: 1.54641 valid acc: 0.956\n",
            "2-199th: train loss: 1.50375, train acc: 0.991 valid loss: 1.54632 valid acc: 0.956\n",
            "2-200th: train loss: 1.50357, train acc: 0.991 valid loss: 1.54627 valid acc: 0.956\n",
            "2-201th: train loss: 1.50339, train acc: 0.991 valid loss: 1.54620 valid acc: 0.956\n",
            "2-202th: train loss: 1.50321, train acc: 0.991 valid loss: 1.54610 valid acc: 0.956\n",
            "2-203th: train loss: 1.50304, train acc: 0.991 valid loss: 1.54600 valid acc: 0.956\n",
            "2-204th: train loss: 1.50287, train acc: 0.991 valid loss: 1.54590 valid acc: 0.956\n",
            "2-205th: train loss: 1.50270, train acc: 0.991 valid loss: 1.54579 valid acc: 0.956\n",
            "2-206th: train loss: 1.50253, train acc: 0.991 valid loss: 1.54569 valid acc: 0.959\n",
            "2-207th: train loss: 1.50237, train acc: 0.991 valid loss: 1.54562 valid acc: 0.959\n",
            "2-208th: train loss: 1.50221, train acc: 0.991 valid loss: 1.54554 valid acc: 0.959\n",
            "2-209th: train loss: 1.50205, train acc: 0.991 valid loss: 1.54541 valid acc: 0.959\n",
            "2-210th: train loss: 1.50189, train acc: 0.991 valid loss: 1.54524 valid acc: 0.959\n",
            "2-211th: train loss: 1.50174, train acc: 0.991 valid loss: 1.54509 valid acc: 0.959\n",
            "2-212th: train loss: 1.50158, train acc: 0.991 valid loss: 1.54498 valid acc: 0.959\n",
            "2-213th: train loss: 1.50143, train acc: 0.991 valid loss: 1.54489 valid acc: 0.959\n",
            "2-214th: train loss: 1.50128, train acc: 0.991 valid loss: 1.54476 valid acc: 0.956\n",
            "2-215th: train loss: 1.50114, train acc: 0.991 valid loss: 1.54459 valid acc: 0.959\n",
            "2-216th: train loss: 1.50099, train acc: 0.991 valid loss: 1.54443 valid acc: 0.959\n",
            "2-217th: train loss: 1.50085, train acc: 0.991 valid loss: 1.54433 valid acc: 0.959\n",
            "2-218th: train loss: 1.50070, train acc: 0.991 valid loss: 1.54425 valid acc: 0.956\n",
            "2-219th: train loss: 1.50056, train acc: 0.991 valid loss: 1.54414 valid acc: 0.956\n",
            "2-220th: train loss: 1.50042, train acc: 0.991 valid loss: 1.54400 valid acc: 0.956\n",
            "2-221th: train loss: 1.50028, train acc: 0.991 valid loss: 1.54387 valid acc: 0.956\n",
            "2-222th: train loss: 1.50015, train acc: 0.991 valid loss: 1.54377 valid acc: 0.956\n",
            "2-223th: train loss: 1.50001, train acc: 0.991 valid loss: 1.54369 valid acc: 0.959\n",
            "2-224th: train loss: 1.49988, train acc: 0.991 valid loss: 1.54359 valid acc: 0.959\n",
            "2-225th: train loss: 1.49974, train acc: 0.991 valid loss: 1.54347 valid acc: 0.959\n",
            "2-226th: train loss: 1.49961, train acc: 0.991 valid loss: 1.54337 valid acc: 0.959\n",
            "2-227th: train loss: 1.49948, train acc: 0.991 valid loss: 1.54328 valid acc: 0.959\n",
            "2-228th: train loss: 1.49935, train acc: 0.991 valid loss: 1.54318 valid acc: 0.959\n",
            "2-229th: train loss: 1.49922, train acc: 0.991 valid loss: 1.54306 valid acc: 0.959\n",
            "2-230th: train loss: 1.49909, train acc: 0.991 valid loss: 1.54295 valid acc: 0.959\n",
            "2-231th: train loss: 1.49896, train acc: 0.991 valid loss: 1.54284 valid acc: 0.959\n",
            "2-232th: train loss: 1.49883, train acc: 0.991 valid loss: 1.54275 valid acc: 0.959\n",
            "2-233th: train loss: 1.49871, train acc: 0.991 valid loss: 1.54266 valid acc: 0.959\n",
            "2-234th: train loss: 1.49858, train acc: 0.991 valid loss: 1.54255 valid acc: 0.962\n",
            "2-235th: train loss: 1.49846, train acc: 0.991 valid loss: 1.54244 valid acc: 0.962\n",
            "2-236th: train loss: 1.49833, train acc: 0.991 valid loss: 1.54232 valid acc: 0.962\n",
            "2-237th: train loss: 1.49821, train acc: 0.991 valid loss: 1.54222 valid acc: 0.962\n",
            "2-238th: train loss: 1.49809, train acc: 0.991 valid loss: 1.54213 valid acc: 0.962\n",
            "2-239th: train loss: 1.49796, train acc: 0.991 valid loss: 1.54204 valid acc: 0.962\n",
            "2-240th: train loss: 1.49784, train acc: 0.991 valid loss: 1.54194 valid acc: 0.962\n",
            "2-241th: train loss: 1.49772, train acc: 0.992 valid loss: 1.54183 valid acc: 0.962\n",
            "2-242th: train loss: 1.49760, train acc: 0.992 valid loss: 1.54172 valid acc: 0.962\n",
            "2-243th: train loss: 1.49749, train acc: 0.992 valid loss: 1.54162 valid acc: 0.962\n",
            "2-244th: train loss: 1.49737, train acc: 0.992 valid loss: 1.54153 valid acc: 0.962\n",
            "2-245th: train loss: 1.49725, train acc: 0.992 valid loss: 1.54144 valid acc: 0.962\n",
            "2-246th: train loss: 1.49714, train acc: 0.992 valid loss: 1.54135 valid acc: 0.959\n",
            "2-247th: train loss: 1.49702, train acc: 0.992 valid loss: 1.54124 valid acc: 0.959\n",
            "2-248th: train loss: 1.49691, train acc: 0.992 valid loss: 1.54113 valid acc: 0.959\n",
            "2-249th: train loss: 1.49680, train acc: 0.992 valid loss: 1.54103 valid acc: 0.959\n",
            "2-250th: train loss: 1.49669, train acc: 0.992 valid loss: 1.54094 valid acc: 0.959\n",
            "2-251th: train loss: 1.49658, train acc: 0.992 valid loss: 1.54084 valid acc: 0.959\n",
            "2-252th: train loss: 1.49646, train acc: 0.992 valid loss: 1.54074 valid acc: 0.959\n",
            "2-253th: train loss: 1.49635, train acc: 0.992 valid loss: 1.54064 valid acc: 0.959\n",
            "2-254th: train loss: 1.49624, train acc: 0.992 valid loss: 1.54054 valid acc: 0.959\n",
            "2-255th: train loss: 1.49613, train acc: 0.992 valid loss: 1.54045 valid acc: 0.959\n",
            "2-256th: train loss: 1.49603, train acc: 0.992 valid loss: 1.54034 valid acc: 0.959\n",
            "2-257th: train loss: 1.49592, train acc: 0.992 valid loss: 1.54025 valid acc: 0.959\n",
            "2-258th: train loss: 1.49581, train acc: 0.992 valid loss: 1.54015 valid acc: 0.959\n",
            "2-259th: train loss: 1.49570, train acc: 0.992 valid loss: 1.54006 valid acc: 0.959\n",
            "2-260th: train loss: 1.49559, train acc: 0.992 valid loss: 1.53996 valid acc: 0.959\n",
            "2-261th: train loss: 1.49549, train acc: 0.992 valid loss: 1.53986 valid acc: 0.959\n",
            "2-262th: train loss: 1.49538, train acc: 0.992 valid loss: 1.53977 valid acc: 0.959\n",
            "2-263th: train loss: 1.49527, train acc: 0.992 valid loss: 1.53968 valid acc: 0.959\n",
            "2-264th: train loss: 1.49517, train acc: 0.992 valid loss: 1.53959 valid acc: 0.959\n",
            "2-265th: train loss: 1.49506, train acc: 0.993 valid loss: 1.53949 valid acc: 0.959\n",
            "2-266th: train loss: 1.49496, train acc: 0.993 valid loss: 1.53940 valid acc: 0.959\n",
            "2-267th: train loss: 1.49485, train acc: 0.993 valid loss: 1.53931 valid acc: 0.959\n",
            "2-268th: train loss: 1.49475, train acc: 0.993 valid loss: 1.53922 valid acc: 0.959\n",
            "2-269th: train loss: 1.49464, train acc: 0.993 valid loss: 1.53913 valid acc: 0.959\n",
            "2-270th: train loss: 1.49454, train acc: 0.994 valid loss: 1.53904 valid acc: 0.959\n",
            "2-271th: train loss: 1.49444, train acc: 0.995 valid loss: 1.53895 valid acc: 0.959\n",
            "2-272th: train loss: 1.49434, train acc: 0.995 valid loss: 1.53886 valid acc: 0.959\n",
            "2-273th: train loss: 1.49424, train acc: 0.995 valid loss: 1.53877 valid acc: 0.959\n",
            "2-274th: train loss: 1.49414, train acc: 0.995 valid loss: 1.53869 valid acc: 0.959\n",
            "2-275th: train loss: 1.49404, train acc: 0.995 valid loss: 1.53861 valid acc: 0.959\n",
            "2-276th: train loss: 1.49395, train acc: 0.995 valid loss: 1.53853 valid acc: 0.959\n",
            "2-277th: train loss: 1.49385, train acc: 0.995 valid loss: 1.53845 valid acc: 0.959\n",
            "2-278th: train loss: 1.49375, train acc: 0.995 valid loss: 1.53837 valid acc: 0.959\n",
            "2-279th: train loss: 1.49366, train acc: 0.995 valid loss: 1.53830 valid acc: 0.959\n",
            "2-280th: train loss: 1.49357, train acc: 0.995 valid loss: 1.53823 valid acc: 0.959\n",
            "2-281th: train loss: 1.49347, train acc: 0.995 valid loss: 1.53816 valid acc: 0.959\n",
            "2-282th: train loss: 1.49338, train acc: 0.995 valid loss: 1.53809 valid acc: 0.959\n",
            "2-283th: train loss: 1.49329, train acc: 0.995 valid loss: 1.53802 valid acc: 0.959\n",
            "2-284th: train loss: 1.49320, train acc: 0.995 valid loss: 1.53796 valid acc: 0.959\n",
            "2-285th: train loss: 1.49311, train acc: 0.995 valid loss: 1.53789 valid acc: 0.959\n",
            "2-286th: train loss: 1.49303, train acc: 0.995 valid loss: 1.53783 valid acc: 0.959\n",
            "2-287th: train loss: 1.49294, train acc: 0.995 valid loss: 1.53777 valid acc: 0.959\n",
            "2-288th: train loss: 1.49286, train acc: 0.995 valid loss: 1.53770 valid acc: 0.959\n",
            "2-289th: train loss: 1.49277, train acc: 0.995 valid loss: 1.53764 valid acc: 0.962\n",
            "2-290th: train loss: 1.49269, train acc: 0.995 valid loss: 1.53758 valid acc: 0.962\n",
            "2-291th: train loss: 1.49260, train acc: 0.995 valid loss: 1.53752 valid acc: 0.962\n",
            "2-292th: train loss: 1.49252, train acc: 0.995 valid loss: 1.53746 valid acc: 0.962\n",
            "2-293th: train loss: 1.49244, train acc: 0.995 valid loss: 1.53740 valid acc: 0.962\n",
            "2-294th: train loss: 1.49236, train acc: 0.995 valid loss: 1.53734 valid acc: 0.962\n",
            "2-295th: train loss: 1.49228, train acc: 0.995 valid loss: 1.53728 valid acc: 0.962\n",
            "2-296th: train loss: 1.49220, train acc: 0.995 valid loss: 1.53723 valid acc: 0.962\n",
            "2-297th: train loss: 1.49212, train acc: 0.995 valid loss: 1.53717 valid acc: 0.962\n",
            "2-298th: train loss: 1.49204, train acc: 0.995 valid loss: 1.53711 valid acc: 0.962\n",
            "2-299th: train loss: 1.49197, train acc: 0.995 valid loss: 1.53705 valid acc: 0.962\n",
            "3-0th: train loss: 2.30703, train acc: 0.121 valid loss: 2.24031 valid acc: 0.201\n",
            "3-1th: train loss: 2.22675, train acc: 0.227 valid loss: 2.19725 valid acc: 0.242\n",
            "3-2th: train loss: 2.18865, train acc: 0.259 valid loss: 2.12628 valid acc: 0.343\n",
            "3-3th: train loss: 2.12184, train acc: 0.340 valid loss: 2.06694 valid acc: 0.431\n",
            "3-4th: train loss: 2.06373, train acc: 0.426 valid loss: 2.05264 valid acc: 0.434\n",
            "3-5th: train loss: 2.05399, train acc: 0.426 valid loss: 2.00523 valid acc: 0.472\n",
            "3-6th: train loss: 2.00718, train acc: 0.480 valid loss: 1.97805 valid acc: 0.497\n",
            "3-7th: train loss: 1.97850, train acc: 0.512 valid loss: 1.96464 valid acc: 0.513\n",
            "3-8th: train loss: 1.96101, train acc: 0.534 valid loss: 1.94981 valid acc: 0.535\n",
            "3-9th: train loss: 1.93983, train acc: 0.569 valid loss: 1.92938 valid acc: 0.572\n",
            "3-10th: train loss: 1.91440, train acc: 0.587 valid loss: 1.91218 valid acc: 0.585\n",
            "3-11th: train loss: 1.89726, train acc: 0.606 valid loss: 1.89865 valid acc: 0.601\n",
            "3-12th: train loss: 1.88515, train acc: 0.616 valid loss: 1.88778 valid acc: 0.604\n",
            "3-13th: train loss: 1.87505, train acc: 0.624 valid loss: 1.87982 valid acc: 0.607\n",
            "3-14th: train loss: 1.86596, train acc: 0.626 valid loss: 1.87390 valid acc: 0.613\n",
            "3-15th: train loss: 1.85715, train acc: 0.631 valid loss: 1.86807 valid acc: 0.623\n",
            "3-16th: train loss: 1.84817, train acc: 0.645 valid loss: 1.85947 valid acc: 0.638\n",
            "3-17th: train loss: 1.83801, train acc: 0.653 valid loss: 1.84472 valid acc: 0.648\n",
            "3-18th: train loss: 1.82358, train acc: 0.674 valid loss: 1.83320 valid acc: 0.676\n",
            "3-19th: train loss: 1.81146, train acc: 0.695 valid loss: 1.82467 valid acc: 0.679\n",
            "3-20th: train loss: 1.80279, train acc: 0.696 valid loss: 1.80660 valid acc: 0.720\n",
            "3-21th: train loss: 1.78561, train acc: 0.714 valid loss: 1.79892 valid acc: 0.711\n",
            "3-22th: train loss: 1.77727, train acc: 0.722 valid loss: 1.79670 valid acc: 0.704\n",
            "3-23th: train loss: 1.77429, train acc: 0.718 valid loss: 1.78894 valid acc: 0.711\n",
            "3-24th: train loss: 1.76796, train acc: 0.723 valid loss: 1.78099 valid acc: 0.723\n",
            "3-25th: train loss: 1.76197, train acc: 0.732 valid loss: 1.77758 valid acc: 0.720\n",
            "3-26th: train loss: 1.75934, train acc: 0.733 valid loss: 1.77503 valid acc: 0.723\n",
            "3-27th: train loss: 1.75674, train acc: 0.733 valid loss: 1.77081 valid acc: 0.717\n",
            "3-28th: train loss: 1.75237, train acc: 0.736 valid loss: 1.76744 valid acc: 0.726\n",
            "3-29th: train loss: 1.74862, train acc: 0.735 valid loss: 1.76553 valid acc: 0.720\n",
            "3-30th: train loss: 1.74588, train acc: 0.740 valid loss: 1.76198 valid acc: 0.720\n",
            "3-31th: train loss: 1.74119, train acc: 0.747 valid loss: 1.75508 valid acc: 0.726\n",
            "3-32th: train loss: 1.73327, train acc: 0.763 valid loss: 1.74539 valid acc: 0.742\n",
            "3-33th: train loss: 1.72362, train acc: 0.777 valid loss: 1.73637 valid acc: 0.774\n",
            "3-34th: train loss: 1.71531, train acc: 0.798 valid loss: 1.73207 valid acc: 0.786\n",
            "3-35th: train loss: 1.71000, train acc: 0.809 valid loss: 1.72263 valid acc: 0.786\n",
            "3-36th: train loss: 1.69778, train acc: 0.824 valid loss: 1.71528 valid acc: 0.789\n",
            "3-37th: train loss: 1.68823, train acc: 0.827 valid loss: 1.71112 valid acc: 0.783\n",
            "3-38th: train loss: 1.68264, train acc: 0.828 valid loss: 1.70732 valid acc: 0.796\n",
            "3-39th: train loss: 1.67706, train acc: 0.836 valid loss: 1.70508 valid acc: 0.802\n",
            "3-40th: train loss: 1.67274, train acc: 0.840 valid loss: 1.70372 valid acc: 0.796\n",
            "3-41th: train loss: 1.66926, train acc: 0.843 valid loss: 1.70252 valid acc: 0.796\n",
            "3-42th: train loss: 1.66611, train acc: 0.848 valid loss: 1.70197 valid acc: 0.799\n",
            "3-43th: train loss: 1.66408, train acc: 0.849 valid loss: 1.70039 valid acc: 0.811\n",
            "3-44th: train loss: 1.66152, train acc: 0.850 valid loss: 1.69794 valid acc: 0.808\n",
            "3-45th: train loss: 1.65820, train acc: 0.849 valid loss: 1.69686 valid acc: 0.805\n",
            "3-46th: train loss: 1.65595, train acc: 0.853 valid loss: 1.69664 valid acc: 0.802\n",
            "3-47th: train loss: 1.65391, train acc: 0.853 valid loss: 1.69616 valid acc: 0.799\n",
            "3-48th: train loss: 1.65126, train acc: 0.856 valid loss: 1.69574 valid acc: 0.808\n",
            "3-49th: train loss: 1.64898, train acc: 0.860 valid loss: 1.69508 valid acc: 0.808\n",
            "3-50th: train loss: 1.64709, train acc: 0.860 valid loss: 1.69365 valid acc: 0.811\n",
            "3-51th: train loss: 1.64511, train acc: 0.863 valid loss: 1.69208 valid acc: 0.808\n",
            "3-52th: train loss: 1.64338, train acc: 0.863 valid loss: 1.69088 valid acc: 0.811\n",
            "3-53th: train loss: 1.64170, train acc: 0.864 valid loss: 1.69013 valid acc: 0.811\n",
            "3-54th: train loss: 1.63993, train acc: 0.865 valid loss: 1.68986 valid acc: 0.805\n",
            "3-55th: train loss: 1.63859, train acc: 0.865 valid loss: 1.68935 valid acc: 0.805\n",
            "3-56th: train loss: 1.63732, train acc: 0.864 valid loss: 1.68821 valid acc: 0.805\n",
            "3-57th: train loss: 1.63576, train acc: 0.865 valid loss: 1.68698 valid acc: 0.811\n",
            "3-58th: train loss: 1.63445, train acc: 0.864 valid loss: 1.68596 valid acc: 0.814\n",
            "3-59th: train loss: 1.63343, train acc: 0.865 valid loss: 1.68493 valid acc: 0.814\n",
            "3-60th: train loss: 1.63220, train acc: 0.867 valid loss: 1.68401 valid acc: 0.818\n",
            "3-61th: train loss: 1.63098, train acc: 0.868 valid loss: 1.68322 valid acc: 0.814\n",
            "3-62th: train loss: 1.63002, train acc: 0.869 valid loss: 1.68224 valid acc: 0.821\n",
            "3-63th: train loss: 1.62904, train acc: 0.869 valid loss: 1.68116 valid acc: 0.821\n",
            "3-64th: train loss: 1.62803, train acc: 0.869 valid loss: 1.68029 valid acc: 0.824\n",
            "3-65th: train loss: 1.62712, train acc: 0.869 valid loss: 1.67967 valid acc: 0.821\n",
            "3-66th: train loss: 1.62621, train acc: 0.869 valid loss: 1.67922 valid acc: 0.824\n",
            "3-67th: train loss: 1.62530, train acc: 0.869 valid loss: 1.67877 valid acc: 0.818\n",
            "3-68th: train loss: 1.62449, train acc: 0.869 valid loss: 1.67804 valid acc: 0.818\n",
            "3-69th: train loss: 1.62365, train acc: 0.870 valid loss: 1.67704 valid acc: 0.821\n",
            "3-70th: train loss: 1.62277, train acc: 0.872 valid loss: 1.67611 valid acc: 0.821\n",
            "3-71th: train loss: 1.62200, train acc: 0.873 valid loss: 1.67542 valid acc: 0.824\n",
            "3-72th: train loss: 1.62125, train acc: 0.873 valid loss: 1.67498 valid acc: 0.821\n",
            "3-73th: train loss: 1.62047, train acc: 0.875 valid loss: 1.67472 valid acc: 0.821\n",
            "3-74th: train loss: 1.61974, train acc: 0.875 valid loss: 1.67439 valid acc: 0.818\n",
            "3-75th: train loss: 1.61903, train acc: 0.875 valid loss: 1.67388 valid acc: 0.818\n",
            "3-76th: train loss: 1.61833, train acc: 0.875 valid loss: 1.67326 valid acc: 0.821\n",
            "3-77th: train loss: 1.61767, train acc: 0.876 valid loss: 1.67267 valid acc: 0.824\n",
            "3-78th: train loss: 1.61701, train acc: 0.878 valid loss: 1.67217 valid acc: 0.821\n",
            "3-79th: train loss: 1.61635, train acc: 0.878 valid loss: 1.67175 valid acc: 0.818\n",
            "3-80th: train loss: 1.61574, train acc: 0.878 valid loss: 1.67129 valid acc: 0.821\n",
            "3-81th: train loss: 1.61514, train acc: 0.878 valid loss: 1.67074 valid acc: 0.821\n",
            "3-82th: train loss: 1.61452, train acc: 0.878 valid loss: 1.67021 valid acc: 0.824\n",
            "3-83th: train loss: 1.61395, train acc: 0.878 valid loss: 1.66974 valid acc: 0.821\n",
            "3-84th: train loss: 1.61338, train acc: 0.878 valid loss: 1.66933 valid acc: 0.821\n",
            "3-85th: train loss: 1.61281, train acc: 0.879 valid loss: 1.66894 valid acc: 0.821\n",
            "3-86th: train loss: 1.61227, train acc: 0.879 valid loss: 1.66849 valid acc: 0.818\n",
            "3-87th: train loss: 1.61173, train acc: 0.879 valid loss: 1.66801 valid acc: 0.818\n",
            "3-88th: train loss: 1.61120, train acc: 0.879 valid loss: 1.66756 valid acc: 0.821\n",
            "3-89th: train loss: 1.61070, train acc: 0.880 valid loss: 1.66720 valid acc: 0.818\n",
            "3-90th: train loss: 1.61020, train acc: 0.880 valid loss: 1.66689 valid acc: 0.818\n",
            "3-91th: train loss: 1.60970, train acc: 0.880 valid loss: 1.66659 valid acc: 0.821\n",
            "3-92th: train loss: 1.60923, train acc: 0.882 valid loss: 1.66623 valid acc: 0.821\n",
            "3-93th: train loss: 1.60877, train acc: 0.882 valid loss: 1.66584 valid acc: 0.821\n",
            "3-94th: train loss: 1.60831, train acc: 0.882 valid loss: 1.66549 valid acc: 0.824\n",
            "3-95th: train loss: 1.60787, train acc: 0.882 valid loss: 1.66521 valid acc: 0.821\n",
            "3-96th: train loss: 1.60744, train acc: 0.882 valid loss: 1.66496 valid acc: 0.821\n",
            "3-97th: train loss: 1.60702, train acc: 0.883 valid loss: 1.66471 valid acc: 0.821\n",
            "3-98th: train loss: 1.60660, train acc: 0.883 valid loss: 1.66441 valid acc: 0.821\n",
            "3-99th: train loss: 1.60620, train acc: 0.883 valid loss: 1.66411 valid acc: 0.824\n",
            "3-100th: train loss: 1.60580, train acc: 0.884 valid loss: 1.66383 valid acc: 0.827\n",
            "3-101th: train loss: 1.60542, train acc: 0.884 valid loss: 1.66356 valid acc: 0.827\n",
            "3-102th: train loss: 1.60504, train acc: 0.884 valid loss: 1.66328 valid acc: 0.827\n",
            "3-103th: train loss: 1.60466, train acc: 0.884 valid loss: 1.66297 valid acc: 0.827\n",
            "3-104th: train loss: 1.60430, train acc: 0.884 valid loss: 1.66267 valid acc: 0.827\n",
            "3-105th: train loss: 1.60394, train acc: 0.884 valid loss: 1.66242 valid acc: 0.827\n",
            "3-106th: train loss: 1.60358, train acc: 0.885 valid loss: 1.66221 valid acc: 0.827\n",
            "3-107th: train loss: 1.60323, train acc: 0.885 valid loss: 1.66201 valid acc: 0.827\n",
            "3-108th: train loss: 1.60289, train acc: 0.885 valid loss: 1.66177 valid acc: 0.827\n",
            "3-109th: train loss: 1.60256, train acc: 0.885 valid loss: 1.66149 valid acc: 0.827\n",
            "3-110th: train loss: 1.60222, train acc: 0.885 valid loss: 1.66122 valid acc: 0.824\n",
            "3-111th: train loss: 1.60189, train acc: 0.885 valid loss: 1.66099 valid acc: 0.827\n",
            "3-112th: train loss: 1.60157, train acc: 0.885 valid loss: 1.66080 valid acc: 0.827\n",
            "3-113th: train loss: 1.60126, train acc: 0.885 valid loss: 1.66062 valid acc: 0.827\n",
            "3-114th: train loss: 1.60095, train acc: 0.886 valid loss: 1.66041 valid acc: 0.827\n",
            "3-115th: train loss: 1.60064, train acc: 0.886 valid loss: 1.66019 valid acc: 0.824\n",
            "3-116th: train loss: 1.60034, train acc: 0.886 valid loss: 1.66000 valid acc: 0.824\n",
            "3-117th: train loss: 1.60004, train acc: 0.886 valid loss: 1.65983 valid acc: 0.824\n",
            "3-118th: train loss: 1.59975, train acc: 0.886 valid loss: 1.65967 valid acc: 0.821\n",
            "3-119th: train loss: 1.59946, train acc: 0.886 valid loss: 1.65949 valid acc: 0.821\n",
            "3-120th: train loss: 1.59918, train acc: 0.886 valid loss: 1.65928 valid acc: 0.821\n",
            "3-121th: train loss: 1.59891, train acc: 0.886 valid loss: 1.65908 valid acc: 0.821\n",
            "3-122th: train loss: 1.59864, train acc: 0.886 valid loss: 1.65892 valid acc: 0.821\n",
            "3-123th: train loss: 1.59838, train acc: 0.886 valid loss: 1.65878 valid acc: 0.821\n",
            "3-124th: train loss: 1.59812, train acc: 0.886 valid loss: 1.65863 valid acc: 0.821\n",
            "3-125th: train loss: 1.59786, train acc: 0.886 valid loss: 1.65846 valid acc: 0.821\n",
            "3-126th: train loss: 1.59761, train acc: 0.886 valid loss: 1.65828 valid acc: 0.821\n",
            "3-127th: train loss: 1.59736, train acc: 0.886 valid loss: 1.65811 valid acc: 0.821\n",
            "3-128th: train loss: 1.59712, train acc: 0.886 valid loss: 1.65796 valid acc: 0.821\n",
            "3-129th: train loss: 1.59688, train acc: 0.886 valid loss: 1.65782 valid acc: 0.821\n",
            "3-130th: train loss: 1.59665, train acc: 0.887 valid loss: 1.65767 valid acc: 0.821\n",
            "3-131th: train loss: 1.59641, train acc: 0.888 valid loss: 1.65750 valid acc: 0.821\n",
            "3-132th: train loss: 1.59618, train acc: 0.888 valid loss: 1.65734 valid acc: 0.821\n",
            "3-133th: train loss: 1.59596, train acc: 0.888 valid loss: 1.65719 valid acc: 0.821\n",
            "3-134th: train loss: 1.59573, train acc: 0.888 valid loss: 1.65705 valid acc: 0.821\n",
            "3-135th: train loss: 1.59551, train acc: 0.888 valid loss: 1.65691 valid acc: 0.818\n",
            "3-136th: train loss: 1.59529, train acc: 0.888 valid loss: 1.65676 valid acc: 0.818\n",
            "3-137th: train loss: 1.59507, train acc: 0.888 valid loss: 1.65660 valid acc: 0.818\n",
            "3-138th: train loss: 1.59486, train acc: 0.888 valid loss: 1.65645 valid acc: 0.818\n",
            "3-139th: train loss: 1.59464, train acc: 0.888 valid loss: 1.65631 valid acc: 0.821\n",
            "3-140th: train loss: 1.59443, train acc: 0.888 valid loss: 1.65618 valid acc: 0.821\n",
            "3-141th: train loss: 1.59422, train acc: 0.889 valid loss: 1.65604 valid acc: 0.821\n",
            "3-142th: train loss: 1.59402, train acc: 0.889 valid loss: 1.65590 valid acc: 0.821\n",
            "3-143th: train loss: 1.59381, train acc: 0.889 valid loss: 1.65576 valid acc: 0.821\n",
            "3-144th: train loss: 1.59361, train acc: 0.890 valid loss: 1.65563 valid acc: 0.821\n",
            "3-145th: train loss: 1.59341, train acc: 0.890 valid loss: 1.65551 valid acc: 0.821\n",
            "3-146th: train loss: 1.59321, train acc: 0.890 valid loss: 1.65539 valid acc: 0.821\n",
            "3-147th: train loss: 1.59301, train acc: 0.890 valid loss: 1.65527 valid acc: 0.821\n",
            "3-148th: train loss: 1.59282, train acc: 0.890 valid loss: 1.65515 valid acc: 0.821\n",
            "3-149th: train loss: 1.59263, train acc: 0.890 valid loss: 1.65503 valid acc: 0.821\n",
            "3-150th: train loss: 1.59244, train acc: 0.890 valid loss: 1.65492 valid acc: 0.821\n",
            "3-151th: train loss: 1.59225, train acc: 0.890 valid loss: 1.65481 valid acc: 0.821\n",
            "3-152th: train loss: 1.59207, train acc: 0.890 valid loss: 1.65471 valid acc: 0.821\n",
            "3-153th: train loss: 1.59188, train acc: 0.890 valid loss: 1.65460 valid acc: 0.821\n",
            "3-154th: train loss: 1.59170, train acc: 0.890 valid loss: 1.65450 valid acc: 0.821\n",
            "3-155th: train loss: 1.59152, train acc: 0.890 valid loss: 1.65441 valid acc: 0.821\n",
            "3-156th: train loss: 1.59134, train acc: 0.890 valid loss: 1.65432 valid acc: 0.821\n",
            "3-157th: train loss: 1.59116, train acc: 0.890 valid loss: 1.65423 valid acc: 0.821\n",
            "3-158th: train loss: 1.59098, train acc: 0.890 valid loss: 1.65415 valid acc: 0.821\n",
            "3-159th: train loss: 1.59080, train acc: 0.890 valid loss: 1.65407 valid acc: 0.821\n",
            "3-160th: train loss: 1.59063, train acc: 0.890 valid loss: 1.65399 valid acc: 0.821\n",
            "3-161th: train loss: 1.59045, train acc: 0.890 valid loss: 1.65391 valid acc: 0.821\n",
            "3-162th: train loss: 1.59028, train acc: 0.890 valid loss: 1.65384 valid acc: 0.821\n",
            "3-163th: train loss: 1.59010, train acc: 0.891 valid loss: 1.65377 valid acc: 0.821\n",
            "3-164th: train loss: 1.58993, train acc: 0.891 valid loss: 1.65370 valid acc: 0.821\n",
            "3-165th: train loss: 1.58976, train acc: 0.891 valid loss: 1.65363 valid acc: 0.821\n",
            "3-166th: train loss: 1.58959, train acc: 0.891 valid loss: 1.65355 valid acc: 0.821\n",
            "3-167th: train loss: 1.58942, train acc: 0.891 valid loss: 1.65347 valid acc: 0.821\n",
            "3-168th: train loss: 1.58926, train acc: 0.891 valid loss: 1.65339 valid acc: 0.821\n",
            "3-169th: train loss: 1.58909, train acc: 0.891 valid loss: 1.65330 valid acc: 0.821\n",
            "3-170th: train loss: 1.58893, train acc: 0.891 valid loss: 1.65321 valid acc: 0.821\n",
            "3-171th: train loss: 1.58877, train acc: 0.891 valid loss: 1.65311 valid acc: 0.821\n",
            "3-172th: train loss: 1.58861, train acc: 0.892 valid loss: 1.65302 valid acc: 0.821\n",
            "3-173th: train loss: 1.58845, train acc: 0.892 valid loss: 1.65292 valid acc: 0.821\n",
            "3-174th: train loss: 1.58828, train acc: 0.892 valid loss: 1.65282 valid acc: 0.821\n",
            "3-175th: train loss: 1.58812, train acc: 0.892 valid loss: 1.65272 valid acc: 0.821\n",
            "3-176th: train loss: 1.58795, train acc: 0.893 valid loss: 1.65262 valid acc: 0.821\n",
            "3-177th: train loss: 1.58777, train acc: 0.893 valid loss: 1.65252 valid acc: 0.821\n",
            "3-178th: train loss: 1.58757, train acc: 0.893 valid loss: 1.65242 valid acc: 0.824\n",
            "3-179th: train loss: 1.58736, train acc: 0.893 valid loss: 1.65232 valid acc: 0.824\n",
            "3-180th: train loss: 1.58710, train acc: 0.893 valid loss: 1.65222 valid acc: 0.824\n",
            "3-181th: train loss: 1.58676, train acc: 0.893 valid loss: 1.65209 valid acc: 0.824\n",
            "3-182th: train loss: 1.58625, train acc: 0.893 valid loss: 1.65191 valid acc: 0.824\n",
            "3-183th: train loss: 1.58539, train acc: 0.895 valid loss: 1.65164 valid acc: 0.827\n",
            "3-184th: train loss: 1.58377, train acc: 0.896 valid loss: 1.65160 valid acc: 0.827\n",
            "3-185th: train loss: 1.58069, train acc: 0.905 valid loss: 1.65259 valid acc: 0.830\n",
            "3-186th: train loss: 1.57620, train acc: 0.915 valid loss: 1.65207 valid acc: 0.843\n",
            "3-187th: train loss: 1.57173, train acc: 0.931 valid loss: 1.64103 valid acc: 0.858\n",
            "3-188th: train loss: 1.56241, train acc: 0.945 valid loss: 1.62766 valid acc: 0.887\n",
            "3-189th: train loss: 1.55186, train acc: 0.951 valid loss: 1.61642 valid acc: 0.893\n",
            "3-190th: train loss: 1.54223, train acc: 0.959 valid loss: 1.61093 valid acc: 0.893\n",
            "3-191th: train loss: 1.53778, train acc: 0.969 valid loss: 1.60582 valid acc: 0.909\n",
            "3-192th: train loss: 1.53523, train acc: 0.973 valid loss: 1.60057 valid acc: 0.906\n",
            "3-193th: train loss: 1.53338, train acc: 0.970 valid loss: 1.59927 valid acc: 0.909\n",
            "3-194th: train loss: 1.53350, train acc: 0.973 valid loss: 1.59910 valid acc: 0.912\n",
            "3-195th: train loss: 1.53266, train acc: 0.976 valid loss: 1.59796 valid acc: 0.909\n",
            "3-196th: train loss: 1.53128, train acc: 0.978 valid loss: 1.59604 valid acc: 0.899\n",
            "3-197th: train loss: 1.53015, train acc: 0.979 valid loss: 1.59309 valid acc: 0.899\n",
            "3-198th: train loss: 1.52789, train acc: 0.977 valid loss: 1.59061 valid acc: 0.909\n",
            "3-199th: train loss: 1.52585, train acc: 0.977 valid loss: 1.58887 valid acc: 0.912\n",
            "3-200th: train loss: 1.52431, train acc: 0.977 valid loss: 1.58701 valid acc: 0.912\n",
            "3-201th: train loss: 1.52231, train acc: 0.980 valid loss: 1.58612 valid acc: 0.912\n",
            "3-202th: train loss: 1.52117, train acc: 0.980 valid loss: 1.58518 valid acc: 0.912\n",
            "3-203th: train loss: 1.52017, train acc: 0.980 valid loss: 1.58364 valid acc: 0.918\n",
            "3-204th: train loss: 1.51905, train acc: 0.980 valid loss: 1.58224 valid acc: 0.915\n",
            "3-205th: train loss: 1.51837, train acc: 0.982 valid loss: 1.58096 valid acc: 0.915\n",
            "3-206th: train loss: 1.51755, train acc: 0.982 valid loss: 1.58010 valid acc: 0.915\n",
            "3-207th: train loss: 1.51662, train acc: 0.982 valid loss: 1.57958 valid acc: 0.918\n",
            "3-208th: train loss: 1.51577, train acc: 0.982 valid loss: 1.57869 valid acc: 0.918\n",
            "3-209th: train loss: 1.51487, train acc: 0.982 valid loss: 1.57728 valid acc: 0.918\n",
            "3-210th: train loss: 1.51396, train acc: 0.983 valid loss: 1.57594 valid acc: 0.918\n",
            "3-211th: train loss: 1.51321, train acc: 0.983 valid loss: 1.57514 valid acc: 0.921\n",
            "3-212th: train loss: 1.51252, train acc: 0.983 valid loss: 1.57494 valid acc: 0.921\n",
            "3-213th: train loss: 1.51193, train acc: 0.983 valid loss: 1.57483 valid acc: 0.918\n",
            "3-214th: train loss: 1.51143, train acc: 0.983 valid loss: 1.57432 valid acc: 0.918\n",
            "3-215th: train loss: 1.51095, train acc: 0.984 valid loss: 1.57369 valid acc: 0.918\n",
            "3-216th: train loss: 1.51052, train acc: 0.985 valid loss: 1.57333 valid acc: 0.918\n",
            "3-217th: train loss: 1.51009, train acc: 0.986 valid loss: 1.57332 valid acc: 0.918\n",
            "3-218th: train loss: 1.50964, train acc: 0.986 valid loss: 1.57336 valid acc: 0.918\n",
            "3-219th: train loss: 1.50921, train acc: 0.987 valid loss: 1.57320 valid acc: 0.918\n",
            "3-220th: train loss: 1.50878, train acc: 0.988 valid loss: 1.57293 valid acc: 0.918\n",
            "3-221th: train loss: 1.50836, train acc: 0.988 valid loss: 1.57273 valid acc: 0.918\n",
            "3-222th: train loss: 1.50797, train acc: 0.988 valid loss: 1.57260 valid acc: 0.918\n",
            "3-223th: train loss: 1.50759, train acc: 0.988 valid loss: 1.57244 valid acc: 0.918\n",
            "3-224th: train loss: 1.50723, train acc: 0.988 valid loss: 1.57218 valid acc: 0.918\n",
            "3-225th: train loss: 1.50689, train acc: 0.988 valid loss: 1.57188 valid acc: 0.918\n",
            "3-226th: train loss: 1.50656, train acc: 0.989 valid loss: 1.57160 valid acc: 0.915\n",
            "3-227th: train loss: 1.50624, train acc: 0.989 valid loss: 1.57134 valid acc: 0.915\n",
            "3-228th: train loss: 1.50594, train acc: 0.989 valid loss: 1.57108 valid acc: 0.915\n",
            "3-229th: train loss: 1.50565, train acc: 0.990 valid loss: 1.57086 valid acc: 0.915\n",
            "3-230th: train loss: 1.50537, train acc: 0.990 valid loss: 1.57066 valid acc: 0.915\n",
            "3-231th: train loss: 1.50510, train acc: 0.989 valid loss: 1.57045 valid acc: 0.918\n",
            "3-232th: train loss: 1.50483, train acc: 0.989 valid loss: 1.57027 valid acc: 0.918\n",
            "3-233th: train loss: 1.50457, train acc: 0.989 valid loss: 1.57016 valid acc: 0.918\n",
            "3-234th: train loss: 1.50433, train acc: 0.990 valid loss: 1.57013 valid acc: 0.921\n",
            "3-235th: train loss: 1.50409, train acc: 0.990 valid loss: 1.57014 valid acc: 0.921\n",
            "3-236th: train loss: 1.50386, train acc: 0.990 valid loss: 1.57014 valid acc: 0.925\n",
            "3-237th: train loss: 1.50364, train acc: 0.990 valid loss: 1.57008 valid acc: 0.925\n",
            "3-238th: train loss: 1.50341, train acc: 0.990 valid loss: 1.56999 valid acc: 0.925\n",
            "3-239th: train loss: 1.50320, train acc: 0.990 valid loss: 1.56993 valid acc: 0.925\n",
            "3-240th: train loss: 1.50299, train acc: 0.990 valid loss: 1.56990 valid acc: 0.928\n",
            "3-241th: train loss: 1.50278, train acc: 0.991 valid loss: 1.56989 valid acc: 0.925\n",
            "3-242th: train loss: 1.50257, train acc: 0.991 valid loss: 1.56986 valid acc: 0.921\n",
            "3-243th: train loss: 1.50237, train acc: 0.991 valid loss: 1.56977 valid acc: 0.921\n",
            "3-244th: train loss: 1.50217, train acc: 0.991 valid loss: 1.56963 valid acc: 0.925\n",
            "3-245th: train loss: 1.50197, train acc: 0.991 valid loss: 1.56953 valid acc: 0.921\n",
            "3-246th: train loss: 1.50179, train acc: 0.991 valid loss: 1.56950 valid acc: 0.921\n",
            "3-247th: train loss: 1.50160, train acc: 0.991 valid loss: 1.56952 valid acc: 0.921\n",
            "3-248th: train loss: 1.50142, train acc: 0.991 valid loss: 1.56952 valid acc: 0.921\n",
            "3-249th: train loss: 1.50125, train acc: 0.991 valid loss: 1.56948 valid acc: 0.918\n",
            "3-250th: train loss: 1.50107, train acc: 0.991 valid loss: 1.56941 valid acc: 0.918\n",
            "3-251th: train loss: 1.50090, train acc: 0.991 valid loss: 1.56937 valid acc: 0.918\n",
            "3-252th: train loss: 1.50074, train acc: 0.991 valid loss: 1.56937 valid acc: 0.921\n",
            "3-253th: train loss: 1.50057, train acc: 0.991 valid loss: 1.56939 valid acc: 0.921\n",
            "3-254th: train loss: 1.50041, train acc: 0.991 valid loss: 1.56938 valid acc: 0.921\n",
            "3-255th: train loss: 1.50025, train acc: 0.991 valid loss: 1.56934 valid acc: 0.921\n",
            "3-256th: train loss: 1.50009, train acc: 0.991 valid loss: 1.56928 valid acc: 0.921\n",
            "3-257th: train loss: 1.49994, train acc: 0.991 valid loss: 1.56922 valid acc: 0.921\n",
            "3-258th: train loss: 1.49979, train acc: 0.991 valid loss: 1.56915 valid acc: 0.921\n",
            "3-259th: train loss: 1.49964, train acc: 0.991 valid loss: 1.56909 valid acc: 0.921\n",
            "3-260th: train loss: 1.49949, train acc: 0.991 valid loss: 1.56902 valid acc: 0.921\n",
            "3-261th: train loss: 1.49934, train acc: 0.991 valid loss: 1.56895 valid acc: 0.921\n",
            "3-262th: train loss: 1.49920, train acc: 0.991 valid loss: 1.56886 valid acc: 0.921\n",
            "3-263th: train loss: 1.49906, train acc: 0.991 valid loss: 1.56879 valid acc: 0.921\n",
            "3-264th: train loss: 1.49892, train acc: 0.991 valid loss: 1.56875 valid acc: 0.921\n",
            "3-265th: train loss: 1.49878, train acc: 0.991 valid loss: 1.56872 valid acc: 0.921\n",
            "3-266th: train loss: 1.49864, train acc: 0.991 valid loss: 1.56868 valid acc: 0.921\n",
            "3-267th: train loss: 1.49851, train acc: 0.991 valid loss: 1.56863 valid acc: 0.921\n",
            "3-268th: train loss: 1.49838, train acc: 0.991 valid loss: 1.56859 valid acc: 0.921\n",
            "3-269th: train loss: 1.49825, train acc: 0.991 valid loss: 1.56856 valid acc: 0.921\n",
            "3-270th: train loss: 1.49812, train acc: 0.991 valid loss: 1.56856 valid acc: 0.921\n",
            "3-271th: train loss: 1.49799, train acc: 0.991 valid loss: 1.56856 valid acc: 0.921\n",
            "3-272th: train loss: 1.49786, train acc: 0.991 valid loss: 1.56854 valid acc: 0.921\n",
            "3-273th: train loss: 1.49774, train acc: 0.991 valid loss: 1.56850 valid acc: 0.921\n",
            "3-274th: train loss: 1.49762, train acc: 0.991 valid loss: 1.56845 valid acc: 0.921\n",
            "3-275th: train loss: 1.49750, train acc: 0.991 valid loss: 1.56841 valid acc: 0.921\n",
            "3-276th: train loss: 1.49738, train acc: 0.991 valid loss: 1.56838 valid acc: 0.921\n",
            "3-277th: train loss: 1.49726, train acc: 0.992 valid loss: 1.56834 valid acc: 0.921\n",
            "3-278th: train loss: 1.49714, train acc: 0.992 valid loss: 1.56830 valid acc: 0.921\n",
            "3-279th: train loss: 1.49702, train acc: 0.992 valid loss: 1.56825 valid acc: 0.921\n",
            "3-280th: train loss: 1.49691, train acc: 0.992 valid loss: 1.56818 valid acc: 0.921\n",
            "3-281th: train loss: 1.49680, train acc: 0.992 valid loss: 1.56812 valid acc: 0.921\n",
            "3-282th: train loss: 1.49668, train acc: 0.992 valid loss: 1.56808 valid acc: 0.925\n",
            "3-283th: train loss: 1.49657, train acc: 0.993 valid loss: 1.56805 valid acc: 0.928\n",
            "3-284th: train loss: 1.49646, train acc: 0.993 valid loss: 1.56802 valid acc: 0.928\n",
            "3-285th: train loss: 1.49636, train acc: 0.993 valid loss: 1.56797 valid acc: 0.925\n",
            "3-286th: train loss: 1.49625, train acc: 0.993 valid loss: 1.56792 valid acc: 0.925\n",
            "3-287th: train loss: 1.49614, train acc: 0.993 valid loss: 1.56787 valid acc: 0.925\n",
            "3-288th: train loss: 1.49604, train acc: 0.993 valid loss: 1.56783 valid acc: 0.925\n",
            "3-289th: train loss: 1.49594, train acc: 0.993 valid loss: 1.56781 valid acc: 0.925\n",
            "3-290th: train loss: 1.49583, train acc: 0.993 valid loss: 1.56778 valid acc: 0.925\n",
            "3-291th: train loss: 1.49573, train acc: 0.993 valid loss: 1.56774 valid acc: 0.928\n",
            "3-292th: train loss: 1.49563, train acc: 0.993 valid loss: 1.56769 valid acc: 0.928\n",
            "3-293th: train loss: 1.49553, train acc: 0.993 valid loss: 1.56764 valid acc: 0.928\n",
            "3-294th: train loss: 1.49543, train acc: 0.993 valid loss: 1.56760 valid acc: 0.928\n",
            "3-295th: train loss: 1.49534, train acc: 0.993 valid loss: 1.56756 valid acc: 0.928\n",
            "3-296th: train loss: 1.49524, train acc: 0.993 valid loss: 1.56751 valid acc: 0.928\n",
            "3-297th: train loss: 1.49515, train acc: 0.993 valid loss: 1.56747 valid acc: 0.928\n",
            "3-298th: train loss: 1.49505, train acc: 0.993 valid loss: 1.56742 valid acc: 0.928\n",
            "3-299th: train loss: 1.49496, train acc: 0.994 valid loss: 1.56737 valid acc: 0.928\n",
            "4-0th: train loss: 2.33047, train acc: 0.084 valid loss: 2.26490 valid acc: 0.170\n",
            "4-1th: train loss: 2.25639, train acc: 0.173 valid loss: 2.18108 valid acc: 0.299\n",
            "4-2th: train loss: 2.17377, train acc: 0.304 valid loss: 2.10862 valid acc: 0.390\n",
            "4-3th: train loss: 2.09746, train acc: 0.385 valid loss: 2.06447 valid acc: 0.425\n",
            "4-4th: train loss: 2.05200, train acc: 0.433 valid loss: 2.03584 valid acc: 0.456\n",
            "4-5th: train loss: 2.00793, train acc: 0.485 valid loss: 2.01363 valid acc: 0.462\n",
            "4-6th: train loss: 1.97362, train acc: 0.519 valid loss: 1.99513 valid acc: 0.509\n",
            "4-7th: train loss: 1.95000, train acc: 0.544 valid loss: 1.97835 valid acc: 0.516\n",
            "4-8th: train loss: 1.92923, train acc: 0.565 valid loss: 1.96330 valid acc: 0.513\n",
            "4-9th: train loss: 1.91139, train acc: 0.580 valid loss: 1.94874 valid acc: 0.538\n",
            "4-10th: train loss: 1.89628, train acc: 0.596 valid loss: 1.93861 valid acc: 0.572\n",
            "4-11th: train loss: 1.88633, train acc: 0.607 valid loss: 1.93007 valid acc: 0.585\n",
            "4-12th: train loss: 1.87767, train acc: 0.620 valid loss: 1.92071 valid acc: 0.597\n",
            "4-13th: train loss: 1.86835, train acc: 0.627 valid loss: 1.91436 valid acc: 0.582\n",
            "4-14th: train loss: 1.86124, train acc: 0.633 valid loss: 1.90962 valid acc: 0.591\n",
            "4-15th: train loss: 1.85558, train acc: 0.638 valid loss: 1.90375 valid acc: 0.604\n",
            "4-16th: train loss: 1.85043, train acc: 0.647 valid loss: 1.89738 valid acc: 0.610\n",
            "4-17th: train loss: 1.84531, train acc: 0.650 valid loss: 1.89218 valid acc: 0.610\n",
            "4-18th: train loss: 1.84048, train acc: 0.652 valid loss: 1.88910 valid acc: 0.607\n",
            "4-19th: train loss: 1.83672, train acc: 0.653 valid loss: 1.88615 valid acc: 0.610\n",
            "4-20th: train loss: 1.83293, train acc: 0.652 valid loss: 1.88236 valid acc: 0.619\n",
            "4-21th: train loss: 1.82935, train acc: 0.657 valid loss: 1.87821 valid acc: 0.619\n",
            "4-22th: train loss: 1.82630, train acc: 0.660 valid loss: 1.87411 valid acc: 0.623\n",
            "4-23th: train loss: 1.82317, train acc: 0.660 valid loss: 1.87098 valid acc: 0.616\n",
            "4-24th: train loss: 1.82041, train acc: 0.660 valid loss: 1.86854 valid acc: 0.623\n",
            "4-25th: train loss: 1.81792, train acc: 0.662 valid loss: 1.86593 valid acc: 0.629\n",
            "4-26th: train loss: 1.81507, train acc: 0.664 valid loss: 1.86318 valid acc: 0.632\n",
            "4-27th: train loss: 1.81182, train acc: 0.667 valid loss: 1.85963 valid acc: 0.632\n",
            "4-28th: train loss: 1.80752, train acc: 0.667 valid loss: 1.85111 valid acc: 0.642\n",
            "4-29th: train loss: 1.79694, train acc: 0.678 valid loss: 1.82409 valid acc: 0.682\n",
            "4-30th: train loss: 1.76247, train acc: 0.741 valid loss: 1.82381 valid acc: 0.682\n",
            "4-31th: train loss: 1.76082, train acc: 0.737 valid loss: 1.80865 valid acc: 0.698\n",
            "4-32th: train loss: 1.74930, train acc: 0.743 valid loss: 1.77957 valid acc: 0.730\n",
            "4-33th: train loss: 1.72412, train acc: 0.769 valid loss: 1.77580 valid acc: 0.736\n",
            "4-34th: train loss: 1.71918, train acc: 0.783 valid loss: 1.77450 valid acc: 0.739\n",
            "4-35th: train loss: 1.71458, train acc: 0.800 valid loss: 1.76478 valid acc: 0.755\n",
            "4-36th: train loss: 1.70283, train acc: 0.816 valid loss: 1.75145 valid acc: 0.761\n",
            "4-37th: train loss: 1.69047, train acc: 0.827 valid loss: 1.74095 valid acc: 0.767\n",
            "4-38th: train loss: 1.68059, train acc: 0.836 valid loss: 1.73220 valid acc: 0.755\n",
            "4-39th: train loss: 1.67159, train acc: 0.843 valid loss: 1.72766 valid acc: 0.764\n",
            "4-40th: train loss: 1.66644, train acc: 0.849 valid loss: 1.72590 valid acc: 0.770\n",
            "4-41th: train loss: 1.66385, train acc: 0.845 valid loss: 1.72376 valid acc: 0.770\n",
            "4-42th: train loss: 1.66066, train acc: 0.847 valid loss: 1.72004 valid acc: 0.780\n",
            "4-43th: train loss: 1.65614, train acc: 0.853 valid loss: 1.71637 valid acc: 0.792\n",
            "4-44th: train loss: 1.65205, train acc: 0.855 valid loss: 1.71489 valid acc: 0.796\n",
            "4-45th: train loss: 1.65004, train acc: 0.859 valid loss: 1.71416 valid acc: 0.792\n",
            "4-46th: train loss: 1.64860, train acc: 0.861 valid loss: 1.71224 valid acc: 0.799\n",
            "4-47th: train loss: 1.64608, train acc: 0.862 valid loss: 1.71016 valid acc: 0.802\n",
            "4-48th: train loss: 1.64324, train acc: 0.862 valid loss: 1.70844 valid acc: 0.792\n",
            "4-49th: train loss: 1.64071, train acc: 0.864 valid loss: 1.70608 valid acc: 0.796\n",
            "4-50th: train loss: 1.63801, train acc: 0.864 valid loss: 1.70305 valid acc: 0.802\n",
            "4-51th: train loss: 1.63531, train acc: 0.865 valid loss: 1.70061 valid acc: 0.805\n",
            "4-52th: train loss: 1.63320, train acc: 0.868 valid loss: 1.69935 valid acc: 0.814\n",
            "4-53th: train loss: 1.63155, train acc: 0.869 valid loss: 1.69860 valid acc: 0.811\n",
            "4-54th: train loss: 1.62980, train acc: 0.870 valid loss: 1.69770 valid acc: 0.811\n",
            "4-55th: train loss: 1.62781, train acc: 0.871 valid loss: 1.69642 valid acc: 0.818\n",
            "4-56th: train loss: 1.62589, train acc: 0.871 valid loss: 1.69488 valid acc: 0.814\n",
            "4-57th: train loss: 1.62424, train acc: 0.871 valid loss: 1.69352 valid acc: 0.821\n",
            "4-58th: train loss: 1.62293, train acc: 0.872 valid loss: 1.69245 valid acc: 0.818\n",
            "4-59th: train loss: 1.62181, train acc: 0.872 valid loss: 1.69134 valid acc: 0.821\n",
            "4-60th: train loss: 1.62055, train acc: 0.873 valid loss: 1.69002 valid acc: 0.818\n",
            "4-61th: train loss: 1.61915, train acc: 0.874 valid loss: 1.68863 valid acc: 0.814\n",
            "4-62th: train loss: 1.61789, train acc: 0.875 valid loss: 1.68724 valid acc: 0.818\n",
            "4-63th: train loss: 1.61689, train acc: 0.875 valid loss: 1.68580 valid acc: 0.824\n",
            "4-64th: train loss: 1.61608, train acc: 0.875 valid loss: 1.68424 valid acc: 0.836\n",
            "4-65th: train loss: 1.61524, train acc: 0.875 valid loss: 1.68267 valid acc: 0.833\n",
            "4-66th: train loss: 1.61425, train acc: 0.876 valid loss: 1.68139 valid acc: 0.830\n",
            "4-67th: train loss: 1.61326, train acc: 0.875 valid loss: 1.68054 valid acc: 0.827\n",
            "4-68th: train loss: 1.61238, train acc: 0.876 valid loss: 1.67992 valid acc: 0.830\n",
            "4-69th: train loss: 1.61156, train acc: 0.877 valid loss: 1.67922 valid acc: 0.830\n",
            "4-70th: train loss: 1.61075, train acc: 0.877 valid loss: 1.67829 valid acc: 0.833\n",
            "4-71th: train loss: 1.60994, train acc: 0.880 valid loss: 1.67721 valid acc: 0.833\n",
            "4-72th: train loss: 1.60917, train acc: 0.882 valid loss: 1.67613 valid acc: 0.833\n",
            "4-73th: train loss: 1.60842, train acc: 0.882 valid loss: 1.67511 valid acc: 0.833\n",
            "4-74th: train loss: 1.60768, train acc: 0.884 valid loss: 1.67422 valid acc: 0.833\n",
            "4-75th: train loss: 1.60699, train acc: 0.885 valid loss: 1.67344 valid acc: 0.833\n",
            "4-76th: train loss: 1.60640, train acc: 0.885 valid loss: 1.67266 valid acc: 0.836\n",
            "4-77th: train loss: 1.60584, train acc: 0.885 valid loss: 1.67191 valid acc: 0.836\n",
            "4-78th: train loss: 1.60524, train acc: 0.885 valid loss: 1.67135 valid acc: 0.836\n",
            "4-79th: train loss: 1.60463, train acc: 0.885 valid loss: 1.67106 valid acc: 0.833\n",
            "4-80th: train loss: 1.60406, train acc: 0.885 valid loss: 1.67091 valid acc: 0.830\n",
            "4-81th: train loss: 1.60353, train acc: 0.885 valid loss: 1.67066 valid acc: 0.833\n",
            "4-82th: train loss: 1.60303, train acc: 0.885 valid loss: 1.67012 valid acc: 0.833\n",
            "4-83th: train loss: 1.60250, train acc: 0.885 valid loss: 1.66935 valid acc: 0.833\n",
            "4-84th: train loss: 1.60197, train acc: 0.885 valid loss: 1.66856 valid acc: 0.840\n",
            "4-85th: train loss: 1.60147, train acc: 0.885 valid loss: 1.66789 valid acc: 0.843\n",
            "4-86th: train loss: 1.60099, train acc: 0.885 valid loss: 1.66739 valid acc: 0.843\n",
            "4-87th: train loss: 1.60053, train acc: 0.885 valid loss: 1.66699 valid acc: 0.840\n",
            "4-88th: train loss: 1.60007, train acc: 0.885 valid loss: 1.66660 valid acc: 0.843\n",
            "4-89th: train loss: 1.59961, train acc: 0.885 valid loss: 1.66622 valid acc: 0.846\n",
            "4-90th: train loss: 1.59917, train acc: 0.885 valid loss: 1.66588 valid acc: 0.843\n",
            "4-91th: train loss: 1.59873, train acc: 0.885 valid loss: 1.66557 valid acc: 0.843\n",
            "4-92th: train loss: 1.59828, train acc: 0.885 valid loss: 1.66530 valid acc: 0.836\n",
            "4-93th: train loss: 1.59782, train acc: 0.886 valid loss: 1.66500 valid acc: 0.836\n",
            "4-94th: train loss: 1.59735, train acc: 0.886 valid loss: 1.66464 valid acc: 0.840\n",
            "4-95th: train loss: 1.59681, train acc: 0.886 valid loss: 1.66423 valid acc: 0.840\n",
            "4-96th: train loss: 1.59616, train acc: 0.887 valid loss: 1.66383 valid acc: 0.840\n",
            "4-97th: train loss: 1.59525, train acc: 0.887 valid loss: 1.66341 valid acc: 0.843\n",
            "4-98th: train loss: 1.59371, train acc: 0.889 valid loss: 1.66264 valid acc: 0.840\n",
            "4-99th: train loss: 1.59044, train acc: 0.896 valid loss: 1.66017 valid acc: 0.836\n",
            "4-100th: train loss: 1.58342, train acc: 0.908 valid loss: 1.65619 valid acc: 0.871\n",
            "4-101th: train loss: 1.57640, train acc: 0.933 valid loss: 1.65458 valid acc: 0.865\n",
            "4-102th: train loss: 1.57534, train acc: 0.944 valid loss: 1.63787 valid acc: 0.884\n",
            "4-103th: train loss: 1.55960, train acc: 0.949 valid loss: 1.63380 valid acc: 0.874\n",
            "4-104th: train loss: 1.55650, train acc: 0.943 valid loss: 1.62515 valid acc: 0.896\n",
            "4-105th: train loss: 1.54991, train acc: 0.951 valid loss: 1.61969 valid acc: 0.899\n",
            "4-106th: train loss: 1.54507, train acc: 0.969 valid loss: 1.62267 valid acc: 0.887\n",
            "4-107th: train loss: 1.54628, train acc: 0.969 valid loss: 1.61863 valid acc: 0.884\n",
            "4-108th: train loss: 1.54280, train acc: 0.968 valid loss: 1.61497 valid acc: 0.896\n",
            "4-109th: train loss: 1.54121, train acc: 0.966 valid loss: 1.61307 valid acc: 0.899\n",
            "4-110th: train loss: 1.54035, train acc: 0.965 valid loss: 1.61124 valid acc: 0.909\n",
            "4-111th: train loss: 1.53832, train acc: 0.970 valid loss: 1.60994 valid acc: 0.903\n",
            "4-112th: train loss: 1.53583, train acc: 0.975 valid loss: 1.60949 valid acc: 0.896\n",
            "4-113th: train loss: 1.53474, train acc: 0.975 valid loss: 1.60693 valid acc: 0.909\n",
            "4-114th: train loss: 1.53301, train acc: 0.975 valid loss: 1.60408 valid acc: 0.906\n",
            "4-115th: train loss: 1.53138, train acc: 0.974 valid loss: 1.60207 valid acc: 0.909\n",
            "4-116th: train loss: 1.53007, train acc: 0.976 valid loss: 1.60087 valid acc: 0.909\n",
            "4-117th: train loss: 1.52880, train acc: 0.975 valid loss: 1.60015 valid acc: 0.903\n",
            "4-118th: train loss: 1.52780, train acc: 0.976 valid loss: 1.59848 valid acc: 0.909\n",
            "4-119th: train loss: 1.52627, train acc: 0.977 valid loss: 1.59734 valid acc: 0.915\n",
            "4-120th: train loss: 1.52532, train acc: 0.977 valid loss: 1.59669 valid acc: 0.915\n",
            "4-121th: train loss: 1.52438, train acc: 0.976 valid loss: 1.59616 valid acc: 0.912\n",
            "4-122th: train loss: 1.52308, train acc: 0.976 valid loss: 1.59651 valid acc: 0.912\n",
            "4-123th: train loss: 1.52241, train acc: 0.977 valid loss: 1.59630 valid acc: 0.906\n",
            "4-124th: train loss: 1.52170, train acc: 0.978 valid loss: 1.59503 valid acc: 0.912\n",
            "4-125th: train loss: 1.52072, train acc: 0.980 valid loss: 1.59381 valid acc: 0.915\n",
            "4-126th: train loss: 1.52005, train acc: 0.980 valid loss: 1.59301 valid acc: 0.915\n",
            "4-127th: train loss: 1.51946, train acc: 0.980 valid loss: 1.59251 valid acc: 0.915\n",
            "4-128th: train loss: 1.51870, train acc: 0.981 valid loss: 1.59224 valid acc: 0.912\n",
            "4-129th: train loss: 1.51796, train acc: 0.980 valid loss: 1.59193 valid acc: 0.912\n",
            "4-130th: train loss: 1.51746, train acc: 0.982 valid loss: 1.59113 valid acc: 0.918\n",
            "4-131th: train loss: 1.51688, train acc: 0.984 valid loss: 1.59009 valid acc: 0.915\n",
            "4-132th: train loss: 1.51623, train acc: 0.984 valid loss: 1.58939 valid acc: 0.915\n",
            "4-133th: train loss: 1.51581, train acc: 0.984 valid loss: 1.58880 valid acc: 0.918\n",
            "4-134th: train loss: 1.51530, train acc: 0.985 valid loss: 1.58828 valid acc: 0.918\n",
            "4-135th: train loss: 1.51476, train acc: 0.984 valid loss: 1.58788 valid acc: 0.918\n",
            "4-136th: train loss: 1.51434, train acc: 0.985 valid loss: 1.58736 valid acc: 0.918\n",
            "4-137th: train loss: 1.51384, train acc: 0.985 valid loss: 1.58678 valid acc: 0.921\n",
            "4-138th: train loss: 1.51337, train acc: 0.986 valid loss: 1.58619 valid acc: 0.921\n",
            "4-139th: train loss: 1.51295, train acc: 0.986 valid loss: 1.58568 valid acc: 0.921\n",
            "4-140th: train loss: 1.51252, train acc: 0.986 valid loss: 1.58529 valid acc: 0.925\n",
            "4-141th: train loss: 1.51211, train acc: 0.987 valid loss: 1.58500 valid acc: 0.925\n",
            "4-142th: train loss: 1.51172, train acc: 0.987 valid loss: 1.58479 valid acc: 0.921\n",
            "4-143th: train loss: 1.51137, train acc: 0.987 valid loss: 1.58450 valid acc: 0.921\n",
            "4-144th: train loss: 1.51100, train acc: 0.987 valid loss: 1.58416 valid acc: 0.925\n",
            "4-145th: train loss: 1.51065, train acc: 0.987 valid loss: 1.58385 valid acc: 0.925\n",
            "4-146th: train loss: 1.51034, train acc: 0.987 valid loss: 1.58350 valid acc: 0.925\n",
            "4-147th: train loss: 1.51000, train acc: 0.987 valid loss: 1.58313 valid acc: 0.925\n",
            "4-148th: train loss: 1.50968, train acc: 0.988 valid loss: 1.58280 valid acc: 0.921\n",
            "4-149th: train loss: 1.50937, train acc: 0.989 valid loss: 1.58245 valid acc: 0.921\n",
            "4-150th: train loss: 1.50906, train acc: 0.988 valid loss: 1.58208 valid acc: 0.921\n",
            "4-151th: train loss: 1.50876, train acc: 0.988 valid loss: 1.58173 valid acc: 0.921\n",
            "4-152th: train loss: 1.50846, train acc: 0.989 valid loss: 1.58146 valid acc: 0.921\n",
            "4-153th: train loss: 1.50817, train acc: 0.989 valid loss: 1.58128 valid acc: 0.921\n",
            "4-154th: train loss: 1.50790, train acc: 0.989 valid loss: 1.58112 valid acc: 0.921\n",
            "4-155th: train loss: 1.50761, train acc: 0.989 valid loss: 1.58091 valid acc: 0.921\n",
            "4-156th: train loss: 1.50735, train acc: 0.989 valid loss: 1.58062 valid acc: 0.921\n",
            "4-157th: train loss: 1.50709, train acc: 0.989 valid loss: 1.58031 valid acc: 0.921\n",
            "4-158th: train loss: 1.50684, train acc: 0.989 valid loss: 1.58009 valid acc: 0.921\n",
            "4-159th: train loss: 1.50660, train acc: 0.989 valid loss: 1.57996 valid acc: 0.921\n",
            "4-160th: train loss: 1.50635, train acc: 0.990 valid loss: 1.57990 valid acc: 0.921\n",
            "4-161th: train loss: 1.50611, train acc: 0.990 valid loss: 1.57984 valid acc: 0.921\n",
            "4-162th: train loss: 1.50589, train acc: 0.990 valid loss: 1.57973 valid acc: 0.921\n",
            "4-163th: train loss: 1.50566, train acc: 0.990 valid loss: 1.57958 valid acc: 0.921\n",
            "4-164th: train loss: 1.50543, train acc: 0.990 valid loss: 1.57945 valid acc: 0.921\n",
            "4-165th: train loss: 1.50521, train acc: 0.990 valid loss: 1.57934 valid acc: 0.921\n",
            "4-166th: train loss: 1.50500, train acc: 0.990 valid loss: 1.57926 valid acc: 0.921\n",
            "4-167th: train loss: 1.50478, train acc: 0.990 valid loss: 1.57917 valid acc: 0.921\n",
            "4-168th: train loss: 1.50457, train acc: 0.990 valid loss: 1.57906 valid acc: 0.921\n",
            "4-169th: train loss: 1.50437, train acc: 0.990 valid loss: 1.57892 valid acc: 0.921\n",
            "4-170th: train loss: 1.50417, train acc: 0.990 valid loss: 1.57876 valid acc: 0.921\n",
            "4-171th: train loss: 1.50397, train acc: 0.990 valid loss: 1.57861 valid acc: 0.921\n",
            "4-172th: train loss: 1.50378, train acc: 0.990 valid loss: 1.57848 valid acc: 0.921\n",
            "4-173th: train loss: 1.50359, train acc: 0.990 valid loss: 1.57837 valid acc: 0.921\n",
            "4-174th: train loss: 1.50340, train acc: 0.990 valid loss: 1.57827 valid acc: 0.921\n",
            "4-175th: train loss: 1.50322, train acc: 0.990 valid loss: 1.57816 valid acc: 0.921\n",
            "4-176th: train loss: 1.50304, train acc: 0.990 valid loss: 1.57804 valid acc: 0.921\n",
            "4-177th: train loss: 1.50286, train acc: 0.990 valid loss: 1.57793 valid acc: 0.921\n",
            "4-178th: train loss: 1.50269, train acc: 0.990 valid loss: 1.57783 valid acc: 0.921\n",
            "4-179th: train loss: 1.50252, train acc: 0.990 valid loss: 1.57775 valid acc: 0.921\n",
            "4-180th: train loss: 1.50235, train acc: 0.990 valid loss: 1.57768 valid acc: 0.921\n",
            "4-181th: train loss: 1.50219, train acc: 0.990 valid loss: 1.57759 valid acc: 0.925\n",
            "4-182th: train loss: 1.50202, train acc: 0.991 valid loss: 1.57751 valid acc: 0.925\n",
            "4-183th: train loss: 1.50186, train acc: 0.991 valid loss: 1.57743 valid acc: 0.925\n",
            "4-184th: train loss: 1.50171, train acc: 0.991 valid loss: 1.57737 valid acc: 0.925\n",
            "4-185th: train loss: 1.50155, train acc: 0.991 valid loss: 1.57734 valid acc: 0.925\n",
            "4-186th: train loss: 1.50140, train acc: 0.991 valid loss: 1.57730 valid acc: 0.925\n",
            "4-187th: train loss: 1.50125, train acc: 0.991 valid loss: 1.57724 valid acc: 0.928\n",
            "4-188th: train loss: 1.50110, train acc: 0.991 valid loss: 1.57715 valid acc: 0.928\n",
            "4-189th: train loss: 1.50096, train acc: 0.991 valid loss: 1.57706 valid acc: 0.928\n",
            "4-190th: train loss: 1.50081, train acc: 0.991 valid loss: 1.57699 valid acc: 0.928\n",
            "4-191th: train loss: 1.50067, train acc: 0.991 valid loss: 1.57695 valid acc: 0.928\n",
            "4-192th: train loss: 1.50053, train acc: 0.991 valid loss: 1.57692 valid acc: 0.928\n",
            "4-193th: train loss: 1.50040, train acc: 0.991 valid loss: 1.57687 valid acc: 0.928\n",
            "4-194th: train loss: 1.50026, train acc: 0.991 valid loss: 1.57680 valid acc: 0.928\n",
            "4-195th: train loss: 1.50013, train acc: 0.991 valid loss: 1.57673 valid acc: 0.928\n",
            "4-196th: train loss: 1.50000, train acc: 0.991 valid loss: 1.57668 valid acc: 0.928\n",
            "4-197th: train loss: 1.49987, train acc: 0.991 valid loss: 1.57664 valid acc: 0.928\n",
            "4-198th: train loss: 1.49974, train acc: 0.991 valid loss: 1.57660 valid acc: 0.928\n",
            "4-199th: train loss: 1.49961, train acc: 0.991 valid loss: 1.57656 valid acc: 0.928\n",
            "4-200th: train loss: 1.49949, train acc: 0.991 valid loss: 1.57650 valid acc: 0.928\n",
            "4-201th: train loss: 1.49937, train acc: 0.991 valid loss: 1.57644 valid acc: 0.928\n",
            "4-202th: train loss: 1.49925, train acc: 0.991 valid loss: 1.57639 valid acc: 0.928\n",
            "4-203th: train loss: 1.49913, train acc: 0.991 valid loss: 1.57634 valid acc: 0.928\n",
            "4-204th: train loss: 1.49901, train acc: 0.991 valid loss: 1.57629 valid acc: 0.925\n",
            "4-205th: train loss: 1.49889, train acc: 0.991 valid loss: 1.57624 valid acc: 0.925\n",
            "4-206th: train loss: 1.49878, train acc: 0.991 valid loss: 1.57618 valid acc: 0.925\n",
            "4-207th: train loss: 1.49866, train acc: 0.991 valid loss: 1.57612 valid acc: 0.925\n",
            "4-208th: train loss: 1.49855, train acc: 0.991 valid loss: 1.57606 valid acc: 0.925\n",
            "4-209th: train loss: 1.49844, train acc: 0.991 valid loss: 1.57601 valid acc: 0.925\n",
            "4-210th: train loss: 1.49833, train acc: 0.991 valid loss: 1.57595 valid acc: 0.925\n",
            "4-211th: train loss: 1.49822, train acc: 0.991 valid loss: 1.57589 valid acc: 0.925\n",
            "4-212th: train loss: 1.49811, train acc: 0.991 valid loss: 1.57584 valid acc: 0.925\n",
            "4-213th: train loss: 1.49800, train acc: 0.991 valid loss: 1.57578 valid acc: 0.925\n",
            "4-214th: train loss: 1.49790, train acc: 0.991 valid loss: 1.57573 valid acc: 0.925\n",
            "4-215th: train loss: 1.49779, train acc: 0.991 valid loss: 1.57568 valid acc: 0.925\n",
            "4-216th: train loss: 1.49769, train acc: 0.991 valid loss: 1.57563 valid acc: 0.925\n",
            "4-217th: train loss: 1.49759, train acc: 0.991 valid loss: 1.57559 valid acc: 0.925\n",
            "4-218th: train loss: 1.49749, train acc: 0.991 valid loss: 1.57555 valid acc: 0.925\n",
            "4-219th: train loss: 1.49739, train acc: 0.991 valid loss: 1.57550 valid acc: 0.925\n",
            "4-220th: train loss: 1.49729, train acc: 0.991 valid loss: 1.57545 valid acc: 0.925\n",
            "4-221th: train loss: 1.49719, train acc: 0.991 valid loss: 1.57540 valid acc: 0.925\n",
            "4-222th: train loss: 1.49709, train acc: 0.991 valid loss: 1.57535 valid acc: 0.925\n",
            "4-223th: train loss: 1.49699, train acc: 0.991 valid loss: 1.57532 valid acc: 0.925\n",
            "4-224th: train loss: 1.49690, train acc: 0.991 valid loss: 1.57528 valid acc: 0.925\n",
            "4-225th: train loss: 1.49680, train acc: 0.991 valid loss: 1.57523 valid acc: 0.925\n",
            "4-226th: train loss: 1.49671, train acc: 0.991 valid loss: 1.57518 valid acc: 0.925\n",
            "4-227th: train loss: 1.49661, train acc: 0.991 valid loss: 1.57514 valid acc: 0.925\n",
            "4-228th: train loss: 1.49652, train acc: 0.991 valid loss: 1.57509 valid acc: 0.925\n",
            "4-229th: train loss: 1.49643, train acc: 0.991 valid loss: 1.57506 valid acc: 0.925\n",
            "4-230th: train loss: 1.49634, train acc: 0.991 valid loss: 1.57502 valid acc: 0.925\n",
            "4-231th: train loss: 1.49625, train acc: 0.991 valid loss: 1.57497 valid acc: 0.925\n",
            "4-232th: train loss: 1.49616, train acc: 0.991 valid loss: 1.57493 valid acc: 0.925\n",
            "4-233th: train loss: 1.49607, train acc: 0.991 valid loss: 1.57489 valid acc: 0.925\n",
            "4-234th: train loss: 1.49598, train acc: 0.991 valid loss: 1.57486 valid acc: 0.925\n",
            "4-235th: train loss: 1.49590, train acc: 0.991 valid loss: 1.57482 valid acc: 0.925\n",
            "4-236th: train loss: 1.49581, train acc: 0.991 valid loss: 1.57479 valid acc: 0.925\n",
            "4-237th: train loss: 1.49572, train acc: 0.991 valid loss: 1.57475 valid acc: 0.925\n",
            "4-238th: train loss: 1.49564, train acc: 0.991 valid loss: 1.57472 valid acc: 0.925\n",
            "4-239th: train loss: 1.49555, train acc: 0.991 valid loss: 1.57469 valid acc: 0.925\n",
            "4-240th: train loss: 1.49547, train acc: 0.991 valid loss: 1.57466 valid acc: 0.925\n",
            "4-241th: train loss: 1.49538, train acc: 0.991 valid loss: 1.57463 valid acc: 0.925\n",
            "4-242th: train loss: 1.49530, train acc: 0.991 valid loss: 1.57460 valid acc: 0.925\n",
            "4-243th: train loss: 1.49522, train acc: 0.991 valid loss: 1.57457 valid acc: 0.925\n",
            "4-244th: train loss: 1.49514, train acc: 0.991 valid loss: 1.57454 valid acc: 0.925\n",
            "4-245th: train loss: 1.49505, train acc: 0.991 valid loss: 1.57451 valid acc: 0.925\n",
            "4-246th: train loss: 1.49497, train acc: 0.991 valid loss: 1.57449 valid acc: 0.925\n",
            "4-247th: train loss: 1.49489, train acc: 0.991 valid loss: 1.57446 valid acc: 0.925\n",
            "4-248th: train loss: 1.49481, train acc: 0.991 valid loss: 1.57444 valid acc: 0.925\n",
            "4-249th: train loss: 1.49473, train acc: 0.991 valid loss: 1.57441 valid acc: 0.925\n",
            "4-250th: train loss: 1.49465, train acc: 0.991 valid loss: 1.57439 valid acc: 0.925\n",
            "4-251th: train loss: 1.49458, train acc: 0.992 valid loss: 1.57436 valid acc: 0.925\n",
            "4-252th: train loss: 1.49450, train acc: 0.992 valid loss: 1.57433 valid acc: 0.925\n",
            "4-253th: train loss: 1.49442, train acc: 0.992 valid loss: 1.57430 valid acc: 0.925\n",
            "4-254th: train loss: 1.49435, train acc: 0.992 valid loss: 1.57428 valid acc: 0.925\n",
            "4-255th: train loss: 1.49427, train acc: 0.992 valid loss: 1.57425 valid acc: 0.925\n",
            "4-256th: train loss: 1.49420, train acc: 0.992 valid loss: 1.57422 valid acc: 0.925\n",
            "4-257th: train loss: 1.49412, train acc: 0.992 valid loss: 1.57419 valid acc: 0.925\n",
            "4-258th: train loss: 1.49405, train acc: 0.992 valid loss: 1.57415 valid acc: 0.925\n",
            "4-259th: train loss: 1.49398, train acc: 0.992 valid loss: 1.57412 valid acc: 0.925\n",
            "4-260th: train loss: 1.49391, train acc: 0.992 valid loss: 1.57409 valid acc: 0.925\n",
            "4-261th: train loss: 1.49384, train acc: 0.992 valid loss: 1.57405 valid acc: 0.928\n",
            "4-262th: train loss: 1.49377, train acc: 0.992 valid loss: 1.57401 valid acc: 0.928\n",
            "4-263th: train loss: 1.49370, train acc: 0.992 valid loss: 1.57397 valid acc: 0.928\n",
            "4-264th: train loss: 1.49363, train acc: 0.992 valid loss: 1.57393 valid acc: 0.931\n",
            "4-265th: train loss: 1.49356, train acc: 0.992 valid loss: 1.57389 valid acc: 0.931\n",
            "4-266th: train loss: 1.49349, train acc: 0.992 valid loss: 1.57385 valid acc: 0.931\n",
            "4-267th: train loss: 1.49342, train acc: 0.992 valid loss: 1.57380 valid acc: 0.931\n",
            "4-268th: train loss: 1.49336, train acc: 0.992 valid loss: 1.57376 valid acc: 0.931\n",
            "4-269th: train loss: 1.49329, train acc: 0.992 valid loss: 1.57371 valid acc: 0.931\n",
            "4-270th: train loss: 1.49322, train acc: 0.992 valid loss: 1.57366 valid acc: 0.931\n",
            "4-271th: train loss: 1.49316, train acc: 0.992 valid loss: 1.57361 valid acc: 0.931\n",
            "4-272th: train loss: 1.49310, train acc: 0.992 valid loss: 1.57356 valid acc: 0.931\n",
            "4-273th: train loss: 1.49303, train acc: 0.992 valid loss: 1.57352 valid acc: 0.931\n",
            "4-274th: train loss: 1.49297, train acc: 0.992 valid loss: 1.57346 valid acc: 0.931\n",
            "4-275th: train loss: 1.49290, train acc: 0.992 valid loss: 1.57341 valid acc: 0.931\n",
            "4-276th: train loss: 1.49284, train acc: 0.992 valid loss: 1.57336 valid acc: 0.931\n",
            "4-277th: train loss: 1.49278, train acc: 0.992 valid loss: 1.57331 valid acc: 0.931\n",
            "4-278th: train loss: 1.49272, train acc: 0.992 valid loss: 1.57326 valid acc: 0.931\n",
            "4-279th: train loss: 1.49266, train acc: 0.992 valid loss: 1.57320 valid acc: 0.931\n",
            "4-280th: train loss: 1.49260, train acc: 0.992 valid loss: 1.57315 valid acc: 0.931\n",
            "4-281th: train loss: 1.49253, train acc: 0.992 valid loss: 1.57309 valid acc: 0.931\n",
            "4-282th: train loss: 1.49247, train acc: 0.992 valid loss: 1.57304 valid acc: 0.931\n",
            "4-283th: train loss: 1.49241, train acc: 0.992 valid loss: 1.57298 valid acc: 0.931\n",
            "4-284th: train loss: 1.49236, train acc: 0.992 valid loss: 1.57293 valid acc: 0.931\n",
            "4-285th: train loss: 1.49230, train acc: 0.992 valid loss: 1.57287 valid acc: 0.931\n",
            "4-286th: train loss: 1.49224, train acc: 0.992 valid loss: 1.57281 valid acc: 0.931\n",
            "4-287th: train loss: 1.49218, train acc: 0.992 valid loss: 1.57276 valid acc: 0.931\n",
            "4-288th: train loss: 1.49212, train acc: 0.992 valid loss: 1.57270 valid acc: 0.931\n",
            "4-289th: train loss: 1.49206, train acc: 0.992 valid loss: 1.57264 valid acc: 0.931\n",
            "4-290th: train loss: 1.49200, train acc: 0.992 valid loss: 1.57258 valid acc: 0.931\n",
            "4-291th: train loss: 1.49194, train acc: 0.992 valid loss: 1.57253 valid acc: 0.931\n",
            "4-292th: train loss: 1.49188, train acc: 0.992 valid loss: 1.57247 valid acc: 0.931\n",
            "4-293th: train loss: 1.49183, train acc: 0.992 valid loss: 1.57241 valid acc: 0.931\n",
            "4-294th: train loss: 1.49177, train acc: 0.992 valid loss: 1.57235 valid acc: 0.931\n",
            "4-295th: train loss: 1.49171, train acc: 0.992 valid loss: 1.57230 valid acc: 0.931\n",
            "4-296th: train loss: 1.49165, train acc: 0.992 valid loss: 1.57224 valid acc: 0.931\n",
            "4-297th: train loss: 1.49159, train acc: 0.992 valid loss: 1.57218 valid acc: 0.931\n",
            "4-298th: train loss: 1.49153, train acc: 0.992 valid loss: 1.57213 valid acc: 0.931\n",
            "4-299th: train loss: 1.49147, train acc: 0.992 valid loss: 1.57207 valid acc: 0.931\n"
          ]
        }
      ],
      "source": [
        "all_all_tr_loss = []\n",
        "all_all_valid_loss = []\n",
        "all_all_tr_acc = []\n",
        "all_all_valid_acc = []\n",
        "\n",
        "max_epochs = 300\n",
        "lr = 0.005\n",
        "n_fold = 5\n",
        "skf = StratifiedKFold(n_splits=n_fold)\n",
        "for i_fold, (tr, te) in enumerate(skf.split(data, label)):\n",
        "    data_tr, data_te, label_tr, label_te = data[tr].to(device), data[te].to(device), label[tr].to(device), label[te].to(device)\n",
        "    model = torch.nn.Sequential(\n",
        "        QNNModel(),\n",
        "        ConstCoeffLayer(35),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=5e-5)\n",
        "    all_tr_loss = []\n",
        "    all_valid_loss = []\n",
        "    all_tr_acc = []\n",
        "    all_valid_acc = []\n",
        "    for i_epoch in range(max_epochs):\n",
        "        print(f\"{i_fold}-{i_epoch}th:\", end=\" \")\n",
        "        loss_tr, acc_tr = train(data_tr, label_tr, model, optimizer)\n",
        "        loss_valid, acc_valid = valid(data_te, label_te, model)\n",
        "        all_tr_loss.append(loss_tr)\n",
        "        all_valid_loss.append(loss_valid)\n",
        "        all_tr_acc.append(acc_tr)\n",
        "        all_valid_acc.append(acc_valid)\n",
        "        ###\n",
        "    all_all_tr_loss.append(all_tr_loss)\n",
        "    all_all_valid_loss.append(all_valid_loss)\n",
        "    all_all_tr_acc.append(all_tr_acc)\n",
        "    all_all_valid_acc.append(all_valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T22:43:15.354983Z",
          "iopub.status.busy": "2023-12-06T22:43:15.354793Z",
          "iopub.status.idle": "2023-12-06T22:43:15.358333Z",
          "shell.execute_reply": "2023-12-06T22:43:15.357831Z"
        },
        "id": "H9RZHvE3k55h",
        "outputId": "362072fe-044b-4bfa-e118-4569faa08f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train acc: 0.9921507064364207, test acc: 0.9435736677115988, train loss: 1.4918200969696045, valid loss: 1.5487030744552612\n",
            "train acc: 0.9945054945054945, test acc: 0.9310344827586207, train loss: 1.4924414157867432, valid loss: 1.562795639038086\n",
            "train acc: 0.9945054945054945, test acc: 0.9623824451410659, train loss: 1.4919666051864624, valid loss: 1.5370540618896484\n",
            "train acc: 0.9937254901960785, test acc: 0.9276729559748428, train loss: 1.494957447052002, valid loss: 1.5673723220825195\n",
            "train acc: 0.9921568627450981, test acc: 0.9308176100628931, train loss: 1.4914723634719849, valid loss: 1.572070598602295\n",
            "0.9934088096777172 0.9390962323298042\n",
            "0.00106357102833039 0.012855456196946162\n",
            "1.4925315856933594 1.557599139213562\n",
            "0.0012522224111452293 0.012908772374517855\n"
          ]
        }
      ],
      "source": [
        "train_acc = []\n",
        "valid_acc = []\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "for i in range(len(all_all_tr_acc)):\n",
        "    train_acc.append(all_all_tr_acc[i][-1])\n",
        "    valid_acc.append(all_all_valid_acc[i][-1])\n",
        "    train_loss.append(all_all_tr_loss[i][-1])\n",
        "    valid_loss.append(all_all_valid_loss[i][-1])\n",
        "    print(f\"train acc: {train_acc[-1]}, test acc: {valid_acc[-1]}, train loss: {train_loss[-1]}, valid loss: {valid_loss[-1]}\")\n",
        "\n",
        "print( np.mean(train_acc), np.mean(valid_acc) )\n",
        "print( np.std(train_acc), np.std(valid_acc) )\n",
        "print( np.mean(train_loss), np.mean(valid_loss))\n",
        "print( np.std(train_loss), np.std(valid_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T22:43:15.360598Z",
          "iopub.status.busy": "2023-12-06T22:43:15.360408Z",
          "iopub.status.idle": "2023-12-06T22:43:15.410909Z",
          "shell.execute_reply": "2023-12-06T22:43:15.410462Z"
        },
        "id": "DFnNQRLu1tYw"
      },
      "outputs": [],
      "source": [
        "nu0 = model[0].qnn1.n_depth_per_block\n",
        "c0 = int(model[1].coeff)\n",
        "prefix_name = dataset_name+\"_\"+\"qnn\"+str(nu0)+\"_c\"+str(c0)+\"_\"+str(n_qubits)+\"qubits_\"\n",
        "if False:\n",
        "    pd.DataFrame(all_all_tr_acc).to_csv(prefix_name+\"_tr_acc.csv\", index=False)\n",
        "    pd.DataFrame(all_all_valid_acc).to_csv(prefix_name+\"_valid_acc.csv\", index=False)\n",
        "    pd.DataFrame(all_all_tr_loss).to_csv(prefix_name+\"_tr_loss.csv\", index=False)\n",
        "    pd.DataFrame(all_all_valid_loss).to_csv(prefix_name+\"_valid_loss.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz0oPaAQk55i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
