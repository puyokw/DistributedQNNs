{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:22.779683Z",
          "iopub.status.busy": "2023-12-06T08:56:22.779592Z",
          "iopub.status.idle": "2023-12-06T08:56:24.578226Z",
          "shell.execute_reply": "2023-12-06T08:56:24.577785Z"
        },
        "id": "UEv1RLJ01tYq"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import gradcheck\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:24.581862Z",
          "iopub.status.busy": "2023-12-06T08:56:24.581643Z",
          "iopub.status.idle": "2023-12-06T08:56:24.583627Z",
          "shell.execute_reply": "2023-12-06T08:56:24.583278Z"
        },
        "id": "UHp0vfRc1-T_",
        "outputId": "424a5495-7fcc-41d0-e082-e9cc75c019ec"
      },
      "outputs": [],
      "source": [
        "# !pip install torchquantum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:24.587213Z",
          "iopub.status.busy": "2023-12-06T08:56:24.586935Z",
          "iopub.status.idle": "2023-12-06T08:56:26.010716Z",
          "shell.execute_reply": "2023-12-06T08:56:26.010330Z"
        },
        "id": "cDueIyyE1-5L"
      },
      "outputs": [],
      "source": [
        "import torchquantum as tq\n",
        "from torchquantum.measurement import expval_joint_analytical\n",
        "import warnings\n",
        "\n",
        "seed = 1001\n",
        "#random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.set_default_dtype(torch.float32)\n",
        "warnings.simplefilter('ignore', UserWarning)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.013653Z",
          "iopub.status.busy": "2023-12-06T08:56:26.013313Z",
          "iopub.status.idle": "2023-12-06T08:56:26.386525Z",
          "shell.execute_reply": "2023-12-06T08:56:26.385940Z"
        },
        "id": "UKTP2AJ-1tYs",
        "outputId": "a452f3ac-e509-49fe-f066-10a32eae2bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "semeion_data = torchvision.datasets.SEMEION(root='./data', download=True)\n",
        "dataset_name = 'semeion'\n",
        "data, label = semeion_data.data, semeion_data.labels\n",
        "data = data/255*math.pi/4 # pi/2\n",
        "n_qubits = 8\n",
        "n_class = len(np.unique(label))\n",
        "\n",
        "data = data.reshape(-1,data.shape[1]*data.shape[2])\n",
        "data = torch.from_numpy(data)\n",
        "label = torch.from_numpy(label)\n",
        "n_data, n_features = data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.419345Z",
          "iopub.status.busy": "2023-12-06T08:56:26.419160Z",
          "iopub.status.idle": "2023-12-06T08:56:26.421654Z",
          "shell.execute_reply": "2023-12-06T08:56:26.421277Z"
        },
        "id": "YPw4rzwS1tYt"
      },
      "outputs": [],
      "source": [
        "class CoeffLayer(nn.Module):\n",
        "    def __init__(self, coeff):\n",
        "        super().__init__()\n",
        "        self.coeff = torch.nn.Parameter(coeff)\n",
        "    def forward(self, x):\n",
        "        ret = x * self.coeff\n",
        "        return ret\n",
        "\n",
        "class ConstCoeffLayer(nn.Module):\n",
        "    def __init__(self, coeff):\n",
        "        super().__init__()\n",
        "        self.coeff = coeff\n",
        "    def forward(self, x):\n",
        "        ret = x * self.coeff\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.423671Z",
          "iopub.status.busy": "2023-12-06T08:56:26.423478Z",
          "iopub.status.idle": "2023-12-06T08:56:26.431021Z",
          "shell.execute_reply": "2023-12-06T08:56:26.430568Z"
        },
        "id": "k4_zRBXbk55h"
      },
      "outputs": [],
      "source": [
        "# 16x16 =. 4x8x8 = 8x8x4\n",
        "class QNNsubModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        # params is numpy array\n",
        "        super().__init__()\n",
        "        self.n_wires = n_qubits\n",
        "        self.encoder_gates_x = ([tq.functional.rx] * self.n_wires + [tq.functional.ry] * self.n_wires)*2\n",
        "        self.n_block = 3\n",
        "        self.n_depth_per_block = 20\n",
        "        params = np.random.rand( self.n_wires*self.n_depth_per_block*self.n_block*2)*math.pi\n",
        "        self.u_layers = tq.QuantumModuleList()\n",
        "        for j in range(self.n_depth_per_block*self.n_block):\n",
        "            for i in range(self.n_wires):\n",
        "                self.u_layers.append( tq.RX(has_params=True, trainable=True, init_params=params[i+(2*j)*self.n_wires]) )\n",
        "            for i in range(self.n_wires):\n",
        "                self.u_layers.append( tq.RY(has_params=True, trainable=True, init_params=params[i+(2*j+1)*self.n_wires]) )\n",
        "\n",
        "    def forward(self, x):\n",
        "        bsz, nx_features = x.shape\n",
        "        qdev = tq.QuantumDevice(\n",
        "            n_wires=self.n_wires, bsz = bsz, device=x.device, record_op=False\n",
        "        )\n",
        "        n_depth_per_block = self.n_depth_per_block\n",
        "        for d in range(self.n_block-1): # (2,4)\n",
        "            for k in range(n_depth_per_block):\n",
        "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
        "                    for i in range(self.n_wires):\n",
        "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
        "                for i in range(self.n_wires):\n",
        "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "            # data encoding\n",
        "            for j in range(2*d,2*d+2): # (0,2) (2,4)\n",
        "                for k in range(self.n_wires):\n",
        "                    self.encoder_gates_x[k+j*self.n_wires](qdev, wires=k, params=x[:, (k+j*self.n_wires)])\n",
        "            for i in range(self.n_wires):\n",
        "                qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "        for d in range(self.n_block-1,self.n_block): # (4,5)\n",
        "            for k in range(n_depth_per_block):\n",
        "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
        "                    for i in range(self.n_wires):\n",
        "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
        "                if k==n_depth_per_block-1:\n",
        "                    break\n",
        "                for i in range(self.n_wires):\n",
        "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
        "\n",
        "        obs_list = [ expval_joint_analytical(qdev, \"I\"*i+Pauli+\"I\"*(self.n_wires-1-i)) for Pauli in [\"X\",\"Z\"] for i in range(n_class//2)]\n",
        "        ret = torch.stack(obs_list, dim=1)\n",
        "        return ret\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.432949Z",
          "iopub.status.busy": "2023-12-06T08:56:26.432774Z",
          "iopub.status.idle": "2023-12-06T08:56:26.435667Z",
          "shell.execute_reply": "2023-12-06T08:56:26.435280Z"
        },
        "id": "n3w6djyB1tYv"
      },
      "outputs": [],
      "source": [
        "class QNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.qnn0, self.qnn1, self.qnn2, self.qnn3 = QNNsubModel(), QNNsubModel(), QNNsubModel(), QNNsubModel()\n",
        "        self.qnn4, self.qnn5, self.qnn6, self.qnn7 = QNNsubModel(), QNNsubModel(), QNNsubModel(), QNNsubModel()\n",
        "    def forward(self, x):\n",
        "        LEN = 256//8\n",
        "        in_x = [x[:,i*LEN:(i+1)*LEN] for i in range(8)]\n",
        "        ret0, ret1, ret2, ret3 = self.qnn0(in_x[0]), self.qnn1(in_x[1]), self.qnn2(in_x[2]), self.qnn3(in_x[3])\n",
        "        ret4, ret5, ret6, ret7 = self.qnn4(in_x[4]), self.qnn5(in_x[5]), self.qnn6(in_x[6]), self.qnn7(in_x[7]) \n",
        "        ret = ret0 + ret1 + ret2 + ret3 + ret4 + ret5 + ret6 + ret7\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.442298Z",
          "iopub.status.busy": "2023-12-06T08:56:26.442097Z",
          "iopub.status.idle": "2023-12-06T08:56:26.445630Z",
          "shell.execute_reply": "2023-12-06T08:56:26.445212Z"
        },
        "id": "F-7DW09j1tYv"
      },
      "outputs": [],
      "source": [
        "def train(data, label, model, optimizer):\n",
        "    model.train(mode=True)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
        "    acc = (pred.argmax(axis=1) == label).sum().item() / len(label)\n",
        "    # acc = accuracy_score(y_tr, pred.argmax(axis=1).cpu().detach().numpy() )\n",
        "    print(f\"train loss: {loss.item():.5f}, train acc: {acc:.3f}\", end=' ')\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item(), acc\n",
        "\n",
        "def valid(data, label, model):\n",
        "    model.train(mode=False)\n",
        "    with torch.no_grad():\n",
        "        pred = model(data)\n",
        "        loss = torch.nn.CrossEntropyLoss()(pred, label)\n",
        "    acc = (pred.argmax(axis=1) == label).sum().item() / len(label)\n",
        "    # acc = accuracy_score(y_te, pred.argmax(axis=1).cpu().detach().numpy() )\n",
        "    print(f\"valid loss: {loss.item():.5f} valid acc: {acc:.3f}\")\n",
        "    return loss.item(), acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-06T08:56:26.447501Z",
          "iopub.status.busy": "2023-12-06T08:56:26.447318Z",
          "iopub.status.idle": "2023-12-06T22:43:15.347017Z",
          "shell.execute_reply": "2023-12-06T22:43:15.346447Z"
        },
        "id": "MarqNpSo1tYv",
        "outputId": "86cc0213-7f0b-4c6d-e743-658394539f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0-0th: train loss: 2.30898, train acc: 0.108 valid loss: 2.23000 valid acc: 0.304\n",
            "0-1th: train loss: 2.23035, train acc: 0.274 valid loss: 2.15195 valid acc: 0.354\n",
            "0-2th: train loss: 2.15245, train acc: 0.342 valid loss: 2.09804 valid acc: 0.373\n",
            "0-3th: train loss: 2.09524, train acc: 0.388 valid loss: 2.05032 valid acc: 0.436\n",
            "0-4th: train loss: 2.04059, train acc: 0.481 valid loss: 1.99942 valid acc: 0.549\n",
            "0-5th: train loss: 1.98124, train acc: 0.586 valid loss: 1.95282 valid acc: 0.633\n",
            "0-6th: train loss: 1.92534, train acc: 0.677 valid loss: 1.91218 valid acc: 0.687\n",
            "0-7th: train loss: 1.87736, train acc: 0.739 valid loss: 1.87509 valid acc: 0.749\n",
            "0-8th: train loss: 1.83701, train acc: 0.779 valid loss: 1.84027 valid acc: 0.796\n",
            "0-9th: train loss: 1.80124, train acc: 0.808 valid loss: 1.80956 valid acc: 0.812\n",
            "0-10th: train loss: 1.76946, train acc: 0.828 valid loss: 1.78494 valid acc: 0.834\n",
            "0-11th: train loss: 1.74311, train acc: 0.844 valid loss: 1.76520 valid acc: 0.840\n",
            "0-12th: train loss: 1.72140, train acc: 0.853 valid loss: 1.74829 valid acc: 0.850\n",
            "0-13th: train loss: 1.70264, train acc: 0.874 valid loss: 1.73323 valid acc: 0.862\n",
            "0-14th: train loss: 1.68597, train acc: 0.887 valid loss: 1.72009 valid acc: 0.868\n",
            "0-15th: train loss: 1.67154, train acc: 0.901 valid loss: 1.70908 valid acc: 0.875\n",
            "0-16th: train loss: 1.65959, train acc: 0.911 valid loss: 1.69980 valid acc: 0.884\n",
            "0-17th: train loss: 1.64959, train acc: 0.916 valid loss: 1.69123 valid acc: 0.890\n",
            "0-18th: train loss: 1.64037, train acc: 0.923 valid loss: 1.68264 valid acc: 0.893\n",
            "0-19th: train loss: 1.63112, train acc: 0.928 valid loss: 1.67431 valid acc: 0.903\n",
            "0-20th: train loss: 1.62203, train acc: 0.929 valid loss: 1.66708 valid acc: 0.903\n",
            "0-21th: train loss: 1.61380, train acc: 0.933 valid loss: 1.66140 valid acc: 0.906\n",
            "0-22th: train loss: 1.60682, train acc: 0.937 valid loss: 1.65682 valid acc: 0.906\n",
            "0-23th: train loss: 1.60079, train acc: 0.943 valid loss: 1.65239 valid acc: 0.906\n",
            "0-24th: train loss: 1.59499, train acc: 0.947 valid loss: 1.64750 valid acc: 0.915\n",
            "0-25th: train loss: 1.58899, train acc: 0.952 valid loss: 1.64227 valid acc: 0.918\n",
            "0-26th: train loss: 1.58294, train acc: 0.958 valid loss: 1.63733 valid acc: 0.925\n",
            "0-27th: train loss: 1.57738, train acc: 0.963 valid loss: 1.63311 valid acc: 0.934\n",
            "0-28th: train loss: 1.57256, train acc: 0.967 valid loss: 1.62957 valid acc: 0.934\n",
            "0-29th: train loss: 1.56829, train acc: 0.969 valid loss: 1.62638 valid acc: 0.937\n",
            "0-30th: train loss: 1.56417, train acc: 0.972 valid loss: 1.62340 valid acc: 0.937\n",
            "0-31th: train loss: 1.56003, train acc: 0.973 valid loss: 1.62082 valid acc: 0.940\n",
            "0-32th: train loss: 1.55607, train acc: 0.975 valid loss: 1.61879 valid acc: 0.940\n",
            "0-33th: train loss: 1.55251, train acc: 0.976 valid loss: 1.61713 valid acc: 0.940\n",
            "0-34th: train loss: 1.54932, train acc: 0.976 valid loss: 1.61549 valid acc: 0.940\n",
            "0-35th: train loss: 1.54630, train acc: 0.979 valid loss: 1.61369 valid acc: 0.940\n",
            "0-36th: train loss: 1.54334, train acc: 0.980 valid loss: 1.61182 valid acc: 0.937\n",
            "0-37th: train loss: 1.54053, train acc: 0.982 valid loss: 1.61008 valid acc: 0.937\n",
            "0-38th: train loss: 1.53797, train acc: 0.983 valid loss: 1.60854 valid acc: 0.937\n",
            "0-39th: train loss: 1.53567, train acc: 0.984 valid loss: 1.60717 valid acc: 0.937\n",
            "0-40th: train loss: 1.53349, train acc: 0.987 valid loss: 1.60592 valid acc: 0.937\n",
            "0-41th: train loss: 1.53137, train acc: 0.987 valid loss: 1.60481 valid acc: 0.934\n",
            "0-42th: train loss: 1.52931, train acc: 0.987 valid loss: 1.60387 valid acc: 0.937\n",
            "0-43th: train loss: 1.52738, train acc: 0.987 valid loss: 1.60303 valid acc: 0.934\n",
            "0-44th: train loss: 1.52561, train acc: 0.990 valid loss: 1.60216 valid acc: 0.931\n",
            "0-45th: train loss: 1.52396, train acc: 0.990 valid loss: 1.60114 valid acc: 0.937\n",
            "0-46th: train loss: 1.52239, train acc: 0.990 valid loss: 1.59996 valid acc: 0.937\n",
            "0-47th: train loss: 1.52088, train acc: 0.990 valid loss: 1.59868 valid acc: 0.937\n",
            "0-48th: train loss: 1.51945, train acc: 0.990 valid loss: 1.59739 valid acc: 0.937\n",
            "0-49th: train loss: 1.51810, train acc: 0.991 valid loss: 1.59616 valid acc: 0.940\n",
            "0-50th: train loss: 1.51682, train acc: 0.991 valid loss: 1.59505 valid acc: 0.944\n",
            "0-51th: train loss: 1.51561, train acc: 0.991 valid loss: 1.59409 valid acc: 0.944\n",
            "0-52th: train loss: 1.51446, train acc: 0.991 valid loss: 1.59324 valid acc: 0.944\n",
            "0-53th: train loss: 1.51337, train acc: 0.991 valid loss: 1.59248 valid acc: 0.944\n",
            "0-54th: train loss: 1.51234, train acc: 0.992 valid loss: 1.59171 valid acc: 0.944\n",
            "0-55th: train loss: 1.51136, train acc: 0.992 valid loss: 1.59089 valid acc: 0.944\n",
            "0-56th: train loss: 1.51043, train acc: 0.992 valid loss: 1.59001 valid acc: 0.944\n",
            "0-57th: train loss: 1.50952, train acc: 0.993 valid loss: 1.58909 valid acc: 0.947\n",
            "0-58th: train loss: 1.50866, train acc: 0.993 valid loss: 1.58818 valid acc: 0.947\n",
            "0-59th: train loss: 1.50784, train acc: 0.993 valid loss: 1.58732 valid acc: 0.950\n",
            "0-60th: train loss: 1.50705, train acc: 0.994 valid loss: 1.58655 valid acc: 0.950\n",
            "0-61th: train loss: 1.50629, train acc: 0.994 valid loss: 1.58588 valid acc: 0.950\n",
            "0-62th: train loss: 1.50556, train acc: 0.994 valid loss: 1.58531 valid acc: 0.950\n",
            "0-63th: train loss: 1.50487, train acc: 0.994 valid loss: 1.58482 valid acc: 0.950\n",
            "0-64th: train loss: 1.50420, train acc: 0.994 valid loss: 1.58436 valid acc: 0.950\n",
            "0-65th: train loss: 1.50356, train acc: 0.994 valid loss: 1.58389 valid acc: 0.947\n",
            "0-66th: train loss: 1.50295, train acc: 0.995 valid loss: 1.58340 valid acc: 0.947\n",
            "0-67th: train loss: 1.50236, train acc: 0.995 valid loss: 1.58288 valid acc: 0.947\n",
            "0-68th: train loss: 1.50179, train acc: 0.995 valid loss: 1.58234 valid acc: 0.950\n",
            "0-69th: train loss: 1.50125, train acc: 0.995 valid loss: 1.58180 valid acc: 0.950\n",
            "0-70th: train loss: 1.50073, train acc: 0.995 valid loss: 1.58128 valid acc: 0.950\n",
            "0-71th: train loss: 1.50023, train acc: 0.995 valid loss: 1.58079 valid acc: 0.950\n",
            "0-72th: train loss: 1.49975, train acc: 0.995 valid loss: 1.58032 valid acc: 0.953\n",
            "0-73th: train loss: 1.49928, train acc: 0.995 valid loss: 1.57987 valid acc: 0.956\n",
            "0-74th: train loss: 1.49883, train acc: 0.995 valid loss: 1.57943 valid acc: 0.956\n",
            "0-75th: train loss: 1.49840, train acc: 0.995 valid loss: 1.57897 valid acc: 0.956\n",
            "0-76th: train loss: 1.49798, train acc: 0.995 valid loss: 1.57850 valid acc: 0.956\n",
            "0-77th: train loss: 1.49758, train acc: 0.995 valid loss: 1.57801 valid acc: 0.956\n",
            "0-78th: train loss: 1.49719, train acc: 0.995 valid loss: 1.57751 valid acc: 0.959\n",
            "0-79th: train loss: 1.49681, train acc: 0.995 valid loss: 1.57702 valid acc: 0.959\n",
            "0-80th: train loss: 1.49644, train acc: 0.995 valid loss: 1.57655 valid acc: 0.956\n",
            "0-81th: train loss: 1.49609, train acc: 0.995 valid loss: 1.57613 valid acc: 0.956\n",
            "0-82th: train loss: 1.49575, train acc: 0.995 valid loss: 1.57574 valid acc: 0.956\n",
            "0-83th: train loss: 1.49541, train acc: 0.995 valid loss: 1.57538 valid acc: 0.959\n",
            "0-84th: train loss: 1.49508, train acc: 0.995 valid loss: 1.57505 valid acc: 0.959\n",
            "0-85th: train loss: 1.49477, train acc: 0.995 valid loss: 1.57473 valid acc: 0.959\n",
            "0-86th: train loss: 1.49446, train acc: 0.996 valid loss: 1.57442 valid acc: 0.959\n",
            "0-87th: train loss: 1.49416, train acc: 0.996 valid loss: 1.57409 valid acc: 0.959\n",
            "0-88th: train loss: 1.49387, train acc: 0.996 valid loss: 1.57376 valid acc: 0.959\n",
            "0-89th: train loss: 1.49358, train acc: 0.996 valid loss: 1.57343 valid acc: 0.959\n",
            "0-90th: train loss: 1.49330, train acc: 0.996 valid loss: 1.57310 valid acc: 0.959\n",
            "0-91th: train loss: 1.49303, train acc: 0.996 valid loss: 1.57278 valid acc: 0.959\n",
            "0-92th: train loss: 1.49277, train acc: 0.996 valid loss: 1.57247 valid acc: 0.959\n",
            "0-93th: train loss: 1.49252, train acc: 0.996 valid loss: 1.57219 valid acc: 0.959\n",
            "0-94th: train loss: 1.49227, train acc: 0.996 valid loss: 1.57191 valid acc: 0.959\n",
            "0-95th: train loss: 1.49202, train acc: 0.996 valid loss: 1.57165 valid acc: 0.959\n",
            "0-96th: train loss: 1.49179, train acc: 0.996 valid loss: 1.57139 valid acc: 0.959\n",
            "0-97th: train loss: 1.49156, train acc: 0.996 valid loss: 1.57113 valid acc: 0.959\n",
            "0-98th: train loss: 1.49133, train acc: 0.996 valid loss: 1.57085 valid acc: 0.959\n",
            "0-99th: train loss: 1.49111, train acc: 0.996 valid loss: 1.57057 valid acc: 0.959\n",
            "0-100th: train loss: 1.49089, train acc: 0.996 valid loss: 1.57029 valid acc: 0.959\n",
            "0-101th: train loss: 1.49068, train acc: 0.996 valid loss: 1.57001 valid acc: 0.959\n",
            "0-102th: train loss: 1.49047, train acc: 0.996 valid loss: 1.56974 valid acc: 0.959\n",
            "0-103th: train loss: 1.49026, train acc: 0.996 valid loss: 1.56948 valid acc: 0.959\n",
            "0-104th: train loss: 1.49006, train acc: 0.996 valid loss: 1.56923 valid acc: 0.959\n",
            "0-105th: train loss: 1.48986, train acc: 0.996 valid loss: 1.56900 valid acc: 0.962\n",
            "0-106th: train loss: 1.48966, train acc: 0.996 valid loss: 1.56878 valid acc: 0.962\n",
            "0-107th: train loss: 1.48946, train acc: 0.997 valid loss: 1.56856 valid acc: 0.962\n",
            "0-108th: train loss: 1.48926, train acc: 0.997 valid loss: 1.56835 valid acc: 0.962\n",
            "0-109th: train loss: 1.48906, train acc: 0.997 valid loss: 1.56813 valid acc: 0.962\n",
            "0-110th: train loss: 1.48887, train acc: 0.997 valid loss: 1.56792 valid acc: 0.962\n",
            "0-111th: train loss: 1.48867, train acc: 0.997 valid loss: 1.56772 valid acc: 0.962\n",
            "0-112th: train loss: 1.48848, train acc: 0.997 valid loss: 1.56752 valid acc: 0.962\n",
            "0-113th: train loss: 1.48829, train acc: 0.997 valid loss: 1.56733 valid acc: 0.962\n",
            "0-114th: train loss: 1.48810, train acc: 0.997 valid loss: 1.56716 valid acc: 0.962\n",
            "0-115th: train loss: 1.48791, train acc: 0.997 valid loss: 1.56700 valid acc: 0.962\n",
            "0-116th: train loss: 1.48772, train acc: 0.997 valid loss: 1.56685 valid acc: 0.962\n",
            "0-117th: train loss: 1.48753, train acc: 0.998 valid loss: 1.56671 valid acc: 0.962\n",
            "0-118th: train loss: 1.48735, train acc: 0.998 valid loss: 1.56658 valid acc: 0.962\n",
            "0-119th: train loss: 1.48718, train acc: 0.998 valid loss: 1.56644 valid acc: 0.962\n",
            "0-120th: train loss: 1.48701, train acc: 0.998 valid loss: 1.56631 valid acc: 0.962\n",
            "0-121th: train loss: 1.48685, train acc: 0.998 valid loss: 1.56616 valid acc: 0.962\n",
            "0-122th: train loss: 1.48669, train acc: 0.998 valid loss: 1.56601 valid acc: 0.962\n",
            "0-123th: train loss: 1.48655, train acc: 0.998 valid loss: 1.56584 valid acc: 0.962\n",
            "0-124th: train loss: 1.48640, train acc: 0.998 valid loss: 1.56565 valid acc: 0.962\n",
            "0-125th: train loss: 1.48626, train acc: 0.998 valid loss: 1.56545 valid acc: 0.962\n",
            "0-126th: train loss: 1.48612, train acc: 0.998 valid loss: 1.56524 valid acc: 0.962\n",
            "0-127th: train loss: 1.48599, train acc: 0.998 valid loss: 1.56503 valid acc: 0.962\n",
            "0-128th: train loss: 1.48585, train acc: 0.998 valid loss: 1.56480 valid acc: 0.962\n",
            "0-129th: train loss: 1.48572, train acc: 0.998 valid loss: 1.56458 valid acc: 0.962\n",
            "0-130th: train loss: 1.48559, train acc: 0.998 valid loss: 1.56436 valid acc: 0.962\n",
            "0-131th: train loss: 1.48546, train acc: 0.998 valid loss: 1.56414 valid acc: 0.962\n",
            "0-132th: train loss: 1.48533, train acc: 0.998 valid loss: 1.56393 valid acc: 0.962\n",
            "0-133th: train loss: 1.48521, train acc: 0.998 valid loss: 1.56373 valid acc: 0.962\n",
            "0-134th: train loss: 1.48509, train acc: 0.998 valid loss: 1.56353 valid acc: 0.962\n",
            "0-135th: train loss: 1.48497, train acc: 0.998 valid loss: 1.56334 valid acc: 0.962\n",
            "0-136th: train loss: 1.48486, train acc: 0.998 valid loss: 1.56316 valid acc: 0.962\n",
            "0-137th: train loss: 1.48474, train acc: 0.998 valid loss: 1.56298 valid acc: 0.962\n",
            "0-138th: train loss: 1.48463, train acc: 0.998 valid loss: 1.56280 valid acc: 0.962\n",
            "0-139th: train loss: 1.48453, train acc: 0.998 valid loss: 1.56263 valid acc: 0.962\n",
            "0-140th: train loss: 1.48442, train acc: 0.998 valid loss: 1.56247 valid acc: 0.962\n",
            "0-141th: train loss: 1.48432, train acc: 0.998 valid loss: 1.56231 valid acc: 0.962\n",
            "0-142th: train loss: 1.48422, train acc: 0.998 valid loss: 1.56216 valid acc: 0.962\n",
            "0-143th: train loss: 1.48412, train acc: 0.998 valid loss: 1.56201 valid acc: 0.962\n",
            "0-144th: train loss: 1.48402, train acc: 0.998 valid loss: 1.56186 valid acc: 0.962\n",
            "0-145th: train loss: 1.48393, train acc: 0.998 valid loss: 1.56172 valid acc: 0.962\n",
            "0-146th: train loss: 1.48384, train acc: 0.998 valid loss: 1.56157 valid acc: 0.962\n",
            "0-147th: train loss: 1.48375, train acc: 0.998 valid loss: 1.56143 valid acc: 0.959\n",
            "0-148th: train loss: 1.48366, train acc: 0.998 valid loss: 1.56128 valid acc: 0.959\n",
            "0-149th: train loss: 1.48357, train acc: 0.998 valid loss: 1.56113 valid acc: 0.959\n",
            "0-150th: train loss: 1.48348, train acc: 0.998 valid loss: 1.56099 valid acc: 0.959\n",
            "0-151th: train loss: 1.48340, train acc: 0.998 valid loss: 1.56084 valid acc: 0.959\n",
            "0-152th: train loss: 1.48331, train acc: 0.998 valid loss: 1.56070 valid acc: 0.959\n",
            "0-153th: train loss: 1.48323, train acc: 0.998 valid loss: 1.56056 valid acc: 0.959\n",
            "0-154th: train loss: 1.48315, train acc: 0.998 valid loss: 1.56042 valid acc: 0.959\n",
            "0-155th: train loss: 1.48307, train acc: 0.998 valid loss: 1.56028 valid acc: 0.959\n",
            "0-156th: train loss: 1.48300, train acc: 0.998 valid loss: 1.56014 valid acc: 0.959\n",
            "0-157th: train loss: 1.48292, train acc: 0.998 valid loss: 1.56000 valid acc: 0.959\n",
            "0-158th: train loss: 1.48285, train acc: 0.998 valid loss: 1.55987 valid acc: 0.959\n",
            "0-159th: train loss: 1.48277, train acc: 0.998 valid loss: 1.55973 valid acc: 0.959\n",
            "0-160th: train loss: 1.48270, train acc: 0.998 valid loss: 1.55960 valid acc: 0.959\n",
            "0-161th: train loss: 1.48263, train acc: 0.998 valid loss: 1.55947 valid acc: 0.959\n",
            "0-162th: train loss: 1.48256, train acc: 0.998 valid loss: 1.55934 valid acc: 0.962\n",
            "0-163th: train loss: 1.48249, train acc: 0.998 valid loss: 1.55921 valid acc: 0.962\n",
            "0-164th: train loss: 1.48242, train acc: 0.998 valid loss: 1.55908 valid acc: 0.962\n",
            "0-165th: train loss: 1.48236, train acc: 0.998 valid loss: 1.55896 valid acc: 0.962\n",
            "0-166th: train loss: 1.48229, train acc: 0.998 valid loss: 1.55884 valid acc: 0.962\n",
            "0-167th: train loss: 1.48223, train acc: 0.998 valid loss: 1.55872 valid acc: 0.962\n",
            "0-168th: train loss: 1.48216, train acc: 0.998 valid loss: 1.55861 valid acc: 0.962\n",
            "0-169th: train loss: 1.48210, train acc: 0.998 valid loss: 1.55849 valid acc: 0.962\n",
            "0-170th: train loss: 1.48204, train acc: 0.998 valid loss: 1.55838 valid acc: 0.962\n",
            "0-171th: train loss: 1.48198, train acc: 0.998 valid loss: 1.55827 valid acc: 0.962\n",
            "0-172th: train loss: 1.48192, train acc: 0.998 valid loss: 1.55816 valid acc: 0.962\n",
            "0-173th: train loss: 1.48187, train acc: 0.998 valid loss: 1.55806 valid acc: 0.962\n",
            "0-174th: train loss: 1.48181, train acc: 0.998 valid loss: 1.55795 valid acc: 0.962\n",
            "0-175th: train loss: 1.48175, train acc: 0.998 valid loss: 1.55785 valid acc: 0.962\n",
            "0-176th: train loss: 1.48170, train acc: 0.998 valid loss: 1.55776 valid acc: 0.962\n",
            "0-177th: train loss: 1.48164, train acc: 0.998 valid loss: 1.55766 valid acc: 0.962\n",
            "0-178th: train loss: 1.48159, train acc: 0.998 valid loss: 1.55757 valid acc: 0.962\n",
            "0-179th: train loss: 1.48154, train acc: 0.998 valid loss: 1.55748 valid acc: 0.962\n",
            "0-180th: train loss: 1.48148, train acc: 0.998 valid loss: 1.55739 valid acc: 0.962\n",
            "0-181th: train loss: 1.48143, train acc: 0.998 valid loss: 1.55731 valid acc: 0.962\n",
            "0-182th: train loss: 1.48138, train acc: 0.998 valid loss: 1.55722 valid acc: 0.962\n",
            "0-183th: train loss: 1.48133, train acc: 0.998 valid loss: 1.55714 valid acc: 0.962\n",
            "0-184th: train loss: 1.48128, train acc: 0.998 valid loss: 1.55706 valid acc: 0.962\n",
            "0-185th: train loss: 1.48123, train acc: 0.998 valid loss: 1.55699 valid acc: 0.962\n",
            "0-186th: train loss: 1.48118, train acc: 0.998 valid loss: 1.55691 valid acc: 0.962\n",
            "0-187th: train loss: 1.48113, train acc: 0.998 valid loss: 1.55684 valid acc: 0.962\n",
            "0-188th: train loss: 1.48109, train acc: 0.998 valid loss: 1.55678 valid acc: 0.962\n",
            "0-189th: train loss: 1.48104, train acc: 0.998 valid loss: 1.55671 valid acc: 0.962\n",
            "0-190th: train loss: 1.48099, train acc: 0.998 valid loss: 1.55665 valid acc: 0.962\n",
            "0-191th: train loss: 1.48094, train acc: 0.998 valid loss: 1.55659 valid acc: 0.962\n",
            "0-192th: train loss: 1.48089, train acc: 0.998 valid loss: 1.55654 valid acc: 0.962\n",
            "0-193th: train loss: 1.48084, train acc: 0.998 valid loss: 1.55649 valid acc: 0.962\n",
            "0-194th: train loss: 1.48079, train acc: 0.998 valid loss: 1.55644 valid acc: 0.962\n",
            "0-195th: train loss: 1.48074, train acc: 0.998 valid loss: 1.55641 valid acc: 0.962\n",
            "0-196th: train loss: 1.48069, train acc: 0.998 valid loss: 1.55637 valid acc: 0.962\n",
            "0-197th: train loss: 1.48063, train acc: 0.998 valid loss: 1.55635 valid acc: 0.962\n",
            "0-198th: train loss: 1.48057, train acc: 0.998 valid loss: 1.55633 valid acc: 0.962\n",
            "0-199th: train loss: 1.48051, train acc: 0.998 valid loss: 1.55632 valid acc: 0.962\n",
            "0-200th: train loss: 1.48044, train acc: 0.998 valid loss: 1.55633 valid acc: 0.962\n",
            "0-201th: train loss: 1.48036, train acc: 0.998 valid loss: 1.55635 valid acc: 0.966\n",
            "0-202th: train loss: 1.48028, train acc: 0.998 valid loss: 1.55638 valid acc: 0.966\n",
            "0-203th: train loss: 1.48018, train acc: 0.998 valid loss: 1.55643 valid acc: 0.966\n",
            "0-204th: train loss: 1.48008, train acc: 0.999 valid loss: 1.55648 valid acc: 0.966\n",
            "0-205th: train loss: 1.47999, train acc: 0.999 valid loss: 1.55654 valid acc: 0.966\n",
            "0-206th: train loss: 1.47990, train acc: 0.999 valid loss: 1.55659 valid acc: 0.966\n",
            "0-207th: train loss: 1.47982, train acc: 0.999 valid loss: 1.55663 valid acc: 0.966\n",
            "0-208th: train loss: 1.47975, train acc: 0.999 valid loss: 1.55665 valid acc: 0.966\n",
            "0-209th: train loss: 1.47969, train acc: 0.999 valid loss: 1.55664 valid acc: 0.966\n",
            "0-210th: train loss: 1.47964, train acc: 0.999 valid loss: 1.55662 valid acc: 0.966\n",
            "0-211th: train loss: 1.47959, train acc: 0.999 valid loss: 1.55659 valid acc: 0.966\n",
            "0-212th: train loss: 1.47955, train acc: 0.999 valid loss: 1.55653 valid acc: 0.962\n",
            "0-213th: train loss: 1.47950, train acc: 0.999 valid loss: 1.55647 valid acc: 0.962\n",
            "0-214th: train loss: 1.47945, train acc: 0.999 valid loss: 1.55639 valid acc: 0.962\n",
            "0-215th: train loss: 1.47940, train acc: 0.999 valid loss: 1.55630 valid acc: 0.962\n",
            "0-216th: train loss: 1.47934, train acc: 0.999 valid loss: 1.55620 valid acc: 0.962\n",
            "0-217th: train loss: 1.47929, train acc: 0.999 valid loss: 1.55610 valid acc: 0.962\n",
            "0-218th: train loss: 1.47924, train acc: 0.999 valid loss: 1.55599 valid acc: 0.962\n",
            "0-219th: train loss: 1.47919, train acc: 0.999 valid loss: 1.55588 valid acc: 0.962\n",
            "0-220th: train loss: 1.47914, train acc: 0.999 valid loss: 1.55577 valid acc: 0.962\n",
            "0-221th: train loss: 1.47909, train acc: 0.999 valid loss: 1.55567 valid acc: 0.962\n",
            "0-222th: train loss: 1.47905, train acc: 0.999 valid loss: 1.55557 valid acc: 0.962\n",
            "0-223th: train loss: 1.47901, train acc: 0.999 valid loss: 1.55548 valid acc: 0.962\n",
            "0-224th: train loss: 1.47897, train acc: 0.999 valid loss: 1.55541 valid acc: 0.962\n",
            "0-225th: train loss: 1.47893, train acc: 0.999 valid loss: 1.55534 valid acc: 0.962\n",
            "0-226th: train loss: 1.47889, train acc: 0.999 valid loss: 1.55528 valid acc: 0.962\n",
            "0-227th: train loss: 1.47885, train acc: 0.999 valid loss: 1.55523 valid acc: 0.962\n",
            "0-228th: train loss: 1.47882, train acc: 0.999 valid loss: 1.55519 valid acc: 0.962\n",
            "0-229th: train loss: 1.47878, train acc: 0.999 valid loss: 1.55516 valid acc: 0.959\n",
            "0-230th: train loss: 1.47875, train acc: 0.999 valid loss: 1.55513 valid acc: 0.959\n",
            "0-231th: train loss: 1.47871, train acc: 0.999 valid loss: 1.55510 valid acc: 0.959\n",
            "0-232th: train loss: 1.47868, train acc: 0.999 valid loss: 1.55508 valid acc: 0.959\n",
            "0-233th: train loss: 1.47865, train acc: 0.999 valid loss: 1.55506 valid acc: 0.959\n",
            "0-234th: train loss: 1.47862, train acc: 0.999 valid loss: 1.55504 valid acc: 0.959\n",
            "0-235th: train loss: 1.47859, train acc: 0.999 valid loss: 1.55501 valid acc: 0.959\n",
            "0-236th: train loss: 1.47856, train acc: 0.999 valid loss: 1.55499 valid acc: 0.959\n",
            "0-237th: train loss: 1.47853, train acc: 0.999 valid loss: 1.55496 valid acc: 0.959\n",
            "0-238th: train loss: 1.47850, train acc: 0.999 valid loss: 1.55492 valid acc: 0.959\n",
            "0-239th: train loss: 1.47847, train acc: 0.999 valid loss: 1.55489 valid acc: 0.959\n",
            "0-240th: train loss: 1.47845, train acc: 0.999 valid loss: 1.55485 valid acc: 0.959\n",
            "0-241th: train loss: 1.47842, train acc: 0.999 valid loss: 1.55481 valid acc: 0.959\n",
            "0-242th: train loss: 1.47839, train acc: 0.999 valid loss: 1.55477 valid acc: 0.959\n",
            "0-243th: train loss: 1.47836, train acc: 0.999 valid loss: 1.55473 valid acc: 0.959\n",
            "0-244th: train loss: 1.47834, train acc: 0.999 valid loss: 1.55468 valid acc: 0.959\n",
            "0-245th: train loss: 1.47831, train acc: 0.999 valid loss: 1.55464 valid acc: 0.959\n",
            "0-246th: train loss: 1.47829, train acc: 0.999 valid loss: 1.55460 valid acc: 0.959\n",
            "0-247th: train loss: 1.47826, train acc: 0.999 valid loss: 1.55455 valid acc: 0.959\n",
            "0-248th: train loss: 1.47824, train acc: 0.999 valid loss: 1.55450 valid acc: 0.959\n",
            "0-249th: train loss: 1.47821, train acc: 0.999 valid loss: 1.55446 valid acc: 0.959\n",
            "0-250th: train loss: 1.47819, train acc: 0.999 valid loss: 1.55441 valid acc: 0.959\n",
            "0-251th: train loss: 1.47816, train acc: 0.999 valid loss: 1.55436 valid acc: 0.959\n",
            "0-252th: train loss: 1.47814, train acc: 0.999 valid loss: 1.55431 valid acc: 0.959\n",
            "0-253th: train loss: 1.47811, train acc: 0.999 valid loss: 1.55426 valid acc: 0.959\n",
            "0-254th: train loss: 1.47809, train acc: 0.999 valid loss: 1.55422 valid acc: 0.956\n",
            "0-255th: train loss: 1.47807, train acc: 0.999 valid loss: 1.55417 valid acc: 0.956\n",
            "0-256th: train loss: 1.47805, train acc: 0.999 valid loss: 1.55413 valid acc: 0.956\n",
            "0-257th: train loss: 1.47802, train acc: 0.999 valid loss: 1.55410 valid acc: 0.956\n",
            "0-258th: train loss: 1.47800, train acc: 0.999 valid loss: 1.55406 valid acc: 0.956\n",
            "0-259th: train loss: 1.47798, train acc: 0.999 valid loss: 1.55402 valid acc: 0.956\n",
            "0-260th: train loss: 1.47796, train acc: 0.999 valid loss: 1.55399 valid acc: 0.956\n",
            "0-261th: train loss: 1.47793, train acc: 0.999 valid loss: 1.55395 valid acc: 0.956\n",
            "0-262th: train loss: 1.47791, train acc: 0.999 valid loss: 1.55392 valid acc: 0.956\n",
            "0-263th: train loss: 1.47789, train acc: 0.999 valid loss: 1.55388 valid acc: 0.956\n",
            "0-264th: train loss: 1.47787, train acc: 0.999 valid loss: 1.55385 valid acc: 0.956\n",
            "0-265th: train loss: 1.47785, train acc: 0.999 valid loss: 1.55381 valid acc: 0.956\n",
            "0-266th: train loss: 1.47783, train acc: 0.999 valid loss: 1.55378 valid acc: 0.956\n",
            "0-267th: train loss: 1.47781, train acc: 0.999 valid loss: 1.55374 valid acc: 0.956\n",
            "0-268th: train loss: 1.47779, train acc: 0.999 valid loss: 1.55371 valid acc: 0.956\n",
            "0-269th: train loss: 1.47777, train acc: 0.999 valid loss: 1.55367 valid acc: 0.956\n",
            "0-270th: train loss: 1.47775, train acc: 0.999 valid loss: 1.55363 valid acc: 0.956\n",
            "0-271th: train loss: 1.47773, train acc: 0.999 valid loss: 1.55359 valid acc: 0.956\n",
            "0-272th: train loss: 1.47771, train acc: 0.999 valid loss: 1.55356 valid acc: 0.956\n",
            "0-273th: train loss: 1.47769, train acc: 0.999 valid loss: 1.55352 valid acc: 0.956\n",
            "0-274th: train loss: 1.47767, train acc: 0.999 valid loss: 1.55348 valid acc: 0.956\n",
            "0-275th: train loss: 1.47765, train acc: 0.999 valid loss: 1.55344 valid acc: 0.956\n",
            "0-276th: train loss: 1.47763, train acc: 0.999 valid loss: 1.55340 valid acc: 0.956\n",
            "0-277th: train loss: 1.47761, train acc: 0.999 valid loss: 1.55336 valid acc: 0.956\n",
            "0-278th: train loss: 1.47760, train acc: 0.999 valid loss: 1.55332 valid acc: 0.956\n",
            "0-279th: train loss: 1.47758, train acc: 0.999 valid loss: 1.55328 valid acc: 0.956\n",
            "0-280th: train loss: 1.47756, train acc: 0.999 valid loss: 1.55325 valid acc: 0.956\n",
            "0-281th: train loss: 1.47754, train acc: 0.999 valid loss: 1.55321 valid acc: 0.956\n",
            "0-282th: train loss: 1.47752, train acc: 0.999 valid loss: 1.55317 valid acc: 0.956\n",
            "0-283th: train loss: 1.47751, train acc: 0.999 valid loss: 1.55314 valid acc: 0.956\n",
            "0-284th: train loss: 1.47749, train acc: 0.999 valid loss: 1.55310 valid acc: 0.956\n",
            "0-285th: train loss: 1.47747, train acc: 0.999 valid loss: 1.55307 valid acc: 0.956\n",
            "0-286th: train loss: 1.47745, train acc: 0.999 valid loss: 1.55304 valid acc: 0.956\n",
            "0-287th: train loss: 1.47744, train acc: 0.999 valid loss: 1.55300 valid acc: 0.956\n",
            "0-288th: train loss: 1.47742, train acc: 0.999 valid loss: 1.55297 valid acc: 0.956\n",
            "0-289th: train loss: 1.47740, train acc: 0.999 valid loss: 1.55294 valid acc: 0.956\n",
            "0-290th: train loss: 1.47739, train acc: 0.999 valid loss: 1.55291 valid acc: 0.956\n",
            "0-291th: train loss: 1.47737, train acc: 0.999 valid loss: 1.55288 valid acc: 0.959\n",
            "0-292th: train loss: 1.47735, train acc: 0.999 valid loss: 1.55285 valid acc: 0.959\n",
            "0-293th: train loss: 1.47734, train acc: 0.999 valid loss: 1.55282 valid acc: 0.959\n",
            "0-294th: train loss: 1.47732, train acc: 0.999 valid loss: 1.55279 valid acc: 0.959\n",
            "0-295th: train loss: 1.47731, train acc: 0.999 valid loss: 1.55276 valid acc: 0.959\n",
            "0-296th: train loss: 1.47729, train acc: 0.999 valid loss: 1.55273 valid acc: 0.959\n",
            "0-297th: train loss: 1.47727, train acc: 0.999 valid loss: 1.55270 valid acc: 0.959\n",
            "0-298th: train loss: 1.47726, train acc: 0.999 valid loss: 1.55268 valid acc: 0.959\n",
            "0-299th: train loss: 1.47724, train acc: 0.999 valid loss: 1.55265 valid acc: 0.959\n",
            "1-0th: train loss: 2.30314, train acc: 0.095 valid loss: 2.23190 valid acc: 0.248\n",
            "1-1th: train loss: 2.21968, train acc: 0.301 valid loss: 2.14835 valid acc: 0.395\n",
            "1-2th: train loss: 2.12782, train acc: 0.442 valid loss: 2.07443 valid acc: 0.486\n",
            "1-3th: train loss: 2.04616, train acc: 0.540 valid loss: 2.01081 valid acc: 0.542\n",
            "1-4th: train loss: 1.97650, train acc: 0.608 valid loss: 1.96030 valid acc: 0.592\n",
            "1-5th: train loss: 1.92129, train acc: 0.644 valid loss: 1.92021 valid acc: 0.636\n",
            "1-6th: train loss: 1.87684, train acc: 0.694 valid loss: 1.88467 valid acc: 0.693\n",
            "1-7th: train loss: 1.83761, train acc: 0.743 valid loss: 1.85088 valid acc: 0.755\n",
            "1-8th: train loss: 1.80052, train acc: 0.802 valid loss: 1.82252 valid acc: 0.787\n",
            "1-9th: train loss: 1.76898, train acc: 0.839 valid loss: 1.80206 valid acc: 0.790\n",
            "1-10th: train loss: 1.74530, train acc: 0.863 valid loss: 1.78524 valid acc: 0.799\n",
            "1-11th: train loss: 1.72524, train acc: 0.874 valid loss: 1.76920 valid acc: 0.815\n",
            "1-12th: train loss: 1.70601, train acc: 0.883 valid loss: 1.75408 valid acc: 0.834\n",
            "1-13th: train loss: 1.68795, train acc: 0.892 valid loss: 1.74114 valid acc: 0.840\n",
            "1-14th: train loss: 1.67245, train acc: 0.903 valid loss: 1.73113 valid acc: 0.843\n",
            "1-15th: train loss: 1.66017, train acc: 0.907 valid loss: 1.72329 valid acc: 0.853\n",
            "1-16th: train loss: 1.65010, train acc: 0.910 valid loss: 1.71638 valid acc: 0.865\n",
            "1-17th: train loss: 1.64085, train acc: 0.915 valid loss: 1.70982 valid acc: 0.862\n",
            "1-18th: train loss: 1.63189, train acc: 0.922 valid loss: 1.70371 valid acc: 0.875\n",
            "1-19th: train loss: 1.62350, train acc: 0.929 valid loss: 1.69818 valid acc: 0.887\n",
            "1-20th: train loss: 1.61604, train acc: 0.938 valid loss: 1.69308 valid acc: 0.893\n",
            "1-21th: train loss: 1.60946, train acc: 0.942 valid loss: 1.68809 valid acc: 0.890\n",
            "1-22th: train loss: 1.60337, train acc: 0.945 valid loss: 1.68295 valid acc: 0.893\n",
            "1-23th: train loss: 1.59743, train acc: 0.947 valid loss: 1.67769 valid acc: 0.893\n",
            "1-24th: train loss: 1.59157, train acc: 0.949 valid loss: 1.67251 valid acc: 0.903\n",
            "1-25th: train loss: 1.58595, train acc: 0.953 valid loss: 1.66770 valid acc: 0.912\n",
            "1-26th: train loss: 1.58071, train acc: 0.956 valid loss: 1.66338 valid acc: 0.909\n",
            "1-27th: train loss: 1.57588, train acc: 0.960 valid loss: 1.65955 valid acc: 0.909\n",
            "1-28th: train loss: 1.57141, train acc: 0.964 valid loss: 1.65613 valid acc: 0.912\n",
            "1-29th: train loss: 1.56720, train acc: 0.968 valid loss: 1.65302 valid acc: 0.918\n",
            "1-30th: train loss: 1.56321, train acc: 0.968 valid loss: 1.65018 valid acc: 0.922\n",
            "1-31th: train loss: 1.55946, train acc: 0.969 valid loss: 1.64753 valid acc: 0.925\n",
            "1-32th: train loss: 1.55595, train acc: 0.970 valid loss: 1.64505 valid acc: 0.928\n",
            "1-33th: train loss: 1.55272, train acc: 0.973 valid loss: 1.64269 valid acc: 0.922\n",
            "1-34th: train loss: 1.54974, train acc: 0.973 valid loss: 1.64041 valid acc: 0.925\n",
            "1-35th: train loss: 1.54696, train acc: 0.974 valid loss: 1.63819 valid acc: 0.925\n",
            "1-36th: train loss: 1.54433, train acc: 0.975 valid loss: 1.63604 valid acc: 0.925\n",
            "1-37th: train loss: 1.54179, train acc: 0.976 valid loss: 1.63403 valid acc: 0.925\n",
            "1-38th: train loss: 1.53938, train acc: 0.976 valid loss: 1.63219 valid acc: 0.928\n",
            "1-39th: train loss: 1.53710, train acc: 0.977 valid loss: 1.63054 valid acc: 0.925\n",
            "1-40th: train loss: 1.53499, train acc: 0.978 valid loss: 1.62902 valid acc: 0.925\n",
            "1-41th: train loss: 1.53300, train acc: 0.978 valid loss: 1.62757 valid acc: 0.925\n",
            "1-42th: train loss: 1.53110, train acc: 0.979 valid loss: 1.62617 valid acc: 0.925\n",
            "1-43th: train loss: 1.52926, train acc: 0.980 valid loss: 1.62480 valid acc: 0.925\n",
            "1-44th: train loss: 1.52749, train acc: 0.981 valid loss: 1.62350 valid acc: 0.925\n",
            "1-45th: train loss: 1.52581, train acc: 0.981 valid loss: 1.62231 valid acc: 0.925\n",
            "1-46th: train loss: 1.52423, train acc: 0.983 valid loss: 1.62125 valid acc: 0.922\n",
            "1-47th: train loss: 1.52275, train acc: 0.984 valid loss: 1.62029 valid acc: 0.922\n",
            "1-48th: train loss: 1.52135, train acc: 0.984 valid loss: 1.61942 valid acc: 0.922\n",
            "1-49th: train loss: 1.52001, train acc: 0.984 valid loss: 1.61861 valid acc: 0.922\n",
            "1-50th: train loss: 1.51872, train acc: 0.985 valid loss: 1.61786 valid acc: 0.918\n",
            "1-51th: train loss: 1.51750, train acc: 0.986 valid loss: 1.61714 valid acc: 0.918\n",
            "1-52th: train loss: 1.51635, train acc: 0.986 valid loss: 1.61644 valid acc: 0.915\n",
            "1-53th: train loss: 1.51525, train acc: 0.987 valid loss: 1.61571 valid acc: 0.918\n",
            "1-54th: train loss: 1.51421, train acc: 0.987 valid loss: 1.61495 valid acc: 0.918\n",
            "1-55th: train loss: 1.51319, train acc: 0.987 valid loss: 1.61415 valid acc: 0.922\n",
            "1-56th: train loss: 1.51221, train acc: 0.987 valid loss: 1.61334 valid acc: 0.922\n",
            "1-57th: train loss: 1.51125, train acc: 0.988 valid loss: 1.61254 valid acc: 0.922\n",
            "1-58th: train loss: 1.51033, train acc: 0.989 valid loss: 1.61175 valid acc: 0.925\n",
            "1-59th: train loss: 1.50945, train acc: 0.989 valid loss: 1.61097 valid acc: 0.925\n",
            "1-60th: train loss: 1.50859, train acc: 0.991 valid loss: 1.61022 valid acc: 0.925\n",
            "1-61th: train loss: 1.50776, train acc: 0.991 valid loss: 1.60947 valid acc: 0.922\n",
            "1-62th: train loss: 1.50696, train acc: 0.991 valid loss: 1.60873 valid acc: 0.922\n",
            "1-63th: train loss: 1.50618, train acc: 0.993 valid loss: 1.60799 valid acc: 0.922\n",
            "1-64th: train loss: 1.50542, train acc: 0.993 valid loss: 1.60725 valid acc: 0.922\n",
            "1-65th: train loss: 1.50469, train acc: 0.993 valid loss: 1.60652 valid acc: 0.925\n",
            "1-66th: train loss: 1.50399, train acc: 0.993 valid loss: 1.60580 valid acc: 0.925\n",
            "1-67th: train loss: 1.50332, train acc: 0.993 valid loss: 1.60509 valid acc: 0.928\n",
            "1-68th: train loss: 1.50266, train acc: 0.993 valid loss: 1.60441 valid acc: 0.928\n",
            "1-69th: train loss: 1.50203, train acc: 0.993 valid loss: 1.60376 valid acc: 0.928\n",
            "1-70th: train loss: 1.50143, train acc: 0.993 valid loss: 1.60315 valid acc: 0.928\n",
            "1-71th: train loss: 1.50084, train acc: 0.993 valid loss: 1.60259 valid acc: 0.928\n",
            "1-72th: train loss: 1.50027, train acc: 0.993 valid loss: 1.60206 valid acc: 0.928\n",
            "1-73th: train loss: 1.49973, train acc: 0.993 valid loss: 1.60156 valid acc: 0.928\n",
            "1-74th: train loss: 1.49919, train acc: 0.994 valid loss: 1.60108 valid acc: 0.931\n",
            "1-75th: train loss: 1.49868, train acc: 0.994 valid loss: 1.60062 valid acc: 0.931\n",
            "1-76th: train loss: 1.49817, train acc: 0.994 valid loss: 1.60018 valid acc: 0.931\n",
            "1-77th: train loss: 1.49768, train acc: 0.994 valid loss: 1.59974 valid acc: 0.928\n",
            "1-78th: train loss: 1.49719, train acc: 0.995 valid loss: 1.59931 valid acc: 0.928\n",
            "1-79th: train loss: 1.49672, train acc: 0.995 valid loss: 1.59889 valid acc: 0.928\n",
            "1-80th: train loss: 1.49626, train acc: 0.995 valid loss: 1.59848 valid acc: 0.928\n",
            "1-81th: train loss: 1.49580, train acc: 0.996 valid loss: 1.59808 valid acc: 0.928\n",
            "1-82th: train loss: 1.49535, train acc: 0.997 valid loss: 1.59770 valid acc: 0.931\n",
            "1-83th: train loss: 1.49491, train acc: 0.997 valid loss: 1.59732 valid acc: 0.931\n",
            "1-84th: train loss: 1.49448, train acc: 0.997 valid loss: 1.59695 valid acc: 0.931\n",
            "1-85th: train loss: 1.49405, train acc: 0.997 valid loss: 1.59659 valid acc: 0.931\n",
            "1-86th: train loss: 1.49364, train acc: 0.997 valid loss: 1.59623 valid acc: 0.934\n",
            "1-87th: train loss: 1.49324, train acc: 0.997 valid loss: 1.59588 valid acc: 0.934\n",
            "1-88th: train loss: 1.49285, train acc: 0.998 valid loss: 1.59553 valid acc: 0.934\n",
            "1-89th: train loss: 1.49247, train acc: 0.998 valid loss: 1.59517 valid acc: 0.934\n",
            "1-90th: train loss: 1.49211, train acc: 0.998 valid loss: 1.59482 valid acc: 0.934\n",
            "1-91th: train loss: 1.49176, train acc: 0.998 valid loss: 1.59447 valid acc: 0.934\n",
            "1-92th: train loss: 1.49142, train acc: 0.998 valid loss: 1.59412 valid acc: 0.934\n",
            "1-93th: train loss: 1.49110, train acc: 0.998 valid loss: 1.59378 valid acc: 0.934\n",
            "1-94th: train loss: 1.49079, train acc: 0.998 valid loss: 1.59343 valid acc: 0.934\n",
            "1-95th: train loss: 1.49049, train acc: 0.998 valid loss: 1.59310 valid acc: 0.934\n",
            "1-96th: train loss: 1.49020, train acc: 0.998 valid loss: 1.59276 valid acc: 0.934\n",
            "1-97th: train loss: 1.48993, train acc: 0.998 valid loss: 1.59244 valid acc: 0.934\n",
            "1-98th: train loss: 1.48966, train acc: 0.998 valid loss: 1.59212 valid acc: 0.934\n",
            "1-99th: train loss: 1.48940, train acc: 0.998 valid loss: 1.59180 valid acc: 0.934\n",
            "1-100th: train loss: 1.48915, train acc: 0.998 valid loss: 1.59150 valid acc: 0.934\n",
            "1-101th: train loss: 1.48891, train acc: 0.998 valid loss: 1.59121 valid acc: 0.934\n",
            "1-102th: train loss: 1.48868, train acc: 0.998 valid loss: 1.59093 valid acc: 0.934\n",
            "1-103th: train loss: 1.48845, train acc: 0.998 valid loss: 1.59065 valid acc: 0.934\n",
            "1-104th: train loss: 1.48823, train acc: 0.998 valid loss: 1.59040 valid acc: 0.934\n",
            "1-105th: train loss: 1.48801, train acc: 0.998 valid loss: 1.59015 valid acc: 0.937\n",
            "1-106th: train loss: 1.48780, train acc: 0.998 valid loss: 1.58991 valid acc: 0.937\n",
            "1-107th: train loss: 1.48759, train acc: 0.998 valid loss: 1.58969 valid acc: 0.937\n",
            "1-108th: train loss: 1.48739, train acc: 0.998 valid loss: 1.58948 valid acc: 0.937\n",
            "1-109th: train loss: 1.48719, train acc: 0.998 valid loss: 1.58928 valid acc: 0.937\n",
            "1-110th: train loss: 1.48699, train acc: 0.998 valid loss: 1.58909 valid acc: 0.937\n",
            "1-111th: train loss: 1.48680, train acc: 0.998 valid loss: 1.58892 valid acc: 0.937\n",
            "1-112th: train loss: 1.48660, train acc: 0.998 valid loss: 1.58876 valid acc: 0.937\n",
            "1-113th: train loss: 1.48641, train acc: 0.998 valid loss: 1.58861 valid acc: 0.937\n",
            "1-114th: train loss: 1.48622, train acc: 0.998 valid loss: 1.58848 valid acc: 0.937\n",
            "1-115th: train loss: 1.48603, train acc: 0.998 valid loss: 1.58835 valid acc: 0.937\n",
            "1-116th: train loss: 1.48584, train acc: 0.998 valid loss: 1.58822 valid acc: 0.937\n",
            "1-117th: train loss: 1.48566, train acc: 0.998 valid loss: 1.58810 valid acc: 0.937\n",
            "1-118th: train loss: 1.48548, train acc: 0.998 valid loss: 1.58798 valid acc: 0.937\n",
            "1-119th: train loss: 1.48530, train acc: 0.998 valid loss: 1.58786 valid acc: 0.937\n",
            "1-120th: train loss: 1.48512, train acc: 0.998 valid loss: 1.58774 valid acc: 0.937\n",
            "1-121th: train loss: 1.48495, train acc: 0.999 valid loss: 1.58762 valid acc: 0.937\n",
            "1-122th: train loss: 1.48479, train acc: 0.999 valid loss: 1.58749 valid acc: 0.937\n",
            "1-123th: train loss: 1.48462, train acc: 0.999 valid loss: 1.58736 valid acc: 0.937\n",
            "1-124th: train loss: 1.48447, train acc: 0.999 valid loss: 1.58722 valid acc: 0.937\n",
            "1-125th: train loss: 1.48432, train acc: 0.999 valid loss: 1.58707 valid acc: 0.937\n",
            "1-126th: train loss: 1.48418, train acc: 0.999 valid loss: 1.58691 valid acc: 0.940\n",
            "1-127th: train loss: 1.48405, train acc: 0.999 valid loss: 1.58675 valid acc: 0.940\n",
            "1-128th: train loss: 1.48392, train acc: 0.999 valid loss: 1.58658 valid acc: 0.940\n",
            "1-129th: train loss: 1.48379, train acc: 0.999 valid loss: 1.58640 valid acc: 0.940\n",
            "1-130th: train loss: 1.48366, train acc: 0.999 valid loss: 1.58621 valid acc: 0.940\n",
            "1-131th: train loss: 1.48354, train acc: 0.999 valid loss: 1.58602 valid acc: 0.940\n",
            "1-132th: train loss: 1.48342, train acc: 0.999 valid loss: 1.58582 valid acc: 0.940\n",
            "1-133th: train loss: 1.48330, train acc: 0.999 valid loss: 1.58562 valid acc: 0.940\n",
            "1-134th: train loss: 1.48318, train acc: 0.999 valid loss: 1.58542 valid acc: 0.940\n",
            "1-135th: train loss: 1.48307, train acc: 0.999 valid loss: 1.58521 valid acc: 0.940\n",
            "1-136th: train loss: 1.48296, train acc: 0.999 valid loss: 1.58501 valid acc: 0.937\n",
            "1-137th: train loss: 1.48285, train acc: 0.999 valid loss: 1.58481 valid acc: 0.937\n",
            "1-138th: train loss: 1.48274, train acc: 0.999 valid loss: 1.58461 valid acc: 0.937\n",
            "1-139th: train loss: 1.48264, train acc: 0.999 valid loss: 1.58441 valid acc: 0.937\n",
            "1-140th: train loss: 1.48254, train acc: 0.999 valid loss: 1.58422 valid acc: 0.940\n",
            "1-141th: train loss: 1.48244, train acc: 0.999 valid loss: 1.58403 valid acc: 0.940\n",
            "1-142th: train loss: 1.48234, train acc: 0.999 valid loss: 1.58385 valid acc: 0.940\n",
            "1-143th: train loss: 1.48225, train acc: 0.999 valid loss: 1.58368 valid acc: 0.940\n",
            "1-144th: train loss: 1.48216, train acc: 0.999 valid loss: 1.58351 valid acc: 0.940\n",
            "1-145th: train loss: 1.48206, train acc: 0.999 valid loss: 1.58335 valid acc: 0.940\n",
            "1-146th: train loss: 1.48197, train acc: 0.999 valid loss: 1.58320 valid acc: 0.940\n",
            "1-147th: train loss: 1.48189, train acc: 0.999 valid loss: 1.58304 valid acc: 0.940\n",
            "1-148th: train loss: 1.48180, train acc: 0.999 valid loss: 1.58289 valid acc: 0.940\n",
            "1-149th: train loss: 1.48172, train acc: 0.999 valid loss: 1.58275 valid acc: 0.937\n",
            "1-150th: train loss: 1.48163, train acc: 0.999 valid loss: 1.58260 valid acc: 0.937\n",
            "1-151th: train loss: 1.48155, train acc: 0.999 valid loss: 1.58246 valid acc: 0.937\n",
            "1-152th: train loss: 1.48147, train acc: 0.999 valid loss: 1.58232 valid acc: 0.937\n",
            "1-153th: train loss: 1.48139, train acc: 0.999 valid loss: 1.58218 valid acc: 0.937\n",
            "1-154th: train loss: 1.48131, train acc: 0.999 valid loss: 1.58204 valid acc: 0.937\n",
            "1-155th: train loss: 1.48124, train acc: 0.999 valid loss: 1.58191 valid acc: 0.937\n",
            "1-156th: train loss: 1.48116, train acc: 0.999 valid loss: 1.58177 valid acc: 0.937\n",
            "1-157th: train loss: 1.48109, train acc: 0.999 valid loss: 1.58164 valid acc: 0.937\n",
            "1-158th: train loss: 1.48102, train acc: 0.999 valid loss: 1.58151 valid acc: 0.937\n",
            "1-159th: train loss: 1.48095, train acc: 0.999 valid loss: 1.58137 valid acc: 0.937\n",
            "1-160th: train loss: 1.48088, train acc: 0.999 valid loss: 1.58124 valid acc: 0.937\n",
            "1-161th: train loss: 1.48081, train acc: 0.999 valid loss: 1.58111 valid acc: 0.937\n",
            "1-162th: train loss: 1.48074, train acc: 0.999 valid loss: 1.58098 valid acc: 0.937\n",
            "1-163th: train loss: 1.48067, train acc: 0.999 valid loss: 1.58085 valid acc: 0.937\n",
            "1-164th: train loss: 1.48061, train acc: 0.999 valid loss: 1.58071 valid acc: 0.937\n",
            "1-165th: train loss: 1.48054, train acc: 0.999 valid loss: 1.58058 valid acc: 0.937\n",
            "1-166th: train loss: 1.48048, train acc: 0.999 valid loss: 1.58046 valid acc: 0.937\n",
            "1-167th: train loss: 1.48042, train acc: 0.999 valid loss: 1.58033 valid acc: 0.937\n",
            "1-168th: train loss: 1.48035, train acc: 0.999 valid loss: 1.58020 valid acc: 0.937\n",
            "1-169th: train loss: 1.48029, train acc: 0.999 valid loss: 1.58008 valid acc: 0.937\n",
            "1-170th: train loss: 1.48023, train acc: 0.999 valid loss: 1.57996 valid acc: 0.937\n",
            "1-171th: train loss: 1.48017, train acc: 0.999 valid loss: 1.57984 valid acc: 0.937\n",
            "1-172th: train loss: 1.48012, train acc: 0.999 valid loss: 1.57972 valid acc: 0.937\n",
            "1-173th: train loss: 1.48006, train acc: 0.999 valid loss: 1.57960 valid acc: 0.937\n",
            "1-174th: train loss: 1.48000, train acc: 0.999 valid loss: 1.57948 valid acc: 0.937\n",
            "1-175th: train loss: 1.47994, train acc: 0.999 valid loss: 1.57937 valid acc: 0.937\n",
            "1-176th: train loss: 1.47989, train acc: 0.999 valid loss: 1.57926 valid acc: 0.937\n",
            "1-177th: train loss: 1.47983, train acc: 0.999 valid loss: 1.57915 valid acc: 0.940\n",
            "1-178th: train loss: 1.47978, train acc: 0.999 valid loss: 1.57904 valid acc: 0.940\n",
            "1-179th: train loss: 1.47973, train acc: 0.999 valid loss: 1.57893 valid acc: 0.940\n",
            "1-180th: train loss: 1.47968, train acc: 0.999 valid loss: 1.57883 valid acc: 0.940\n",
            "1-181th: train loss: 1.47962, train acc: 0.999 valid loss: 1.57872 valid acc: 0.940\n",
            "1-182th: train loss: 1.47957, train acc: 0.999 valid loss: 1.57862 valid acc: 0.940\n",
            "1-183th: train loss: 1.47952, train acc: 0.999 valid loss: 1.57852 valid acc: 0.940\n",
            "1-184th: train loss: 1.47947, train acc: 0.999 valid loss: 1.57842 valid acc: 0.940\n",
            "1-185th: train loss: 1.47942, train acc: 0.999 valid loss: 1.57832 valid acc: 0.940\n",
            "1-186th: train loss: 1.47937, train acc: 0.999 valid loss: 1.57823 valid acc: 0.940\n",
            "1-187th: train loss: 1.47933, train acc: 0.999 valid loss: 1.57814 valid acc: 0.944\n",
            "1-188th: train loss: 1.47928, train acc: 0.999 valid loss: 1.57804 valid acc: 0.944\n",
            "1-189th: train loss: 1.47923, train acc: 0.999 valid loss: 1.57795 valid acc: 0.944\n",
            "1-190th: train loss: 1.47919, train acc: 0.999 valid loss: 1.57787 valid acc: 0.944\n",
            "1-191th: train loss: 1.47914, train acc: 0.999 valid loss: 1.57778 valid acc: 0.944\n",
            "1-192th: train loss: 1.47910, train acc: 0.999 valid loss: 1.57770 valid acc: 0.944\n",
            "1-193th: train loss: 1.47905, train acc: 0.999 valid loss: 1.57762 valid acc: 0.944\n",
            "1-194th: train loss: 1.47901, train acc: 0.999 valid loss: 1.57754 valid acc: 0.944\n",
            "1-195th: train loss: 1.47897, train acc: 0.999 valid loss: 1.57746 valid acc: 0.944\n",
            "1-196th: train loss: 1.47892, train acc: 0.999 valid loss: 1.57738 valid acc: 0.944\n",
            "1-197th: train loss: 1.47888, train acc: 0.999 valid loss: 1.57731 valid acc: 0.944\n",
            "1-198th: train loss: 1.47884, train acc: 0.999 valid loss: 1.57723 valid acc: 0.944\n",
            "1-199th: train loss: 1.47880, train acc: 0.999 valid loss: 1.57716 valid acc: 0.944\n",
            "1-200th: train loss: 1.47876, train acc: 0.999 valid loss: 1.57709 valid acc: 0.944\n",
            "1-201th: train loss: 1.47872, train acc: 0.999 valid loss: 1.57702 valid acc: 0.944\n",
            "1-202th: train loss: 1.47868, train acc: 0.999 valid loss: 1.57696 valid acc: 0.944\n",
            "1-203th: train loss: 1.47864, train acc: 0.999 valid loss: 1.57689 valid acc: 0.944\n",
            "1-204th: train loss: 1.47860, train acc: 0.999 valid loss: 1.57683 valid acc: 0.944\n",
            "1-205th: train loss: 1.47856, train acc: 0.999 valid loss: 1.57676 valid acc: 0.944\n",
            "1-206th: train loss: 1.47853, train acc: 0.999 valid loss: 1.57670 valid acc: 0.944\n",
            "1-207th: train loss: 1.47849, train acc: 0.999 valid loss: 1.57664 valid acc: 0.944\n",
            "1-208th: train loss: 1.47845, train acc: 0.999 valid loss: 1.57659 valid acc: 0.944\n",
            "1-209th: train loss: 1.47842, train acc: 0.999 valid loss: 1.57653 valid acc: 0.944\n",
            "1-210th: train loss: 1.47838, train acc: 0.999 valid loss: 1.57647 valid acc: 0.944\n",
            "1-211th: train loss: 1.47835, train acc: 0.999 valid loss: 1.57642 valid acc: 0.944\n",
            "1-212th: train loss: 1.47832, train acc: 0.999 valid loss: 1.57637 valid acc: 0.944\n",
            "1-213th: train loss: 1.47828, train acc: 0.999 valid loss: 1.57632 valid acc: 0.944\n",
            "1-214th: train loss: 1.47825, train acc: 0.999 valid loss: 1.57627 valid acc: 0.944\n",
            "1-215th: train loss: 1.47822, train acc: 0.999 valid loss: 1.57622 valid acc: 0.944\n",
            "1-216th: train loss: 1.47818, train acc: 0.999 valid loss: 1.57618 valid acc: 0.944\n",
            "1-217th: train loss: 1.47815, train acc: 0.999 valid loss: 1.57613 valid acc: 0.944\n",
            "1-218th: train loss: 1.47812, train acc: 0.999 valid loss: 1.57609 valid acc: 0.944\n",
            "1-219th: train loss: 1.47809, train acc: 0.999 valid loss: 1.57605 valid acc: 0.944\n",
            "1-220th: train loss: 1.47806, train acc: 0.999 valid loss: 1.57601 valid acc: 0.944\n",
            "1-221th: train loss: 1.47803, train acc: 0.999 valid loss: 1.57597 valid acc: 0.944\n",
            "1-222th: train loss: 1.47800, train acc: 0.999 valid loss: 1.57593 valid acc: 0.944\n",
            "1-223th: train loss: 1.47797, train acc: 0.999 valid loss: 1.57590 valid acc: 0.944\n",
            "1-224th: train loss: 1.47794, train acc: 0.999 valid loss: 1.57586 valid acc: 0.940\n",
            "1-225th: train loss: 1.47791, train acc: 0.999 valid loss: 1.57583 valid acc: 0.940\n",
            "1-226th: train loss: 1.47789, train acc: 0.999 valid loss: 1.57580 valid acc: 0.940\n",
            "1-227th: train loss: 1.47786, train acc: 0.999 valid loss: 1.57577 valid acc: 0.940\n",
            "1-228th: train loss: 1.47783, train acc: 0.999 valid loss: 1.57574 valid acc: 0.940\n",
            "1-229th: train loss: 1.47781, train acc: 0.999 valid loss: 1.57572 valid acc: 0.940\n",
            "1-230th: train loss: 1.47778, train acc: 0.999 valid loss: 1.57569 valid acc: 0.940\n",
            "1-231th: train loss: 1.47775, train acc: 0.999 valid loss: 1.57567 valid acc: 0.940\n",
            "1-232th: train loss: 1.47773, train acc: 0.999 valid loss: 1.57565 valid acc: 0.940\n",
            "1-233th: train loss: 1.47770, train acc: 0.999 valid loss: 1.57563 valid acc: 0.940\n",
            "1-234th: train loss: 1.47768, train acc: 0.999 valid loss: 1.57561 valid acc: 0.940\n",
            "1-235th: train loss: 1.47766, train acc: 0.999 valid loss: 1.57559 valid acc: 0.940\n",
            "1-236th: train loss: 1.47763, train acc: 0.999 valid loss: 1.57557 valid acc: 0.940\n",
            "1-237th: train loss: 1.47761, train acc: 0.999 valid loss: 1.57555 valid acc: 0.940\n",
            "1-238th: train loss: 1.47759, train acc: 0.999 valid loss: 1.57554 valid acc: 0.940\n",
            "1-239th: train loss: 1.47756, train acc: 0.999 valid loss: 1.57553 valid acc: 0.940\n",
            "1-240th: train loss: 1.47754, train acc: 0.999 valid loss: 1.57551 valid acc: 0.940\n",
            "1-241th: train loss: 1.47752, train acc: 0.999 valid loss: 1.57550 valid acc: 0.944\n",
            "1-242th: train loss: 1.47750, train acc: 0.999 valid loss: 1.57549 valid acc: 0.944\n",
            "1-243th: train loss: 1.47748, train acc: 0.999 valid loss: 1.57548 valid acc: 0.944\n",
            "1-244th: train loss: 1.47745, train acc: 0.999 valid loss: 1.57548 valid acc: 0.944\n",
            "1-245th: train loss: 1.47743, train acc: 0.999 valid loss: 1.57547 valid acc: 0.944\n",
            "1-246th: train loss: 1.47741, train acc: 0.999 valid loss: 1.57547 valid acc: 0.944\n",
            "1-247th: train loss: 1.47739, train acc: 0.999 valid loss: 1.57546 valid acc: 0.947\n",
            "1-248th: train loss: 1.47737, train acc: 0.999 valid loss: 1.57546 valid acc: 0.947\n",
            "1-249th: train loss: 1.47735, train acc: 0.999 valid loss: 1.57546 valid acc: 0.947\n",
            "1-250th: train loss: 1.47733, train acc: 0.999 valid loss: 1.57546 valid acc: 0.947\n",
            "1-251th: train loss: 1.47731, train acc: 0.999 valid loss: 1.57546 valid acc: 0.947\n",
            "1-252th: train loss: 1.47729, train acc: 0.999 valid loss: 1.57546 valid acc: 0.947\n",
            "1-253th: train loss: 1.47728, train acc: 0.999 valid loss: 1.57546 valid acc: 0.947\n",
            "1-254th: train loss: 1.47726, train acc: 0.999 valid loss: 1.57547 valid acc: 0.947\n",
            "1-255th: train loss: 1.47724, train acc: 0.999 valid loss: 1.57547 valid acc: 0.947\n",
            "1-256th: train loss: 1.47722, train acc: 0.999 valid loss: 1.57548 valid acc: 0.947\n",
            "1-257th: train loss: 1.47720, train acc: 0.999 valid loss: 1.57548 valid acc: 0.947\n",
            "1-258th: train loss: 1.47718, train acc: 0.999 valid loss: 1.57549 valid acc: 0.947\n",
            "1-259th: train loss: 1.47717, train acc: 0.999 valid loss: 1.57550 valid acc: 0.947\n",
            "1-260th: train loss: 1.47715, train acc: 0.999 valid loss: 1.57551 valid acc: 0.947\n",
            "1-261th: train loss: 1.47713, train acc: 0.999 valid loss: 1.57552 valid acc: 0.947\n",
            "1-262th: train loss: 1.47712, train acc: 0.999 valid loss: 1.57553 valid acc: 0.947\n",
            "1-263th: train loss: 1.47710, train acc: 0.999 valid loss: 1.57554 valid acc: 0.947\n",
            "1-264th: train loss: 1.47708, train acc: 0.999 valid loss: 1.57555 valid acc: 0.947\n",
            "1-265th: train loss: 1.47706, train acc: 0.999 valid loss: 1.57557 valid acc: 0.947\n",
            "1-266th: train loss: 1.47705, train acc: 0.999 valid loss: 1.57558 valid acc: 0.947\n",
            "1-267th: train loss: 1.47703, train acc: 0.999 valid loss: 1.57560 valid acc: 0.947\n",
            "1-268th: train loss: 1.47701, train acc: 0.999 valid loss: 1.57561 valid acc: 0.947\n",
            "1-269th: train loss: 1.47700, train acc: 0.999 valid loss: 1.57563 valid acc: 0.947\n",
            "1-270th: train loss: 1.47698, train acc: 0.999 valid loss: 1.57565 valid acc: 0.947\n",
            "1-271th: train loss: 1.47697, train acc: 0.999 valid loss: 1.57566 valid acc: 0.947\n",
            "1-272th: train loss: 1.47695, train acc: 0.999 valid loss: 1.57568 valid acc: 0.944\n",
            "1-273th: train loss: 1.47693, train acc: 0.999 valid loss: 1.57570 valid acc: 0.944\n",
            "1-274th: train loss: 1.47692, train acc: 0.999 valid loss: 1.57572 valid acc: 0.944\n",
            "1-275th: train loss: 1.47690, train acc: 0.999 valid loss: 1.57574 valid acc: 0.944\n",
            "1-276th: train loss: 1.47689, train acc: 0.999 valid loss: 1.57577 valid acc: 0.944\n",
            "1-277th: train loss: 1.47687, train acc: 0.999 valid loss: 1.57579 valid acc: 0.944\n",
            "1-278th: train loss: 1.47686, train acc: 0.999 valid loss: 1.57581 valid acc: 0.944\n",
            "1-279th: train loss: 1.47684, train acc: 0.999 valid loss: 1.57583 valid acc: 0.944\n",
            "1-280th: train loss: 1.47683, train acc: 0.999 valid loss: 1.57586 valid acc: 0.944\n",
            "1-281th: train loss: 1.47681, train acc: 0.999 valid loss: 1.57588 valid acc: 0.944\n",
            "1-282th: train loss: 1.47680, train acc: 0.999 valid loss: 1.57591 valid acc: 0.944\n",
            "1-283th: train loss: 1.47678, train acc: 0.999 valid loss: 1.57594 valid acc: 0.944\n",
            "1-284th: train loss: 1.47677, train acc: 0.999 valid loss: 1.57596 valid acc: 0.944\n",
            "1-285th: train loss: 1.47675, train acc: 0.999 valid loss: 1.57599 valid acc: 0.944\n",
            "1-286th: train loss: 1.47674, train acc: 0.999 valid loss: 1.57602 valid acc: 0.944\n",
            "1-287th: train loss: 1.47672, train acc: 0.999 valid loss: 1.57605 valid acc: 0.944\n",
            "1-288th: train loss: 1.47671, train acc: 0.999 valid loss: 1.57608 valid acc: 0.944\n",
            "1-289th: train loss: 1.47669, train acc: 0.999 valid loss: 1.57611 valid acc: 0.944\n",
            "1-290th: train loss: 1.47668, train acc: 0.999 valid loss: 1.57614 valid acc: 0.944\n",
            "1-291th: train loss: 1.47667, train acc: 0.999 valid loss: 1.57617 valid acc: 0.944\n",
            "1-292th: train loss: 1.47665, train acc: 0.999 valid loss: 1.57620 valid acc: 0.944\n",
            "1-293th: train loss: 1.47664, train acc: 0.999 valid loss: 1.57623 valid acc: 0.944\n",
            "1-294th: train loss: 1.47662, train acc: 0.999 valid loss: 1.57627 valid acc: 0.944\n",
            "1-295th: train loss: 1.47661, train acc: 0.999 valid loss: 1.57630 valid acc: 0.944\n",
            "1-296th: train loss: 1.47660, train acc: 0.999 valid loss: 1.57633 valid acc: 0.944\n",
            "1-297th: train loss: 1.47658, train acc: 0.999 valid loss: 1.57637 valid acc: 0.944\n",
            "1-298th: train loss: 1.47657, train acc: 0.999 valid loss: 1.57640 valid acc: 0.944\n",
            "1-299th: train loss: 1.47656, train acc: 0.999 valid loss: 1.57644 valid acc: 0.947\n",
            "2-0th: train loss: 2.30384, train acc: 0.097 valid loss: 2.22519 valid acc: 0.310\n",
            "2-1th: train loss: 2.21650, train acc: 0.307 valid loss: 2.13345 valid acc: 0.455\n",
            "2-2th: train loss: 2.12245, train acc: 0.440 valid loss: 2.05250 valid acc: 0.527\n",
            "2-3th: train loss: 2.04095, train acc: 0.527 valid loss: 1.98745 valid acc: 0.577\n",
            "2-4th: train loss: 1.97670, train acc: 0.580 valid loss: 1.93461 valid acc: 0.611\n",
            "2-5th: train loss: 1.92518, train acc: 0.629 valid loss: 1.89001 valid acc: 0.671\n",
            "2-6th: train loss: 1.88137, train acc: 0.678 valid loss: 1.85306 valid acc: 0.721\n",
            "2-7th: train loss: 1.84397, train acc: 0.718 valid loss: 1.82347 valid acc: 0.768\n",
            "2-8th: train loss: 1.81325, train acc: 0.757 valid loss: 1.79785 valid acc: 0.790\n",
            "2-9th: train loss: 1.78712, train acc: 0.776 valid loss: 1.77292 valid acc: 0.812\n",
            "2-10th: train loss: 1.76266, train acc: 0.808 valid loss: 1.74846 valid acc: 0.846\n",
            "2-11th: train loss: 1.73920, train acc: 0.832 valid loss: 1.72662 valid acc: 0.868\n",
            "2-12th: train loss: 1.71799, train acc: 0.857 valid loss: 1.70986 valid acc: 0.881\n",
            "2-13th: train loss: 1.70076, train acc: 0.875 valid loss: 1.69724 valid acc: 0.884\n",
            "2-14th: train loss: 1.68694, train acc: 0.890 valid loss: 1.68551 valid acc: 0.890\n",
            "2-15th: train loss: 1.67406, train acc: 0.896 valid loss: 1.67380 valid acc: 0.906\n",
            "2-16th: train loss: 1.66143, train acc: 0.906 valid loss: 1.66337 valid acc: 0.912\n",
            "2-17th: train loss: 1.64989, train acc: 0.914 valid loss: 1.65499 valid acc: 0.912\n",
            "2-18th: train loss: 1.63983, train acc: 0.921 valid loss: 1.64845 valid acc: 0.918\n",
            "2-19th: train loss: 1.63090, train acc: 0.929 valid loss: 1.64319 valid acc: 0.918\n",
            "2-20th: train loss: 1.62268, train acc: 0.933 valid loss: 1.63869 valid acc: 0.922\n",
            "2-21th: train loss: 1.61496, train acc: 0.937 valid loss: 1.63458 valid acc: 0.925\n",
            "2-22th: train loss: 1.60769, train acc: 0.940 valid loss: 1.63059 valid acc: 0.931\n",
            "2-23th: train loss: 1.60096, train acc: 0.943 valid loss: 1.62659 valid acc: 0.937\n",
            "2-24th: train loss: 1.59486, train acc: 0.947 valid loss: 1.62254 valid acc: 0.937\n",
            "2-25th: train loss: 1.58931, train acc: 0.953 valid loss: 1.61850 valid acc: 0.940\n",
            "2-26th: train loss: 1.58415, train acc: 0.955 valid loss: 1.61461 valid acc: 0.937\n",
            "2-27th: train loss: 1.57928, train acc: 0.958 valid loss: 1.61104 valid acc: 0.937\n",
            "2-28th: train loss: 1.57464, train acc: 0.959 valid loss: 1.60792 valid acc: 0.940\n",
            "2-29th: train loss: 1.57024, train acc: 0.961 valid loss: 1.60531 valid acc: 0.940\n",
            "2-30th: train loss: 1.56616, train acc: 0.963 valid loss: 1.60320 valid acc: 0.944\n",
            "2-31th: train loss: 1.56242, train acc: 0.965 valid loss: 1.60144 valid acc: 0.947\n",
            "2-32th: train loss: 1.55898, train acc: 0.966 valid loss: 1.59983 valid acc: 0.947\n",
            "2-33th: train loss: 1.55575, train acc: 0.967 valid loss: 1.59824 valid acc: 0.947\n",
            "2-34th: train loss: 1.55265, train acc: 0.969 valid loss: 1.59665 valid acc: 0.947\n",
            "2-35th: train loss: 1.54970, train acc: 0.972 valid loss: 1.59516 valid acc: 0.947\n",
            "2-36th: train loss: 1.54691, train acc: 0.973 valid loss: 1.59382 valid acc: 0.947\n",
            "2-37th: train loss: 1.54428, train acc: 0.974 valid loss: 1.59266 valid acc: 0.944\n",
            "2-38th: train loss: 1.54179, train acc: 0.975 valid loss: 1.59166 valid acc: 0.940\n",
            "2-39th: train loss: 1.53938, train acc: 0.979 valid loss: 1.59079 valid acc: 0.940\n",
            "2-40th: train loss: 1.53704, train acc: 0.980 valid loss: 1.59002 valid acc: 0.940\n",
            "2-41th: train loss: 1.53481, train acc: 0.982 valid loss: 1.58930 valid acc: 0.940\n",
            "2-42th: train loss: 1.53271, train acc: 0.983 valid loss: 1.58855 valid acc: 0.944\n",
            "2-43th: train loss: 1.53074, train acc: 0.984 valid loss: 1.58770 valid acc: 0.950\n",
            "2-44th: train loss: 1.52890, train acc: 0.985 valid loss: 1.58673 valid acc: 0.950\n",
            "2-45th: train loss: 1.52715, train acc: 0.986 valid loss: 1.58566 valid acc: 0.947\n",
            "2-46th: train loss: 1.52549, train acc: 0.986 valid loss: 1.58453 valid acc: 0.950\n",
            "2-47th: train loss: 1.52391, train acc: 0.986 valid loss: 1.58338 valid acc: 0.950\n",
            "2-48th: train loss: 1.52239, train acc: 0.986 valid loss: 1.58227 valid acc: 0.953\n",
            "2-49th: train loss: 1.52093, train acc: 0.986 valid loss: 1.58121 valid acc: 0.953\n",
            "2-50th: train loss: 1.51952, train acc: 0.987 valid loss: 1.58023 valid acc: 0.953\n",
            "2-51th: train loss: 1.51818, train acc: 0.988 valid loss: 1.57932 valid acc: 0.956\n",
            "2-52th: train loss: 1.51691, train acc: 0.989 valid loss: 1.57844 valid acc: 0.956\n",
            "2-53th: train loss: 1.51572, train acc: 0.990 valid loss: 1.57754 valid acc: 0.956\n",
            "2-54th: train loss: 1.51459, train acc: 0.990 valid loss: 1.57662 valid acc: 0.959\n",
            "2-55th: train loss: 1.51353, train acc: 0.990 valid loss: 1.57567 valid acc: 0.959\n",
            "2-56th: train loss: 1.51253, train acc: 0.990 valid loss: 1.57472 valid acc: 0.962\n",
            "2-57th: train loss: 1.51159, train acc: 0.990 valid loss: 1.57381 valid acc: 0.962\n",
            "2-58th: train loss: 1.51072, train acc: 0.990 valid loss: 1.57295 valid acc: 0.962\n",
            "2-59th: train loss: 1.50989, train acc: 0.990 valid loss: 1.57216 valid acc: 0.962\n",
            "2-60th: train loss: 1.50910, train acc: 0.990 valid loss: 1.57145 valid acc: 0.962\n",
            "2-61th: train loss: 1.50834, train acc: 0.990 valid loss: 1.57082 valid acc: 0.962\n",
            "2-62th: train loss: 1.50760, train acc: 0.990 valid loss: 1.57025 valid acc: 0.962\n",
            "2-63th: train loss: 1.50690, train acc: 0.990 valid loss: 1.56973 valid acc: 0.962\n",
            "2-64th: train loss: 1.50622, train acc: 0.990 valid loss: 1.56922 valid acc: 0.962\n",
            "2-65th: train loss: 1.50557, train acc: 0.991 valid loss: 1.56871 valid acc: 0.962\n",
            "2-66th: train loss: 1.50495, train acc: 0.991 valid loss: 1.56819 valid acc: 0.962\n",
            "2-67th: train loss: 1.50433, train acc: 0.991 valid loss: 1.56766 valid acc: 0.962\n",
            "2-68th: train loss: 1.50374, train acc: 0.991 valid loss: 1.56714 valid acc: 0.962\n",
            "2-69th: train loss: 1.50316, train acc: 0.991 valid loss: 1.56664 valid acc: 0.962\n",
            "2-70th: train loss: 1.50261, train acc: 0.991 valid loss: 1.56619 valid acc: 0.962\n",
            "2-71th: train loss: 1.50206, train acc: 0.993 valid loss: 1.56578 valid acc: 0.962\n",
            "2-72th: train loss: 1.50154, train acc: 0.993 valid loss: 1.56542 valid acc: 0.962\n",
            "2-73th: train loss: 1.50102, train acc: 0.993 valid loss: 1.56509 valid acc: 0.962\n",
            "2-74th: train loss: 1.50052, train acc: 0.993 valid loss: 1.56478 valid acc: 0.962\n",
            "2-75th: train loss: 1.50002, train acc: 0.993 valid loss: 1.56448 valid acc: 0.962\n",
            "2-76th: train loss: 1.49954, train acc: 0.993 valid loss: 1.56418 valid acc: 0.962\n",
            "2-77th: train loss: 1.49907, train acc: 0.993 valid loss: 1.56387 valid acc: 0.962\n",
            "2-78th: train loss: 1.49861, train acc: 0.994 valid loss: 1.56355 valid acc: 0.962\n",
            "2-79th: train loss: 1.49816, train acc: 0.995 valid loss: 1.56323 valid acc: 0.959\n",
            "2-80th: train loss: 1.49773, train acc: 0.995 valid loss: 1.56291 valid acc: 0.959\n",
            "2-81th: train loss: 1.49731, train acc: 0.995 valid loss: 1.56262 valid acc: 0.959\n",
            "2-82th: train loss: 1.49690, train acc: 0.996 valid loss: 1.56235 valid acc: 0.959\n",
            "2-83th: train loss: 1.49652, train acc: 0.996 valid loss: 1.56211 valid acc: 0.959\n",
            "2-84th: train loss: 1.49614, train acc: 0.996 valid loss: 1.56188 valid acc: 0.959\n",
            "2-85th: train loss: 1.49578, train acc: 0.996 valid loss: 1.56168 valid acc: 0.959\n",
            "2-86th: train loss: 1.49542, train acc: 0.996 valid loss: 1.56148 valid acc: 0.959\n",
            "2-87th: train loss: 1.49508, train acc: 0.996 valid loss: 1.56128 valid acc: 0.959\n",
            "2-88th: train loss: 1.49475, train acc: 0.996 valid loss: 1.56108 valid acc: 0.959\n",
            "2-89th: train loss: 1.49442, train acc: 0.996 valid loss: 1.56088 valid acc: 0.959\n",
            "2-90th: train loss: 1.49411, train acc: 0.996 valid loss: 1.56067 valid acc: 0.959\n",
            "2-91th: train loss: 1.49380, train acc: 0.996 valid loss: 1.56048 valid acc: 0.959\n",
            "2-92th: train loss: 1.49351, train acc: 0.996 valid loss: 1.56029 valid acc: 0.959\n",
            "2-93th: train loss: 1.49322, train acc: 0.996 valid loss: 1.56012 valid acc: 0.959\n",
            "2-94th: train loss: 1.49294, train acc: 0.996 valid loss: 1.55997 valid acc: 0.959\n",
            "2-95th: train loss: 1.49268, train acc: 0.996 valid loss: 1.55984 valid acc: 0.959\n",
            "2-96th: train loss: 1.49242, train acc: 0.996 valid loss: 1.55972 valid acc: 0.959\n",
            "2-97th: train loss: 1.49217, train acc: 0.996 valid loss: 1.55960 valid acc: 0.959\n",
            "2-98th: train loss: 1.49192, train acc: 0.996 valid loss: 1.55949 valid acc: 0.956\n",
            "2-99th: train loss: 1.49168, train acc: 0.996 valid loss: 1.55938 valid acc: 0.956\n",
            "2-100th: train loss: 1.49145, train acc: 0.996 valid loss: 1.55927 valid acc: 0.956\n",
            "2-101th: train loss: 1.49122, train acc: 0.996 valid loss: 1.55917 valid acc: 0.956\n",
            "2-102th: train loss: 1.49100, train acc: 0.996 valid loss: 1.55906 valid acc: 0.956\n",
            "2-103th: train loss: 1.49078, train acc: 0.996 valid loss: 1.55895 valid acc: 0.956\n",
            "2-104th: train loss: 1.49056, train acc: 0.996 valid loss: 1.55884 valid acc: 0.956\n",
            "2-105th: train loss: 1.49035, train acc: 0.996 valid loss: 1.55874 valid acc: 0.959\n",
            "2-106th: train loss: 1.49014, train acc: 0.996 valid loss: 1.55864 valid acc: 0.959\n",
            "2-107th: train loss: 1.48993, train acc: 0.996 valid loss: 1.55855 valid acc: 0.959\n",
            "2-108th: train loss: 1.48972, train acc: 0.996 valid loss: 1.55845 valid acc: 0.959\n",
            "2-109th: train loss: 1.48952, train acc: 0.996 valid loss: 1.55835 valid acc: 0.959\n",
            "2-110th: train loss: 1.48931, train acc: 0.997 valid loss: 1.55825 valid acc: 0.959\n",
            "2-111th: train loss: 1.48912, train acc: 0.997 valid loss: 1.55816 valid acc: 0.959\n",
            "2-112th: train loss: 1.48892, train acc: 0.997 valid loss: 1.55806 valid acc: 0.959\n",
            "2-113th: train loss: 1.48873, train acc: 0.997 valid loss: 1.55796 valid acc: 0.959\n",
            "2-114th: train loss: 1.48855, train acc: 0.997 valid loss: 1.55786 valid acc: 0.959\n",
            "2-115th: train loss: 1.48838, train acc: 0.997 valid loss: 1.55776 valid acc: 0.959\n",
            "2-116th: train loss: 1.48821, train acc: 0.997 valid loss: 1.55766 valid acc: 0.959\n",
            "2-117th: train loss: 1.48805, train acc: 0.997 valid loss: 1.55755 valid acc: 0.959\n",
            "2-118th: train loss: 1.48789, train acc: 0.997 valid loss: 1.55743 valid acc: 0.959\n",
            "2-119th: train loss: 1.48773, train acc: 0.997 valid loss: 1.55731 valid acc: 0.959\n",
            "2-120th: train loss: 1.48758, train acc: 0.997 valid loss: 1.55717 valid acc: 0.959\n",
            "2-121th: train loss: 1.48743, train acc: 0.997 valid loss: 1.55703 valid acc: 0.959\n",
            "2-122th: train loss: 1.48728, train acc: 0.997 valid loss: 1.55688 valid acc: 0.959\n",
            "2-123th: train loss: 1.48713, train acc: 0.997 valid loss: 1.55673 valid acc: 0.959\n",
            "2-124th: train loss: 1.48698, train acc: 0.997 valid loss: 1.55658 valid acc: 0.959\n",
            "2-125th: train loss: 1.48684, train acc: 0.997 valid loss: 1.55644 valid acc: 0.959\n",
            "2-126th: train loss: 1.48670, train acc: 0.997 valid loss: 1.55630 valid acc: 0.959\n",
            "2-127th: train loss: 1.48655, train acc: 0.997 valid loss: 1.55618 valid acc: 0.959\n",
            "2-128th: train loss: 1.48641, train acc: 0.997 valid loss: 1.55606 valid acc: 0.959\n",
            "2-129th: train loss: 1.48628, train acc: 0.998 valid loss: 1.55595 valid acc: 0.959\n",
            "2-130th: train loss: 1.48614, train acc: 0.998 valid loss: 1.55585 valid acc: 0.959\n",
            "2-131th: train loss: 1.48600, train acc: 0.998 valid loss: 1.55575 valid acc: 0.959\n",
            "2-132th: train loss: 1.48586, train acc: 0.998 valid loss: 1.55566 valid acc: 0.959\n",
            "2-133th: train loss: 1.48573, train acc: 0.998 valid loss: 1.55557 valid acc: 0.959\n",
            "2-134th: train loss: 1.48560, train acc: 0.998 valid loss: 1.55548 valid acc: 0.959\n",
            "2-135th: train loss: 1.48547, train acc: 0.998 valid loss: 1.55540 valid acc: 0.959\n",
            "2-136th: train loss: 1.48534, train acc: 0.998 valid loss: 1.55531 valid acc: 0.959\n",
            "2-137th: train loss: 1.48521, train acc: 0.998 valid loss: 1.55523 valid acc: 0.959\n",
            "2-138th: train loss: 1.48510, train acc: 0.998 valid loss: 1.55514 valid acc: 0.959\n",
            "2-139th: train loss: 1.48498, train acc: 0.998 valid loss: 1.55504 valid acc: 0.959\n",
            "2-140th: train loss: 1.48487, train acc: 0.998 valid loss: 1.55494 valid acc: 0.959\n",
            "2-141th: train loss: 1.48476, train acc: 0.998 valid loss: 1.55483 valid acc: 0.959\n",
            "2-142th: train loss: 1.48466, train acc: 0.998 valid loss: 1.55471 valid acc: 0.959\n",
            "2-143th: train loss: 1.48456, train acc: 0.998 valid loss: 1.55457 valid acc: 0.959\n",
            "2-144th: train loss: 1.48445, train acc: 0.998 valid loss: 1.55443 valid acc: 0.959\n",
            "2-145th: train loss: 1.48435, train acc: 0.998 valid loss: 1.55427 valid acc: 0.959\n",
            "2-146th: train loss: 1.48425, train acc: 0.998 valid loss: 1.55411 valid acc: 0.959\n",
            "2-147th: train loss: 1.48416, train acc: 0.998 valid loss: 1.55394 valid acc: 0.959\n",
            "2-148th: train loss: 1.48406, train acc: 0.998 valid loss: 1.55378 valid acc: 0.959\n",
            "2-149th: train loss: 1.48397, train acc: 0.998 valid loss: 1.55362 valid acc: 0.959\n",
            "2-150th: train loss: 1.48387, train acc: 0.998 valid loss: 1.55346 valid acc: 0.959\n",
            "2-151th: train loss: 1.48378, train acc: 0.998 valid loss: 1.55330 valid acc: 0.959\n",
            "2-152th: train loss: 1.48369, train acc: 0.998 valid loss: 1.55316 valid acc: 0.959\n",
            "2-153th: train loss: 1.48360, train acc: 0.998 valid loss: 1.55301 valid acc: 0.959\n",
            "2-154th: train loss: 1.48351, train acc: 0.998 valid loss: 1.55288 valid acc: 0.959\n",
            "2-155th: train loss: 1.48343, train acc: 0.998 valid loss: 1.55275 valid acc: 0.959\n",
            "2-156th: train loss: 1.48334, train acc: 0.998 valid loss: 1.55262 valid acc: 0.959\n",
            "2-157th: train loss: 1.48326, train acc: 0.998 valid loss: 1.55249 valid acc: 0.959\n",
            "2-158th: train loss: 1.48318, train acc: 0.998 valid loss: 1.55238 valid acc: 0.959\n",
            "2-159th: train loss: 1.48310, train acc: 0.998 valid loss: 1.55226 valid acc: 0.956\n",
            "2-160th: train loss: 1.48302, train acc: 0.998 valid loss: 1.55215 valid acc: 0.956\n",
            "2-161th: train loss: 1.48294, train acc: 0.998 valid loss: 1.55204 valid acc: 0.956\n",
            "2-162th: train loss: 1.48286, train acc: 0.998 valid loss: 1.55194 valid acc: 0.956\n",
            "2-163th: train loss: 1.48279, train acc: 0.998 valid loss: 1.55184 valid acc: 0.956\n",
            "2-164th: train loss: 1.48271, train acc: 0.998 valid loss: 1.55174 valid acc: 0.956\n",
            "2-165th: train loss: 1.48263, train acc: 0.998 valid loss: 1.55164 valid acc: 0.956\n",
            "2-166th: train loss: 1.48256, train acc: 0.998 valid loss: 1.55154 valid acc: 0.956\n",
            "2-167th: train loss: 1.48248, train acc: 0.998 valid loss: 1.55144 valid acc: 0.956\n",
            "2-168th: train loss: 1.48240, train acc: 0.998 valid loss: 1.55134 valid acc: 0.956\n",
            "2-169th: train loss: 1.48233, train acc: 0.998 valid loss: 1.55125 valid acc: 0.956\n",
            "2-170th: train loss: 1.48225, train acc: 0.998 valid loss: 1.55115 valid acc: 0.956\n",
            "2-171th: train loss: 1.48217, train acc: 0.998 valid loss: 1.55106 valid acc: 0.956\n",
            "2-172th: train loss: 1.48209, train acc: 0.998 valid loss: 1.55098 valid acc: 0.956\n",
            "2-173th: train loss: 1.48201, train acc: 0.998 valid loss: 1.55089 valid acc: 0.956\n",
            "2-174th: train loss: 1.48193, train acc: 0.998 valid loss: 1.55081 valid acc: 0.956\n",
            "2-175th: train loss: 1.48185, train acc: 0.998 valid loss: 1.55073 valid acc: 0.953\n",
            "2-176th: train loss: 1.48177, train acc: 0.998 valid loss: 1.55065 valid acc: 0.953\n",
            "2-177th: train loss: 1.48169, train acc: 0.998 valid loss: 1.55057 valid acc: 0.953\n",
            "2-178th: train loss: 1.48161, train acc: 0.998 valid loss: 1.55049 valid acc: 0.953\n",
            "2-179th: train loss: 1.48153, train acc: 0.998 valid loss: 1.55040 valid acc: 0.953\n",
            "2-180th: train loss: 1.48146, train acc: 0.998 valid loss: 1.55031 valid acc: 0.953\n",
            "2-181th: train loss: 1.48139, train acc: 0.998 valid loss: 1.55021 valid acc: 0.953\n",
            "2-182th: train loss: 1.48133, train acc: 0.998 valid loss: 1.55011 valid acc: 0.953\n",
            "2-183th: train loss: 1.48126, train acc: 0.998 valid loss: 1.55000 valid acc: 0.953\n",
            "2-184th: train loss: 1.48120, train acc: 0.998 valid loss: 1.54989 valid acc: 0.953\n",
            "2-185th: train loss: 1.48114, train acc: 0.998 valid loss: 1.54979 valid acc: 0.953\n",
            "2-186th: train loss: 1.48108, train acc: 0.998 valid loss: 1.54968 valid acc: 0.953\n",
            "2-187th: train loss: 1.48102, train acc: 0.998 valid loss: 1.54957 valid acc: 0.953\n",
            "2-188th: train loss: 1.48095, train acc: 0.998 valid loss: 1.54946 valid acc: 0.953\n",
            "2-189th: train loss: 1.48090, train acc: 0.998 valid loss: 1.54934 valid acc: 0.953\n",
            "2-190th: train loss: 1.48084, train acc: 0.998 valid loss: 1.54923 valid acc: 0.953\n",
            "2-191th: train loss: 1.48078, train acc: 0.998 valid loss: 1.54912 valid acc: 0.953\n",
            "2-192th: train loss: 1.48072, train acc: 0.998 valid loss: 1.54901 valid acc: 0.953\n",
            "2-193th: train loss: 1.48067, train acc: 0.998 valid loss: 1.54890 valid acc: 0.953\n",
            "2-194th: train loss: 1.48061, train acc: 0.998 valid loss: 1.54880 valid acc: 0.953\n",
            "2-195th: train loss: 1.48056, train acc: 0.998 valid loss: 1.54869 valid acc: 0.953\n",
            "2-196th: train loss: 1.48051, train acc: 0.998 valid loss: 1.54860 valid acc: 0.953\n",
            "2-197th: train loss: 1.48046, train acc: 0.998 valid loss: 1.54850 valid acc: 0.953\n",
            "2-198th: train loss: 1.48041, train acc: 0.998 valid loss: 1.54840 valid acc: 0.953\n",
            "2-199th: train loss: 1.48036, train acc: 0.998 valid loss: 1.54831 valid acc: 0.953\n",
            "2-200th: train loss: 1.48031, train acc: 0.998 valid loss: 1.54822 valid acc: 0.953\n",
            "2-201th: train loss: 1.48026, train acc: 0.998 valid loss: 1.54812 valid acc: 0.953\n",
            "2-202th: train loss: 1.48021, train acc: 0.998 valid loss: 1.54803 valid acc: 0.953\n",
            "2-203th: train loss: 1.48016, train acc: 0.998 valid loss: 1.54793 valid acc: 0.953\n",
            "2-204th: train loss: 1.48012, train acc: 0.998 valid loss: 1.54784 valid acc: 0.953\n",
            "2-205th: train loss: 1.48007, train acc: 0.998 valid loss: 1.54775 valid acc: 0.953\n",
            "2-206th: train loss: 1.48003, train acc: 0.998 valid loss: 1.54765 valid acc: 0.953\n",
            "2-207th: train loss: 1.47998, train acc: 0.998 valid loss: 1.54756 valid acc: 0.956\n",
            "2-208th: train loss: 1.47994, train acc: 0.998 valid loss: 1.54747 valid acc: 0.956\n",
            "2-209th: train loss: 1.47989, train acc: 0.998 valid loss: 1.54739 valid acc: 0.956\n",
            "2-210th: train loss: 1.47985, train acc: 0.998 valid loss: 1.54730 valid acc: 0.956\n",
            "2-211th: train loss: 1.47980, train acc: 0.998 valid loss: 1.54721 valid acc: 0.956\n",
            "2-212th: train loss: 1.47976, train acc: 0.998 valid loss: 1.54713 valid acc: 0.956\n",
            "2-213th: train loss: 1.47972, train acc: 0.998 valid loss: 1.54704 valid acc: 0.956\n",
            "2-214th: train loss: 1.47967, train acc: 0.998 valid loss: 1.54695 valid acc: 0.956\n",
            "2-215th: train loss: 1.47962, train acc: 0.998 valid loss: 1.54686 valid acc: 0.956\n",
            "2-216th: train loss: 1.47958, train acc: 0.998 valid loss: 1.54677 valid acc: 0.956\n",
            "2-217th: train loss: 1.47953, train acc: 0.998 valid loss: 1.54668 valid acc: 0.956\n",
            "2-218th: train loss: 1.47948, train acc: 0.998 valid loss: 1.54659 valid acc: 0.956\n",
            "2-219th: train loss: 1.47943, train acc: 0.998 valid loss: 1.54649 valid acc: 0.956\n",
            "2-220th: train loss: 1.47937, train acc: 0.998 valid loss: 1.54639 valid acc: 0.956\n",
            "2-221th: train loss: 1.47931, train acc: 0.998 valid loss: 1.54629 valid acc: 0.956\n",
            "2-222th: train loss: 1.47926, train acc: 0.999 valid loss: 1.54619 valid acc: 0.956\n",
            "2-223th: train loss: 1.47920, train acc: 0.999 valid loss: 1.54609 valid acc: 0.956\n",
            "2-224th: train loss: 1.47914, train acc: 0.999 valid loss: 1.54598 valid acc: 0.956\n",
            "2-225th: train loss: 1.47909, train acc: 0.999 valid loss: 1.54587 valid acc: 0.956\n",
            "2-226th: train loss: 1.47904, train acc: 0.999 valid loss: 1.54576 valid acc: 0.956\n",
            "2-227th: train loss: 1.47900, train acc: 0.999 valid loss: 1.54565 valid acc: 0.956\n",
            "2-228th: train loss: 1.47895, train acc: 0.999 valid loss: 1.54556 valid acc: 0.956\n",
            "2-229th: train loss: 1.47891, train acc: 0.999 valid loss: 1.54547 valid acc: 0.956\n",
            "2-230th: train loss: 1.47888, train acc: 0.999 valid loss: 1.54539 valid acc: 0.956\n",
            "2-231th: train loss: 1.47884, train acc: 0.999 valid loss: 1.54533 valid acc: 0.956\n",
            "2-232th: train loss: 1.47880, train acc: 0.999 valid loss: 1.54528 valid acc: 0.956\n",
            "2-233th: train loss: 1.47876, train acc: 0.999 valid loss: 1.54524 valid acc: 0.956\n",
            "2-234th: train loss: 1.47872, train acc: 0.999 valid loss: 1.54521 valid acc: 0.956\n",
            "2-235th: train loss: 1.47867, train acc: 0.999 valid loss: 1.54518 valid acc: 0.956\n",
            "2-236th: train loss: 1.47863, train acc: 0.999 valid loss: 1.54515 valid acc: 0.956\n",
            "2-237th: train loss: 1.47859, train acc: 0.999 valid loss: 1.54512 valid acc: 0.956\n",
            "2-238th: train loss: 1.47855, train acc: 0.999 valid loss: 1.54509 valid acc: 0.956\n",
            "2-239th: train loss: 1.47852, train acc: 0.999 valid loss: 1.54506 valid acc: 0.956\n",
            "2-240th: train loss: 1.47848, train acc: 0.999 valid loss: 1.54503 valid acc: 0.956\n",
            "2-241th: train loss: 1.47844, train acc: 0.999 valid loss: 1.54500 valid acc: 0.956\n",
            "2-242th: train loss: 1.47841, train acc: 0.999 valid loss: 1.54496 valid acc: 0.956\n",
            "2-243th: train loss: 1.47837, train acc: 0.999 valid loss: 1.54492 valid acc: 0.956\n",
            "2-244th: train loss: 1.47834, train acc: 0.999 valid loss: 1.54488 valid acc: 0.956\n",
            "2-245th: train loss: 1.47830, train acc: 0.999 valid loss: 1.54483 valid acc: 0.956\n",
            "2-246th: train loss: 1.47827, train acc: 0.999 valid loss: 1.54478 valid acc: 0.956\n",
            "2-247th: train loss: 1.47824, train acc: 0.999 valid loss: 1.54472 valid acc: 0.956\n",
            "2-248th: train loss: 1.47820, train acc: 0.999 valid loss: 1.54466 valid acc: 0.956\n",
            "2-249th: train loss: 1.47817, train acc: 0.999 valid loss: 1.54460 valid acc: 0.956\n",
            "2-250th: train loss: 1.47814, train acc: 0.999 valid loss: 1.54454 valid acc: 0.956\n",
            "2-251th: train loss: 1.47811, train acc: 0.999 valid loss: 1.54448 valid acc: 0.956\n",
            "2-252th: train loss: 1.47808, train acc: 0.999 valid loss: 1.54443 valid acc: 0.956\n",
            "2-253th: train loss: 1.47805, train acc: 0.999 valid loss: 1.54437 valid acc: 0.956\n",
            "2-254th: train loss: 1.47802, train acc: 0.999 valid loss: 1.54432 valid acc: 0.956\n",
            "2-255th: train loss: 1.47799, train acc: 0.999 valid loss: 1.54427 valid acc: 0.956\n",
            "2-256th: train loss: 1.47796, train acc: 0.999 valid loss: 1.54423 valid acc: 0.956\n",
            "2-257th: train loss: 1.47794, train acc: 0.999 valid loss: 1.54418 valid acc: 0.956\n",
            "2-258th: train loss: 1.47791, train acc: 0.999 valid loss: 1.54414 valid acc: 0.956\n",
            "2-259th: train loss: 1.47788, train acc: 0.999 valid loss: 1.54410 valid acc: 0.959\n",
            "2-260th: train loss: 1.47785, train acc: 0.999 valid loss: 1.54406 valid acc: 0.959\n",
            "2-261th: train loss: 1.47783, train acc: 0.999 valid loss: 1.54402 valid acc: 0.959\n",
            "2-262th: train loss: 1.47780, train acc: 0.999 valid loss: 1.54398 valid acc: 0.959\n",
            "2-263th: train loss: 1.47777, train acc: 0.999 valid loss: 1.54395 valid acc: 0.959\n",
            "2-264th: train loss: 1.47775, train acc: 0.999 valid loss: 1.54391 valid acc: 0.959\n",
            "2-265th: train loss: 1.47772, train acc: 0.999 valid loss: 1.54388 valid acc: 0.959\n",
            "2-266th: train loss: 1.47769, train acc: 0.999 valid loss: 1.54384 valid acc: 0.959\n",
            "2-267th: train loss: 1.47767, train acc: 0.999 valid loss: 1.54381 valid acc: 0.959\n",
            "2-268th: train loss: 1.47765, train acc: 0.999 valid loss: 1.54377 valid acc: 0.959\n",
            "2-269th: train loss: 1.47762, train acc: 0.999 valid loss: 1.54373 valid acc: 0.959\n",
            "2-270th: train loss: 1.47760, train acc: 0.999 valid loss: 1.54370 valid acc: 0.959\n",
            "2-271th: train loss: 1.47757, train acc: 0.999 valid loss: 1.54366 valid acc: 0.959\n",
            "2-272th: train loss: 1.47755, train acc: 0.999 valid loss: 1.54363 valid acc: 0.959\n",
            "2-273th: train loss: 1.47752, train acc: 0.999 valid loss: 1.54359 valid acc: 0.959\n",
            "2-274th: train loss: 1.47750, train acc: 0.999 valid loss: 1.54356 valid acc: 0.959\n",
            "2-275th: train loss: 1.47748, train acc: 0.999 valid loss: 1.54352 valid acc: 0.959\n",
            "2-276th: train loss: 1.47746, train acc: 0.999 valid loss: 1.54349 valid acc: 0.959\n",
            "2-277th: train loss: 1.47743, train acc: 0.999 valid loss: 1.54346 valid acc: 0.959\n",
            "2-278th: train loss: 1.47741, train acc: 0.999 valid loss: 1.54343 valid acc: 0.959\n",
            "2-279th: train loss: 1.47739, train acc: 0.999 valid loss: 1.54339 valid acc: 0.959\n",
            "2-280th: train loss: 1.47737, train acc: 0.999 valid loss: 1.54337 valid acc: 0.959\n",
            "2-281th: train loss: 1.47735, train acc: 0.999 valid loss: 1.54334 valid acc: 0.959\n",
            "2-282th: train loss: 1.47733, train acc: 0.999 valid loss: 1.54331 valid acc: 0.956\n",
            "2-283th: train loss: 1.47730, train acc: 0.999 valid loss: 1.54329 valid acc: 0.956\n",
            "2-284th: train loss: 1.47728, train acc: 0.999 valid loss: 1.54327 valid acc: 0.956\n",
            "2-285th: train loss: 1.47726, train acc: 0.999 valid loss: 1.54324 valid acc: 0.956\n",
            "2-286th: train loss: 1.47724, train acc: 0.999 valid loss: 1.54322 valid acc: 0.956\n",
            "2-287th: train loss: 1.47722, train acc: 0.999 valid loss: 1.54320 valid acc: 0.956\n",
            "2-288th: train loss: 1.47720, train acc: 0.999 valid loss: 1.54318 valid acc: 0.956\n",
            "2-289th: train loss: 1.47718, train acc: 0.999 valid loss: 1.54316 valid acc: 0.956\n",
            "2-290th: train loss: 1.47717, train acc: 0.999 valid loss: 1.54315 valid acc: 0.956\n",
            "2-291th: train loss: 1.47715, train acc: 0.999 valid loss: 1.54313 valid acc: 0.956\n",
            "2-292th: train loss: 1.47713, train acc: 0.999 valid loss: 1.54311 valid acc: 0.956\n",
            "2-293th: train loss: 1.47711, train acc: 0.999 valid loss: 1.54309 valid acc: 0.956\n",
            "2-294th: train loss: 1.47709, train acc: 0.999 valid loss: 1.54308 valid acc: 0.956\n",
            "2-295th: train loss: 1.47707, train acc: 0.999 valid loss: 1.54306 valid acc: 0.956\n",
            "2-296th: train loss: 1.47706, train acc: 0.999 valid loss: 1.54304 valid acc: 0.956\n",
            "2-297th: train loss: 1.47704, train acc: 0.999 valid loss: 1.54303 valid acc: 0.956\n",
            "2-298th: train loss: 1.47702, train acc: 0.999 valid loss: 1.54301 valid acc: 0.956\n",
            "2-299th: train loss: 1.47701, train acc: 0.999 valid loss: 1.54299 valid acc: 0.956\n",
            "3-0th: train loss: 2.30184, train acc: 0.103 valid loss: 2.21942 valid acc: 0.302\n",
            "3-1th: train loss: 2.22439, train acc: 0.283 valid loss: 2.13939 valid acc: 0.437\n",
            "3-2th: train loss: 2.13998, train acc: 0.420 valid loss: 2.06461 valid acc: 0.513\n",
            "3-3th: train loss: 2.06068, train acc: 0.511 valid loss: 2.00254 valid acc: 0.566\n",
            "3-4th: train loss: 1.99317, train acc: 0.589 valid loss: 1.95012 valid acc: 0.642\n",
            "3-5th: train loss: 1.93520, train acc: 0.656 valid loss: 1.90359 valid acc: 0.686\n",
            "3-6th: train loss: 1.88431, train acc: 0.718 valid loss: 1.86492 valid acc: 0.711\n",
            "3-7th: train loss: 1.84137, train acc: 0.751 valid loss: 1.83546 valid acc: 0.758\n",
            "3-8th: train loss: 1.80741, train acc: 0.780 valid loss: 1.81311 valid acc: 0.777\n",
            "3-9th: train loss: 1.78027, train acc: 0.802 valid loss: 1.79376 valid acc: 0.792\n",
            "3-10th: train loss: 1.75621, train acc: 0.824 valid loss: 1.77570 valid acc: 0.802\n",
            "3-11th: train loss: 1.73406, train acc: 0.843 valid loss: 1.75953 valid acc: 0.811\n",
            "3-12th: train loss: 1.71450, train acc: 0.849 valid loss: 1.74587 valid acc: 0.818\n",
            "3-13th: train loss: 1.69779, train acc: 0.865 valid loss: 1.73445 valid acc: 0.824\n",
            "3-14th: train loss: 1.68335, train acc: 0.877 valid loss: 1.72462 valid acc: 0.833\n",
            "3-15th: train loss: 1.67032, train acc: 0.890 valid loss: 1.71596 valid acc: 0.833\n",
            "3-16th: train loss: 1.65835, train acc: 0.900 valid loss: 1.70844 valid acc: 0.840\n",
            "3-17th: train loss: 1.64750, train acc: 0.906 valid loss: 1.70203 valid acc: 0.846\n",
            "3-18th: train loss: 1.63791, train acc: 0.920 valid loss: 1.69650 valid acc: 0.852\n",
            "3-19th: train loss: 1.62938, train acc: 0.929 valid loss: 1.69144 valid acc: 0.855\n",
            "3-20th: train loss: 1.62153, train acc: 0.933 valid loss: 1.68658 valid acc: 0.852\n",
            "3-21th: train loss: 1.61406, train acc: 0.940 valid loss: 1.68187 valid acc: 0.855\n",
            "3-22th: train loss: 1.60696, train acc: 0.941 valid loss: 1.67740 valid acc: 0.855\n",
            "3-23th: train loss: 1.60032, train acc: 0.944 valid loss: 1.67320 valid acc: 0.858\n",
            "3-24th: train loss: 1.59419, train acc: 0.946 valid loss: 1.66921 valid acc: 0.871\n",
            "3-25th: train loss: 1.58851, train acc: 0.952 valid loss: 1.66536 valid acc: 0.874\n",
            "3-26th: train loss: 1.58315, train acc: 0.955 valid loss: 1.66165 valid acc: 0.874\n",
            "3-27th: train loss: 1.57809, train acc: 0.958 valid loss: 1.65815 valid acc: 0.871\n",
            "3-28th: train loss: 1.57334, train acc: 0.960 valid loss: 1.65496 valid acc: 0.871\n",
            "3-29th: train loss: 1.56897, train acc: 0.962 valid loss: 1.65210 valid acc: 0.871\n",
            "3-30th: train loss: 1.56495, train acc: 0.964 valid loss: 1.64953 valid acc: 0.871\n",
            "3-31th: train loss: 1.56120, train acc: 0.966 valid loss: 1.64718 valid acc: 0.877\n",
            "3-32th: train loss: 1.55766, train acc: 0.968 valid loss: 1.64500 valid acc: 0.874\n",
            "3-33th: train loss: 1.55429, train acc: 0.971 valid loss: 1.64298 valid acc: 0.890\n",
            "3-34th: train loss: 1.55111, train acc: 0.973 valid loss: 1.64110 valid acc: 0.893\n",
            "3-35th: train loss: 1.54814, train acc: 0.973 valid loss: 1.63933 valid acc: 0.896\n",
            "3-36th: train loss: 1.54538, train acc: 0.976 valid loss: 1.63762 valid acc: 0.899\n",
            "3-37th: train loss: 1.54276, train acc: 0.976 valid loss: 1.63592 valid acc: 0.903\n",
            "3-38th: train loss: 1.54026, train acc: 0.977 valid loss: 1.63424 valid acc: 0.903\n",
            "3-39th: train loss: 1.53786, train acc: 0.980 valid loss: 1.63263 valid acc: 0.903\n",
            "3-40th: train loss: 1.53557, train acc: 0.982 valid loss: 1.63111 valid acc: 0.906\n",
            "3-41th: train loss: 1.53340, train acc: 0.983 valid loss: 1.62967 valid acc: 0.903\n",
            "3-42th: train loss: 1.53134, train acc: 0.984 valid loss: 1.62831 valid acc: 0.903\n",
            "3-43th: train loss: 1.52937, train acc: 0.984 valid loss: 1.62699 valid acc: 0.903\n",
            "3-44th: train loss: 1.52747, train acc: 0.986 valid loss: 1.62571 valid acc: 0.906\n",
            "3-45th: train loss: 1.52566, train acc: 0.987 valid loss: 1.62448 valid acc: 0.906\n",
            "3-46th: train loss: 1.52394, train acc: 0.987 valid loss: 1.62330 valid acc: 0.906\n",
            "3-47th: train loss: 1.52232, train acc: 0.989 valid loss: 1.62213 valid acc: 0.909\n",
            "3-48th: train loss: 1.52078, train acc: 0.989 valid loss: 1.62098 valid acc: 0.912\n",
            "3-49th: train loss: 1.51933, train acc: 0.989 valid loss: 1.61982 valid acc: 0.909\n",
            "3-50th: train loss: 1.51796, train acc: 0.990 valid loss: 1.61867 valid acc: 0.912\n",
            "3-51th: train loss: 1.51665, train acc: 0.990 valid loss: 1.61753 valid acc: 0.912\n",
            "3-52th: train loss: 1.51543, train acc: 0.991 valid loss: 1.61640 valid acc: 0.912\n",
            "3-53th: train loss: 1.51427, train acc: 0.991 valid loss: 1.61529 valid acc: 0.909\n",
            "3-54th: train loss: 1.51318, train acc: 0.991 valid loss: 1.61422 valid acc: 0.909\n",
            "3-55th: train loss: 1.51213, train acc: 0.991 valid loss: 1.61320 valid acc: 0.909\n",
            "3-56th: train loss: 1.51113, train acc: 0.991 valid loss: 1.61223 valid acc: 0.912\n",
            "3-57th: train loss: 1.51018, train acc: 0.991 valid loss: 1.61131 valid acc: 0.912\n",
            "3-58th: train loss: 1.50927, train acc: 0.991 valid loss: 1.61043 valid acc: 0.912\n",
            "3-59th: train loss: 1.50840, train acc: 0.991 valid loss: 1.60957 valid acc: 0.912\n",
            "3-60th: train loss: 1.50757, train acc: 0.991 valid loss: 1.60873 valid acc: 0.915\n",
            "3-61th: train loss: 1.50677, train acc: 0.992 valid loss: 1.60788 valid acc: 0.915\n",
            "3-62th: train loss: 1.50601, train acc: 0.992 valid loss: 1.60704 valid acc: 0.918\n",
            "3-63th: train loss: 1.50528, train acc: 0.992 valid loss: 1.60621 valid acc: 0.918\n",
            "3-64th: train loss: 1.50458, train acc: 0.992 valid loss: 1.60540 valid acc: 0.921\n",
            "3-65th: train loss: 1.50390, train acc: 0.994 valid loss: 1.60462 valid acc: 0.925\n",
            "3-66th: train loss: 1.50326, train acc: 0.994 valid loss: 1.60386 valid acc: 0.925\n",
            "3-67th: train loss: 1.50264, train acc: 0.994 valid loss: 1.60313 valid acc: 0.925\n",
            "3-68th: train loss: 1.50204, train acc: 0.994 valid loss: 1.60243 valid acc: 0.925\n",
            "3-69th: train loss: 1.50146, train acc: 0.994 valid loss: 1.60175 valid acc: 0.925\n",
            "3-70th: train loss: 1.50091, train acc: 0.994 valid loss: 1.60110 valid acc: 0.925\n",
            "3-71th: train loss: 1.50038, train acc: 0.994 valid loss: 1.60046 valid acc: 0.925\n",
            "3-72th: train loss: 1.49987, train acc: 0.994 valid loss: 1.59985 valid acc: 0.925\n",
            "3-73th: train loss: 1.49938, train acc: 0.994 valid loss: 1.59927 valid acc: 0.921\n",
            "3-74th: train loss: 1.49890, train acc: 0.994 valid loss: 1.59872 valid acc: 0.921\n",
            "3-75th: train loss: 1.49844, train acc: 0.995 valid loss: 1.59821 valid acc: 0.921\n",
            "3-76th: train loss: 1.49798, train acc: 0.995 valid loss: 1.59773 valid acc: 0.921\n",
            "3-77th: train loss: 1.49754, train acc: 0.995 valid loss: 1.59729 valid acc: 0.918\n",
            "3-78th: train loss: 1.49711, train acc: 0.995 valid loss: 1.59688 valid acc: 0.918\n",
            "3-79th: train loss: 1.49668, train acc: 0.995 valid loss: 1.59648 valid acc: 0.918\n",
            "3-80th: train loss: 1.49627, train acc: 0.995 valid loss: 1.59610 valid acc: 0.918\n",
            "3-81th: train loss: 1.49586, train acc: 0.995 valid loss: 1.59573 valid acc: 0.918\n",
            "3-82th: train loss: 1.49545, train acc: 0.996 valid loss: 1.59537 valid acc: 0.918\n",
            "3-83th: train loss: 1.49505, train acc: 0.996 valid loss: 1.59501 valid acc: 0.915\n",
            "3-84th: train loss: 1.49466, train acc: 0.997 valid loss: 1.59466 valid acc: 0.915\n",
            "3-85th: train loss: 1.49429, train acc: 0.997 valid loss: 1.59431 valid acc: 0.915\n",
            "3-86th: train loss: 1.49392, train acc: 0.997 valid loss: 1.59397 valid acc: 0.915\n",
            "3-87th: train loss: 1.49357, train acc: 0.997 valid loss: 1.59364 valid acc: 0.915\n",
            "3-88th: train loss: 1.49324, train acc: 0.997 valid loss: 1.59331 valid acc: 0.915\n",
            "3-89th: train loss: 1.49292, train acc: 0.997 valid loss: 1.59299 valid acc: 0.915\n",
            "3-90th: train loss: 1.49261, train acc: 0.997 valid loss: 1.59266 valid acc: 0.915\n",
            "3-91th: train loss: 1.49232, train acc: 0.997 valid loss: 1.59232 valid acc: 0.915\n",
            "3-92th: train loss: 1.49203, train acc: 0.997 valid loss: 1.59198 valid acc: 0.915\n",
            "3-93th: train loss: 1.49176, train acc: 0.997 valid loss: 1.59165 valid acc: 0.915\n",
            "3-94th: train loss: 1.49149, train acc: 0.997 valid loss: 1.59131 valid acc: 0.915\n",
            "3-95th: train loss: 1.49122, train acc: 0.997 valid loss: 1.59098 valid acc: 0.918\n",
            "3-96th: train loss: 1.49097, train acc: 0.997 valid loss: 1.59067 valid acc: 0.921\n",
            "3-97th: train loss: 1.49072, train acc: 0.997 valid loss: 1.59037 valid acc: 0.921\n",
            "3-98th: train loss: 1.49047, train acc: 0.997 valid loss: 1.59008 valid acc: 0.921\n",
            "3-99th: train loss: 1.49024, train acc: 0.997 valid loss: 1.58980 valid acc: 0.921\n",
            "3-100th: train loss: 1.49001, train acc: 0.997 valid loss: 1.58953 valid acc: 0.921\n",
            "3-101th: train loss: 1.48978, train acc: 0.997 valid loss: 1.58927 valid acc: 0.921\n",
            "3-102th: train loss: 1.48957, train acc: 0.997 valid loss: 1.58901 valid acc: 0.921\n",
            "3-103th: train loss: 1.48936, train acc: 0.997 valid loss: 1.58874 valid acc: 0.921\n",
            "3-104th: train loss: 1.48915, train acc: 0.997 valid loss: 1.58848 valid acc: 0.921\n",
            "3-105th: train loss: 1.48895, train acc: 0.997 valid loss: 1.58823 valid acc: 0.921\n",
            "3-106th: train loss: 1.48876, train acc: 0.997 valid loss: 1.58798 valid acc: 0.921\n",
            "3-107th: train loss: 1.48857, train acc: 0.997 valid loss: 1.58774 valid acc: 0.921\n",
            "3-108th: train loss: 1.48839, train acc: 0.997 valid loss: 1.58752 valid acc: 0.921\n",
            "3-109th: train loss: 1.48821, train acc: 0.997 valid loss: 1.58731 valid acc: 0.918\n",
            "3-110th: train loss: 1.48803, train acc: 0.997 valid loss: 1.58711 valid acc: 0.918\n",
            "3-111th: train loss: 1.48786, train acc: 0.997 valid loss: 1.58693 valid acc: 0.921\n",
            "3-112th: train loss: 1.48769, train acc: 0.997 valid loss: 1.58676 valid acc: 0.921\n",
            "3-113th: train loss: 1.48753, train acc: 0.997 valid loss: 1.58659 valid acc: 0.921\n",
            "3-114th: train loss: 1.48737, train acc: 0.997 valid loss: 1.58643 valid acc: 0.921\n",
            "3-115th: train loss: 1.48721, train acc: 0.997 valid loss: 1.58628 valid acc: 0.921\n",
            "3-116th: train loss: 1.48705, train acc: 0.997 valid loss: 1.58612 valid acc: 0.921\n",
            "3-117th: train loss: 1.48690, train acc: 0.997 valid loss: 1.58596 valid acc: 0.918\n",
            "3-118th: train loss: 1.48675, train acc: 0.997 valid loss: 1.58581 valid acc: 0.918\n",
            "3-119th: train loss: 1.48661, train acc: 0.997 valid loss: 1.58566 valid acc: 0.918\n",
            "3-120th: train loss: 1.48646, train acc: 0.997 valid loss: 1.58551 valid acc: 0.918\n",
            "3-121th: train loss: 1.48632, train acc: 0.997 valid loss: 1.58537 valid acc: 0.918\n",
            "3-122th: train loss: 1.48618, train acc: 0.997 valid loss: 1.58524 valid acc: 0.918\n",
            "3-123th: train loss: 1.48604, train acc: 0.997 valid loss: 1.58510 valid acc: 0.918\n",
            "3-124th: train loss: 1.48590, train acc: 0.997 valid loss: 1.58498 valid acc: 0.918\n",
            "3-125th: train loss: 1.48576, train acc: 0.998 valid loss: 1.58485 valid acc: 0.918\n",
            "3-126th: train loss: 1.48562, train acc: 0.998 valid loss: 1.58473 valid acc: 0.918\n",
            "3-127th: train loss: 1.48549, train acc: 0.998 valid loss: 1.58461 valid acc: 0.918\n",
            "3-128th: train loss: 1.48535, train acc: 0.998 valid loss: 1.58449 valid acc: 0.918\n",
            "3-129th: train loss: 1.48522, train acc: 0.998 valid loss: 1.58437 valid acc: 0.918\n",
            "3-130th: train loss: 1.48509, train acc: 0.998 valid loss: 1.58425 valid acc: 0.918\n",
            "3-131th: train loss: 1.48496, train acc: 0.998 valid loss: 1.58413 valid acc: 0.918\n",
            "3-132th: train loss: 1.48483, train acc: 0.998 valid loss: 1.58401 valid acc: 0.918\n",
            "3-133th: train loss: 1.48471, train acc: 0.998 valid loss: 1.58388 valid acc: 0.918\n",
            "3-134th: train loss: 1.48458, train acc: 0.998 valid loss: 1.58374 valid acc: 0.921\n",
            "3-135th: train loss: 1.48446, train acc: 0.998 valid loss: 1.58361 valid acc: 0.921\n",
            "3-136th: train loss: 1.48434, train acc: 0.998 valid loss: 1.58346 valid acc: 0.921\n",
            "3-137th: train loss: 1.48422, train acc: 0.998 valid loss: 1.58332 valid acc: 0.925\n",
            "3-138th: train loss: 1.48410, train acc: 0.998 valid loss: 1.58317 valid acc: 0.925\n",
            "3-139th: train loss: 1.48397, train acc: 0.998 valid loss: 1.58302 valid acc: 0.925\n",
            "3-140th: train loss: 1.48384, train acc: 0.998 valid loss: 1.58287 valid acc: 0.925\n",
            "3-141th: train loss: 1.48371, train acc: 0.998 valid loss: 1.58273 valid acc: 0.925\n",
            "3-142th: train loss: 1.48358, train acc: 0.998 valid loss: 1.58259 valid acc: 0.925\n",
            "3-143th: train loss: 1.48344, train acc: 0.998 valid loss: 1.58245 valid acc: 0.925\n",
            "3-144th: train loss: 1.48330, train acc: 0.998 valid loss: 1.58232 valid acc: 0.925\n",
            "3-145th: train loss: 1.48317, train acc: 0.998 valid loss: 1.58219 valid acc: 0.925\n",
            "3-146th: train loss: 1.48304, train acc: 0.998 valid loss: 1.58206 valid acc: 0.925\n",
            "3-147th: train loss: 1.48292, train acc: 0.998 valid loss: 1.58193 valid acc: 0.925\n",
            "3-148th: train loss: 1.48280, train acc: 0.998 valid loss: 1.58181 valid acc: 0.928\n",
            "3-149th: train loss: 1.48268, train acc: 0.998 valid loss: 1.58171 valid acc: 0.928\n",
            "3-150th: train loss: 1.48256, train acc: 0.998 valid loss: 1.58162 valid acc: 0.928\n",
            "3-151th: train loss: 1.48243, train acc: 0.998 valid loss: 1.58156 valid acc: 0.928\n",
            "3-152th: train loss: 1.48231, train acc: 0.999 valid loss: 1.58151 valid acc: 0.928\n",
            "3-153th: train loss: 1.48218, train acc: 0.999 valid loss: 1.58148 valid acc: 0.928\n",
            "3-154th: train loss: 1.48207, train acc: 0.999 valid loss: 1.58145 valid acc: 0.928\n",
            "3-155th: train loss: 1.48196, train acc: 0.999 valid loss: 1.58141 valid acc: 0.928\n",
            "3-156th: train loss: 1.48187, train acc: 0.999 valid loss: 1.58136 valid acc: 0.931\n",
            "3-157th: train loss: 1.48177, train acc: 0.999 valid loss: 1.58127 valid acc: 0.934\n",
            "3-158th: train loss: 1.48169, train acc: 0.999 valid loss: 1.58114 valid acc: 0.934\n",
            "3-159th: train loss: 1.48160, train acc: 0.999 valid loss: 1.58097 valid acc: 0.934\n",
            "3-160th: train loss: 1.48151, train acc: 0.999 valid loss: 1.58076 valid acc: 0.934\n",
            "3-161th: train loss: 1.48143, train acc: 0.999 valid loss: 1.58053 valid acc: 0.934\n",
            "3-162th: train loss: 1.48134, train acc: 0.999 valid loss: 1.58027 valid acc: 0.934\n",
            "3-163th: train loss: 1.48126, train acc: 0.999 valid loss: 1.58001 valid acc: 0.937\n",
            "3-164th: train loss: 1.48118, train acc: 0.999 valid loss: 1.57976 valid acc: 0.937\n",
            "3-165th: train loss: 1.48110, train acc: 0.999 valid loss: 1.57952 valid acc: 0.937\n",
            "3-166th: train loss: 1.48102, train acc: 0.999 valid loss: 1.57930 valid acc: 0.937\n",
            "3-167th: train loss: 1.48094, train acc: 0.999 valid loss: 1.57912 valid acc: 0.937\n",
            "3-168th: train loss: 1.48087, train acc: 0.999 valid loss: 1.57896 valid acc: 0.937\n",
            "3-169th: train loss: 1.48080, train acc: 0.999 valid loss: 1.57882 valid acc: 0.937\n",
            "3-170th: train loss: 1.48074, train acc: 0.999 valid loss: 1.57871 valid acc: 0.937\n",
            "3-171th: train loss: 1.48067, train acc: 0.999 valid loss: 1.57861 valid acc: 0.937\n",
            "3-172th: train loss: 1.48061, train acc: 0.999 valid loss: 1.57851 valid acc: 0.940\n",
            "3-173th: train loss: 1.48055, train acc: 0.999 valid loss: 1.57842 valid acc: 0.940\n",
            "3-174th: train loss: 1.48049, train acc: 0.999 valid loss: 1.57832 valid acc: 0.940\n",
            "3-175th: train loss: 1.48043, train acc: 0.999 valid loss: 1.57822 valid acc: 0.940\n",
            "3-176th: train loss: 1.48037, train acc: 0.999 valid loss: 1.57810 valid acc: 0.940\n",
            "3-177th: train loss: 1.48031, train acc: 0.999 valid loss: 1.57799 valid acc: 0.940\n",
            "3-178th: train loss: 1.48025, train acc: 0.999 valid loss: 1.57787 valid acc: 0.940\n",
            "3-179th: train loss: 1.48020, train acc: 0.999 valid loss: 1.57776 valid acc: 0.940\n",
            "3-180th: train loss: 1.48015, train acc: 0.999 valid loss: 1.57764 valid acc: 0.940\n",
            "3-181th: train loss: 1.48009, train acc: 0.999 valid loss: 1.57753 valid acc: 0.940\n",
            "3-182th: train loss: 1.48004, train acc: 0.999 valid loss: 1.57743 valid acc: 0.940\n",
            "3-183th: train loss: 1.47999, train acc: 0.999 valid loss: 1.57732 valid acc: 0.940\n",
            "3-184th: train loss: 1.47994, train acc: 0.999 valid loss: 1.57721 valid acc: 0.940\n",
            "3-185th: train loss: 1.47989, train acc: 0.999 valid loss: 1.57710 valid acc: 0.940\n",
            "3-186th: train loss: 1.47985, train acc: 0.999 valid loss: 1.57699 valid acc: 0.940\n",
            "3-187th: train loss: 1.47980, train acc: 0.999 valid loss: 1.57687 valid acc: 0.943\n",
            "3-188th: train loss: 1.47975, train acc: 0.999 valid loss: 1.57675 valid acc: 0.943\n",
            "3-189th: train loss: 1.47971, train acc: 0.999 valid loss: 1.57663 valid acc: 0.943\n",
            "3-190th: train loss: 1.47966, train acc: 0.999 valid loss: 1.57650 valid acc: 0.943\n",
            "3-191th: train loss: 1.47962, train acc: 0.999 valid loss: 1.57638 valid acc: 0.943\n",
            "3-192th: train loss: 1.47957, train acc: 0.999 valid loss: 1.57626 valid acc: 0.943\n",
            "3-193th: train loss: 1.47953, train acc: 0.999 valid loss: 1.57615 valid acc: 0.947\n",
            "3-194th: train loss: 1.47949, train acc: 0.999 valid loss: 1.57605 valid acc: 0.947\n",
            "3-195th: train loss: 1.47945, train acc: 0.999 valid loss: 1.57595 valid acc: 0.947\n",
            "3-196th: train loss: 1.47941, train acc: 0.999 valid loss: 1.57585 valid acc: 0.947\n",
            "3-197th: train loss: 1.47937, train acc: 0.999 valid loss: 1.57576 valid acc: 0.947\n",
            "3-198th: train loss: 1.47933, train acc: 0.999 valid loss: 1.57567 valid acc: 0.947\n",
            "3-199th: train loss: 1.47929, train acc: 0.999 valid loss: 1.57558 valid acc: 0.947\n",
            "3-200th: train loss: 1.47925, train acc: 0.999 valid loss: 1.57549 valid acc: 0.947\n",
            "3-201th: train loss: 1.47921, train acc: 0.999 valid loss: 1.57540 valid acc: 0.947\n",
            "3-202th: train loss: 1.47917, train acc: 0.999 valid loss: 1.57531 valid acc: 0.947\n",
            "3-203th: train loss: 1.47914, train acc: 0.999 valid loss: 1.57522 valid acc: 0.947\n",
            "3-204th: train loss: 1.47910, train acc: 0.999 valid loss: 1.57512 valid acc: 0.947\n",
            "3-205th: train loss: 1.47906, train acc: 0.999 valid loss: 1.57504 valid acc: 0.947\n",
            "3-206th: train loss: 1.47903, train acc: 0.999 valid loss: 1.57495 valid acc: 0.947\n",
            "3-207th: train loss: 1.47899, train acc: 0.999 valid loss: 1.57486 valid acc: 0.947\n",
            "3-208th: train loss: 1.47896, train acc: 0.999 valid loss: 1.57478 valid acc: 0.947\n",
            "3-209th: train loss: 1.47893, train acc: 0.999 valid loss: 1.57470 valid acc: 0.947\n",
            "3-210th: train loss: 1.47889, train acc: 0.999 valid loss: 1.57462 valid acc: 0.947\n",
            "3-211th: train loss: 1.47886, train acc: 0.999 valid loss: 1.57455 valid acc: 0.947\n",
            "3-212th: train loss: 1.47883, train acc: 0.999 valid loss: 1.57448 valid acc: 0.947\n",
            "3-213th: train loss: 1.47879, train acc: 0.999 valid loss: 1.57441 valid acc: 0.943\n",
            "3-214th: train loss: 1.47876, train acc: 0.999 valid loss: 1.57435 valid acc: 0.943\n",
            "3-215th: train loss: 1.47873, train acc: 0.999 valid loss: 1.57429 valid acc: 0.943\n",
            "3-216th: train loss: 1.47870, train acc: 0.999 valid loss: 1.57423 valid acc: 0.943\n",
            "3-217th: train loss: 1.47867, train acc: 0.999 valid loss: 1.57418 valid acc: 0.943\n",
            "3-218th: train loss: 1.47864, train acc: 0.999 valid loss: 1.57412 valid acc: 0.943\n",
            "3-219th: train loss: 1.47861, train acc: 0.999 valid loss: 1.57406 valid acc: 0.943\n",
            "3-220th: train loss: 1.47858, train acc: 0.999 valid loss: 1.57401 valid acc: 0.943\n",
            "3-221th: train loss: 1.47855, train acc: 0.999 valid loss: 1.57396 valid acc: 0.943\n",
            "3-222th: train loss: 1.47852, train acc: 0.999 valid loss: 1.57390 valid acc: 0.943\n",
            "3-223th: train loss: 1.47850, train acc: 0.999 valid loss: 1.57385 valid acc: 0.940\n",
            "3-224th: train loss: 1.47847, train acc: 0.999 valid loss: 1.57380 valid acc: 0.940\n",
            "3-225th: train loss: 1.47844, train acc: 0.999 valid loss: 1.57375 valid acc: 0.940\n",
            "3-226th: train loss: 1.47841, train acc: 0.999 valid loss: 1.57371 valid acc: 0.940\n",
            "3-227th: train loss: 1.47839, train acc: 0.999 valid loss: 1.57366 valid acc: 0.940\n",
            "3-228th: train loss: 1.47836, train acc: 0.999 valid loss: 1.57362 valid acc: 0.940\n",
            "3-229th: train loss: 1.47833, train acc: 0.999 valid loss: 1.57358 valid acc: 0.940\n",
            "3-230th: train loss: 1.47831, train acc: 0.999 valid loss: 1.57354 valid acc: 0.940\n",
            "3-231th: train loss: 1.47828, train acc: 0.999 valid loss: 1.57350 valid acc: 0.940\n",
            "3-232th: train loss: 1.47826, train acc: 0.999 valid loss: 1.57346 valid acc: 0.940\n",
            "3-233th: train loss: 1.47823, train acc: 0.999 valid loss: 1.57343 valid acc: 0.940\n",
            "3-234th: train loss: 1.47821, train acc: 0.999 valid loss: 1.57339 valid acc: 0.940\n",
            "3-235th: train loss: 1.47818, train acc: 0.999 valid loss: 1.57336 valid acc: 0.940\n",
            "3-236th: train loss: 1.47816, train acc: 0.999 valid loss: 1.57333 valid acc: 0.940\n",
            "3-237th: train loss: 1.47813, train acc: 0.999 valid loss: 1.57330 valid acc: 0.940\n",
            "3-238th: train loss: 1.47811, train acc: 0.999 valid loss: 1.57327 valid acc: 0.943\n",
            "3-239th: train loss: 1.47809, train acc: 0.999 valid loss: 1.57324 valid acc: 0.943\n",
            "3-240th: train loss: 1.47806, train acc: 0.999 valid loss: 1.57322 valid acc: 0.943\n",
            "3-241th: train loss: 1.47804, train acc: 0.999 valid loss: 1.57319 valid acc: 0.943\n",
            "3-242th: train loss: 1.47802, train acc: 0.999 valid loss: 1.57317 valid acc: 0.943\n",
            "3-243th: train loss: 1.47799, train acc: 0.999 valid loss: 1.57314 valid acc: 0.943\n",
            "3-244th: train loss: 1.47797, train acc: 0.999 valid loss: 1.57312 valid acc: 0.943\n",
            "3-245th: train loss: 1.47795, train acc: 0.999 valid loss: 1.57309 valid acc: 0.943\n",
            "3-246th: train loss: 1.47793, train acc: 0.999 valid loss: 1.57307 valid acc: 0.943\n",
            "3-247th: train loss: 1.47790, train acc: 0.999 valid loss: 1.57305 valid acc: 0.943\n",
            "3-248th: train loss: 1.47788, train acc: 0.999 valid loss: 1.57303 valid acc: 0.943\n",
            "3-249th: train loss: 1.47786, train acc: 0.999 valid loss: 1.57300 valid acc: 0.943\n",
            "3-250th: train loss: 1.47784, train acc: 0.999 valid loss: 1.57298 valid acc: 0.943\n",
            "3-251th: train loss: 1.47782, train acc: 0.999 valid loss: 1.57296 valid acc: 0.943\n",
            "3-252th: train loss: 1.47780, train acc: 0.999 valid loss: 1.57294 valid acc: 0.943\n",
            "3-253th: train loss: 1.47778, train acc: 0.999 valid loss: 1.57292 valid acc: 0.943\n",
            "3-254th: train loss: 1.47775, train acc: 0.999 valid loss: 1.57290 valid acc: 0.943\n",
            "3-255th: train loss: 1.47773, train acc: 0.999 valid loss: 1.57287 valid acc: 0.943\n",
            "3-256th: train loss: 1.47771, train acc: 0.999 valid loss: 1.57285 valid acc: 0.943\n",
            "3-257th: train loss: 1.47769, train acc: 0.999 valid loss: 1.57283 valid acc: 0.943\n",
            "3-258th: train loss: 1.47767, train acc: 0.999 valid loss: 1.57281 valid acc: 0.943\n",
            "3-259th: train loss: 1.47765, train acc: 0.999 valid loss: 1.57278 valid acc: 0.947\n",
            "3-260th: train loss: 1.47763, train acc: 0.999 valid loss: 1.57276 valid acc: 0.947\n",
            "3-261th: train loss: 1.47761, train acc: 0.999 valid loss: 1.57274 valid acc: 0.947\n",
            "3-262th: train loss: 1.47759, train acc: 0.999 valid loss: 1.57271 valid acc: 0.947\n",
            "3-263th: train loss: 1.47758, train acc: 0.999 valid loss: 1.57269 valid acc: 0.947\n",
            "3-264th: train loss: 1.47756, train acc: 0.999 valid loss: 1.57266 valid acc: 0.947\n",
            "3-265th: train loss: 1.47754, train acc: 0.999 valid loss: 1.57264 valid acc: 0.947\n",
            "3-266th: train loss: 1.47752, train acc: 0.999 valid loss: 1.57261 valid acc: 0.947\n",
            "3-267th: train loss: 1.47750, train acc: 0.999 valid loss: 1.57258 valid acc: 0.947\n",
            "3-268th: train loss: 1.47748, train acc: 0.999 valid loss: 1.57255 valid acc: 0.947\n",
            "3-269th: train loss: 1.47746, train acc: 0.999 valid loss: 1.57252 valid acc: 0.947\n",
            "3-270th: train loss: 1.47745, train acc: 0.999 valid loss: 1.57249 valid acc: 0.947\n",
            "3-271th: train loss: 1.47743, train acc: 0.999 valid loss: 1.57246 valid acc: 0.943\n",
            "3-272th: train loss: 1.47741, train acc: 0.999 valid loss: 1.57243 valid acc: 0.943\n",
            "3-273th: train loss: 1.47739, train acc: 0.999 valid loss: 1.57239 valid acc: 0.943\n",
            "3-274th: train loss: 1.47738, train acc: 0.999 valid loss: 1.57236 valid acc: 0.943\n",
            "3-275th: train loss: 1.47736, train acc: 0.999 valid loss: 1.57232 valid acc: 0.943\n",
            "3-276th: train loss: 1.47734, train acc: 0.999 valid loss: 1.57229 valid acc: 0.943\n",
            "3-277th: train loss: 1.47733, train acc: 0.999 valid loss: 1.57225 valid acc: 0.943\n",
            "3-278th: train loss: 1.47731, train acc: 0.999 valid loss: 1.57221 valid acc: 0.943\n",
            "3-279th: train loss: 1.47729, train acc: 0.999 valid loss: 1.57217 valid acc: 0.943\n",
            "3-280th: train loss: 1.47728, train acc: 0.999 valid loss: 1.57213 valid acc: 0.943\n",
            "3-281th: train loss: 1.47726, train acc: 0.999 valid loss: 1.57208 valid acc: 0.943\n",
            "3-282th: train loss: 1.47724, train acc: 0.999 valid loss: 1.57204 valid acc: 0.943\n",
            "3-283th: train loss: 1.47723, train acc: 0.999 valid loss: 1.57200 valid acc: 0.943\n",
            "3-284th: train loss: 1.47721, train acc: 0.999 valid loss: 1.57195 valid acc: 0.940\n",
            "3-285th: train loss: 1.47720, train acc: 0.999 valid loss: 1.57190 valid acc: 0.940\n",
            "3-286th: train loss: 1.47718, train acc: 0.999 valid loss: 1.57185 valid acc: 0.940\n",
            "3-287th: train loss: 1.47717, train acc: 0.999 valid loss: 1.57180 valid acc: 0.940\n",
            "3-288th: train loss: 1.47715, train acc: 0.999 valid loss: 1.57175 valid acc: 0.940\n",
            "3-289th: train loss: 1.47714, train acc: 0.999 valid loss: 1.57170 valid acc: 0.940\n",
            "3-290th: train loss: 1.47712, train acc: 0.999 valid loss: 1.57165 valid acc: 0.940\n",
            "3-291th: train loss: 1.47711, train acc: 0.999 valid loss: 1.57159 valid acc: 0.940\n",
            "3-292th: train loss: 1.47709, train acc: 0.999 valid loss: 1.57154 valid acc: 0.940\n",
            "3-293th: train loss: 1.47708, train acc: 0.999 valid loss: 1.57148 valid acc: 0.940\n",
            "3-294th: train loss: 1.47706, train acc: 0.999 valid loss: 1.57142 valid acc: 0.940\n",
            "3-295th: train loss: 1.47705, train acc: 0.999 valid loss: 1.57136 valid acc: 0.940\n",
            "3-296th: train loss: 1.47704, train acc: 0.999 valid loss: 1.57130 valid acc: 0.940\n",
            "3-297th: train loss: 1.47702, train acc: 0.999 valid loss: 1.57124 valid acc: 0.940\n",
            "3-298th: train loss: 1.47701, train acc: 0.999 valid loss: 1.57118 valid acc: 0.940\n",
            "3-299th: train loss: 1.47699, train acc: 0.999 valid loss: 1.57112 valid acc: 0.940\n",
            "4-0th: train loss: 2.29860, train acc: 0.115 valid loss: 2.22796 valid acc: 0.292\n",
            "4-1th: train loss: 2.21939, train acc: 0.293 valid loss: 2.15564 valid acc: 0.390\n",
            "4-2th: train loss: 2.14135, train acc: 0.405 valid loss: 2.08561 valid acc: 0.487\n",
            "4-3th: train loss: 2.06539, train acc: 0.525 valid loss: 2.01879 valid acc: 0.579\n",
            "4-4th: train loss: 1.99318, train acc: 0.612 valid loss: 1.96663 valid acc: 0.604\n",
            "4-5th: train loss: 1.93596, train acc: 0.659 valid loss: 1.92734 valid acc: 0.642\n",
            "4-6th: train loss: 1.89118, train acc: 0.692 valid loss: 1.89264 valid acc: 0.698\n",
            "4-7th: train loss: 1.85134, train acc: 0.730 valid loss: 1.85947 valid acc: 0.726\n",
            "4-8th: train loss: 1.81349, train acc: 0.783 valid loss: 1.82954 valid acc: 0.770\n",
            "4-9th: train loss: 1.77895, train acc: 0.825 valid loss: 1.80620 valid acc: 0.786\n",
            "4-10th: train loss: 1.75104, train acc: 0.851 valid loss: 1.78993 valid acc: 0.808\n",
            "4-11th: train loss: 1.73013, train acc: 0.866 valid loss: 1.77534 valid acc: 0.818\n",
            "4-12th: train loss: 1.71131, train acc: 0.879 valid loss: 1.75988 valid acc: 0.808\n",
            "4-13th: train loss: 1.69223, train acc: 0.887 valid loss: 1.74570 valid acc: 0.821\n",
            "4-14th: train loss: 1.67487, train acc: 0.902 valid loss: 1.73452 valid acc: 0.830\n",
            "4-15th: train loss: 1.66078, train acc: 0.910 valid loss: 1.72585 valid acc: 0.840\n",
            "4-16th: train loss: 1.64927, train acc: 0.916 valid loss: 1.71836 valid acc: 0.849\n",
            "4-17th: train loss: 1.63895, train acc: 0.921 valid loss: 1.71126 valid acc: 0.849\n",
            "4-18th: train loss: 1.62904, train acc: 0.928 valid loss: 1.70450 valid acc: 0.852\n",
            "4-19th: train loss: 1.61963, train acc: 0.935 valid loss: 1.69840 valid acc: 0.858\n",
            "4-20th: train loss: 1.61113, train acc: 0.940 valid loss: 1.69316 valid acc: 0.871\n",
            "4-21th: train loss: 1.60378, train acc: 0.946 valid loss: 1.68863 valid acc: 0.877\n",
            "4-22th: train loss: 1.59739, train acc: 0.951 valid loss: 1.68442 valid acc: 0.881\n",
            "4-23th: train loss: 1.59149, train acc: 0.955 valid loss: 1.68018 valid acc: 0.874\n",
            "4-24th: train loss: 1.58567, train acc: 0.961 valid loss: 1.67592 valid acc: 0.874\n",
            "4-25th: train loss: 1.57992, train acc: 0.962 valid loss: 1.67193 valid acc: 0.884\n",
            "4-26th: train loss: 1.57453, train acc: 0.966 valid loss: 1.66842 valid acc: 0.884\n",
            "4-27th: train loss: 1.56974, train acc: 0.968 valid loss: 1.66530 valid acc: 0.881\n",
            "4-28th: train loss: 1.56549, train acc: 0.969 valid loss: 1.66230 valid acc: 0.881\n",
            "4-29th: train loss: 1.56154, train acc: 0.971 valid loss: 1.65924 valid acc: 0.881\n",
            "4-30th: train loss: 1.55769, train acc: 0.973 valid loss: 1.65614 valid acc: 0.881\n",
            "4-31th: train loss: 1.55396, train acc: 0.976 valid loss: 1.65314 valid acc: 0.893\n",
            "4-32th: train loss: 1.55046, train acc: 0.978 valid loss: 1.65038 valid acc: 0.893\n",
            "4-33th: train loss: 1.54725, train acc: 0.979 valid loss: 1.64787 valid acc: 0.899\n",
            "4-34th: train loss: 1.54430, train acc: 0.981 valid loss: 1.64555 valid acc: 0.899\n",
            "4-35th: train loss: 1.54152, train acc: 0.984 valid loss: 1.64337 valid acc: 0.903\n",
            "4-36th: train loss: 1.53884, train acc: 0.984 valid loss: 1.64131 valid acc: 0.906\n",
            "4-37th: train loss: 1.53626, train acc: 0.985 valid loss: 1.63937 valid acc: 0.906\n",
            "4-38th: train loss: 1.53384, train acc: 0.985 valid loss: 1.63755 valid acc: 0.906\n",
            "4-39th: train loss: 1.53158, train acc: 0.987 valid loss: 1.63581 valid acc: 0.906\n",
            "4-40th: train loss: 1.52949, train acc: 0.987 valid loss: 1.63414 valid acc: 0.906\n",
            "4-41th: train loss: 1.52751, train acc: 0.988 valid loss: 1.63252 valid acc: 0.906\n",
            "4-42th: train loss: 1.52562, train acc: 0.990 valid loss: 1.63098 valid acc: 0.903\n",
            "4-43th: train loss: 1.52381, train acc: 0.990 valid loss: 1.62955 valid acc: 0.903\n",
            "4-44th: train loss: 1.52209, train acc: 0.991 valid loss: 1.62826 valid acc: 0.903\n",
            "4-45th: train loss: 1.52048, train acc: 0.991 valid loss: 1.62707 valid acc: 0.903\n",
            "4-46th: train loss: 1.51897, train acc: 0.991 valid loss: 1.62596 valid acc: 0.903\n",
            "4-47th: train loss: 1.51753, train acc: 0.991 valid loss: 1.62489 valid acc: 0.903\n",
            "4-48th: train loss: 1.51615, train acc: 0.992 valid loss: 1.62385 valid acc: 0.906\n",
            "4-49th: train loss: 1.51485, train acc: 0.992 valid loss: 1.62284 valid acc: 0.903\n",
            "4-50th: train loss: 1.51363, train acc: 0.994 valid loss: 1.62183 valid acc: 0.903\n",
            "4-51th: train loss: 1.51249, train acc: 0.994 valid loss: 1.62081 valid acc: 0.899\n",
            "4-52th: train loss: 1.51141, train acc: 0.994 valid loss: 1.61978 valid acc: 0.896\n",
            "4-53th: train loss: 1.51038, train acc: 0.994 valid loss: 1.61872 valid acc: 0.896\n",
            "4-54th: train loss: 1.50938, train acc: 0.994 valid loss: 1.61765 valid acc: 0.896\n",
            "4-55th: train loss: 1.50843, train acc: 0.995 valid loss: 1.61659 valid acc: 0.896\n",
            "4-56th: train loss: 1.50753, train acc: 0.995 valid loss: 1.61554 valid acc: 0.899\n",
            "4-57th: train loss: 1.50667, train acc: 0.995 valid loss: 1.61450 valid acc: 0.899\n",
            "4-58th: train loss: 1.50586, train acc: 0.995 valid loss: 1.61350 valid acc: 0.903\n",
            "4-59th: train loss: 1.50507, train acc: 0.995 valid loss: 1.61252 valid acc: 0.906\n",
            "4-60th: train loss: 1.50432, train acc: 0.995 valid loss: 1.61160 valid acc: 0.906\n",
            "4-61th: train loss: 1.50361, train acc: 0.995 valid loss: 1.61074 valid acc: 0.912\n",
            "4-62th: train loss: 1.50293, train acc: 0.995 valid loss: 1.60993 valid acc: 0.915\n",
            "4-63th: train loss: 1.50228, train acc: 0.995 valid loss: 1.60917 valid acc: 0.915\n",
            "4-64th: train loss: 1.50166, train acc: 0.995 valid loss: 1.60845 valid acc: 0.915\n",
            "4-65th: train loss: 1.50107, train acc: 0.995 valid loss: 1.60776 valid acc: 0.918\n",
            "4-66th: train loss: 1.50049, train acc: 0.995 valid loss: 1.60709 valid acc: 0.918\n",
            "4-67th: train loss: 1.49993, train acc: 0.995 valid loss: 1.60645 valid acc: 0.918\n",
            "4-68th: train loss: 1.49940, train acc: 0.995 valid loss: 1.60583 valid acc: 0.918\n",
            "4-69th: train loss: 1.49888, train acc: 0.995 valid loss: 1.60524 valid acc: 0.918\n",
            "4-70th: train loss: 1.49837, train acc: 0.995 valid loss: 1.60467 valid acc: 0.921\n",
            "4-71th: train loss: 1.49788, train acc: 0.995 valid loss: 1.60413 valid acc: 0.921\n",
            "4-72th: train loss: 1.49740, train acc: 0.995 valid loss: 1.60361 valid acc: 0.921\n",
            "4-73th: train loss: 1.49693, train acc: 0.995 valid loss: 1.60313 valid acc: 0.921\n",
            "4-74th: train loss: 1.49648, train acc: 0.995 valid loss: 1.60266 valid acc: 0.925\n",
            "4-75th: train loss: 1.49604, train acc: 0.996 valid loss: 1.60221 valid acc: 0.925\n",
            "4-76th: train loss: 1.49562, train acc: 0.996 valid loss: 1.60177 valid acc: 0.921\n",
            "4-77th: train loss: 1.49520, train acc: 0.996 valid loss: 1.60134 valid acc: 0.921\n",
            "4-78th: train loss: 1.49481, train acc: 0.996 valid loss: 1.60091 valid acc: 0.921\n",
            "4-79th: train loss: 1.49443, train acc: 0.997 valid loss: 1.60047 valid acc: 0.921\n",
            "4-80th: train loss: 1.49406, train acc: 0.997 valid loss: 1.60003 valid acc: 0.921\n",
            "4-81th: train loss: 1.49371, train acc: 0.997 valid loss: 1.59959 valid acc: 0.921\n",
            "4-82th: train loss: 1.49338, train acc: 0.997 valid loss: 1.59914 valid acc: 0.921\n",
            "4-83th: train loss: 1.49305, train acc: 0.997 valid loss: 1.59869 valid acc: 0.925\n",
            "4-84th: train loss: 1.49274, train acc: 0.997 valid loss: 1.59823 valid acc: 0.925\n",
            "4-85th: train loss: 1.49243, train acc: 0.997 valid loss: 1.59777 valid acc: 0.925\n",
            "4-86th: train loss: 1.49213, train acc: 0.997 valid loss: 1.59731 valid acc: 0.925\n",
            "4-87th: train loss: 1.49185, train acc: 0.997 valid loss: 1.59684 valid acc: 0.925\n",
            "4-88th: train loss: 1.49156, train acc: 0.998 valid loss: 1.59638 valid acc: 0.928\n",
            "4-89th: train loss: 1.49129, train acc: 0.998 valid loss: 1.59592 valid acc: 0.928\n",
            "4-90th: train loss: 1.49101, train acc: 0.998 valid loss: 1.59548 valid acc: 0.928\n",
            "4-91th: train loss: 1.49075, train acc: 0.998 valid loss: 1.59505 valid acc: 0.928\n",
            "4-92th: train loss: 1.49049, train acc: 0.998 valid loss: 1.59465 valid acc: 0.928\n",
            "4-93th: train loss: 1.49024, train acc: 0.998 valid loss: 1.59426 valid acc: 0.928\n",
            "4-94th: train loss: 1.48999, train acc: 0.998 valid loss: 1.59389 valid acc: 0.931\n",
            "4-95th: train loss: 1.48974, train acc: 0.998 valid loss: 1.59354 valid acc: 0.934\n",
            "4-96th: train loss: 1.48951, train acc: 0.998 valid loss: 1.59321 valid acc: 0.934\n",
            "4-97th: train loss: 1.48927, train acc: 0.998 valid loss: 1.59288 valid acc: 0.934\n",
            "4-98th: train loss: 1.48905, train acc: 0.998 valid loss: 1.59256 valid acc: 0.934\n",
            "4-99th: train loss: 1.48883, train acc: 0.998 valid loss: 1.59225 valid acc: 0.937\n",
            "4-100th: train loss: 1.48861, train acc: 0.998 valid loss: 1.59194 valid acc: 0.937\n",
            "4-101th: train loss: 1.48840, train acc: 0.998 valid loss: 1.59164 valid acc: 0.937\n",
            "4-102th: train loss: 1.48820, train acc: 0.998 valid loss: 1.59134 valid acc: 0.937\n",
            "4-103th: train loss: 1.48800, train acc: 0.998 valid loss: 1.59105 valid acc: 0.937\n",
            "4-104th: train loss: 1.48781, train acc: 0.998 valid loss: 1.59077 valid acc: 0.940\n",
            "4-105th: train loss: 1.48762, train acc: 0.998 valid loss: 1.59048 valid acc: 0.940\n",
            "4-106th: train loss: 1.48744, train acc: 0.998 valid loss: 1.59020 valid acc: 0.943\n",
            "4-107th: train loss: 1.48726, train acc: 0.998 valid loss: 1.58992 valid acc: 0.947\n",
            "4-108th: train loss: 1.48708, train acc: 0.998 valid loss: 1.58963 valid acc: 0.947\n",
            "4-109th: train loss: 1.48691, train acc: 0.998 valid loss: 1.58934 valid acc: 0.947\n",
            "4-110th: train loss: 1.48674, train acc: 0.998 valid loss: 1.58905 valid acc: 0.947\n",
            "4-111th: train loss: 1.48658, train acc: 0.998 valid loss: 1.58876 valid acc: 0.947\n",
            "4-112th: train loss: 1.48642, train acc: 0.998 valid loss: 1.58847 valid acc: 0.947\n",
            "4-113th: train loss: 1.48626, train acc: 0.998 valid loss: 1.58819 valid acc: 0.947\n",
            "4-114th: train loss: 1.48611, train acc: 0.998 valid loss: 1.58791 valid acc: 0.943\n",
            "4-115th: train loss: 1.48595, train acc: 0.998 valid loss: 1.58765 valid acc: 0.943\n",
            "4-116th: train loss: 1.48581, train acc: 0.998 valid loss: 1.58739 valid acc: 0.943\n",
            "4-117th: train loss: 1.48566, train acc: 0.998 valid loss: 1.58714 valid acc: 0.943\n",
            "4-118th: train loss: 1.48552, train acc: 0.998 valid loss: 1.58690 valid acc: 0.943\n",
            "4-119th: train loss: 1.48538, train acc: 0.998 valid loss: 1.58666 valid acc: 0.943\n",
            "4-120th: train loss: 1.48524, train acc: 0.998 valid loss: 1.58644 valid acc: 0.943\n",
            "4-121th: train loss: 1.48511, train acc: 0.998 valid loss: 1.58621 valid acc: 0.943\n",
            "4-122th: train loss: 1.48498, train acc: 0.998 valid loss: 1.58599 valid acc: 0.943\n",
            "4-123th: train loss: 1.48485, train acc: 0.998 valid loss: 1.58578 valid acc: 0.943\n",
            "4-124th: train loss: 1.48472, train acc: 0.998 valid loss: 1.58557 valid acc: 0.940\n",
            "4-125th: train loss: 1.48459, train acc: 0.998 valid loss: 1.58537 valid acc: 0.940\n",
            "4-126th: train loss: 1.48447, train acc: 0.998 valid loss: 1.58517 valid acc: 0.940\n",
            "4-127th: train loss: 1.48435, train acc: 0.998 valid loss: 1.58498 valid acc: 0.940\n",
            "4-128th: train loss: 1.48423, train acc: 0.998 valid loss: 1.58480 valid acc: 0.940\n",
            "4-129th: train loss: 1.48411, train acc: 0.998 valid loss: 1.58463 valid acc: 0.940\n",
            "4-130th: train loss: 1.48399, train acc: 0.998 valid loss: 1.58445 valid acc: 0.940\n",
            "4-131th: train loss: 1.48388, train acc: 0.998 valid loss: 1.58429 valid acc: 0.940\n",
            "4-132th: train loss: 1.48377, train acc: 0.998 valid loss: 1.58412 valid acc: 0.940\n",
            "4-133th: train loss: 1.48365, train acc: 0.998 valid loss: 1.58397 valid acc: 0.940\n",
            "4-134th: train loss: 1.48354, train acc: 0.998 valid loss: 1.58381 valid acc: 0.940\n",
            "4-135th: train loss: 1.48343, train acc: 0.998 valid loss: 1.58366 valid acc: 0.940\n",
            "4-136th: train loss: 1.48332, train acc: 0.998 valid loss: 1.58351 valid acc: 0.937\n",
            "4-137th: train loss: 1.48321, train acc: 0.998 valid loss: 1.58337 valid acc: 0.937\n",
            "4-138th: train loss: 1.48310, train acc: 0.998 valid loss: 1.58323 valid acc: 0.940\n",
            "4-139th: train loss: 1.48299, train acc: 0.998 valid loss: 1.58310 valid acc: 0.940\n",
            "4-140th: train loss: 1.48288, train acc: 0.998 valid loss: 1.58297 valid acc: 0.940\n",
            "4-141th: train loss: 1.48277, train acc: 0.998 valid loss: 1.58284 valid acc: 0.940\n",
            "4-142th: train loss: 1.48266, train acc: 0.998 valid loss: 1.58272 valid acc: 0.940\n",
            "4-143th: train loss: 1.48255, train acc: 0.998 valid loss: 1.58261 valid acc: 0.940\n",
            "4-144th: train loss: 1.48244, train acc: 0.998 valid loss: 1.58249 valid acc: 0.940\n",
            "4-145th: train loss: 1.48234, train acc: 0.998 valid loss: 1.58239 valid acc: 0.940\n",
            "4-146th: train loss: 1.48223, train acc: 0.998 valid loss: 1.58228 valid acc: 0.940\n",
            "4-147th: train loss: 1.48213, train acc: 0.998 valid loss: 1.58218 valid acc: 0.943\n",
            "4-148th: train loss: 1.48203, train acc: 0.998 valid loss: 1.58209 valid acc: 0.943\n",
            "4-149th: train loss: 1.48194, train acc: 0.998 valid loss: 1.58199 valid acc: 0.943\n",
            "4-150th: train loss: 1.48185, train acc: 0.998 valid loss: 1.58190 valid acc: 0.943\n",
            "4-151th: train loss: 1.48176, train acc: 0.998 valid loss: 1.58181 valid acc: 0.943\n",
            "4-152th: train loss: 1.48167, train acc: 0.998 valid loss: 1.58171 valid acc: 0.943\n",
            "4-153th: train loss: 1.48159, train acc: 0.998 valid loss: 1.58162 valid acc: 0.943\n",
            "4-154th: train loss: 1.48150, train acc: 0.998 valid loss: 1.58153 valid acc: 0.943\n",
            "4-155th: train loss: 1.48142, train acc: 0.998 valid loss: 1.58144 valid acc: 0.947\n",
            "4-156th: train loss: 1.48134, train acc: 0.998 valid loss: 1.58135 valid acc: 0.947\n",
            "4-157th: train loss: 1.48126, train acc: 0.998 valid loss: 1.58126 valid acc: 0.947\n",
            "4-158th: train loss: 1.48118, train acc: 0.998 valid loss: 1.58117 valid acc: 0.947\n",
            "4-159th: train loss: 1.48110, train acc: 0.998 valid loss: 1.58108 valid acc: 0.947\n",
            "4-160th: train loss: 1.48102, train acc: 0.998 valid loss: 1.58099 valid acc: 0.947\n",
            "4-161th: train loss: 1.48095, train acc: 0.998 valid loss: 1.58091 valid acc: 0.947\n",
            "4-162th: train loss: 1.48088, train acc: 0.998 valid loss: 1.58082 valid acc: 0.947\n",
            "4-163th: train loss: 1.48080, train acc: 0.998 valid loss: 1.58074 valid acc: 0.947\n",
            "4-164th: train loss: 1.48073, train acc: 0.998 valid loss: 1.58066 valid acc: 0.947\n",
            "4-165th: train loss: 1.48066, train acc: 0.998 valid loss: 1.58059 valid acc: 0.947\n",
            "4-166th: train loss: 1.48059, train acc: 0.998 valid loss: 1.58052 valid acc: 0.947\n",
            "4-167th: train loss: 1.48052, train acc: 0.998 valid loss: 1.58045 valid acc: 0.947\n",
            "4-168th: train loss: 1.48045, train acc: 0.998 valid loss: 1.58039 valid acc: 0.943\n",
            "4-169th: train loss: 1.48039, train acc: 0.998 valid loss: 1.58033 valid acc: 0.943\n",
            "4-170th: train loss: 1.48032, train acc: 0.998 valid loss: 1.58028 valid acc: 0.947\n",
            "4-171th: train loss: 1.48026, train acc: 0.998 valid loss: 1.58024 valid acc: 0.947\n",
            "4-172th: train loss: 1.48019, train acc: 0.998 valid loss: 1.58020 valid acc: 0.947\n",
            "4-173th: train loss: 1.48013, train acc: 0.998 valid loss: 1.58017 valid acc: 0.947\n",
            "4-174th: train loss: 1.48006, train acc: 0.998 valid loss: 1.58014 valid acc: 0.947\n",
            "4-175th: train loss: 1.48000, train acc: 0.998 valid loss: 1.58011 valid acc: 0.947\n",
            "4-176th: train loss: 1.47994, train acc: 0.998 valid loss: 1.58009 valid acc: 0.947\n",
            "4-177th: train loss: 1.47988, train acc: 0.998 valid loss: 1.58007 valid acc: 0.947\n",
            "4-178th: train loss: 1.47981, train acc: 0.998 valid loss: 1.58006 valid acc: 0.947\n",
            "4-179th: train loss: 1.47975, train acc: 0.998 valid loss: 1.58004 valid acc: 0.947\n",
            "4-180th: train loss: 1.47969, train acc: 0.998 valid loss: 1.58003 valid acc: 0.947\n",
            "4-181th: train loss: 1.47962, train acc: 0.998 valid loss: 1.58002 valid acc: 0.947\n",
            "4-182th: train loss: 1.47955, train acc: 0.998 valid loss: 1.58001 valid acc: 0.943\n",
            "4-183th: train loss: 1.47948, train acc: 0.998 valid loss: 1.58001 valid acc: 0.940\n",
            "4-184th: train loss: 1.47941, train acc: 0.998 valid loss: 1.58000 valid acc: 0.940\n",
            "4-185th: train loss: 1.47934, train acc: 0.999 valid loss: 1.58000 valid acc: 0.940\n",
            "4-186th: train loss: 1.47926, train acc: 0.999 valid loss: 1.58000 valid acc: 0.940\n",
            "4-187th: train loss: 1.47918, train acc: 0.999 valid loss: 1.58000 valid acc: 0.940\n",
            "4-188th: train loss: 1.47910, train acc: 0.999 valid loss: 1.58000 valid acc: 0.940\n",
            "4-189th: train loss: 1.47902, train acc: 0.999 valid loss: 1.57999 valid acc: 0.940\n",
            "4-190th: train loss: 1.47895, train acc: 0.999 valid loss: 1.57997 valid acc: 0.940\n",
            "4-191th: train loss: 1.47888, train acc: 0.999 valid loss: 1.57995 valid acc: 0.940\n",
            "4-192th: train loss: 1.47881, train acc: 0.999 valid loss: 1.57992 valid acc: 0.943\n",
            "4-193th: train loss: 1.47875, train acc: 0.999 valid loss: 1.57988 valid acc: 0.940\n",
            "4-194th: train loss: 1.47869, train acc: 0.999 valid loss: 1.57985 valid acc: 0.940\n",
            "4-195th: train loss: 1.47864, train acc: 0.999 valid loss: 1.57982 valid acc: 0.940\n",
            "4-196th: train loss: 1.47858, train acc: 0.999 valid loss: 1.57980 valid acc: 0.940\n",
            "4-197th: train loss: 1.47853, train acc: 0.999 valid loss: 1.57978 valid acc: 0.940\n",
            "4-198th: train loss: 1.47848, train acc: 0.999 valid loss: 1.57978 valid acc: 0.940\n",
            "4-199th: train loss: 1.47842, train acc: 0.999 valid loss: 1.57977 valid acc: 0.940\n",
            "4-200th: train loss: 1.47836, train acc: 0.999 valid loss: 1.57977 valid acc: 0.940\n",
            "4-201th: train loss: 1.47831, train acc: 0.999 valid loss: 1.57976 valid acc: 0.940\n",
            "4-202th: train loss: 1.47826, train acc: 0.999 valid loss: 1.57976 valid acc: 0.937\n",
            "4-203th: train loss: 1.47820, train acc: 0.999 valid loss: 1.57975 valid acc: 0.937\n",
            "4-204th: train loss: 1.47815, train acc: 0.999 valid loss: 1.57975 valid acc: 0.937\n",
            "4-205th: train loss: 1.47810, train acc: 0.999 valid loss: 1.57975 valid acc: 0.937\n",
            "4-206th: train loss: 1.47805, train acc: 0.999 valid loss: 1.57976 valid acc: 0.937\n",
            "4-207th: train loss: 1.47800, train acc: 0.999 valid loss: 1.57978 valid acc: 0.937\n",
            "4-208th: train loss: 1.47796, train acc: 0.999 valid loss: 1.57980 valid acc: 0.937\n",
            "4-209th: train loss: 1.47791, train acc: 0.999 valid loss: 1.57982 valid acc: 0.940\n",
            "4-210th: train loss: 1.47787, train acc: 0.999 valid loss: 1.57984 valid acc: 0.937\n",
            "4-211th: train loss: 1.47783, train acc: 0.999 valid loss: 1.57987 valid acc: 0.937\n",
            "4-212th: train loss: 1.47778, train acc: 0.999 valid loss: 1.57988 valid acc: 0.937\n",
            "4-213th: train loss: 1.47774, train acc: 0.999 valid loss: 1.57989 valid acc: 0.937\n",
            "4-214th: train loss: 1.47770, train acc: 0.999 valid loss: 1.57990 valid acc: 0.937\n",
            "4-215th: train loss: 1.47766, train acc: 0.999 valid loss: 1.57991 valid acc: 0.937\n",
            "4-216th: train loss: 1.47762, train acc: 0.999 valid loss: 1.57991 valid acc: 0.937\n",
            "4-217th: train loss: 1.47758, train acc: 0.999 valid loss: 1.57991 valid acc: 0.937\n",
            "4-218th: train loss: 1.47755, train acc: 0.999 valid loss: 1.57992 valid acc: 0.937\n",
            "4-219th: train loss: 1.47751, train acc: 0.999 valid loss: 1.57993 valid acc: 0.937\n",
            "4-220th: train loss: 1.47747, train acc: 0.999 valid loss: 1.57993 valid acc: 0.937\n",
            "4-221th: train loss: 1.47744, train acc: 0.999 valid loss: 1.57994 valid acc: 0.937\n",
            "4-222th: train loss: 1.47740, train acc: 0.999 valid loss: 1.57995 valid acc: 0.937\n",
            "4-223th: train loss: 1.47737, train acc: 0.999 valid loss: 1.57996 valid acc: 0.937\n",
            "4-224th: train loss: 1.47733, train acc: 0.999 valid loss: 1.57997 valid acc: 0.937\n",
            "4-225th: train loss: 1.47730, train acc: 0.999 valid loss: 1.57998 valid acc: 0.937\n",
            "4-226th: train loss: 1.47726, train acc: 0.999 valid loss: 1.57999 valid acc: 0.937\n",
            "4-227th: train loss: 1.47723, train acc: 0.999 valid loss: 1.58000 valid acc: 0.937\n",
            "4-228th: train loss: 1.47720, train acc: 0.999 valid loss: 1.58002 valid acc: 0.937\n",
            "4-229th: train loss: 1.47717, train acc: 0.999 valid loss: 1.58003 valid acc: 0.937\n",
            "4-230th: train loss: 1.47713, train acc: 0.999 valid loss: 1.58005 valid acc: 0.937\n",
            "4-231th: train loss: 1.47710, train acc: 0.999 valid loss: 1.58007 valid acc: 0.937\n",
            "4-232th: train loss: 1.47707, train acc: 0.999 valid loss: 1.58009 valid acc: 0.937\n",
            "4-233th: train loss: 1.47704, train acc: 0.999 valid loss: 1.58011 valid acc: 0.937\n",
            "4-234th: train loss: 1.47701, train acc: 0.999 valid loss: 1.58012 valid acc: 0.937\n",
            "4-235th: train loss: 1.47698, train acc: 0.999 valid loss: 1.58014 valid acc: 0.937\n",
            "4-236th: train loss: 1.47695, train acc: 0.999 valid loss: 1.58016 valid acc: 0.937\n",
            "4-237th: train loss: 1.47692, train acc: 0.999 valid loss: 1.58017 valid acc: 0.937\n",
            "4-238th: train loss: 1.47690, train acc: 0.999 valid loss: 1.58019 valid acc: 0.937\n",
            "4-239th: train loss: 1.47687, train acc: 0.999 valid loss: 1.58020 valid acc: 0.937\n",
            "4-240th: train loss: 1.47684, train acc: 0.999 valid loss: 1.58022 valid acc: 0.937\n",
            "4-241th: train loss: 1.47682, train acc: 0.999 valid loss: 1.58023 valid acc: 0.937\n",
            "4-242th: train loss: 1.47679, train acc: 0.999 valid loss: 1.58025 valid acc: 0.937\n",
            "4-243th: train loss: 1.47676, train acc: 0.999 valid loss: 1.58026 valid acc: 0.937\n",
            "4-244th: train loss: 1.47674, train acc: 0.999 valid loss: 1.58027 valid acc: 0.937\n",
            "4-245th: train loss: 1.47671, train acc: 0.999 valid loss: 1.58028 valid acc: 0.937\n",
            "4-246th: train loss: 1.47669, train acc: 0.999 valid loss: 1.58029 valid acc: 0.937\n",
            "4-247th: train loss: 1.47666, train acc: 0.999 valid loss: 1.58030 valid acc: 0.937\n",
            "4-248th: train loss: 1.47664, train acc: 0.999 valid loss: 1.58031 valid acc: 0.937\n",
            "4-249th: train loss: 1.47662, train acc: 0.999 valid loss: 1.58032 valid acc: 0.937\n",
            "4-250th: train loss: 1.47659, train acc: 0.999 valid loss: 1.58034 valid acc: 0.937\n",
            "4-251th: train loss: 1.47657, train acc: 0.999 valid loss: 1.58035 valid acc: 0.937\n",
            "4-252th: train loss: 1.47655, train acc: 0.999 valid loss: 1.58036 valid acc: 0.937\n",
            "4-253th: train loss: 1.47652, train acc: 0.999 valid loss: 1.58037 valid acc: 0.937\n",
            "4-254th: train loss: 1.47650, train acc: 0.999 valid loss: 1.58039 valid acc: 0.937\n",
            "4-255th: train loss: 1.47648, train acc: 0.999 valid loss: 1.58040 valid acc: 0.937\n",
            "4-256th: train loss: 1.47646, train acc: 0.999 valid loss: 1.58041 valid acc: 0.937\n",
            "4-257th: train loss: 1.47644, train acc: 0.999 valid loss: 1.58042 valid acc: 0.937\n",
            "4-258th: train loss: 1.47642, train acc: 0.999 valid loss: 1.58044 valid acc: 0.937\n",
            "4-259th: train loss: 1.47640, train acc: 0.999 valid loss: 1.58045 valid acc: 0.940\n",
            "4-260th: train loss: 1.47637, train acc: 0.999 valid loss: 1.58046 valid acc: 0.940\n",
            "4-261th: train loss: 1.47635, train acc: 0.999 valid loss: 1.58048 valid acc: 0.943\n",
            "4-262th: train loss: 1.47633, train acc: 0.999 valid loss: 1.58049 valid acc: 0.943\n",
            "4-263th: train loss: 1.47632, train acc: 0.999 valid loss: 1.58050 valid acc: 0.943\n",
            "4-264th: train loss: 1.47630, train acc: 0.999 valid loss: 1.58051 valid acc: 0.943\n",
            "4-265th: train loss: 1.47628, train acc: 0.999 valid loss: 1.58053 valid acc: 0.943\n",
            "4-266th: train loss: 1.47626, train acc: 0.999 valid loss: 1.58054 valid acc: 0.943\n",
            "4-267th: train loss: 1.47624, train acc: 0.999 valid loss: 1.58055 valid acc: 0.943\n",
            "4-268th: train loss: 1.47622, train acc: 0.999 valid loss: 1.58056 valid acc: 0.943\n",
            "4-269th: train loss: 1.47620, train acc: 0.999 valid loss: 1.58057 valid acc: 0.943\n",
            "4-270th: train loss: 1.47619, train acc: 0.999 valid loss: 1.58059 valid acc: 0.943\n",
            "4-271th: train loss: 1.47617, train acc: 0.999 valid loss: 1.58060 valid acc: 0.943\n",
            "4-272th: train loss: 1.47615, train acc: 0.999 valid loss: 1.58061 valid acc: 0.943\n",
            "4-273th: train loss: 1.47613, train acc: 0.999 valid loss: 1.58063 valid acc: 0.943\n",
            "4-274th: train loss: 1.47612, train acc: 0.999 valid loss: 1.58064 valid acc: 0.943\n",
            "4-275th: train loss: 1.47610, train acc: 0.999 valid loss: 1.58065 valid acc: 0.943\n",
            "4-276th: train loss: 1.47608, train acc: 0.999 valid loss: 1.58067 valid acc: 0.943\n",
            "4-277th: train loss: 1.47607, train acc: 0.999 valid loss: 1.58068 valid acc: 0.943\n",
            "4-278th: train loss: 1.47605, train acc: 0.999 valid loss: 1.58069 valid acc: 0.943\n",
            "4-279th: train loss: 1.47604, train acc: 0.999 valid loss: 1.58071 valid acc: 0.943\n",
            "4-280th: train loss: 1.47602, train acc: 0.999 valid loss: 1.58072 valid acc: 0.943\n",
            "4-281th: train loss: 1.47601, train acc: 0.999 valid loss: 1.58074 valid acc: 0.943\n",
            "4-282th: train loss: 1.47599, train acc: 0.999 valid loss: 1.58075 valid acc: 0.943\n",
            "4-283th: train loss: 1.47598, train acc: 0.999 valid loss: 1.58077 valid acc: 0.940\n",
            "4-284th: train loss: 1.47596, train acc: 0.999 valid loss: 1.58079 valid acc: 0.940\n",
            "4-285th: train loss: 1.47595, train acc: 0.999 valid loss: 1.58081 valid acc: 0.940\n",
            "4-286th: train loss: 1.47593, train acc: 0.999 valid loss: 1.58082 valid acc: 0.940\n",
            "4-287th: train loss: 1.47592, train acc: 0.999 valid loss: 1.58084 valid acc: 0.940\n",
            "4-288th: train loss: 1.47590, train acc: 0.999 valid loss: 1.58086 valid acc: 0.940\n",
            "4-289th: train loss: 1.47589, train acc: 0.999 valid loss: 1.58088 valid acc: 0.940\n",
            "4-290th: train loss: 1.47588, train acc: 0.999 valid loss: 1.58090 valid acc: 0.940\n",
            "4-291th: train loss: 1.47586, train acc: 0.999 valid loss: 1.58092 valid acc: 0.940\n",
            "4-292th: train loss: 1.47585, train acc: 0.999 valid loss: 1.58094 valid acc: 0.940\n",
            "4-293th: train loss: 1.47584, train acc: 0.999 valid loss: 1.58097 valid acc: 0.940\n",
            "4-294th: train loss: 1.47582, train acc: 0.999 valid loss: 1.58099 valid acc: 0.940\n",
            "4-295th: train loss: 1.47581, train acc: 0.999 valid loss: 1.58101 valid acc: 0.940\n",
            "4-296th: train loss: 1.47580, train acc: 0.999 valid loss: 1.58104 valid acc: 0.940\n",
            "4-297th: train loss: 1.47578, train acc: 0.999 valid loss: 1.58106 valid acc: 0.940\n",
            "4-298th: train loss: 1.47577, train acc: 0.999 valid loss: 1.58109 valid acc: 0.940\n",
            "4-299th: train loss: 1.47576, train acc: 0.999 valid loss: 1.58111 valid acc: 0.940\n"
          ]
        }
      ],
      "source": [
        "all_all_tr_loss = []\n",
        "all_all_valid_loss = []\n",
        "all_all_tr_acc = []\n",
        "all_all_valid_acc = []\n",
        "\n",
        "max_epochs = 300\n",
        "lr = 0.005\n",
        "n_fold = 5\n",
        "skf = StratifiedKFold(n_splits=n_fold)\n",
        "for i_fold, (tr, te) in enumerate(skf.split(data, label)):\n",
        "    data_tr, data_te, label_tr, label_te = data[tr].to(device), data[te].to(device), label[tr].to(device), label[te].to(device)\n",
        "    model = torch.nn.Sequential(\n",
        "        QNNModel(),\n",
        "        ConstCoeffLayer(5),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=5e-5)\n",
        "    all_tr_loss = []\n",
        "    all_valid_loss = []\n",
        "    all_tr_acc = []\n",
        "    all_valid_acc = []\n",
        "    for i_epoch in range(max_epochs):\n",
        "        print(f\"{i_fold}-{i_epoch}th:\", end=\" \")\n",
        "        loss_tr, acc_tr = train(data_tr, label_tr, model, optimizer)\n",
        "        loss_valid, acc_valid = valid(data_te, label_te, model)\n",
        "        all_tr_loss.append(loss_tr)\n",
        "        all_valid_loss.append(loss_valid)\n",
        "        all_tr_acc.append(acc_tr)\n",
        "        all_valid_acc.append(acc_valid)\n",
        "        ###\n",
        "    all_all_tr_loss.append(all_tr_loss)\n",
        "    all_all_valid_loss.append(all_valid_loss)\n",
        "    all_all_tr_acc.append(all_tr_acc)\n",
        "    all_all_valid_acc.append(all_valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T22:43:15.354983Z",
          "iopub.status.busy": "2023-12-06T22:43:15.354793Z",
          "iopub.status.idle": "2023-12-06T22:43:15.358333Z",
          "shell.execute_reply": "2023-12-06T22:43:15.357831Z"
        },
        "id": "H9RZHvE3k55h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train acc: 0.9992150706436421, test acc: 0.9592476489028213, train loss: 1.4772440195083618, valid loss: 1.5526493787765503\n",
            "train acc: 0.9992150706436421, test acc: 0.9467084639498433, train loss: 1.4765560626983643, valid loss: 1.5764409303665161\n",
            "train acc: 0.9992150706436421, test acc: 0.9561128526645768, train loss: 1.477005958557129, valid loss: 1.5429946184158325\n",
            "train acc: 0.9992156862745099, test acc: 0.940251572327044, train loss: 1.4769947528839111, valid loss: 1.571118950843811\n",
            "train acc: 0.9992156862745099, test acc: 0.940251572327044, train loss: 1.4757587909698486, valid loss: 1.5811115503311157\n",
            "0.9992153168959892 0.948514422034266\n",
            "3.015962991683502e-07 0.007908845203017835\n",
            "1.476711916923523 1.5648630857467651\n",
            "0.0005258002370942716 0.014591774647785449\n"
          ]
        }
      ],
      "source": [
        "train_acc = []\n",
        "valid_acc = []\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "for i in range(len(all_all_tr_acc)):\n",
        "    train_acc.append(all_all_tr_acc[i][-1])\n",
        "    valid_acc.append(all_all_valid_acc[i][-1])\n",
        "    train_loss.append(all_all_tr_loss[i][-1])\n",
        "    valid_loss.append(all_all_valid_loss[i][-1])\n",
        "    print(f\"train acc: {train_acc[-1]}, test acc: {valid_acc[-1]}, train loss: {train_loss[-1]}, valid loss: {valid_loss[-1]}\")\n",
        "\n",
        "print( np.mean(train_acc), np.mean(valid_acc) )\n",
        "print( np.std(train_acc), np.std(valid_acc) )\n",
        "print( np.mean(train_loss), np.mean(valid_loss))\n",
        "print( np.std(train_loss), np.std(valid_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T22:43:15.360598Z",
          "iopub.status.busy": "2023-12-06T22:43:15.360408Z",
          "iopub.status.idle": "2023-12-06T22:43:15.410909Z",
          "shell.execute_reply": "2023-12-06T22:43:15.410462Z"
        },
        "id": "DFnNQRLu1tYw"
      },
      "outputs": [],
      "source": [
        "nu0 = model[0].qnn1.n_depth_per_block\n",
        "c0 = int(model[1].coeff)\n",
        "prefix_name = dataset_name+\"16x16_\"+\"8qnn\"+str(nu0)+\"_c\"+str(c0)+\"_\"+str(n_qubits)+\"qubits_\"\n",
        "if False:\n",
        "    pd.DataFrame(all_all_tr_acc).to_csv(prefix_name+\"_tr_acc.csv\", index=False)\n",
        "    pd.DataFrame(all_all_valid_acc).to_csv(prefix_name+\"_valid_acc.csv\", index=False)\n",
        "    pd.DataFrame(all_all_tr_loss).to_csv(prefix_name+\"_tr_loss.csv\", index=False)\n",
        "    pd.DataFrame(all_all_valid_loss).to_csv(prefix_name+\"_valid_loss.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz0oPaAQk55i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
